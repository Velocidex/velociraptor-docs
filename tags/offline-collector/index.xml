<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Offline Collector on Velociraptor - Digging deeper!</title><link>https://docs.velociraptor.app/tags/offline-collector/</link><description>Recent content in Offline Collector on Velociraptor - Digging deeper!</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 20 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://docs.velociraptor.app/tags/offline-collector/index.xml" rel="self" type="application/rss+xml"/><item><title>SFTP in AWS</title><link>https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/</link><pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/</guid><description>&lt;p>Many people use Velociraptor&amp;rsquo;s &lt;a href="https://docs.velociraptor.app/docs/offline_triage/" >offline collector&lt;/a>
 feature to collect any artifacts without
having the Velociraptor client actually installed on the
endpoint. While the offline collector feature is great to
interactively triage a machine, the produced collection zip file is
normally quite large and unwieldy to transfer.&lt;/p>
&lt;p>To help with this, Velociraptor offers the option to send the file
back to the cloud via a number of mechanisms, including upload to S3
buckets directly, WebDAV upload and using Secure FTP (sftp).&lt;/p>
&lt;p>One of the challenges with automatic uploading to the cloud is
securely configuring the upload mechanism. Since the credentials for
any upload service are embedded inside the collector, it is important
to ensure that these credentials have minimal additional permissions.&lt;/p>
&lt;p>For example, when using a cloud bucket to collect triage data from
endpoints, the bucket policy must be configured to allow a service
account full write access. However, using these credentials should not
allow anyone to list existing bucket resources, or to download
critical triage data from other hosts!&lt;/p>
&lt;p>I have &lt;a href="https://docs.velociraptor.app/blog/2019/2019-10-08_triage-with-velociraptor-pt-3-d6f63215f579/" >previously&lt;/a>
 described how to use Google cloud&amp;rsquo;s service accounts to upload to
a GCP bucket securely.&lt;/p>
&lt;p>In this post I describe how to set up Amazon&amp;rsquo;s SFTP transfer service
to securely allow the Velociraptor collector to upload files without
granting the collector permission to download the files again, delete
them or discover other uploads in the bucket.&lt;/p>
&lt;p>I would like to thank Simon Irwin from Rapid7 for his assistance and
guidance with AWS - I am certainly not an expert and needed a lot of
help figuring this process out. This is one of the reasons I wanted to
document the process in order to save others time.&lt;/p>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>The main AWS service I will use is the &lt;a href="https://docs.aws.amazon.com/transfer/latest/userguide/what-is-aws-transfer-family.html" target="_blank" >AWS Transfer Family&lt;/a>
 documented extensively on the AWS documentation site.&lt;/p>
&lt;p>In a nutshell, the service requires creating an sftp transfer server
backed by an S3 bucket. The SFTP server does not use real usernames
for authentication, but rather throwaway usernames I create just for
that service.&lt;/p>
&lt;p>Each of these throwaway sftp users are given an SSH key pair (public
and private keys) which they use to authenticate with the service. The
private key will be embedded in the Velociraptor collector and allow
the collector to upload to the service. However, by setting up
restrictive policies I can limit the permissions of the sftp user.&lt;/p>
&lt;h2 id="creating-an-aws-bucket">Creating an AWS bucket&lt;/h2>
&lt;p>I will begin by creating an S3 bucket called &lt;code>velociraptor-test&lt;/code> that
will contain all the collector files uploaded from the endpoints.&lt;/p>
&lt;p>











&lt;figure id="4c3d61ba8d60da3eb245ff2ecad7bc67">
 &lt;div data-featherlight="#4c3d61ba8d60da3eb245ff2ecad7bc67" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/creating_S3_bucket.png" alt="Creating an S3 bucket">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="creating_S3_bucket.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating an S3 bucket
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;h2 id="aws-policies">AWS Policies&lt;/h2>
&lt;p>AWS controls access via roles and policies. For this configuration I
will need to create two policies:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The first policy I will call &lt;code>velociraptor-upload-policy&lt;/code> grants
full access to the AWS transfer service with full use of the
provided s3 bucket.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The second policy I will call &lt;code>velociraptor-sftp-upload-only&lt;/code>
policy will apply to the sftp user and only grant upload
permissions.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="velociraptor-upload-policy">velociraptor-upload-policy&lt;/h3>
&lt;p>This policy grants full access to the new bucket I created earlier.&lt;/p>
&lt;pre>&lt;code class="language-json">
{
 &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
 &amp;quot;Statement&amp;quot;: [
 {
 &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
 &amp;quot;Action&amp;quot;: [
 &amp;quot;s3:PutObject&amp;quot;,
 &amp;quot;s3:GetObject&amp;quot;,
 &amp;quot;s3:ListBucket&amp;quot;,
 &amp;quot;s3:DeleteObject&amp;quot;,
 &amp;quot;s3:PutObjectAcl&amp;quot;
 ],
 &amp;quot;Resource&amp;quot;: [
 &amp;quot;arn:aws:s3:::velociraptor-test&amp;quot;,
 &amp;quot;arn:aws:s3:::velociraptor-test/*&amp;quot;
 ]
 }
 ]
}
&lt;/code>&lt;/pre>
&lt;h3 id="velociraptor-sftp-upload-only">velociraptor-sftp-upload-only&lt;/h3>
&lt;p>This policy only grants upload rights&lt;/p>
&lt;pre>&lt;code class="language-json">{
&amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
&amp;quot;Statement&amp;quot;: [
 {
 &amp;quot;Sid&amp;quot;: &amp;quot;AllowListingOfUserFolder&amp;quot;,
 &amp;quot;Action&amp;quot;: [
 &amp;quot;s3:ListBucket&amp;quot;
 ],
 &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
 &amp;quot;Resource&amp;quot;: [
 &amp;quot;arn:aws:s3:::${transfer:HomeBucket}&amp;quot;
 ],
 &amp;quot;Condition&amp;quot;: {
 &amp;quot;StringLike&amp;quot;: {
 &amp;quot;s3:prefix&amp;quot;: [
 &amp;quot;${transfer:HomeFolder}/*&amp;quot;,
 &amp;quot;${transfer:HomeFolder}&amp;quot;
 ]
 }
 }
 },
 {
 &amp;quot;Sid&amp;quot;: &amp;quot;HomeDirObjectAccess&amp;quot;,
 &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
 &amp;quot;Action&amp;quot;: [
 &amp;quot;s3:PutObject&amp;quot;,
 &amp;quot;s3:PutObjectACL&amp;quot;
 ],
 &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::${transfer:HomeDirectory}*&amp;quot;
 }
]
}
&lt;/code>&lt;/pre>

&lt;div class="mynotices note">
 &lt;div heading="note">&lt;p>I found that I needed to give the &lt;code>s3:ListBucket&lt;/code> permission in order
to upload files - this seems a bit strange to me but I could not get
upload to work without this permission. Despite having this
permission, it is still not possible to actually list the files in the
bucket anyway.&lt;/p>
&lt;/div>
&lt;/div>


&lt;h2 id="aws-roles">AWS Roles&lt;/h2>
&lt;p>An AWS role is a set of policies that applies to a particular
service. In this case I will create a new role that allows uploading
to the s3 bucket I created. Search for the &lt;a href="https://console.aws.amazon.com/iamv2/home#/roles" target="_blank" >IAM
screen&lt;/a>
 in the AWS
console and select &amp;ldquo;Create a new role&amp;rdquo;.&lt;/p>
&lt;p>In the first step, the UI asks us to associate the role with a
service, Select the &lt;code>Transfer&lt;/code> as the service.&lt;/p>
&lt;p>











&lt;figure id="4c31157c085282232ab4a87bc754a87b">
 &lt;div data-featherlight="#4c31157c085282232ab4a87bc754a87b" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/create_role_1.png" alt="Creating a new role">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="create_role_1.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating a new role
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>Next associate the role with the &lt;code>velociraptor-upload-policy&lt;/code>
policy. I will name the role &lt;code>velociraptor-upload-role&lt;/code>.&lt;/p>
&lt;p>











&lt;figure id="eafcb84dc40fa490ad73642145b6c33e">
 &lt;div data-featherlight="#eafcb84dc40fa490ad73642145b6c33e" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/create_role_2.png" alt="Creating a new role - associating with policy">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="create_role_2.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating a new role - associating with policy
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;h2 id="creating-the-sftp-server">Creating the SFTP server&lt;/h2>
&lt;p>Now I need to create an sftp server in the Transfer service. Search
for the &lt;a href="https://us-east-2.console.aws.amazon.com/transfer/home" target="_blank" >AWS Transfer
Family&lt;/a>
 screen
and select &amp;ldquo;Create Server&amp;rdquo;. I will choose this to be an SFTP server.&lt;/p>
&lt;p>











&lt;figure id="111ed8b76270da1c8c6e733f41c9d2d2">
 &lt;div data-featherlight="#111ed8b76270da1c8c6e733f41c9d2d2" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/creating_sftp_server.png" alt="Creating the sftp server">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="creating_sftp_server.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating the sftp server
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>The identity provider is &amp;ldquo;Service managed&amp;rdquo; - this means I will manage
the sftp users with throwaway ssh keys.&lt;/p>
&lt;p>











&lt;figure id="949eaaa113828affc723861e42b0eca3">
 &lt;div data-featherlight="#949eaaa113828affc723861e42b0eca3" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/sftp_server_2.png" alt="Creating the sftp server - Identity Providers">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="sftp_server_2.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating the sftp server - Identity Providers
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>Finally I will choose S3 to be our storage backend&lt;/p>
&lt;p>











&lt;figure id="393005be81fd3b34853161bdd986a64d">
 &lt;div data-featherlight="#393005be81fd3b34853161bdd986a64d" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/sftp_server_3.png" alt="Creating the sftp server - Backend storage">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="sftp_server_3.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating the sftp server - Backend storage
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>Once the server is created, the AWS console will remind us that no
users are added to the service yet. This will be our next task&amp;hellip;&lt;/p>
&lt;p>











&lt;figure id="a3d6bf736f1570c77a159c956ef0b213">
 &lt;div data-featherlight="#a3d6bf736f1570c77a159c956ef0b213" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/create_sftp_server_final.png" alt="Creating the sftp server - Success!">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="create_sftp_server_final.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating the sftp server - Success!
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;h2 id="adding-sftp-users-to-the-sftp-server">Adding SFTP users to the sftp server.&lt;/h2>
&lt;p>Our ultimate goal is to create throw-away sftp users which can
authenticate to the service with an SSH key pair and upload triage
files.&lt;/p>
&lt;p>I will now create an SSH key pair on my machine - this will contain a
private key and a public key (Note: do not protect these keys with a
passphrase):&lt;/p>
&lt;p>











&lt;figure id="3acece6ca5509bfab5be835f19e6d31f">
 &lt;div data-featherlight="#3acece6ca5509bfab5be835f19e6d31f" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/generating_keys.png" alt="Generating SSH key pair for the new sftp user">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="generating_keys.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Generating SSH key pair for the new sftp user
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>In the AWS console I select the new server and click on &amp;ldquo;Add user&amp;rdquo; to
add a new user.&lt;/p>
&lt;p>











&lt;figure id="72f907f39190f980e4823dc6fda8fe71">
 &lt;div data-featherlight="#72f907f39190f980e4823dc6fda8fe71" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/adding_user.png" alt="Adding a new SFTP user">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="adding_user.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Adding a new SFTP user
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>I will add the &lt;code>velociraptor-upload-role&lt;/code> role I created earlier to
this sftp user, allowing the user to interact with the s3 bucket.&lt;/p>
&lt;p>I will now also add a &lt;code>scope down policy&lt;/code> to further restrict the
access this user has to upload only by selecting the
&lt;code>velociraptor-sftp-upload-only&lt;/code> policy.&lt;/p>
&lt;p>Next I will add the user&amp;rsquo;s public key to the AWS console&amp;rsquo;s
configuration by simply pasting the public key I generated earlier.&lt;/p>
&lt;p>











&lt;figure id="a5088a5322a2a7430ff64012c6935661">
 &lt;div data-featherlight="#a5088a5322a2a7430ff64012c6935661" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/adding_public_key_to_user.png" alt="Adding a new SFTP users public keys">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="adding_public_key_to_user.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Adding a new SFTP users public keys
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>Finally I create the new user with the name &lt;code>velouploader&lt;/code>&lt;/p>

&lt;div class="mynotices tip">
 &lt;div heading=" Creating users with different access ">&lt;p>In our example I created a user with an upload only policy that could
not read any of the files in the bucket. However, you can also create
a user with full access to the bucket by removing the scope down policy
or apply a different policy per user.&lt;/p>
&lt;p>This is convenient to allow the investigator the ability to download
the collected files by creating a separate sftp user for them without
a scope-down policy.&lt;/p>
&lt;/div>
&lt;/div>


&lt;h2 id="testing-access-controls">Testing access controls&lt;/h2>
&lt;p>It is imperative to ensure that access controls are working the way
they are supposed to! Therefore I will now test my setup using the
built in sftp client in my operating system (I can find the endpoint&amp;rsquo;s
public DNS name using the AWS console).&lt;/p>
&lt;pre>&lt;code class="language-sh">sftp -i sftpuser.key velouploader@s-9d35031a046643d88.server.transfer.us-east-2.amazonaws.com
&lt;/code>&lt;/pre>
&lt;p>











&lt;figure id="fc19bce12b71716d5785848c6dfe1071">
 &lt;div data-featherlight="#fc19bce12b71716d5785848c6dfe1071" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/testing_permissions.png" alt="Testing ACLs">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="testing_permissions.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Testing ACLs
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>At first I upload a small file and confirm it works as expected. Then
I try to list the directory, and read the file out again - both
attempts fail due to the scope down policy.&lt;/p>
&lt;p>Finally attempting to overwrite the old file by re-uploading the same
file again, also fails.&lt;/p>
&lt;h2 id="creating-an-sftp-offline-collector">Creating an SFTP Offline Collector&lt;/h2>
&lt;p>I am now ready to create our offline collectors. I will login to
Velociraptor&amp;rsquo;s web UI and navigate to &lt;code>Server Artifacts&lt;/code> screen. Once
there I click the &lt;code>Build Offline Collector&lt;/code> button. For this example,
I will create a collector using the &lt;code>Windows.KapeFiles.Targets&lt;/code>
artifact and just collect the &lt;code>$MFT&lt;/code> file.&lt;/p>
&lt;p>











&lt;figure id="03a6f626c7dc9257d0f6f5dc10f45b05">
 &lt;div data-featherlight="#03a6f626c7dc9257d0f6f5dc10f45b05" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/kapefiles_1.png" alt="Creating an offline collector">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="kapefiles_1.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Creating an offline collector
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>Now I will configure the collector to use the SFTP upload method,
giving the username I created earlier and pasting the private key I
generated.&lt;/p>
&lt;p>











&lt;figure id="d89d188c2b1292cbce1be02ebad522a4">
 &lt;div data-featherlight="#d89d188c2b1292cbce1be02ebad522a4" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/kapefiles_2.png" alt="Configuring the offline collector for SFTP uploads">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="kapefiles_2.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Configuring the offline collector for SFTP uploads
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>I selected the collection method to SFTP which changes the form to
allow for more parameters to be specified:&lt;/p>
&lt;ul>
&lt;li>The Private key is the file I generated earlier with &lt;code>ssh-keygen&lt;/code> - I will just paste the file content into this form.&lt;/li>
&lt;li>The user is the sftp user that Velociraptor will log in as.&lt;/li>
&lt;li>The Endpoint is the DNS name of the sftp server I created followed
by a colon and the port number (usually port 22).&lt;/li>
&lt;/ul>
&lt;p>Once the collector is created I am able to run it on a test system.&lt;/p>
&lt;p>











&lt;figure id="10c8abe76dcf953a35457450239ad6be">
 &lt;div data-featherlight="#10c8abe76dcf953a35457450239ad6be" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/kapefiles_3.png" alt="Running the collector to collect the MFT">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="kapefiles_3.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Running the collector to collect the MFT
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>As can be seen the upload is mostly fine except there are some
features that are not possible due to the restricted
permissions. Although, the log file shows a failure the file did
successfully upload as can be confirmed in the bucket view.&lt;/p>
&lt;p>











&lt;figure id="812d03654f322e6b1694781d6d413067">
 &lt;div data-featherlight="#812d03654f322e6b1694781d6d413067" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2021/2021-12-11-sftp-in-aws/success.png" alt="Verifying files uploaded in the S3 bucket">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="success.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 Verifying files uploaded in the S3 bucket
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;h1 id="conclusions">Conclusions&lt;/h1>
&lt;p>In this post I examined how to configure a secure SFTP upload service
in AWS that can safely receive triage data from the Velociraptor
offline collector.&lt;/p>
&lt;p>The sftp uploading functionality is actually implemented by the
&lt;code>upload_sftp()&lt;/code> plugin &lt;a href="https://docs.velociraptor.app/vql_reference/other/upload_sftp/" >documented here&lt;/a>
. This means that you can use
this functionality in any VQL query at all - either on the client side
or on the server side.&lt;/p>
&lt;p>For example it is possible to automatically back up server side hunts
or collections to the SFTP bucket.&lt;/p></description></item><item><title>Triage with Velociraptor — Pt 4</title><link>https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/</link><pubDate>Tue, 14 Jul 2020 00:38:44 +0000</pubDate><guid>https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/</guid><description>&lt;p>






&lt;figure id="c4dd922bd5e8a66f7687f3e7033d8bab">
 &lt;div data-featherlight="#c4dd922bd5e8a66f7687f3e7033d8bab" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/https://cdn-images-1.medium.com/max/2560/1*M5dVyBt08NsIIsxq32V3uQ.jpeg" alt="Woman vector created by vectorpouch — www.freepik.com" />
 &lt;/div>
 &lt;figcaption>
 Woman vector created by vectorpouch — www.freepik.com
 &lt;/figcaption>
&lt;/figure>


&lt;em>&lt;a href="https://www.freepik.com/free-photos-vectors/woman" target="_blank" >Woman vector created by vectorpouch &lt;/a>
— &lt;a href="http://www.freepik.com" target="_blank" >www.freepik.com&lt;/a>
&lt;/em>&lt;/p>
&lt;p>Velociraptor is a great tool for collecting Artifacts such as files and other state information from endpoints. Artifacts are simply VQL queries wrapped inside a YAML file providing the query with sufficient context to operate. Typically the triage phase of the DFIR process involves collecting and preserving evidence as quickly as possible, performing quick analysis in order to identify machines of interest for further analysis.&lt;/p>
&lt;p>The previous parts in this triage article series covered various scenarios where Velociraptor can help with triage. &lt;a href="https://medium.com/velociraptor-ir/triage-with-velociraptor-pt-1-253f57ce96c0" target="_blank" >Part 1&lt;/a>
 explored the &lt;strong>Windows.KapeFiles.Targets&lt;/strong> artifact — an artifact primarily focused on collecting and preserving files. &lt;a href="https://medium.com/velociraptor-ir/triage-with-velociraptor-pt-2-d0f79066ca0e" target="_blank" >Part 2&lt;/a>
 explained how artifacts can be added to a configuration file embedded inside the binary producing an automated collector — as soon as the binary is run, it will simply collect the artifacts it was pre-programmed with. &lt;a href="https://medium.com/velociraptor-ir/triage-with-velociraptor-pt-3-d6f63215f579" target="_blank" >Part 3&lt;/a>
 levels up our capabilities and shows how to automatically upload the collected files to a cloud bucket.&lt;/p>
&lt;p>We have received a lot of feedback from users about the processes described in these articles and to be honest it is a bit fiddly — one needed to edit YAML config files and call a sequence of commands to make it work.&lt;/p>
&lt;p>Therefore, in recent releases, Velociraptor has grown a GUI to make this process much easier and more robust. This article will introduce this GUI and discuss how you can build a custom offline collector that collects a bunch of artifacts, then uploads them into a cloud bucket.&lt;/p>
&lt;h3 id="installing-a-local-server">Installing a local server&lt;/h3>
&lt;p>Before we can create a new custom collector, we need to access the GUI — this means running a minimal Velociraptor server. If you already have a proper Velociraptor server deployed you could just use that. For this article I will work on windows by spinning up a local temporary server.&lt;/p>
&lt;p>First I have downloaded and installed the official MSI package from the &lt;a href="https://github.com/Velocidex/velociraptor/releases" target="_blank" >Velociraptor releases page&lt;/a>
. This will unpack the executable in the **C:\Program Files\Velociraptor\ ** directory.&lt;/p>
&lt;p>In order to start a Velociraptor server I will create new server configuration file by running the interactive wizard using&lt;/p>
&lt;pre>&lt;code class="language-sh"># velociraptor.exe config generate -i
&lt;/code>&lt;/pre>
&lt;p>






&lt;figure id="cb62ea9bbfeb1e732a7fb06c3019fb5b">
 &lt;div data-featherlight="#cb62ea9bbfeb1e732a7fb06c3019fb5b" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/15wHG_tix0ZpeXIJuYScWKg.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>We will be running the server on &lt;strong>Windows&lt;/strong>, Using the &lt;strong>FileBaseDataStore&lt;/strong> with a &lt;strong>Self-signed SSL&lt;/strong> configuration. I will also add a user called “&lt;strong>mic&lt;/strong>” to the server (basically I pressed enter on each question to accept the default).&lt;/p>
&lt;p>Now I can start the frontend using:&lt;/p>
&lt;pre>&lt;code class="language-sh"># velociraptor.exe -c server.config.yaml frontend -v
&lt;/code>&lt;/pre>
&lt;p>






&lt;figure id="60cb74ea5007dd960f1ab4e45d3e018c">
 &lt;div data-featherlight="#60cb74ea5007dd960f1ab4e45d3e018c" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1MneJxbjF5TmYUxzmCaOrWw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>The GUI will be listening on &lt;a href="https://127.0.0.1:8889/" target="_blank" >https://127.0.0.1:8889/&lt;/a>
 by default. So let&amp;rsquo;s visit it with our browser&lt;/p>
&lt;p>






&lt;figure id="3944715e52a8b20cc90ee23af37aefdf">
 &lt;div data-featherlight="#3944715e52a8b20cc90ee23af37aefdf" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1vcBHvISTTRm_B0NlBanD2Q.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;h3 id="building-the-offline-collector">Building the offline collector&lt;/h3>
&lt;p>An offline collector is simply a binary which is pre-configured to collect certain artifacts — when the user runs it without arguments, the binary will start collecting the artifacts and then terminate.&lt;/p>
&lt;p>The script that actually builds the binary is a server side VQL artifact (it is actually running VQL on the server) hence we need to launch it from the “Server Artifacts” screen on the left sidebar.&lt;/p>
&lt;p>






&lt;figure id="907a7a111093e463df0ffc8eabe653ac">
 &lt;div data-featherlight="#907a7a111093e463df0ffc8eabe653ac" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1yA8N8OgcVKP-kvjJwnljwQ.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Click the &lt;strong>Build Collector&lt;/strong> button to bring up an artifact search dialog. This dialog is very similar to the one you use to collect artifacts from the endpoint in a client/server model — and for a good reason! An offline collector is simply a way to collect the artifacts that we could have collected using a client/server without having a full Velociraptor deployment. We are using sneakernet rather than internet to transfer the files, but the data we collect are exactly the same!&lt;/p>
&lt;p>For this example, we will collect the KapeFiles targets as in previous articles. Simply click add to add this artifact to the collection set. You can add multiple different artifacts at the same time. Note that you are not restricted to just collect files! You can collect processes, memory or any other artifact you can think of — Velociraptor will just collect each one into the one output zip file.&lt;/p>
&lt;h3 id="configuring-the-artifacts">Configuring the artifacts&lt;/h3>
&lt;p>Velociraptor artifacts take parameters to control and customize the VQL they run. Depending on the chosen artifacts, different parameters will be available for configuration. Simply scroll down to select which Kape target file to collect As a reminder a KapeFile target (.&lt;strong>tkape&lt;/strong>) file is a simple YAML file specifying a file glob pattern selecting certain files to collect.&lt;/p>
&lt;p>






&lt;figure id="63d5463413218179ccaa2df03dbb65f8">
 &lt;div data-featherlight="#63d5463413218179ccaa2df03dbb65f8" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1sfdds6gdFa5irpLQuCsh1A.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>We will simply select the &lt;strong>BasicCollection&lt;/strong> which includes things like the registry hives, the USN Journal etc. When we are happy with the collection, click Next.&lt;/p>
&lt;p>






&lt;figure id="149250a08b87c82cca5067d4d5922b40">
 &lt;div data-featherlight="#149250a08b87c82cca5067d4d5922b40" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1UP2MAPGNch_5ezdrWKUL9g.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Velociraptor will repack the Velociraptor binary with the required artifacts, so here we need to select the target operating system. Let’s leave the &lt;strong>Collection Type&lt;/strong> as &lt;em>Zip Archive&lt;/em> for now — this simply creates a large Zip file containing all the collected data. Clicking Next now begins the build process. The first time we run this after install, Velociraptor will contact Github to download all the binaries it might require so it might take a few minutes to get started.&lt;/p>
&lt;p>






&lt;figure id="8af7fb65461e817b58254714f2221ff0">
 &lt;div data-featherlight="#8af7fb65461e817b58254714f2221ff0" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1URkBb2Wl0uQZszjygM7Baw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>This process simply ends up calling the &lt;strong>Server.Utils.CreateCollector&lt;/strong> artifact. The Artifact runs VQL query which creates the packed binary (on the server) and uploads it to the server again. We can simply click* “Prepare Download”* to obtain a zip file with the executable in it.&lt;/p>
&lt;h3 id="running-the-collector">Running the collector&lt;/h3>
&lt;p>I will now download the zip file from the server and extract the collector into the download directory for testing.&lt;/p>
&lt;p>






&lt;figure id="9b54f7ccb09a4596d2d84a018d0f166b">
 &lt;div data-featherlight="#9b54f7ccb09a4596d2d84a018d0f166b" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1djPVk9gI3TP-c-zQhd93uA.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>






&lt;figure id="8c670f5382586cc4fd8fb2d25eaaa990">
 &lt;div data-featherlight="#8c670f5382586cc4fd8fb2d25eaaa990" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1NOxJpFX8xRlepBT2YZD8qA.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Simply running the binary will begin to collect all the artifacts we specified — in this case the KapeFile Basic Collection target. Finally an output Zip file and a HTML report will be produced using the hostname and timestamp.&lt;/p>
&lt;p>






&lt;figure id="836b8365a198a0848ff54a6c27308bd1">
 &lt;div data-featherlight="#836b8365a198a0848ff54a6c27308bd1" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/18Dv9vI8lZ8FYm1MxbUAR1w.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;h3 id="including-external-tools">Including external tools&lt;/h3>
&lt;p>Since release 0.4.6, Velociraptor has built in support for external tools. This means that artifacts that declare tools that they need will receive those binaries on the endpoint when they are being collected. We previously described&lt;a href="https://medium.com/velociraptor-ir/velociraptor-in-the-tool-age-d896dfe71b9?source=friends_link&amp;amp;sk=20178bda3d9accc46d343b1c825c75a6" target="_blank" > this process&lt;/a>
 using the client/server model.&lt;/p>
&lt;p>When building an Offline collector, Velociraptor will also embed the external tools directly into the binary without needing to do anything different with the artifact. Note that the offline collector &lt;strong>does not download&lt;/strong> the tool from an external URL — the tool is already packaged in the collector binary itself.&lt;/p>

&lt;div class="mynotices tip">
 &lt;div heading="tip">&lt;p>The artifact will run the same way when used in client/server mode or
in offline collector mode. This makes it easier to use the same
reusable VQL in different contexts.&lt;/p>
&lt;/div>
&lt;/div>


&lt;p>Let’s try to collect the same artifact we did previously — the &lt;strong>hollows hunter&lt;/strong> artifact. Just to recap the artifact is shown below&lt;/p>
&lt;pre>&lt;code class="language-vql">name: Custom.Windows.Detection.ProcessHollowing
description: |
 Use hollows_hunter to detect suspicious process injections.

 Upload any findings to the server, including process dumps.

tools:
 - name: hollows_hunter
 url: https://github.com/hasherezade/hollows_hunter/releases/download/v0.2.7.1/hollows_hunter64.exe

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- Get the path to the hollows_hunter tool and a fresh temp directory.
 LET binaries &amp;lt;= SELECT FullPath, tempdir() AS TempDir
 FROM Artifact.Generic.Utils.FetchBinary(
 ToolName=&amp;quot;hollows_hunter&amp;quot;)

 -- Run the tool and relay back the output, as well as upload all the files from the tempdir.
 SELECT * FROM chain(
 a={SELECT Stdout, NULL AS Upload
 FROM execve(argv=[binaries[0].FullPath,
 &amp;quot;/json&amp;quot;, &amp;quot;/dir&amp;quot;, binaries[0].TempDir], length=100000)},
 b={
 SELECT upload(file=FullPath) AS Upload
 FROM glob(globs=&amp;quot;*&amp;quot;, root=binaries[0].TempDir)
 })
&lt;/code>&lt;/pre>
&lt;p>I will just add it to the Offline Collector builder&lt;/p>
&lt;p>






&lt;figure id="32894f27a1386eeaead19c07a77d6c86">
 &lt;div data-featherlight="#32894f27a1386eeaead19c07a77d6c86" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/11zNKC3hp53YU6rqlcW3bfQ.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Build the collector as before… extract it to the downloads directory again and launch the collector binary.&lt;/p>
&lt;p>






&lt;figure id="56f100aac29498dbce7307d37e74a6ff">
 &lt;div data-featherlight="#56f100aac29498dbce7307d37e74a6ff" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/17xUMzXapzXS_7HFXgQQzww.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>We can see that the &lt;strong>hollows_hunter64.exe&lt;/strong> binary is copied into a temp file, executed and its results uploaded into the zip file. All temp files are cleaned up after collection.&lt;/p>
&lt;h3 id="collecting-to-the-cloud">Collecting to the cloud.&lt;/h3>
&lt;p>Previously we collected files into a local Zip file. Sometimes it is more convenient to upload the collection to a cloud bucket so the user does not need to worry about transferring a large collection to us.&lt;/p>
&lt;p>To do this, simply select a different Collection Type — I will choose AWS bucket or you can also upload to Google Cloud Storage. You will need to obtain an upload key for the S3 bucket. This is described in the &lt;a href="https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys" target="_blank" >AWS documentation&lt;/a>
. You should also restrict key access to the bucket to upload only since the keys are embedded inside the collector binary (See the AWS &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/example-policies-s3.html" target="_blank" >examples on user policies&lt;/a>
).&lt;/p>
&lt;p>






&lt;figure id="5339d2b0c53910d17cf1f7b5189cb416">
 &lt;div data-featherlight="#5339d2b0c53910d17cf1f7b5189cb416" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1hcyeu84ENyeT0z3f4i7ocA.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Running this, the collector will automatically upload the zip file and the report to the cloud bucket.&lt;/p>
&lt;p>






&lt;figure id="ff7a5f1e66cc0fa1956938f2dbc4d8d1">
 &lt;div data-featherlight="#ff7a5f1e66cc0fa1956938f2dbc4d8d1" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-14-triage-with-velociraptor-pt-4-cf0e60810d1e/../../img/1wx7sv-gvtvSUXBHYwDLzUA.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;h3 id="conclusions">Conclusions&lt;/h3>
&lt;p>Velociraptor is simply a VQL evaluation engine. Although it works best in client/server mode sometimes we have to use an offline collector. The Offline collector is independent and pre-programmed to collect the most appropriate artifacts for triage and then upload the data to a safe location. You can launch the offline artifact across the network via group policy, WMI or WinRM as a kind of poor-man’s remote forensics platform.&lt;/p>
&lt;p>Remember that the offline collector is not limited to simply collecting files! It has the full power of Velociraptor at its disposal so it can collect any volatile machine state that can be collected by Velociraptor — including process memory scanning and dumping, file yara scans, MFT analysis and more.&lt;/p>
&lt;p>To play with this new feature yourself, take Velociraptor for a spin! It is a available on &lt;a href="https://github.com/Velocidex/velociraptor" target="_blank" >GitHub&lt;/a>
 under an open source license. As always please file issues on the bug tracker or ask questions on our mailing list &lt;a href="mailto:velociraptor-discuss@googlegroups.com" >velociraptor-discuss@googlegroups.com&lt;/a>
 . You can also chat with us directly on discord &lt;a href="https://www.velocidex.com/discord" target="_blank" >https://www.velocidex.com/discord&lt;/a>
&lt;/p></description></item></channel></rss>
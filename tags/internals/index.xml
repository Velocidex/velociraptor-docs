<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Internals on Velociraptor - Digging deeper!</title><link>https://docs.velociraptor.app/tags/internals/</link><description>Recent content in Internals on Velociraptor - Digging deeper!</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 27 Sep 2020 01:38:44 +0000</lastBuildDate><atom:link href="https://docs.velociraptor.app/tags/internals/index.xml" rel="self" type="application/rss+xml"/><item><title>Velociraptor Communications</title><link>https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/</link><pubDate>Sun, 27 Sep 2020 01:38:44 +0000</pubDate><guid>https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/</guid><description>&lt;p>






&lt;figure id="0c63fd90ab3f089e345393474bb5496c">
 &lt;div data-featherlight="#0c63fd90ab3f089e345393474bb5496c" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/0qkAnwMlxrKGQR6ke?width=600px" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>You might have heard that Velociraptor allows you to quickly query endpoint state for rapid response and monitoring of many thousands of devices across the internet. Unlike some other tools, Velociraptor’s communication is scalable, secure and instantaneous.&lt;/p>
&lt;p>Many people ask me about the client/server communication protocol. The &lt;a href="https://www.velocidex.com/docs/getting-started/stand_alone/" target="_blank" >Velociraptor documentation&lt;/a>
 simply states that communications is encrypted over a TLS connection but there is more to it than that.&lt;/p>
&lt;p>In this post I would like to delve into the low level details of how clients securely communicate with the server and cover some common deployment scenarios. By understanding exactly how this works we will gain insight into debugging communication problems and enabling more sophisticated deployment scenarios.&lt;/p>
&lt;h3 id="velociraptors-config-file">Velociraptor’s config file&lt;/h3>
&lt;p>In the following discussion we will refer to a typical Velociraptor configuration file as generated by the command&lt;/p>
&lt;pre>&lt;code class="language-sh">velociraptor config generate -i
&lt;/code>&lt;/pre>
&lt;p>For this example we select a typical self-signed deployment.&lt;/p>
&lt;pre>&lt;code class="language-yaml">version:
 name: velociraptor
 version: 0.5.0
 commit: 6fc96b5f
 build_time: &amp;quot;2020-09-22T18:21:45+10:00&amp;quot;
Client:
 server_urls:
 - https://test.velocidex-training.com:8000/
 ca_certificate: |
 -----BEGIN CERTIFICATE-----
 MIIDKzCCAhOgAwIBAgIRAJ6I1o7Yv+8BqsEF4oLIhV4wDQYJKoZIhvcNAQELBQAw
 GjEYMBYGA1UEChMPVmVsb2NpcmFwdG9yIENBMB4XDTIwMDkyNzEyNTUzN1oXDTMw
 GwbIKrNW8iIkxQT4iKMHgF4+vGn4YteNpysatCGZtSHWRcvUB+cnDYv+kbch70dx
 zF54976UPzOCv+xN7blJFMugWnCHPBOnURaBvQ4cPOdtWv3BgtbF+3EPiaKf9EE=
 -----END CERTIFICATE-----
 nonce: Imxp3zf+GM4=
 use_self_signed_ssl: true
 pinned_server_name: VelociraptorServer
API:
GUI:
 bind_address: 127.0.0.1
 bind_port: 8889
 base_path: /gui
 gw_certificate: |
 -----BEGIN CERTIFICATE-----
 wpgSJX5UXEJUHhlRLWenVNTrRS8jmmjgw6ovnZKosahV/skItKEsVGQByi1x32zW
 FwpP3uggQlfSpgIufr2n86Jxu9eGwdLUIrAq8crZXuZkBQPONOWz3yTF3fuhy9Zr
 MBjRGfI5jEPkoIVkVv4UXWfmKuCSoNJ17HVa2GRwOojW8qZvEDTJSSRn2xJb0lkU
 pvrd4AJ3gBePJtF/+oQOR08=
 -----END CERTIFICATE-----
 gw_private_key: |
 -----BEGIN RSA PRIVATE KEY-----
 MIIEpAIBAAKCAQEAptwLTXopCLWD483r9EWfn8YbxXiaxjvhSVc9MWxk7yBEvYYa
 LTHjtwMhlh1I1YVNr1MH4GAoTXMASJsscLwEVol200tOGLVfb2I0uGVmunkjXXOh
 eFCrGdIYJFAwhj4USZBsby5olORTHw8rBlvVvK+NieRptpg+bj+o23Xw8uryAotw
 3InWtyaNQd+UEXqaaf6dnStYhX/CFJrudOobJHgiJ7cB33QG3nvZxg==
 -----END RSA PRIVATE KEY-----
CA:
 private_key: |
 -----BEGIN RSA PRIVATE KEY-----
 MIIEpQIBAAKCAQEA3AGxHT80+B70+mtjj08njg9Se0c02K9qkcrTiy0knJEf7QpS
 s4K5MQG22kxreW3sRXcJlVYa0MgrDCZRJjtGn8Fw1Zc3f28KGcyTqWAKO0xiQeVR
 4+JQQ3INuNuGkCjWAxMj2p8wh23vsCWLWjUsZsD17uzqactTpr0gQQRGiI2sx/On
 Q0hF/m5+o9f3j18kK3sQsOaZv/WRwYgzEZZVgeLH+Z1CFUaaAZZeR38=
 -----END RSA PRIVATE KEY-----
Frontend:
 hostname: test.velocidex-training.com
 bind_address: 0.0.0.0
 bind_port: 8000
 certificate: |
 -----BEGIN CERTIFICATE-----
 MIIDGDCCAgCgAwIBAgIRAOXGwSQ8EzUy74lzrRtZFjYwDQYJKoZIhvcNAQELBQAw
 GjEYMBYGA1UEChMPVmVsb2NpcmFwdG9yIENBMB4XDTIwMDkyNzEyNTUzN1oXDTIx
 yxHjv87Dvl9UmaaQljXfUxsxgjzWbCCvRD4ohNJoAcfS296CeUmvD31uVLR3Pbor
 dcxFS4Nm/yOLARa9HVwawVFRoIQm/SG0oQwe2Bres2NnOGDu5xVQzHNGnqU1c7g3
 GXTpLdDYULsHtfCh2PQZ9IKAFeCPxmu5hS+qmw==
 -----END CERTIFICATE-----
 private_key: |
 -----BEGIN RSA PRIVATE KEY-----
 MIIEowIBAAKCAQEAm289U7G6J0DIAmGqs9YN+NeF3odwcfFtp4YLASkud1r2p6t6
 2DALF68hDqbSpR2FWsHRyFab5lSwI/kLsamGxBfLMVzeGkVQAXgGDzRxTRW/esa3
 wpFwq5rJw8dDivYXK2PPY0xxBeznsxc//2/WgGp3gHmtfqRh0mP2uk/OZ323oiSK
 rlJu+Ep6R4yBnxn+beeb+duXXuAGXS5CAdGXrMimrJYLgX4Wx7Ag
 -----END RSA PRIVATE KEY-----
 max_upload_size: 10485760
 dyn_dns: {}
 default_client_monitoring_artifacts:
 - Generic.Client.Stats
 run_as_user: velociraptor
 expected_clients: 10000
 GRPC_pool_max_size: 100
 GRPC_pool_max_wait: 60
Datastore:
 implementation: FileBaseDataStore
 location: /opt/velociraptor
 filestore_directory: /opt/velociraptor
&lt;/code>&lt;/pre>
&lt;h3 id="communication-overview">Communication overview&lt;/h3>
&lt;p>Clients (Velociraptor instances running on endpoints) connect to the server over the http protocol, typically embedded within a TLS connection. Although Velociraptor shares the same communication protocol as was used in the GRR project, it was enhanced for Velociraptor’s use to be more secure and efficient.&lt;/p>
&lt;h3 id="velociraptors-internal-pki">Velociraptor’s internal PKI&lt;/h3>
&lt;p>Every Velociraptor deployments creates an internal PKI which underpins it. The configuration wizard creates an internal CA with an X.509 certificate and a private key. This CA is used to:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create initial server certificates and any additional certificates for key rotation.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>CA public certificate is embedded in the client’s configuration and is used to verify server communications.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The CA is used to create API keys for programmatic access. The server is then able to verify API clients.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The configuration file contains the CA’s X.509 certificate in the &lt;strong>Client.ca_certificate&lt;/strong> parameter (it is therefore embedded in the client configuration). The private key is contained in the &lt;strong>CA.private_key&lt;/strong> parameter.&lt;/p>

&lt;div class="mynotices tip">
 &lt;div heading="tip">&lt;p>In a secure installation you should remove the &lt;strong>CA.private_key&lt;/strong> section from the server config and keep it offline. You only need it to create new API keys using the &lt;em>velociraptor config api_client&lt;/em> command, and the server does not need it in normal operations.&lt;/p>
&lt;/div>
&lt;/div>


&lt;h3 id="messages">Messages&lt;/h3>
&lt;p>Clients and servers communicate by sending each other messages (which are simply protocol buffers), for example, a message may contain VQL queries or result sets. Messages are collected into a list and sent in a single POST operation in a &lt;strong>MessageList&lt;/strong> protobuf. This protobuf is encrypted using a session key with a symmetric cipher (&lt;code>aes_128_cbc&lt;/code>). The session key is chosen by the sending party and is written into an encrypted &lt;strong>Cipher&lt;/strong> protobuf and sent along with each message.&lt;/p>
&lt;p>






&lt;figure id="ff831bd2595e13cc7df0b8b641b59fd9">
 &lt;div data-featherlight="#ff831bd2595e13cc7df0b8b641b59fd9" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/1ntQkR2sRm8mIg5vkYjngEg.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>This symmetric key is encoded in a &lt;strong>Cipher Properties&lt;/strong> protobuf which is encrypted in turn using the receiving party’s public key and signed using the sending party’s private key.&lt;/p>
&lt;h3 id="key-caching">Key caching&lt;/h3>
&lt;p>The encrypted cipher is sent with each message and contains an encrypted version of the same session key. This means that it is always possible to derive the session key from each post message by performing RSA decrypt/verify operations, but having decoded the symmetric key once — it is possible to cache it for the remainder of the session. This avoids expensive RSA operations — as long as the server communicated with the client recently, the symmetric key will be cached and can be reused.&lt;/p>
&lt;p>On a loaded server you might notice CPU utilization spikes for a few seconds after the system starts up, as the server unlocks the session keys from incoming clients, but after that the server should not need to perform many RSA operations and CPU load should be low since most session keys are cached in memory.&lt;/p>
&lt;p>The &lt;strong>Frontend.expected_clients&lt;/strong> setting controls the size of the memory cache of session keys. If this is too small, keys will be evicted from cache and CPU load will rapidly rise as the server is forced to do more RSA operations to decrypt client messages. You should increase this value to reflect how many clients you expect to be active at the same time.&lt;/p>
&lt;h2 id="http-protocol">HTTP protocol&lt;/h2>
&lt;p>In the last section we saw that Velociraptor messages are both signed and encrypted by the internal deployment CA. But how are these messages exchanged over the internet?&lt;/p>
&lt;p>Velociraptor uses HTTPS POST messages to deliver message sets to the server. The server in turn sends messages to the client in the body of the POST request. The client connects to one of the server URLs provided in the &lt;strong>Client.server_urls&lt;/strong> setting in its config file.&lt;/p>
&lt;p>Before the client communicates with the server, the client must verify it is actually talking with the correct server. This happens at two levels:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If the URL is a HTTPS URL then the TLS connection needs to be verified&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The client will fetch the url /server.pem to receive the server’s internal certificate. This certificate must be verified by the embedded CA.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Note that this verification is essential in order to prevent the client from accidentally talking with captive portals or MITM proxies.&lt;/p>
&lt;h3 id="tls-verification">TLS verification&lt;/h3>
&lt;p>Velociraptor currently supports 2 modes for deployment via the config wizard:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Self-signed mode uses internal CAs for the TLS certificates. The client knows it is in self-signed mode if the &lt;strong>Client.use_self_signed_ssl&lt;/strong> flag is true.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Proper certificates minted by Let’s encrypt.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Velociraptor verifies self-signed TLS certificates using its built in CA. This essentially pins the server’s certificate inside the client — even if a MITM was able to mint another certificate (even if it was trusted by the global roots!) it would not be valid since it was not issued by Velociraptor’s internal CA which is the only CA we trust in this mode! In this way self-signed mode is more secure than use a public CA.&lt;/p>
&lt;p>The &lt;strong>Client.pinned_server_name&lt;/strong> specifies the common name of the server (or DNS name in the Server Alternate Name (SAN) field). The client verifies that the certificate is correct &lt;strong>AND&lt;/strong> that the name is the same as the pinned name. You typically do not need to change this setting.&lt;/p>
&lt;p>If the client is not in self-signed mode (i.e. &lt;strong>Client.use_self_signed_ssl&lt;/strong> is false or not present), it expects to verify TLS connections using the system’s root certificate store. In this configuration, Velociraptor is susceptible to a MITM SSL inspection proxy, and we must rely on the internal encryption mechanism as described in the previous section to protect communications.&lt;/p>
&lt;p>&lt;strong>NOTE&lt;/strong>: In practice we find that often customer networks do contain SSL inspection proxies and using self-signed certificates breaks communications altogether. We typically prefer to deploy Let’s Encrypt certificates for reliability and better interoperability.&lt;/p>
&lt;h3 id="debugging-client-communications">Debugging client communications&lt;/h3>
&lt;p>Now that we have an understanding on the low level communication mechanism, let’s try to apply our understanding to debugging common deployment issues.&lt;/p>
&lt;p>If the client does not appear to properly connect to the server, the first thing is to run it manually (using the &lt;em>velociraptor client -v&lt;/em> command):&lt;/p>
&lt;p>






&lt;figure id="200039270f12657d7dd1c4a0d07a1783">
 &lt;div data-featherlight="#200039270f12657d7dd1c4a0d07a1783" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/1TOeyrCcX69mtUdO8E4ZK9g.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>In the above example, I ran the client manually with the -v switch. I see the client starting up and immediately trying to connect to its URL (in this case &lt;a href="https://test.velocidex-training.com/" target="_blank" >https://test.velocidex-training.com/&lt;/a>
 ) However this fails and the client will wait for a short time before retrying to connect again.&lt;/p>
&lt;p>






&lt;figure id="c9c5609faf917e54ae11b2d50c4a3447">
 &lt;div data-featherlight="#c9c5609faf917e54ae11b2d50c4a3447" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/1IzCgKdN28sjntuxd9mUJew.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>A common problem here is network filtering making it impossible to reach the server. You can test this by simply running curl with the server’s URL.&lt;/p>
&lt;p>Once you enable connectivity, you might encounter another problem&lt;/p>
&lt;p>






&lt;figure id="8b30565a8e4a29d882abc477726f4562">
 &lt;div data-featherlight="#8b30565a8e4a29d882abc477726f4562" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/1p3MPNfTbXBzNMs-X4yv4SA.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>The &lt;strong>Unable to parse PEM&lt;/strong> message indicates that the client is trying to fetch the &lt;strong>server.pem&lt;/strong> file but it is not able to validate it. This often happens with captive portal type of proxies which interfere with the data transferred. It can also happen if your DNS setting point to a completely different server.&lt;/p>
&lt;p>We can verify the &lt;strong>server.pem&lt;/strong> manually by using curl (note that when using self-signed mode you might need to provide curl with the -k flag to ignore the certificate errors):&lt;/p>
&lt;p>






&lt;figure id="fb1215b81bb59e4b6312a38be9f70698">
 &lt;div data-featherlight="#fb1215b81bb59e4b6312a38be9f70698" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/1P9W4CnX9qNLGiRgnHGyLAw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Note that the &lt;strong>server.pem&lt;/strong> is always signed by the velociraptor internal CA in all deployment modes (even with lets encrypt). You can view the certificate details by using openssl:&lt;/p>
&lt;pre>&lt;code class="language-sh">curl https://test.velocidex-training.com/server.pem | openssl x509 -text
&lt;/code>&lt;/pre>
&lt;h2 id="ssl-offloading">SSL Offloading&lt;/h2>
&lt;p>The Velociraptor server is very fast and can typically handle many thousands of clients connected at the same time. One of the largest limitations though is SSL processing. Typically SSL operations can take a significant amount of CPU resources in performing cryptography (we noted previously that Velociraptor’s own cryptography can be cached and therefore usually does not use much CPU).&lt;/p>
&lt;p>Once approach to help scalability is to offload SSL processing to special reverse proxies. Typically these can use hardware cryptography acceleration to offload crypto from the CPU.&lt;/p>
&lt;p>






&lt;figure id="88ee652c8fd835d4f4be412a5e20e25f">
 &lt;div data-featherlight="#88ee652c8fd835d4f4be412a5e20e25f" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/1ppLjm2qy0pRt3RsDVKDDWA.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>In this example, we will show how nginx can be used to terminate the TLS connections and then forward plain HTTP connections to the Velociraptor server (Many cloud provides also offer a cloud version of an SSL load balancer). This setup is also suitable if you want to use standard certificates (i.e. not Let’s Encrypt ones).&lt;/p>
&lt;p>First I will install nginx according to any number of tutorials on the net (for &lt;a href="https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-18-04" target="_blank" >this&lt;/a>
 or &lt;a href="https://www.nginx.com/blog/using-free-ssltls-certificates-from-lets-encrypt-with-nginx/" target="_blank" >this&lt;/a>
). My config file is as follows:&lt;/p>
&lt;pre>&lt;code class="language-text">server {
 server_name test.velocidex-training.com;
 location /gui {
 proxy_pass http://127.0.0.1:8889/gui;
 proxy_redirect off;
 proxy_set_header Host $host;
 }

 location / {
 proxy_pass http://127.0.0.1:8000;
 }

 listen [::]:443 ssl ipv6only=on; # managed by Certbot
 listen 443 ssl; # managed by Certbot
 ssl_certificate /etc/letsencrypt/live/test.velocidex-training.com/fullchain.pem; # managed by Certbot
 ssl_certificate_key /etc/letsencrypt/live/test.velocidex-training.com/privkey.pem; # managed by Certbot
 include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
 ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot

}
server {
 if ($host = test.velocidex-training.com) {
 return 301 https://$host$request_uri;
 } # managed by Certbot

 listen 80;
 listen [::]:80;

 server_name test.velocidex-training.com;
 return 404; # managed by Certbot
}
&lt;/code>&lt;/pre>
&lt;p>I am using certbot to manage the lets encrypt certificates and I have two main routes:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>URLs starting with &lt;strong>/gui/&lt;/strong> will be redirected to the Velociraptor GUI port (by default port 8889) using plain HTTP.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>All other URLs will be redirected to the frontend port (port 8000) using plain http.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Now I need to make Velociraptor listen on plain http instead of the default TLS. I do this simply by adding the &lt;strong>use_plain_http: true&lt;/strong> flag both to the GUI and Frontend sections.&lt;/p>
&lt;p>






&lt;figure id="d7515a6a8a029b11e99c710faaaa07b4">
 &lt;div data-featherlight="#d7515a6a8a029b11e99c710faaaa07b4" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-09-28-velociraptor-network-communications-30568624043a/../../img/19YhBBqOhnLVanACm3Vdbog.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>I also specify the GUI to listen on the path starting with “/gui” instead of the root — this allows nginx to proxy the GUI at a different URL to the default.&lt;/p>
&lt;p>On the client’s side, the server appears to be a proper SSL server. The client needs to connect to nginx which will present a valid certificate. Therefore the client needs to specify &lt;strong>use_self_signed_ssl: false&lt;/strong> (or omit it) and also specify a https URL as the server’s location (i.e. &lt;strong>Client.server_urls: [https://test.velocidex-training.com/]&lt;/strong>).&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>We have seen that Velociraptor utilizes its own PKI to secure client/server communication. This PKI is used both to prevent interception of messages as well as preventing messages from being forged. The server verifies the client the message came from and the client verifies the server before it connects to it.&lt;/p>
&lt;p>In addition, Velociraptor uses standard TLS communications to deliver messages using POST requests. TLS connections can either be self-signed (but pinned) or use public CA PKI. Using a standard network protocol allows Velociraptor to easily fit into any modern corporate network (which might include SSL interception proxies etc).&lt;/p>
&lt;p>By understanding how the communication takes place, we saw how we can debug network problems and even configure a reverse proxy for TLS offloading — an important feature to be able to scale even higher.&lt;/p>
&lt;p>If you are interested in learning more about Velociraptor, check out our courses on &lt;a href="https://www.velocidex.com/training/" target="_blank" >https://www.velocidex.com/training/&lt;/a>
 or join us on discord &lt;a href="https://www.velocidex.com/discord" target="_blank" >https://www.velocidex.com/discord&lt;/a>
.&lt;/p></description></item><item><title>Profiling the beast</title><link>https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/</link><pubDate>Sun, 16 Aug 2020 00:38:44 +0000</pubDate><guid>https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/</guid><description>&lt;p>






&lt;figure id="680527925ff98d51c76e5a8e65d06db5">
 &lt;div data-featherlight="#680527925ff98d51c76e5a8e65d06db5" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/https://cdn-images-1.medium.com/max/10582/0*VRw2NF77V7mzrtQw?width=600px" alt="Photo by Daniel Cheung on Unsplash" />
 &lt;/div>
 &lt;figcaption>
 Photo by Daniel Cheung on Unsplash
 &lt;/figcaption>
&lt;/figure>


&lt;em>Photo by &lt;a href="https://unsplash.com/@danielkcheung?utm_source=medium&amp;amp;utm_medium=referral" target="_blank" >Daniel Cheung&lt;/a>
 on &lt;a href="https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral" target="_blank" >Unsplash&lt;/a>
&lt;/em>&lt;/p>
&lt;p>You might have previously heard about Velociraptor — fast becoming the standard open source agent for endpoint monitoring and collection. Being an open source project provides users with visibility into the inner workings of the tool since anyone can see the source code and even contribute to it!&lt;/p>
&lt;p>While I usually write about Velociraptor features that make DFIR work easier and more effective, this time I am actually going to talk about a feature of the Golang programming language itself (which Velociraptor is written in). Golang provides unprecedented visibility to the state of production binaries, and these mechanisms are available and easily accessible within Velociraptor.&lt;/p>
&lt;p>This post introduces new tools available for users since the 0.4.8 release to more easily gain visibility into the inner workings of Velociraptor, and be able to share these with the developers in order to assist in finding and fixing bugs. Although the post will focus on the very technical low level details available for developers, end users can see how they can assist developers by collecting important runtime information (Or even using it to understand what the tool is actually doing).&lt;/p>
&lt;h2 id="endpoint-telemetry">Endpoint Telemetry&lt;/h2>
&lt;p>Those who have already seen Velociraptor in action might be very familiar with the built in telemetry available within the tool. The Velociraptor endpoint agents (termed Client) collect memory and CPU utilization information about the agent process every 10 seconds and send it to the server. The client performance stats are available right in the host overview page.&lt;/p>
&lt;p>






&lt;figure id="043f0e7f92c6e26e6b3c345b31ac3e5b">
 &lt;div data-featherlight="#043f0e7f92c6e26e6b3c345b31ac3e5b" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/1ojviZVbiMFj-fBS2nBVbLQ.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>In the example above we see a typical hunt running on this specific endpoint — the CPU load spikes for a few seconds to a few minutes, then when the collection completes, the CPU load returns to normal levels (at less than 1% of one core), and a short time later memory use is also returned to the system. Of course depending on the specific hunt run, the amount of work the client has to do may be larger and take longer.&lt;/p>
&lt;p>Similarly, the server also collects telemetry periodically, which you can see on the main dashboard (this data is also available using Prometheus/Grafana which are more appropriate for larger deployments). Again depending on the amount of post processing done on the server the CPU and memory footprint can vary.&lt;/p>
&lt;p>






&lt;figure id="eac32897c9bbf29925e5fc1a36397910">
 &lt;div data-featherlight="#eac32897c9bbf29925e5fc1a36397910" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/1EchDpaQPy19KrQe9ZouF3g.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;h2 id="profiling">Profiling&lt;/h2>
&lt;p>Velociraptor is written in Golang and one of the more useful (if not well advertised) feature of the Go runtime is the ability to profile the running program. Most programming languages have mechanisms to profile running code and collect information about memory allocations, backtraces etc — however in many programming languages, this information can only be collected by running a special debug build of the binary.&lt;/p>
&lt;p>What makes Golang different is that &lt;strong>every binary&lt;/strong> has the ability to profile itself out of the box. Obviously this capability is disabled by default (since profiling itself has a non-trivial runtime cost) but it can simply be switched on at runtime for a limited time and then switched off. This means that we do not need to restart the binary in debug mode, nor replace a running binary with a special debug build! As a developer, I can not overstate the usefulness of this!&lt;/p>

&lt;div class="mynotices note">
 &lt;div heading="note">&lt;p>If we see a Golang process running in production and want to inspect its inner working all we need to do is enable profiling for a short time (say 30 seconds) capturing execution traces &lt;strong>without restarting or otherwise affecting the running process!&lt;/strong>&lt;/p>
&lt;/div>
&lt;/div>


&lt;p>Velociraptor exposes this functionality by simply offering the &lt;strong>profile()&lt;/strong> VQL function. This is then utilized by two artifacts:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The &lt;strong>Generic.Client.Profile&lt;/strong> artifact allows collecting profile information for a running client on the endpoint.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;strong>Server.Monitor.Profile&lt;/strong> artifact similarly allows to collect profiling information from the server.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>In the following example we examine how profiling can be used to gain an understanding of what is going on under the covers.&lt;/p>
&lt;h3 id="example--recursive-file-hash">Example — recursive file hash&lt;/h3>
&lt;p>To illustrate this process I will launch a CPU heavy collection on my endpoint. I create a new artifact collection of the &lt;strong>Windows.Search.FileFinder&lt;/strong> artifacts, searching recursively for all files below &lt;em>C:\Users&lt;/em> and hashing them all.&lt;/p>
&lt;p>






&lt;figure id="7ace8fb88b3f22fe88db905f51ae3715">
 &lt;div data-featherlight="#7ace8fb88b3f22fe88db905f51ae3715" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/1K5FlQK6zzhpg0SObQFcTcg.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>This collection is very CPU intensive and actually takes some time to complete on the endpoint. I can tell this because the CPU footprint in the host’s VQL drilldown pane shows the collection progressing with CPU load around 100% of a core and memory use between 50 and 100mb for about 8 minutes.&lt;/p>
&lt;p>






&lt;figure id="31688b98eda55d344d7515016fa2c06f">
 &lt;div data-featherlight="#31688b98eda55d344d7515016fa2c06f" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/1mxVuPJ1lWuGSHnYyObwnpw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>For the sake of this discussion, assume that I am not 100% sure what is going on with this collection and why it is taking so long (although I have a theory!). I can remotely acquire profiling information from the client, &lt;strong>while the collection is taking place!&lt;/strong>&lt;/p>
&lt;p>Simply schedule a new collection of the &lt;strong>Generic.Client.Profile&lt;/strong> artifact, selecting the CPU profile checkbox (There are a number of other debugging data and traces that can be acquired at the same time but I won’t go into these here).&lt;/p>
&lt;p>






&lt;figure id="b788d8ac80cc6c30456220211c52bef2">
 &lt;div data-featherlight="#b788d8ac80cc6c30456220211c52bef2" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/16SDwrh4quetvE_emHQnfmg.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>When launching this collection, the profiles will be acquired concurrently (note that Velociraptor can collect multiple artifacts at the same time). So actually collecting the &lt;strong>Generic.Client.Profile&lt;/strong> artifact will result in collecting information on whatever else is happening within the Velociraptor process at the same time — Collecting this artifact essentially starts recording traces for 30 seconds, then stops recording traces and sends those traces back.&lt;/p>
&lt;p>






&lt;figure id="278d4442274f8acd13fb6f39242f1343">
 &lt;div data-featherlight="#278d4442274f8acd13fb6f39242f1343" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/1Ypb_iKi_s9ypRzexekYAAw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>By default the profile is taken over 30 seconds, after which it is uploaded to the server like any uploaded file. I can simply download the profile from the &lt;strong>Uploaded Files&lt;/strong> tab by clicking the link.&lt;/p>
&lt;p>






&lt;figure id="5b847e38977d20204b40d77a7e68c7f8">
 &lt;div data-featherlight="#5b847e38977d20204b40d77a7e68c7f8" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/17ZeuBYe5dIV_LATRLZkUaw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>After downloading the profile file, I convert it to a callgrind format, so it can be viewed by my favourite profile inspector &lt;a href="https://kcachegrind.github.io/html/Home.html" target="_blank" >kcachegrind&lt;/a>
 (there are other similar viewers and the Golang one is &lt;a href="https://github.com/google/pprof" target="_blank" >called pprof&lt;/a>
).&lt;/p>
&lt;pre>&lt;code class="language-sh">$ go tool pprof -callgrind -output=profile.grind profile.bin
$ kcachegrind profile.grind
&lt;/code>&lt;/pre>
&lt;p>






&lt;figure id="ab7cb2ae2e75b31b09a3ea06a51ec38d">
 &lt;div data-featherlight="#ab7cb2ae2e75b31b09a3ea06a51ec38d" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/1GFekz4L0I4hm-LzR6EZbCQ.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>The &lt;a href="https://kcachegrind.github.io/html/Home.html" target="_blank" >kcachegrind&lt;/a>
 tool allows me to interactively inspect the relative CPU time spent on each function. In the screenshot above we can see the left pane showing the relative amount of time taken by each function. The bottom right pane shows an interactive call graph visualizing how each function spends its time. In this case we can see the &lt;em>HashFunction.Call()&lt;/em> function is responsible for 65% of the time spent. In turn it spends about 5% of CPU time reading the file, 4% calculating the sha1, 10% the sha256 and 3.5% the md5 hashes. (The exact numbers will depend on the actual set of files present on the endpoint)&lt;/p>
&lt;p>






&lt;figure id="42a15e1f0d9fe6d22ced32e324f2c0d3">
 &lt;div data-featherlight="#42a15e1f0d9fe6d22ced32e324f2c0d3" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-08-16-profiling-the-beast-58913437fd16/../../img/1VV4GJRhUlO2rnN8zG1ahKA.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Scrolling the call graph in this case shows that the &lt;code>os.Open()&lt;/code>
function spends about 35% of the time. Since &lt;code>os.Open()&lt;/code> is not a part
of our own code, it shows we end up spending most of our time in the
operating system. In fact 35% of our time is spent waiting for Windows
Defender’s real time scanner (which blocks &lt;code>os.Open&lt;/code> for us as it
scans the files on demand — Windows defender is a huge performance
killer.).&lt;/p>

&lt;div class="mynotices note">
 &lt;div heading="note">&lt;p>Our job as Velociraptor developers is to spend as little time as possible in our own code relative to the time spent in the operating system or external libraries.&lt;/p>
&lt;/div>
&lt;/div>


&lt;p>The function’s source code is shown in the top right pane and we see how much time is spent at each line of code. This makes it easy to see what function calls end up taking the most time and guides our thinking into possible optimizations&lt;/p>
&lt;p>A performance bug arises when our function does more work than is necessary and therefore spends too long doing it. This slows down processing. Clearly in this case the biggest contributors are hashing and filesystem operations which exist outside our code base — so this VQL query is pretty good already.&lt;/p>
&lt;p>NOTE: The astute reader may spot 5.8% lost to the garbage collector through calls to &lt;em>makeslice()&lt;/em> in line 67. These calls were eliminated by a recent commit.&lt;/p>
&lt;h3 id="conclusions">Conclusions&lt;/h3>
&lt;p>Velociraptor is an open source project — exposing its inner working to all users. While we do not require users to be able to understand the profiling information themselves, they are able to easily collect this data on running production deployments.&lt;/p>
&lt;p>By exposing debugging and profiling tools in an easy way to end users, developers enable users to attach more useful traces to bug reports, and allow developers to assist in a more efficient way than simply reporting qualitative information such as high memory use or non-performant code.&lt;/p>
&lt;p>The profiling traces are typically much smaller than full memory core dumps and usually do not contain sensitive information. Profiles only contain high level statistics about memory and CPU usage (For example the CPU profile we saw in this article are obtained by statistic analysis of&lt;a href="https://golang.org/pkg/net/http/pprof/" target="_blank" > sampled backtrace&lt;/a>
s).&lt;/p>
&lt;p>We find this extremely valuable in the Velociraptor project, but the same approach can be replicated by any Golang project:&lt;/p>

&lt;div class="mynotices note">
 &lt;div heading="note">&lt;p>By exposing profiling and debugging information to our users, in running production binaries we are able to easily get high value visibility into hard to reproduce error conditions and therefore be more effective in isolating and fixing bugs.&lt;/p>
&lt;/div>
&lt;/div>


&lt;p>If you are interested in looking inside Velociraptor’s inner workings, check out the&lt;a href="https://github.com/Velocidex/velociraptor" target="_blank" > GitHub&lt;/a>
 page and join us on Discord and our mailing list.&lt;/p></description></item><item><title>Velociraptor in the tool age</title><link>https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/</link><pubDate>Mon, 13 Jul 2020 00:38:44 +0000</pubDate><guid>https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/</guid><description>&lt;p>Velociraptor is a powerful endpoint visibility tool. It has plugins
and parsers for many file formats, such as raw NTFS access, raw
registry hive, prefetch files etc.&lt;/p>
&lt;p>However, as most DFIR professionals know, there are so many tools out
there that we would love to use in our IR work. One of the strengths
of Velociraptor is its flexibility afforded by the use of the&lt;a href="https://docs.velociraptor.app/docs/vql/" >
Velociraptor Query Language (VQL).&lt;/a>
&lt;/p>
&lt;p>We have written before on how VQL can be extended by use of short
&lt;a href="https://docs.velociraptor.app/blog/2020/2020-06-14-the-velociraptor-query-language-pt-1-d721bff100bf/" >PowerShell scripts&lt;/a>
, by including these scripts directly in the Artifact
definitions. This is a great way to extend the functionality provided
by VQL, but what if we wanted to launch a completely separate binary
on the endpoint, or a larger powershell module? How can Velociraptor
facilitate the distribution, coordination and collection of tool
output from thousands of endpoints efficiently and quickly?&lt;/p>
&lt;p>Since&lt;a href="https://github.com/Velocidex/velociraptor/releases" target="_blank" > release
0.4.6&lt;/a>
,
Velociraptor supports including external tools directly in the
artifact definition. This makes it easier than ever before to use
external tools in your artifacts transparently — Velociraptor will
ensure the tool is downloaded to the endpoint if needed and is
available for use in your VQL.&lt;/p>
&lt;h3 id="example-hollows-hunter">Example: Hollows hunter&lt;/h3>
&lt;p>To illustrate the process, we will use the &lt;a href="https://github.com/hasherezade/hollows_hunter" target="_blank" >hollows hunter
tool&lt;/a>
 as an
example. This tool is written by the amazing
&lt;a href="https://hasherezade.github.io/" target="_blank" >HASHEREZADE&lt;/a>
 who develops a bunch of
useful tools to inspect binaries in memory (most famous is the
&lt;a href="https://github.com/hasherezade/pe-sieve" target="_blank" >pe_sieve&lt;/a>
 tool).&lt;/p>
&lt;p>We would like to develop a Velociraptor artifact that collects all
processes potentially injected by using the hollows hunter on the
endpoint. Before we start though, we need to actually have such a
sample to test on.&lt;/p>
&lt;p>Thanks to the Atomic Red Team we can use a simple test to inject a dll
into notepad++. I will use the test for
&lt;a href="https://github.com/redcanaryco/atomic-red-team/blob/master/atomics/T1055/T1055.md#atomic-test-1---process-injection-via-mavinjectexe" target="_blank" >T1055&lt;/a>

to inject the dll into &lt;em>notepad++.exe&lt;/em> on my test VM (which has the
Process ID 4108):&lt;/p>
&lt;p>











&lt;img class="inline" src="1E6SBS406C2B-3BVVJ10Sig.png" />




&lt;/p>
&lt;p>Now we can check that hollows hunter detects this:&lt;/p>
&lt;p>











&lt;img class="inline" src="1wt1KqixkeSs8Ael96fpAXA.png" />




&lt;/p>
&lt;h3 id="writing-the-artifact">Writing the artifact&lt;/h3>
&lt;p>We now create the artifact in the Velociraptor GUI. Start off by
selecting the &lt;em>“View Artifacts”&lt;/em> pane in the left sidebar and click
the* “New Artifact”* button to bring up the artifact editor UI. The
editor will have a pre-filled in template which helps to guide the
user to produce the correct syntax so I will just edit that.&lt;/p>
&lt;p>











&lt;figure id="7c5bbfd50b9fe6355cb088a058b99d9f">
 &lt;div data-featherlight="#7c5bbfd50b9fe6355cb088a058b99d9f" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/1s9fGjhLnwf2uW4vRt3qCQA.png" alt="">
 &lt;/div>
 &lt;figcaption>
 &lt;a class="image-link" href="1s9fGjhLnwf2uW4vRt3qCQA.png">&lt;i class="fa fa-download">&lt;/i>&lt;/a>
 
 &lt;/figcaption>
&lt;/figure>




&lt;/p>
&lt;p>The first thing I will do is name the artifact
&lt;em>“Custom.Windows.Detection.ProcessHollowing”&lt;/em>. Since this is a custom
artifact, it must start with the word **Custom. **to keep it distinct
from Velociraptor’s built in artifacts. I can also add a quick
description to help users understand what this artifact does.&lt;/p>
&lt;p>Next I will declare that this artifact needs the &lt;strong>hollows_hunter&lt;/strong>
tool. Velociraptor will ensure this tool is available on the endpoint
when the artifact is collected. The tool’s name is simply a string
that I will use to refer to the tool below. It will be automatically
added to Velociraptor’s inventory of external tools.&lt;/p>
&lt;p>By providing the url, Velociraptor can fetch the tool by itself from
this URL. If the tool is not yet known to Velociraptor, the server
will fetch the file and calculate the hash the first time and store
it. In the next section we can see how to manage tools in
Velociraptor.&lt;/p>
&lt;p>Now we are ready to write the VQL that will use the tool. The VQL will
run on the endpoint during collection and will need a valid path to
the hollows hunter executable. Velociraptor will manage uploading the
executable to the endpoint and caching the binary locally, ensuring
its hash does not change over time. To make this process as easy to
use as possible, as far as the artifact writer is concerned, they
simply need to call the &lt;em>“Generic.Utils.FetchBinary()”&lt;/em> artifact to
get a path to the local binary.&lt;/p>
&lt;p>






&lt;figure id="439670b3463db5ddfa2e8d5f69fed3e2">
 &lt;div data-featherlight="#439670b3463db5ddfa2e8d5f69fed3e2" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/../../img/1WWMvYGQvreCfPbKrtDYuew.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>The first VQL query simply calls the &lt;strong>Generic.Utils.FetchBinary()&lt;/strong>
artifact with the required tool name (Note that we don&amp;rsquo;t need to
specify a url since this is already known to the system). We assign
the result of this query to the &lt;em>“binaries”&lt;/em> variable — which will
contain an array of rows as is always the case with assigning a query
to a variable (in this case only one row).&lt;/p>
&lt;p>At the same time we also obtain a temporary directory to store results
in. This directory will be automatically removed when the query ends
to clean up.&lt;/p>
&lt;p>Next we call the binary using the &lt;strong>execve()&lt;/strong> plugin with the
appropriate arguments — We wish to dump the memory of affected
processed and write json results into the temp directory (The length
parameter forces the execve() plugin to wait until the buffer is full
before emitting the row — this will wait until the program is done and
emit a single row with Stdout as a column.)&lt;/p>
&lt;p>After the hollows hunter program ends, we glob over all the files in
the temp directory and just upload them to the server (we chain the
two queries together using the &lt;em>chain()&lt;/em> plugin).&lt;/p>
&lt;p>The complete artifact can be seen below:&lt;/p>
&lt;pre>&lt;code class="language-yaml">name: Custom.Windows.Detection.ProcessHollowing
description: |
 Use hollows_hunter to detect suspicious process injections.

 Upload any findings to the server, including process dumps.
tools:
 - name: hollows_hunter
 url: https://github.com/hasherezade/hollows_hunter/releases/download/v0.2.7.1/hollows_hunter64.exe

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- Get the path to the hollows_hunter tool and a fresh temp directory.
 LET binaries &amp;lt;= SELECT FullPath, tempdir() AS TempDir
 FROM Artifact.Generic.Utils.FetchBinary(
 ToolName=&amp;quot;hollows_hunter&amp;quot;)

 -- Run the tool and relay back the output, as well as upload all the files from the tempdir.
 SELECT * FROM chain(
 a={SELECT Stdout, NULL AS Upload
 FROM execve(argv=[binaries[0].FullPath,
 &amp;quot;/json&amp;quot;, &amp;quot;/dir&amp;quot;, binaries[0].TempDir], length=100000)},
 b={
 SELECT upload(file=FullPath) AS Upload
 FROM glob(globs=&amp;quot;*&amp;quot;, root=binaries[0].TempDir)
 })
&lt;/code>&lt;/pre>
&lt;h3 id="collecting-from-the-endpoint">Collecting from the endpoint&lt;/h3>
&lt;p>Now let&amp;rsquo;s test this artifact by collecting it from our test VM. Simply
search for the hostname in the search box, and view the* “Collected
Artifacts”* pane to see previously collected artifacts. Click the
&lt;em>“Collect new artifacts”&lt;/em> button and search for our newly created
hollows hunter artifact.&lt;/p>
&lt;p>






&lt;figure id="9bd417d89e24aa262cd0ecddc911c1cb">
 &lt;div data-featherlight="#9bd417d89e24aa262cd0ecddc911c1cb" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/../../img/1iTGEgzlLFnoQpwwLBTylQg.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Click* “Launch Collection” *to collect it from the endpoint. We can
view the query log as it is executing on the endpoint to really
appreciate what is happening behind the scenes.&lt;/p>
&lt;p>






&lt;figure id="802100cc54784c250b91a35be1bd89e8">
 &lt;div data-featherlight="#802100cc54784c250b91a35be1bd89e8" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/../../img/1uf7vfDoXWEUYO6KOabXHtw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>The endpoint initially does not have a copy of the hollows hunter
binary cached locally, so it needs to download it. The endpoint will
now sleep a random time before actually downloading it in order to
stagger downloads from potentially thousands of endpoints in a hunt.&lt;/p>
&lt;p>After a short sleep, the endpoint will download the binary directly
from GitHub, it will then calculate the hash of the binary it
downloaded with the expected hash that was sent by the server. If the
hashes match, then the endpoint will keep this file in the temp
directory. The hash comparison protects endpoints from the GitHub
binary changing unexpectedly.&lt;/p>
&lt;p>Finally, the endpoint simply runs the tool, and uploads the results to
the server.&lt;/p>
&lt;p>






&lt;figure id="5b69ab4376b819195e389d833d8f3283">
 &lt;div data-featherlight="#5b69ab4376b819195e389d833d8f3283" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/../../img/15U_9frnLTdA1vsyPuewh4g.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>The user can access those results as normally by simply getting the
results in a zip file from the &lt;strong>Artifact Collection&lt;/strong> tab.&lt;/p>
&lt;p>






&lt;figure id="e59168be6a27669a5cd0070b66aa4502">
 &lt;div data-featherlight="#e59168be6a27669a5cd0070b66aa4502" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/../../img/1G9m-FkIBjgzQh1xURAnpzw.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>We can now also hunt for this on our entire fleet to retrieve all the
injected binaries in minutes!&lt;/p>
&lt;p>Note that once the binary is cached on the endpoint, the Velociraptor
client will not need to download it again, as long as the cached hash
matches the expected hash.&lt;/p>
&lt;h3 id="tool-support--deep-dive">Tool support — deep dive&lt;/h3>
&lt;p>In the above example, from the point of view of the artifact writer,
the hollows hunter binary just magically appeared on the endpoint when
it was required by an artifact that used it. How does this actually
work?&lt;/p>
&lt;p>Velociraptor has integrated support for external tools since
0.4.6. The tools are managed by the velociraptor tools command. You
can see what tools Velociraptor knows about using the &lt;strong>velociraptor
tools show&lt;/strong> command:&lt;/p>
&lt;p>






&lt;figure id="5a6d8edcaf775d8f0a5f036d72f6a158">
 &lt;div data-featherlight="#5a6d8edcaf775d8f0a5f036d72f6a158" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/../../img/1y0ApRgFzYELr7A2Ko4AHNQ.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>We can see that Velociraptor knows the hash of the hollows hunter tool
and it also keeps a copy of the binary in the filestore under a
special obfuscated name.&lt;/p>
&lt;h3 id="using-a-custom-tool">Using a custom tool&lt;/h3>
&lt;p>Previously we have seen that the endpoints all downloaded the hollows
hunter binary directly from GitHub. In practice, if you have thousands
of clients all trying to download the same binary in a hunt it might
trigger GitHub’s DDoS protections. At larger scale it might be better
to serve binaries from more reliable source, like cloud buckets or
Velociraptor’s server itself.&lt;/p>
&lt;p>Suppose we also wanted to use a special version of hollows_hunter
(perhaps an unreleased version with extra features or detections) so
we would really like to host the binary ourselves.&lt;/p>
&lt;p>We can directly upload our custom version to Velociraptor using the
&lt;strong>velociraptor tools upload&lt;/strong> command&lt;/p>
&lt;p>






&lt;figure id="a20431d8d04f7bbfbc4d34e4d7f84ef5">
 &lt;div data-featherlight="#a20431d8d04f7bbfbc4d34e4d7f84ef5" class="figure">
 &lt;img src="https://docs.velociraptor.app/blog/2020/2020-07-13-velociraptor-in-the-tool-age-d896dfe71b9/../../img/1cQ-vwx6uj3JSavrF5m5ejQ.png" alt="" />
 &lt;/div>
 &lt;figcaption>
 
 &lt;/figcaption>
&lt;/figure>


&lt;/p>
&lt;p>Velociraptor will now serve the binary from the frontends directly
when used (seen by the serve_locally flag). Note that the binary will
still only be downloaded if the local copy on the endpoint does not
have the required hash so if this is a frequently used tool it will
generally not generate a lot of download traffic.&lt;/p>
&lt;h3 id="conclusions">Conclusions&lt;/h3>
&lt;p>The aim of the new tool integration is to have Velociraptor
automatically manage local caching on the endpoint of external
files. It is possible to have the endpoints download the files from
any URL, or serve it locally from Velociraptor itself. Either way,
Velociraptor ensures the file integrity by specifying in the
collection request the required file hash.&lt;/p>
&lt;p>Although in this example we used a binary on the endpoint, this is not
necessary. The scheme works just as well with any file type. For
example, sysmon configuration files can also be kept in a central
place and artifacts can sync them on the endpoint and load them as
required.&lt;/p>
&lt;p>The ability to resync tools on the endpoint opens the door to
versioned files. For example, we frequently use Yara rule files
containing frequently changing signatures from threat feeds and other
intel. By updating the hashes on the Velociraptor server we can force
endpoints to use the latest version of the signatures whenever an
artifact is run, but only if they don&amp;rsquo;t already have the latest pack
of yara rules (which may be large).&lt;/p>
&lt;p>Caching the files locally means the overheads of downloading the file
each time is eliminated, the artifact YAML itself contains all one
needs to collect this specific type of evidence. In the above example,
we can collect the hollows hunter multiple times, but the binary will
only be actually downloaded once per endpoint. The next collection
will simply use the same local binary while its hash is not changed.&lt;/p>
&lt;p>To play with this new feature yourself, take Velociraptor for a spin!
It is a available on
&lt;a href="https://github.com/Velocidex/velociraptor" target="_blank" >GitHub&lt;/a>
 under and open
source license. As always please file issues on the bug tracker or ask
questions on our mailing list
&lt;a href="mailto:velociraptor-discuss@googlegroups.com" >velociraptor-discuss@googlegroups.com&lt;/a>

. You can also chat with us directly on discord
&lt;a href="../../img/discord" >https://www.velocidex.com/discord&lt;/a>
&lt;/p></description></item></channel></rss>
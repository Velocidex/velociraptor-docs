<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Artifact Reference on Velociraptor - Digging deeper!</title><link>https://docs.velociraptor.app/artifact_references/</link><description>Recent content in Artifact Reference on Velociraptor - Digging deeper!</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate><atom:link href="https://docs.velociraptor.app/artifact_references/index.xml" rel="self" type="application/rss+xml"/><item><title>Admin.Client.Remove</title><link>https://docs.velociraptor.app/artifact_references/pages/admin.client.remove/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/admin.client.remove/</guid><description>&lt;p>This artifact will remove clients that have not checked in for a
while. All data for these clients will be removed.&lt;/p>
&lt;p>The artifact enumerates all the files that are removed.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Admin.Client.Remove
description: |
 This artifact will remove clients that have not checked in for a
 while. All data for these clients will be removed.

 The artifact enumerates all the files that are removed.

type: SERVER

parameters:
 - name: Age
 description: Remove clients older than this many days
 default: "7"
 type: int

 - name: ReallyDoIt
 type: bool

sources:
 - query: |
 LET Threshold &amp;lt;= timestamp(epoch=now() - Age * 3600 * 24 )
 LET old_clients = SELECT os_info.fqdn AS Fqdn, client_id,
 timestamp(epoch=last_seen_at) AS LastSeen FROM clients()
 WHERE LastSeen &amp;lt; Threshold

 SELECT * FROM foreach(row=old_clients,
 query={
 SELECT *, Fqdn, LastSeen FROM client_delete(
 client_id=client_id, really_do_it=ReallyDoIt)
 })

&lt;/code>&lt;/pre></description></item><item><title>Admin.Client.Uninstall</title><link>https://docs.velociraptor.app/artifact_references/pages/admin.client.uninstall/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/admin.client.uninstall/</guid><description>&lt;p>Uninstall Velociraptor from the endpoint.&lt;/p>
&lt;p>This artifact uninstalls a Velociraptor client (or any other MSI
package) from the endpoint.&lt;/p>
&lt;p>Typically the client will be hard terminated during the uninstall
process, so on the server it would appear that the collection is not
completed. This is normal.&lt;/p>
&lt;p>NOTE: Be careful with the DisplayNameRegex to ensure you do not
uninstall another package accidentally.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Admin.Client.Uninstall
description: |
 Uninstall Velociraptor from the endpoint.

 This artifact uninstalls a Velociraptor client (or any other MSI
 package) from the endpoint.

 Typically the client will be hard terminated during the uninstall
 process, so on the server it would appear that the collection is not
 completed. This is normal.

 NOTE: Be careful with the DisplayNameRegex to ensure you do not
 uninstall another package accidentally.

required_permissions:
 - EXECVE

parameters:
 - name: DisplayNameRegex
 type: regex
 default: Velociraptor
 description: A regex that will match the package to uninstall.

 - name: ReallyDoIt
 type: bool

sources:
 - name: Windows
 precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET packages = SELECT KeyName, DisplayName,UninstallString
 FROM Artifact.Windows.Sys.Programs()
 WHERE DisplayName =~ DisplayNameRegex AND
 log(message="Will uninstall " + DisplayName)

 LET uninstall(UninstallString) = SELECT * FROM execve(
 argv=commandline_split(command=UninstallString) + "/quiet")

 SELECT KeyName, DisplayName, UninstallString,
 if(condition=ReallyDoIt,
 then=uninstall(UninstallString=UninstallString).Stdout) AS UninstallLog
 FROM packages

 - name: Debian
 precondition: |
 -- Only run if dpkg is installed.
 SELECT OS, {
 SELECT ReturnCode FROM execve(argv=["dpkg", "--help"])
 } AS ReturnCode
 FROM info()
 WHERE OS = 'linux' AND ReturnCode = 0

 query: |
 SELECT * FROM if(condition=ReallyDoIt,
 then={
 SELECT * FROM execve(argv=["dpkg", "--remove", "velociraptor-client"])
 })

 - name: RPMBased
 precondition: |
 -- Only run if rpm is installed.
 SELECT OS, {
 SELECT ReturnCode FROM execve(argv=["rpm", "--help"])
 } AS ReturnCode
 FROM info()
 WHERE OS = 'linux' AND ReturnCode = 0

 query: |
 SELECT * FROM if(condition=ReallyDoIt,
 then={
 SELECT * FROM execve(argv=["rpm", "--erase", "velociraptor-client"])
 })

 - name: MacOS
 precondition: |
 SELECT OS
 FROM info()
 WHERE OS = 'darwin'

 query: |
 LET me &amp;lt;= SELECT Exe FROM info()

 SELECT * FROM if(condition=ReallyDoIt,
 then={
 SELECT * FROM execve(argv=[me[0].Exe, "service", "remove"])
 })

&lt;/code>&lt;/pre></description></item><item><title>Admin.Client.UpdateClientConfig</title><link>https://docs.velociraptor.app/artifact_references/pages/admin.client.updateclientconfig/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/admin.client.updateclientconfig/</guid><description>&lt;p>Sometimes we wish to move a client from one org ID to another. This
requires updating the config on the client and rekeying the client.&lt;/p>
&lt;p>This artifact will replace the client&amp;rsquo;s config file and restart
it. The config file will be verified before replacing it. If set to
not rekey, the client will retain its client id but will be killed -
the service manager should restart it and cause the new config to
reload.&lt;/p>
&lt;p>This artifact has a notebook suggestion that allows a client to be
changed to a different org.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Admin.Client.UpdateClientConfig
description: |
 Sometimes we wish to move a client from one org ID to another. This
 requires updating the config on the client and rekeying the client.

 This artifact will replace the client's config file and restart
 it. The config file will be verified before replacing it. If set to
 not rekey, the client will retain its client id but will be killed -
 the service manager should restart it and cause the new config to
 reload.

 This artifact has a notebook suggestion that allows a client to be
 changed to a different org.

parameters:
 - name: ConfigYaml
 description: The new config to write in yaml form.
 - name: ConfigPath
 description: Path of config file to overwrite
 - name: WaitPeriod
 type: int
 default: 10
 - name: RekeyClient
 type: bool
 default: Y
 description: Should the client rekey its client ID.

required_permissions:
 - EXECVE
 - FILESYSTEM_WRITE

sources:
 - query: |

 LET ValidateConfig(Config) = Config.Client.server_urls
 AND Config.Client.ca_certificate =~ "(?ms)-----BEGIN CERTIFICATE-----.+-----END CERTIFICATE-----"
 AND Config.Client.nonce

 LET CheckConfigPath(ConfigPath) = SELECT * FROM stat(filename=ConfigPath)
 LET Config &amp;lt;= parse_yaml(accessor="data", filename=ConfigYaml)

 LET DoIt = if(condition=ValidateConfig(Config=Config),
 else=log(level="ERROR", message="Config is invalid") AND FALSE,
 then=if(condition=CheckConfigPath(ConfigPath=ConfigPath).OSPath,
 else=log(level="ERROR",
 message="Config Path %v is invalid",
 args=ConfigPath) AND FALSE,
 then=copy(accessor="data", filename=ConfigYaml, dest=ConfigPath)
 AND if(condition= RekeyClient,
 then=log(message="Rekeying in %v seconds ", args=WaitPeriod)
 AND rekey(wait=WaitPeriod),
 else=pskill(pid=getpid()))
 ))

 SELECT DoIt AS Success FROM scope()

 notebook:
 - name: Move a client to a different OrgId
 type: vql_suggestion
 template: |

 LET ClientId = "C.622d19ea21109231"
 LET RequiredOrgId = "O123"
 LET ConfigPath = "C:/Program Files/Velociraptor/client.config.yaml"

 SELECT _client_config AS Config, OrgId ,
 collect_client(artifacts="Admin.Client.UpdateClientConfig",
 client_id=ClientId,
 env=dict(ConfigYaml=_client_config,
 ConfigPath=ConfigPath))
 FROM orgs()
 WHERE OrgId = RequiredOrgId
 LIMIT 1

&lt;/code>&lt;/pre></description></item><item><title>Admin.Client.Upgrade.Debian</title><link>https://docs.velociraptor.app/artifact_references/pages/admin.client.upgrade.debian/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/admin.client.upgrade.debian/</guid><description>&lt;p>Remotely push new client updates to Debian hosts.&lt;/p>
&lt;p>NOTE: This artifact requires that you supply a client Debian package by using the
tools interface or by using the &amp;ldquo;debian client&amp;rdquo; command. Simply click on the tool
in the GUI and upload a package.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Admin.Client.Upgrade.Debian
description: |
 Remotely push new client updates to Debian hosts.

 NOTE: This artifact requires that you supply a client Debian package by using the
 tools interface or by using the "debian client" command. Simply click on the tool
 in the GUI and upload a package.

tools:
 - name: VelociraptorDebian

parameters:
 - name: SleepDuration
 default: "600"
 type: int
 description: |
 The package is typically large and we do not want to
 overwhelm the server so we stagger the download over this many
 seconds.

 - name: ServiceName
 default: "velociraptor_client"
 type: str
 description: |
 The name of the service to restart after the upgrade.

implied_permissions:
 - EXECVE
 - FILESYSTEM_WRITE

sources:
 - precondition:
 SELECT OS From info() where OS =~ 'linux'

 query: |
 // FetchBinary downloads to /tmp on linux
 LET bin &amp;lt;= SELECT OSPath AS Dest
 FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="VelociraptorDebian", IsExecutable=FALSE,
 SleepDuration=SleepDuration)

 // Version handling for older clients.
 LET Rm(X) = if(
 condition=version(function='rm')!=NULL,
 then=rm(filename=X),
 else={ SELECT * FROM execve(argv=["rm", "-f", X]) })

 // Call the binary and return all its output in a single row.
 // If we fail to download the binary we do not run the command.
 SELECT * FROM foreach(row=bin,
 query={
 SELECT * FROM chain(
 // Remove the existing prerm - Previous versions had a bug that
 // would shutdown the service during uninstall. See #3122
 a={SELECT * FROM Rm(X="/var/lib/dpkg/info/velociraptor-client.prerm")},

 // Install the new client
 b={SELECT * FROM execve(argv=["dpkg", "-i", str(str=Dest)])},

 // Restart the client
 c={SELECT * FROM execve(argv=["systemctl", "restart", ServiceName])}
 )
 })

&lt;/code>&lt;/pre></description></item><item><title>Admin.Client.Upgrade.RedHat</title><link>https://docs.velociraptor.app/artifact_references/pages/admin.client.upgrade.redhat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/admin.client.upgrade.redhat/</guid><description>&lt;p>Remotely push new client updates to Red Hat hosts.&lt;/p>
&lt;p>NOTE: This artifact requires that you supply a client Red Hat package by using the
tools interface or by using the &amp;ldquo;rpm client&amp;rdquo; command. Simply click on the tool
in the GUI and upload a package.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Admin.Client.Upgrade.RedHat
description: |
 Remotely push new client updates to Red Hat hosts.

 NOTE: This artifact requires that you supply a client Red Hat package by using the
 tools interface or by using the "rpm client" command. Simply click on the tool
 in the GUI and upload a package.

tools:
 - name: VelociraptorRedHat

parameters:
 - name: SleepDuration
 default: "600"
 type: int
 description: |
 The package is typically large and we do not want to
 overwhelm the server so we stagger the download over this many
 seconds.

 - name: ServiceName
 default: "velociraptor_client"
 type: str
 description: |
 The name of the service to restart after the upgrade.

implied_permissions:
 - EXECVE

sources:
 - precondition:
 SELECT OS From info() where OS =~ 'linux'

 query: |
 // FetchBinary downloads to /tmp on linux
 LET bin &amp;lt;= SELECT OSPath AS Dest
 FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="VelociraptorRedHat", IsExecutable=FALSE,
 SleepDuration=SleepDuration)

 // Call the binary and return all its output in a single row.
 // If we fail to download the binary we do not run the command.
 SELECT * FROM foreach(row=bin,
 query={
 SELECT * FROM chain(
 // Install the new client (Disabled preun because older versions
 // had a bug where preun would shut down the service - see #3122).

 b={SELECT * FROM execve(argv=["rpm", "--nopreun", "-U", str(str=Dest)])},
 c={SELECT * FROM execve(argv=["systemctl", "restart", ServiceName])}
 )
 })

&lt;/code>&lt;/pre></description></item><item><title>Admin.Client.Upgrade.Windows</title><link>https://docs.velociraptor.app/artifact_references/pages/admin.client.upgrade.windows/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/admin.client.upgrade.windows/</guid><description>&lt;p>Remotely push new client updates.&lt;/p>
&lt;p>NOTE: This artifact requires that you supply a client MSI by using the
tools interface. Simply click on the tool in the GUI and upload a
pre-packaged MSI.&lt;/p>
&lt;p>While typically the MSI will contain the Velociraptor windows
client, you can install any other MSI as well by customizing this
artifact or uploading a different MSI file.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Admin.Client.Upgrade.Windows
description: |
 Remotely push new client updates.

 NOTE: This artifact requires that you supply a client MSI by using the
 tools interface. Simply click on the tool in the GUI and upload a
 pre-packaged MSI.

 While typically the MSI will contain the Velociraptor windows
 client, you can install any other MSI as well by customizing this
 artifact or uploading a different MSI file.

tools:
 - name: WindowsMSI

parameters:
 - name: SleepDuration
 default: "600"
 type: int
 description: |
 The MSI file is typically very large and we do not want to
 overwhelm the server so we stagger the download over this many
 seconds.

implied_permissions:
 - EXECVE
 - FILESYSTEM_WRITE

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 // Force the file to be copied to the real temp directory since
 // we are just about to remove the Tools directory.
 LET bin &amp;lt;= SELECT copy(filename=OSPath,
 dest=expand(path="%SYSTEMROOT%\\Temp\\") + basename(path=OSPath)) AS Dest
 FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="WindowsMSI", IsExecutable=FALSE,
 SleepDuration=SleepDuration)

 // Call the binary and return all its output in a single row.
 // If we fail to download the binary we do not run the command.
 SELECT * FROM foreach(row=bin,
 query={
 SELECT * FROM execve(
 argv=["msiexec.exe", "/i", Dest, "/q", "REINSTALL=ALL", "REINSTALLMODE=A"],
 length=10000000)
 })

&lt;/code>&lt;/pre></description></item><item><title>Demo.Plugins.Fifo</title><link>https://docs.velociraptor.app/artifact_references/pages/demo.plugins.fifo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/demo.plugins.fifo/</guid><description>&lt;p>This is a demo of the fifo() plugin. The Fifo plugin collects and
caches rows from its inner query. Every subsequent execution of the
query then reads from the cache. The plugin will expire old rows
depending on its expiration policy - so we always see recent rows.&lt;/p>
&lt;p>You can use this to build queries which consider historical events
together with current events at the same time. In this example, we
check for a successful logon preceded by several failed logon
attempts.&lt;/p>
&lt;p>In this example, we use the clock() plugin to simulate events. We
simulate failed logon attempts by using the clock() plugin every
second. By feeding the failed logon events to the fifo() plugin we
ensure the fifo() plugin cache contains the last 5 failed logon
events.&lt;/p>
&lt;p>We simulate a successful logon event every 3 seconds, again by using
the clock plugin. Once a successful logon event is detected, we go
back over the last 5 login events, count them and collect the last
failed logon times (using the GROUP BY operator we group the
FailedTime for every unique SuccessTime).&lt;/p>
&lt;p>If we receive more than 3 events, we emit the row.&lt;/p>
&lt;p>This now represents a high value signal! It will only occur when a
successful logon event is preceded by at least 3 failed logon
events in the last hour. It is now possible to escalate this on the
server via email or other alerts.&lt;/p>
&lt;p>Here is sample output:&lt;/p>
&lt;p>.. code-block:: json&lt;/p>
&lt;pre>&lt;code>{
 &amp;quot;Count&amp;quot;: 5,
 &amp;quot;FailedTime&amp;quot;: [
 1549527272,
 1549527273,
 1549527274,
 1549527275,
 1549527276
 ],
 &amp;quot;SuccessTime&amp;quot;: 1549527277
}
&lt;/code>&lt;/pre>
&lt;p>Of course in the real artifact we would want to include more
information than just times (i.e. who logged on to where etc).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Demo.Plugins.Fifo
description: |
 This is a demo of the fifo() plugin. The Fifo plugin collects and
 caches rows from its inner query. Every subsequent execution of the
 query then reads from the cache. The plugin will expire old rows
 depending on its expiration policy - so we always see recent rows.

 You can use this to build queries which consider historical events
 together with current events at the same time. In this example, we
 check for a successful logon preceded by several failed logon
 attempts.

 In this example, we use the clock() plugin to simulate events. We
 simulate failed logon attempts by using the clock() plugin every
 second. By feeding the failed logon events to the fifo() plugin we
 ensure the fifo() plugin cache contains the last 5 failed logon
 events.

 We simulate a successful logon event every 3 seconds, again by using
 the clock plugin. Once a successful logon event is detected, we go
 back over the last 5 login events, count them and collect the last
 failed logon times (using the GROUP BY operator we group the
 FailedTime for every unique SuccessTime).

 If we receive more than 3 events, we emit the row.

 This now represents a high value signal! It will only occur when a
 successful logon event is preceded by at least 3 failed logon
 events in the last hour. It is now possible to escalate this on the
 server via email or other alerts.

 Here is sample output:

 .. code-block:: json

 {
 "Count": 5,
 "FailedTime": [
 1549527272,
 1549527273,
 1549527274,
 1549527275,
 1549527276
 ],
 "SuccessTime": 1549527277
 }

 Of course in the real artifact we would want to include more
 information than just times (i.e. who logged on to where etc).
type: CLIENT_EVENT

sources:
 - query: |
 // This query simulates failed logon attempts.
 LET failed_logon = SELECT Unix as FailedTime from clock(period=1)

 // This is the fifo which holds the last 5 failed logon attempts
 // within the last hour.
 LET last_5_events = SELECT FailedTime
 FROM fifo(query=failed_logon, max_rows=5, max_age=3600)

 // We need to get it started collecting data immediately by
 // materializing the cache contents. Otherwise the fifo wont
 // start until it is first called (i.e. the first successful
 // login and we will miss the failed events before hand).
 LET foo &amp;lt;= SELECT * FROM last_5_events

 // This simulates successful logon - we assume every 3 seonds.
 LET success_logon = SELECT Unix as SuccessTime from clock(period=3)

 // For each successful logon, query the last failed logon
 // attempts from the fifo(). We also count the total number of
 // failed logons. We only actually emit results if there are more
 // than 3 failed logon attempts before each successful one.
 SELECT * FROM foreach(
 row=success_logon,
 query={
 SELECT SuccessTime,
 enumerate(items=FailedTime) as FailedTime,
 count(items=FailedTime) as Count
 FROM last_5_events GROUP BY SuccessTime
 }) WHERE Count &amp;gt; 3

&lt;/code>&lt;/pre></description></item><item><title>Demo.Plugins.GUI</title><link>https://docs.velociraptor.app/artifact_references/pages/demo.plugins.gui/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/demo.plugins.gui/</guid><description>&lt;p>A demo plugin showing some GUI features.&lt;/p>
&lt;p>This plugin is also used for tests.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Demo.Plugins.GUI
description: |
 A demo plugin showing some GUI features.

 This plugin is also used for tests.

resources:
 timeout: 20
 ops_per_second: 60
 max_rows: 213
 max_upload_bytes: 545454

parameters:
 - name: ChoiceSelector
 description: Choose one item from a selection
 type: choices
 default: First Choice
 choices:
 - First Choice
 - Second Choice
 - Third Choice

 - name: MultiChoiceSelector
 description: Choose one or more items from a selection
 type: multichoice
 default: '["Bananas"]'
 choices:
 - Apples
 - Bananas
 - Oranges
 - Grapes

 - name: Hashes
 validating_regex: '^\s*([A-F0-9]+\s*)+$'
 description: One or more hashes in hex separated by white space.

 - name: RegularExpression
 type: regex
 default: "."

 - name: MultipleRegularExpression
 type: regex_array
 default: '[".+"]'

 - name: YaraRule
 type: yara

 - name: Flag
 friendly_name: A Flag with a name
 type: bool
 default: True

 - name: Flag2
 type: bool
 default: Y

 - name: Flag3
 type: bool
 default: Y

 - name: OffFlag
 type: bool

 - name: StartDate
 type: timestamp

 - name: StartDate2
 type: timestamp

 - name: StartDate3
 type: timestamp

 - name: CSVData
 type: csv
 default: |
 Column1,Column2
 A,B
 C,D

 - name: JSONData
 type: json_array
 default: '["First","Second"]'

 - name: JSONDataWithObject
 type: json_array
 default: |
 [{"foo": "bar"}]

 - name: FileUpload1
 type: upload
 description: |
 FileUpload1 can receive a file upload.

 The upload content will be available in this variable when
 executing on the client.

 - name: FileUpload2
 type: upload_file
 description: |
 FileUpload2 can receive a file upload.

 The upload content will be stored in a temp file which will be
 available in this variable when executing on the client.

 - name: ArtifactSelections
 type: artifactset
 description: A selection of artifact
 artifact_type: CLIENT_EVENT
 default: |
 Artifact
 Windows.Detection.PsexecService
 Windows.Events.ProcessCreation
 Windows.Events.ServiceCreation

column_types:
 - name: Base64Hex
 type: base64hex

sources:
 - query: |
 SELECT base64encode(string="This should popup in a hex editor") AS Base64Hex,
 ChoiceSelector, MultiChoiceSelector, Flag, Flag2, Flag3,
 OffFlag, StartDate, StartDate2, StartDate3,
 CSVData, JSONData, JSONDataWithObject,
 len(list=FileUpload1) AS FileUpload1Length,
 stat(filename=FileUpload2) AS FileUpload2Stats
 FROM scope()

 notebook:
 - type: vql_suggestion
 name: Test Suggestion
 template: |
 /*
 # This is a suggestion notebook cell.

 It should be available from the suggestions list.
 */
 SELECT * FROM info()

 - type: markdown
 name: Test Template
 template: |
 # GUI Notebook tests

 The following cells are testing the notebook in the flow. To
 run this test simply collect the `Demo.Plugins.GUI` artifact
 and check the output is correct.

 **Each of the below cells should have a H2 heading**

 ## Check that notebook environment variables are populated

 Some of these are populated from the artifact parameters.

 {{ $x := Query "LET X = scope() SELECT * FROM items(\
 item=dict(NotebookId=X.NotebookId, ClientId=X.ClientId,\
 FlowId=X.FlowId, ArtifactName=X.ArtifactName, \
 ChoiceSelector=X.ChoiceSelector, StartDate=X.StartDate, \
 HuntId=X.HuntId))" | Expand }}

 {{ range $x }}
 * {{ Get . "_key" }} - {{ Get . "_value" }}
 {{- end -}}

 - type: markdown
 name: Test Code Highlighting
 template: |
 ## Code syntax highlighting for VQL

 ```vql
 SELECT * FROM info()
 ```

 - type: vql
 name: Test Markdown in VQL cell
 template: |
 /*
 ## A VQL cell with a heading.
 */
 LET ColumnTypes = dict(
 Time1="timestamp",
 Time2="timestamp",
 Time3="timestamp",
 Time4="timestamp",
 FlowId="flow",
 ClientId="client",
 Data="hex",
 URL="url",
 SafeURL="safe_url", // Present dialog before click.
 Base64Data="base64hex"
 )

 LET Base64Data = base64encode(string="\x00\x01\x20\x32\x12\x10")
 LET URL = "[Google](https://www.google.com)"

 SELECT 1628609690.1 AS Raw,

 -- float
 1628609690.1 AS Time1,

 -- ms as a string
 "1628609690100" AS Time2,

 -- ns
 1628609690100000 AS Time3,

 -- Standard string form
 "2021-08-10T15:34:50Z" AS Time4,

 FlowId, ClientId, URL, URL AS SafeURL, Base64Data,

 format(format="%02x", args="Hello") AS Data,
 TRUE, 4, NULL
 FROM scope()

 - type: VQL
 name: Test Default ColumnTypes
 template: |
 /*
 ## Ensure that Base64hex data is automatically typed
 */
 SELECT base64encode(string="This should popup in a hex editor") AS Base64Hex FROM scope()

 - type: Markdown
 name: Scatter Chart
 template: |
 ## Scatter Chart with a named column

 {{ define "ScatterTest" }}
 SELECT X, Name, Y, Y3
 FROM parse_csv(accessor="data", filename='''
 X,Name,Y,Y3
 1,Bob,2,3
 2,Frank,4,6
 3,Mike,6,8
 4,Sally,3,2
 ''')
 {{ end }}
 {{ Query "ScatterTest" | ScatterChart "name_column" "Name" }}

 ## Stacked Bar Chart (Categories are first column)

 {{ define "Test" }}
 SELECT X, Y, Y3
 FROM parse_csv(accessor="data", filename='''
 X,Y,Y3
 Bob,2,3
 Bill,4,6
 Foo,6,8
 Bar,7,2
 ''')
 {{ end }}
 {{ Query "Test" | BarChart "type" "stacked" }}

 ## Time chart with timestamp in first column

 {{ define "TimeTest" }}
 SELECT Timestamp, Y, Y3
 FROM parse_csv(accessor="data", filename='''
 Timestamp,Y,Y3
 2021-10-09,2,3
 2021-10-10,4,6
 2021-10-11,6,8
 2021-10-12,7,2
 ''')
 {{ end }}
 {{ Query "TimeTest" | TimeChart }}

 ## Line chart

 {{ define "LineTest" }}
 SELECT X, Y, Y3
 FROM parse_csv(accessor="data", filename='''
 X,Y,Y3
 1,2,3
 2,4,6
 3,6,8
 4,7,2
 ''')
 {{ end }}
 {{ Query "LineTest" | LineChart }}

 - type: Markdown
 name: Line Chart
 template: |
 ## A Line Chart

 The following should show a CPU load chart of the last 10 min.

 {{ define "Q" }}
 SELECT _ts, CPUPercent
 FROM monitoring(
 client_id="server",
 artifact="Server.Monitor.Health/Prometheus",
 start_time=now() - 10 * 60)
 LIMIT 100
 {{ end }}

 {{ Query "Q" | TimeChart }}

 - type: vql
 name: Test Timeline
 template: |
 /*
 ## Adding timelines

 Add a timeline from this time series data. (This only works
 for root org because it relies on server health events).

 */
 SELECT timestamp(epoch=_ts) AS Timestamp, CPUPercent
 FROM monitoring(
 client_id="server",
 source="Prometheus",
 artifact="Server.Monitor.Health",
 start_time=now() - 10 * 60)

 LET T1 = SELECT
 timestamp(epoch=_ts) AS Timestamp,
 dict(X=CPUPercent, Y=1) AS Dict
 FROM monitoring(
 client_id="server",
 source="Prometheus",
 artifact="Server.Monitor.Health",
 start_time=now() - 10 * 60)

 -- Add the time series into the timeline.
 SELECT timeline_add(
 key="Timestamp", name="Time 你好世界 'line' &amp;amp;\" ",
 query=T1, timeline="Test \"Timeline 你好世界\""),
 timeline_add(
 key="Timestamp", name="2",
 query=T1, timeline="Test \"Timeline 你好世界\"")
 FROM scope()

 - type: Markdown
 name: Test Cell Environment
 env:
 - key: Timeline
 value: Test "Timeline 你好世界"
 template: |
 ## This super timeline should have two timelines.

 Add a timeline manually and hit refresh on this cell to
 check it is being updated.

 {{ Scope "Timeline" | Timeline }}

 - type: VQL
 name: Test Table Scrolling
 template: |
 /*
 # Test table scrolling.

 Check both expanded and contracted states of the cell
 */
 LET zalgo = "1̴̣̜̗̰͇͖͖̞̮͈͍̂͜.̸̢̧̨͙̻̜̰̼̔̿̓̄̀̅͌̈́͒͗̈́̒̕̚͜͠e̶̙̞̬̹̥͖̤̟͑͒̂̀̔͠x̵̛̱̠̳͍̦̘̤̙͚̙͈̬́̈́͂̎̽̇̀͝ę̵̯̦̫͖͖͍͈̟̠͉̥͒̑̐̏̕̚̕͜͠"
 LET Test = "Hellothereongline" + zalgo

 SELECT Test AS Test1, Test AS Test2, Test AS Test3,
 Test AS Test4, Test AS Test5,
 Test AS Test11, Test AS Test21,
 Test AS Test13, Test AS Test14, Test AS Test15,
 Test AS Test21, Test AS Test22,
 Test AS Test23, Test AS Test24, Test AS Test25
 FROM range(start=0, end=100, step=1)

 - type: VQL
 name: Test Column Types
 template: |
 /*
 # Column types set in the artifact's `column_types` field

 These apply to notebooks automatically without needing to
 define them again.

 * Hash column should right click to VT
 * upload preview should show the uploaded file.

 */

 LET ColumnTypes = dict(`StartDate`='timestamp', Download='download',
 Hex='hex', Upload='preview_upload')
 LET Hex = "B0 EC 48 5F 18 77"

 SELECT Hex, StartDate, hash(accessor="data", path="Hello") AS Hash,
 upload(accessor="data", file="Hello world",
 name="test.txt") AS Upload,
 upload(accessor="data", file="Hello world",
 name="test.txt") AS Download
 FROM source()

 - type: VQL
 name: Test JSON renderer
 template: |
 /* Test the JSON renderer. */
 LET Strings = SELECT "Hello World" AS A FROM range(end=100)

 LET MultiColumn = SELECT * FROM chain(a={
 SELECT 1 AS A FROM range(end=10)
 }, b={
 SELECT 1 AS B FROM range(end=10)
 })

 SELECT dict(
 MultiColumn=MultiColumn,
 Strings=Strings.A,
 `NULL`=NULL,
 Bool=TRUE,
 BoolF=FALSE,
 BinaryData=base64encode(string="hello world"),
 Rows={
 SELECT count() AS Count,
 rand() AS R
 FROM range(end=20)
 },
 Integer=1, Float=1.235,
 LongString="Hello world " * 100,
 MixedList=[1, 2, dict(A=3)],
 NestedDict=dict(
 Foo=dict(A=1,
 B=dict(z=1,
 nesting=dict(Foo="Hello world"))))) AS A
 FROM scope()

 - type: VQL
 name: Test Links
 template: |
 /*
 # Test the link_to() VQL Function
 */
 LET ColumnTypes &amp;lt;= dict(
 LinkToFlow="url_internal",
 LinkToHunt="url_internal",
 LinkToArtifact="url_internal",
 Download="url_internal",
 LinkToClient="url_internal")

 LET s = scope()
 LET Uploaded &amp;lt;= upload(accessor="data", file="Hello", name="test.txt")

 SELECT link_to(client_id=ClientId, flow_id=s.FlowId || "F.123") AS LinkToFlow,
 link_to(client_id=ClientId) AS LinkToClient,
 link_to(hunt_id=s.HuntId || "H.123") AS LinkToHunt,
 link_to(artifact=ArtifactName) AS LinkToArtifact,
 link_to(upload=Uploaded) AS Download
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Elastic.EventLogs.Sysmon</title><link>https://docs.velociraptor.app/artifact_references/pages/elastic.eventlogs.sysmon/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/elastic.eventlogs.sysmon/</guid><description>&lt;p>Ships the the Sysmon event log in ECS schema.&lt;/p>
&lt;p>The Elastic Common Schema (ECS) is an open source specification,
developed with support from the Elastic user community. ECS defines
a common set of fields to be used when storing event data in
Elasticsearch, such as logs and metrics.&lt;/p>
&lt;p>NOTE: ECS is poorly documented. There is no clear documentation of
where each field in the ECS record comes from other than the actual
source code of the Winlogbeat client. This artifact implements the
Winlogbeat transformation as described in
&lt;a href="https://github.com/elastic/beats/blob/master/x-pack/winlogbeat/module/sysmon/ingest/sysmon.yml" target="_blank" >https://github.com/elastic/beats/blob/master/x-pack/winlogbeat/module/sysmon/ingest/sysmon.yml&lt;/a>
&lt;/p>
&lt;p>There may be slight variations between the data produced by this
artifact and the official Winlogbeat client. If you find such
variation, please file an issue on Velociraptor&amp;rsquo;s GitHub issue
board.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Elastic.EventLogs.Sysmon
description: |
 Ships the the Sysmon event log in ECS schema.

 The Elastic Common Schema (ECS) is an open source specification,
 developed with support from the Elastic user community. ECS defines
 a common set of fields to be used when storing event data in
 Elasticsearch, such as logs and metrics.

 NOTE: ECS is poorly documented. There is no clear documentation of
 where each field in the ECS record comes from other than the actual
 source code of the Winlogbeat client. This artifact implements the
 Winlogbeat transformation as described in
 https://github.com/elastic/beats/blob/master/x-pack/winlogbeat/module/sysmon/ingest/sysmon.yml

 There may be slight variations between the data produced by this
 artifact and the official Winlogbeat client. If you find such
 variation, please file an issue on Velociraptor's GitHub issue
 board.

reference:
 - https://www.elastic.co/guide/en/ecs/current/ecs-reference.html

parameters:
 - name: LogFileGlob
 default: C:/Windows/System32/WinEvt/Logs/Microsoft-Windows-Sysmon%4Operational.evtx

export: |
 -- ECS clears many fields from EventData but we preserve them all,
 -- although to ensure that Elastic does not reject the fields we
 -- convert them all to strings.
 LET NormalizeEventData(EventData) = to_dict(item={
 SELECT _key, str(str=_value) AS _value FROM items(item=EventData)
 })

 LET OpcodesLookup &amp;lt;= dict(
 `0`= "Info",
 `1`= "Start",
 `2`= "Stop",
 `3`= "DCStart",
 `4`= "DCStop",
 `5`= "Extension",
 `6`= "Reply",
 `7`= "Resume",
 `8`= "Suspend",
 `9`= "Send")

 LET LevelLookup &amp;lt;= dict(
 `0`= "Information",
 `1`= "Critical",
 `2`= "Error",
 `3`= "Warning",
 `4`= "Information",
 `5`= "Verbose")

 LET CategoryLookup &amp;lt;= dict(
 `1`=["process",],
 `2`=["file",],
 `3`=["network",],
 `4`=["process",],
 `5`=["process",],
 `6`=["driver",],
 `7`=["process",],
 `8`=["process",],
 `9`=["process",],
 `10`=["process",],
 `11`=["file",],
 `12`=["configuration","registry"],
 `13`=["configuration","registry"],
 `14`=["configuration","registry"],
 `15`=["file",],
 `16`=["configuration",],
 `17`=["file",],
 `18`=["file",],
 `19`=["process",],
 `20`=["process",],
 `21`=["network",],
 `22`=["network",],
 `23`=["file",],
 `24`=["",],
 `25`=["process",],
 `26`=["file",],
 `27`=["file",],
 `28`=["file",],
 `255`=["process",])

 LET TypeLookup &amp;lt;= dict(
 `1`=["start",],
 `2`=["change",],
 `3`=["start", "connection", "protocol"],
 `4`=["change",],
 `5`=["end",],
 `6`=["start",],
 `7`=["change",],
 `8`=["change",],
 `9`=["access",],
 `10`=["access",],
 `11`=["creation",],
 `12`=["change",],
 `13`=["change",],
 `14`=["change",],
 `15`=["access",],
 `16`=["change",],
 `17`=["creation",],
 `18`=["access",],
 `19`=["creation",],
 `20`=["creation",],
 `21`=["access",],
 `22`=["connection", "protocol", "info"],
 `23`=["deletion",],
 `24`=["change",],
 `25`=["change",],
 `26`=["deletion",],
 `27`=["creation", "denied"],
 `28`=["deletion", "denied"],
 `255`=["error",])

 LET DNSLookup &amp;lt;= dict(
 `1`= "A",
 `2`= "NS",
 `3`= "MD",
 `4`= "MF",
 `5`= "CNAME",
 `6`= "SOA",
 `7`= "MB",
 `8`= "MG",
 `9`= "MR",
 `10`= "NULL",
 `11`= "WKS",
 `12`= "PTR",
 `13`= "HINFO",
 `14`= "MINFO",
 `15`= "MX",
 `16`= "TXT",
 `17`= "RP",
 `18`= "AFSDB",
 `19`= "X25",
 `20`= "ISDN",
 `21`= "RT",
 `22`= "NSAP",
 `23`= "NSAPPTR",
 `24`= "SIG",
 `25`= "KEY",
 `26`= "PX",
 `27`= "GPOS",
 `28`= "AAAA",
 `29`= "LOC",
 `30`= "NXT",
 `31`= "EID",
 `32`= "NIMLOC",
 `33`= "SRV",
 `34`= "ATMA",
 `35`= "NAPTR",
 `36`= "KX",
 `37`= "CERT",
 `38`= "A6",
 `39`= "DNAME",
 `40`= "SINK",
 `41`= "OPT",
 `43`= "DS",
 `46`= "RRSIG",
 `47`= "NSEC",
 `48`= "DNSKEY",
 `49`= "DHCID",
 `100`= "UINFO",
 `101`= "UID",
 `102`= "GID",
 `103`= "UNSPEC",
 `248`= "ADDRS",
 `249`= "TKEY",
 `250`= "TSIG",
 `251`= "IXFR",
 `252`= "AXFR",
 `253`= "MAILB",
 `254`= "MAILA",
 `255`= "ANY",
 `65281`= "WINS",
 `65282`= "WINSR"
 )

 LET DnsStatusLookup &amp;lt;= dict(
 `5`= "ERROR_ACCESS_DENIED",
 `0`= "SUCCESS",
 `8`= "ERROR_NOT_ENOUGH_MEMORY",
 `13`= "ERROR_INVALID_DATA",
 `14`= "ERROR_OUTOFMEMORY",
 `123`= "ERROR_INVALID_NAME",
 `1214`= "ERROR_INVALID_NETNAME",
 `1223`= "ERROR_CANCELLED",
 `1460`= "ERROR_TIMEOUT",
 `4312`= "ERROR_OBJECT_NOT_FOUND",
 `9001`= "DNS_ERROR_RCODE_FORMAT_ERROR",
 `9002`= "DNS_ERROR_RCODE_SERVER_FAILURE",
 `9003`= "DNS_ERROR_RCODE_NAME_ERROR",
 `9004`= "DNS_ERROR_RCODE_NOT_IMPLEMENTED",
 `9005`= "DNS_ERROR_RCODE_REFUSED",
 `9006`= "DNS_ERROR_RCODE_YXDOMAIN",
 `9007`= "DNS_ERROR_RCODE_YXRRSET",
 `9008`= "DNS_ERROR_RCODE_NXRRSET",
 `9009`= "DNS_ERROR_RCODE_NOTAUTH",
 `9010`= "DNS_ERROR_RCODE_NOTZONE",
 `9016`= "DNS_ERROR_RCODE_BADSIG",
 `9017`= "DNS_ERROR_RCODE_BADKEY",
 `9018`= "DNS_ERROR_RCODE_BADTIME",
 `9101`= "DNS_ERROR_KEYMASTER_REQUIRED",
 `9102`= "DNS_ERROR_NOT_ALLOWED_ON_SIGNED_ZONE",
 `9103`= "DNS_ERROR_NSEC3_INCOMPATIBLE_WITH_RSA_SHA1",
 `9104`= "DNS_ERROR_NOT_ENOUGH_SIGNING_KEY_DESCRIPTORS",
 `9105`= "DNS_ERROR_UNSUPPORTED_ALGORITHM",
 `9106`= "DNS_ERROR_INVALID_KEY_SIZE",
 `9107`= "DNS_ERROR_SIGNING_KEY_NOT_ACCESSIBLE",
 `9108`= "DNS_ERROR_KSP_DOES_NOT_SUPPORT_PROTECTION",
 `9109`= "DNS_ERROR_UNEXPECTED_DATA_PROTECTION_ERROR",
 `9110`= "DNS_ERROR_UNEXPECTED_CNG_ERROR",
 `9111`= "DNS_ERROR_UNKNOWN_SIGNING_PARAMETER_VERSION",
 `9112`= "DNS_ERROR_KSP_NOT_ACCESSIBLE",
 `9113`= "DNS_ERROR_TOO_MANY_SKDS",
 `9114`= "DNS_ERROR_INVALID_ROLLOVER_PERIOD",
 `9115`= "DNS_ERROR_INVALID_INITIAL_ROLLOVER_OFFSET",
 `9116`= "DNS_ERROR_ROLLOVER_IN_PROGRESS",
 `9117`= "DNS_ERROR_STANDBY_KEY_NOT_PRESENT",
 `9118`= "DNS_ERROR_NOT_ALLOWED_ON_ZSK",
 `9119`= "DNS_ERROR_NOT_ALLOWED_ON_ACTIVE_SKD",
 `9120`= "DNS_ERROR_ROLLOVER_ALREADY_QUEUED",
 `9121`= "DNS_ERROR_NOT_ALLOWED_ON_UNSIGNED_ZONE",
 `9122`= "DNS_ERROR_BAD_KEYMASTER",
 `9123`= "DNS_ERROR_INVALID_SIGNATURE_VALIDITY_PERIOD",
 `9124`= "DNS_ERROR_INVALID_NSEC3_ITERATION_COUNT",
 `9125`= "DNS_ERROR_DNSSEC_IS_DISABLED",
 `9126`= "DNS_ERROR_INVALID_XML",
 `9127`= "DNS_ERROR_NO_VALID_TRUST_ANCHORS",
 `9128`= "DNS_ERROR_ROLLOVER_NOT_POKEABLE",
 `9129`= "DNS_ERROR_NSEC3_NAME_COLLISION",
 `9130`= "DNS_ERROR_NSEC_INCOMPATIBLE_WITH_NSEC3_RSA_SHA1",
 `9501`= "DNS_INFO_NO_RECORDS",
 `9502`= "DNS_ERROR_BAD_PACKET",
 `9503`= "DNS_ERROR_NO_PACKET",
 `9504`= "DNS_ERROR_RCODE",
 `9505`= "DNS_ERROR_UNSECURE_PACKET",
 `9506`= "DNS_REQUEST_PENDING",
 `9551`= "DNS_ERROR_INVALID_TYPE",
 `9552`= "DNS_ERROR_INVALID_IP_ADDRESS",
 `9553`= "DNS_ERROR_INVALID_PROPERTY",
 `9554`= "DNS_ERROR_TRY_AGAIN_LATER",
 `9555`= "DNS_ERROR_NOT_UNIQUE",
 `9556`= "DNS_ERROR_NON_RFC_NAME",
 `9557`= "DNS_STATUS_FQDN",
 `9558`= "DNS_STATUS_DOTTED_NAME",
 `9559`= "DNS_STATUS_SINGLE_PART_NAME",
 `9560`= "DNS_ERROR_INVALID_NAME_CHAR",
 `9561`= "DNS_ERROR_NUMERIC_NAME",
 `9562`= "DNS_ERROR_NOT_ALLOWED_ON_ROOT_SERVER",
 `9563`= "DNS_ERROR_NOT_ALLOWED_UNDER_DELEGATION",
 `9564`= "DNS_ERROR_CANNOT_FIND_ROOT_HINTS",
 `9565`= "DNS_ERROR_INCONSISTENT_ROOT_HINTS",
 `9566`= "DNS_ERROR_DWORD_VALUE_TOO_SMALL",
 `9567`= "DNS_ERROR_DWORD_VALUE_TOO_LARGE",
 `9568`= "DNS_ERROR_BACKGROUND_LOADING",
 `9569`= "DNS_ERROR_NOT_ALLOWED_ON_RODC",
 `9570`= "DNS_ERROR_NOT_ALLOWED_UNDER_DNAME",
 `9571`= "DNS_ERROR_DELEGATION_REQUIRED",
 `9572`= "DNS_ERROR_INVALID_POLICY_TABLE",
 `9573`= "DNS_ERROR_ADDRESS_REQUIRED",
 `9601`= "DNS_ERROR_ZONE_DOES_NOT_EXIST",
 `9602`= "DNS_ERROR_NO_ZONE_INFO",
 `9603`= "DNS_ERROR_INVALID_ZONE_OPERATION",
 `9604`= "DNS_ERROR_ZONE_CONFIGURATION_ERROR",
 `9605`= "DNS_ERROR_ZONE_HAS_NO_SOA_RECORD",
 `9606`= "DNS_ERROR_ZONE_HAS_NO_NS_RECORDS",
 `9607`= "DNS_ERROR_ZONE_LOCKED",
 `9608`= "DNS_ERROR_ZONE_CREATION_FAILED",
 `9609`= "DNS_ERROR_ZONE_ALREADY_EXISTS",
 `9610`= "DNS_ERROR_AUTOZONE_ALREADY_EXISTS",
 `9611`= "DNS_ERROR_INVALID_ZONE_TYPE",
 `9612`= "DNS_ERROR_SECONDARY_REQUIRES_MASTER_IP",
 `9613`= "DNS_ERROR_ZONE_NOT_SECONDARY",
 `9614`= "DNS_ERROR_NEED_SECONDARY_ADDRESSES",
 `9615`= "DNS_ERROR_WINS_INIT_FAILED",
 `9616`= "DNS_ERROR_NEED_WINS_SERVERS",
 `9617`= "DNS_ERROR_NBSTAT_INIT_FAILED",
 `9618`= "DNS_ERROR_SOA_DELETE_INVALID",
 `9619`= "DNS_ERROR_FORWARDER_ALREADY_EXISTS",
 `9620`= "DNS_ERROR_ZONE_REQUIRES_MASTER_IP",
 `9621`= "DNS_ERROR_ZONE_IS_SHUTDOWN",
 `9622`= "DNS_ERROR_ZONE_LOCKED_FOR_SIGNING",
 `9651`= "DNS_ERROR_PRIMARY_REQUIRES_DATAFILE",
 `9652`= "DNS_ERROR_INVALID_DATAFILE_NAME",
 `9653`= "DNS_ERROR_DATAFILE_OPEN_FAILURE",
 `9654`= "DNS_ERROR_FILE_WRITEBACK_FAILED",
 `9655`= "DNS_ERROR_DATAFILE_PARSING",
 `9701`= "DNS_ERROR_RECORD_DOES_NOT_EXIST",
 `9702`= "DNS_ERROR_RECORD_FORMAT",
 `9703`= "DNS_ERROR_NODE_CREATION_FAILED",
 `9704`= "DNS_ERROR_UNKNOWN_RECORD_TYPE",
 `9705`= "DNS_ERROR_RECORD_TIMED_OUT",
 `9706`= "DNS_ERROR_NAME_NOT_IN_ZONE",
 `9707`= "DNS_ERROR_CNAME_LOOP",
 `9708`= "DNS_ERROR_NODE_IS_CNAME",
 `9709`= "DNS_ERROR_CNAME_COLLISION",
 `9710`= "DNS_ERROR_RECORD_ONLY_AT_ZONE_ROOT",
 `9711`= "DNS_ERROR_RECORD_ALREADY_EXISTS",
 `9712`= "DNS_ERROR_SECONDARY_DATA",
 `9713`= "DNS_ERROR_NO_CREATE_CACHE_DATA",
 `9714`= "DNS_ERROR_NAME_DOES_NOT_EXIST",
 `9715`= "DNS_WARNING_PTR_CREATE_FAILED",
 `9716`= "DNS_WARNING_DOMAIN_UNDELETED",
 `9717`= "DNS_ERROR_DS_UNAVAILABLE",
 `9718`= "DNS_ERROR_DS_ZONE_ALREADY_EXISTS",
 `9719`= "DNS_ERROR_NO_BOOTFILE_IF_DS_ZONE",
 `9720`= "DNS_ERROR_NODE_IS_DNAME",
 `9721`= "DNS_ERROR_DNAME_COLLISION",
 `9722`= "DNS_ERROR_ALIAS_LOOP",
 `9751`= "DNS_INFO_AXFR_COMPLETE",
 `9752`= "DNS_ERROR_AXFR",
 `9753`= "DNS_INFO_ADDED_LOCAL_WINS",
 `9801`= "DNS_STATUS_CONTINUE_NEEDED",
 `9851`= "DNS_ERROR_NO_TCPIP",
 `9852`= "DNS_ERROR_NO_DNS_SERVERS",
 `9901`= "DNS_ERROR_DP_DOES_NOT_EXIST",
 `9902`= "DNS_ERROR_DP_ALREADY_EXISTS",
 `9903`= "DNS_ERROR_DP_NOT_ENLISTED",
 `9904`= "DNS_ERROR_DP_ALREADY_ENLISTED",
 `9905`= "DNS_ERROR_DP_NOT_AVAILABLE",
 `9906`= "DNS_ERROR_DP_FSMO_ERROR",
 `9911`= "DNS_ERROR_RRL_NOT_ENABLED",
 `9912`= "DNS_ERROR_RRL_INVALID_WINDOW_SIZE",
 `9913`= "DNS_ERROR_RRL_INVALID_IPV4_PREFIX",
 `9914`= "DNS_ERROR_RRL_INVALID_IPV6_PREFIX",
 `9915`= "DNS_ERROR_RRL_INVALID_TC_RATE",
 `9916`= "DNS_ERROR_RRL_INVALID_LEAK_RATE",
 `9917`= "DNS_ERROR_RRL_LEAK_RATE_LESSTHAN_TC_RATE",
 `9921`= "DNS_ERROR_VIRTUALIZATION_INSTANCE_ALREADY_EXISTS",
 `9922`= "DNS_ERROR_VIRTUALIZATION_INSTANCE_DOES_NOT_EXIST",
 `9923`= "DNS_ERROR_VIRTUALIZATION_TREE_LOCKED",
 `9924`= "DNS_ERROR_INVAILD_VIRTUALIZATION_INSTANCE_NAME",
 `9925`= "DNS_ERROR_DEFAULT_VIRTUALIZATION_INSTANCE",
 `9951`= "DNS_ERROR_ZONESCOPE_ALREADY_EXISTS",
 `9952`= "DNS_ERROR_ZONESCOPE_DOES_NOT_EXIST",
 `9953`= "DNS_ERROR_DEFAULT_ZONESCOPE",
 `9954`= "DNS_ERROR_INVALID_ZONESCOPE_NAME",
 `9955`= "DNS_ERROR_NOT_ALLOWED_WITH_ZONESCOPES",
 `9956`= "DNS_ERROR_LOAD_ZONESCOPE_FAILED",
 `9957`= "DNS_ERROR_ZONESCOPE_FILE_WRITEBACK_FAILED",
 `9958`= "DNS_ERROR_INVALID_SCOPE_NAME",
 `9959`= "DNS_ERROR_SCOPE_DOES_NOT_EXIST",
 `9960`= "DNS_ERROR_DEFAULT_SCOPE",
 `9961`= "DNS_ERROR_INVALID_SCOPE_OPERATION",
 `9962`= "DNS_ERROR_SCOPE_LOCKED",
 `9963`= "DNS_ERROR_SCOPE_ALREADY_EXISTS",
 `9971`= "DNS_ERROR_POLICY_ALREADY_EXISTS",
 `9972`= "DNS_ERROR_POLICY_DOES_NOT_EXIST",
 `9973`= "DNS_ERROR_POLICY_INVALID_CRITERIA",
 `9974`= "DNS_ERROR_POLICY_INVALID_SETTINGS",
 `9975`= "DNS_ERROR_CLIENT_SUBNET_IS_ACCESSED",
 `9976`= "DNS_ERROR_CLIENT_SUBNET_DOES_NOT_EXIST",
 `9977`= "DNS_ERROR_CLIENT_SUBNET_ALREADY_EXISTS",
 `9978`= "DNS_ERROR_SUBNET_DOES_NOT_EXIST",
 `9979`= "DNS_ERROR_SUBNET_ALREADY_EXISTS",
 `9980`= "DNS_ERROR_POLICY_LOCKED",
 `9981`= "DNS_ERROR_POLICY_INVALID_WEIGHT",
 `9982`= "DNS_ERROR_POLICY_INVALID_NAME",
 `9983`= "DNS_ERROR_POLICY_MISSING_CRITERIA",
 `9984`= "DNS_ERROR_INVALID_CLIENT_SUBNET_NAME",
 `9985`= "DNS_ERROR_POLICY_PROCESSING_ORDER_INVALID",
 `9986`= "DNS_ERROR_POLICY_SCOPE_MISSING",
 `9987`= "DNS_ERROR_POLICY_SCOPE_NOT_ALLOWED",
 `9988`= "DNS_ERROR_SERVERSCOPE_IS_REFERENCED",
 `9989`= "DNS_ERROR_ZONESCOPE_IS_REFERENCED",
 `9990`= "DNS_ERROR_POLICY_INVALID_CRITERIA_CLIENT_SUBNET",
 `9991`= "DNS_ERROR_POLICY_INVALID_CRITERIA_TRANSPORT_PROTOCOL",
 `9992`= "DNS_ERROR_POLICY_INVALID_CRITERIA_NETWORK_PROTOCOL",
 `9993`= "DNS_ERROR_POLICY_INVALID_CRITERIA_INTERFACE",
 `9994`= "DNS_ERROR_POLICY_INVALID_CRITERIA_FQDN",
 `9995`= "DNS_ERROR_POLICY_INVALID_CRITERIA_QUERY_TYPE",
 `9996`= "DNS_ERROR_POLICY_INVALID_CRITERIA_TIME_OF_DAY",
 `10054`= "WSAECONNRESET",
 `10055`= "WSAENOBUFS",
 `10060`= "WSAETIMEDOUT"
 )

 LET ParseDNSAnswers(X) = SELECT if(condition=_value =~ "^type",
 then=dict(
 data=parse_string_with_regex(
 string=regex_replace(source=_value, replace="", re="::ffff:"),
 regex="(?P&amp;lt;Data&amp;gt;[^\\s]+)$").Data,
 type=get(item=DNSLookup,
 field=parse_string_with_regex(
 string=_value, regex="type:\\s+([0-9]+)").g1)),
 else=dict(
 data=regex_replace(source=_value, replace="", re="::ffff:"),
 type=if(condition=regex_replace(source=_value, replace="", re="::ffff:") =~ ":",
 then="AAAA", else="A")
 )) AS Field
 FROM foreach(row=split(string=X, sep=";"))
 WHERE _value

 LET ParseHashes(Hashes) = to_dict(item={
 SELECT split(string=_value, sep="=")[0] AS _key,
 split(string=_value, sep="=")[1] AS _value
 FROM foreach(row=split(string=Hashes, sep=","))
 })

 LET _EventToECSBase(System, EventData) = dict(
 ecs=dict(version="1.12.0"),
 log=dict(level=System.Level),
 event=dict(
 module="sysmon",
 kind="event",
 code=System.EventID.Value,
 category=get(item=CategoryLookup, field=str(str=System.EventID.Value)),
 type=get(item=TypeLookup, field=str(str=System.EventID.Value)),
 created=timestamp(epoch=System.TimeCreated.SystemTime)
 ),
 error=dict(
 code=if(condition=System.EventID.Value = 255, then=EventData.ID, else=0)
 ),
 rule=dict(
 name=EventData.RuleName
 ),
 message=if(condition=System.EventID.Value = 255, then=EventData.Type, else=""),
 winlog=dict(
 api="wineventlog",
 channel=System.Channel,
 computer_name=System.Computer,
 event_data=NormalizeEventData(EventData=EventData),
 event_id=System.EventID.Value ,
 opcode=get(item=OpcodesLookup, field=str(str=System.Opcode)),
 process=dict(
 pid=System.Execution.ProcessID,
 thread=dict(
 id=System.Execution.ThreadID
 )
 ),
 provider_guid=System.Provider.Guid,
 provider_name=System.Provider.Name,
 record_id=str(str=System.EventRecordID),
 user=dict(
 identifier=System.Security.UserID
 )
 )
 )

 LET _EventToECSProcess(System, EventData) = dict(
 process=dict(
 hash=ParseHashes(Hashes=EventData.Hashes),
 entity_id=EventData.ProcessGuid || EventData.SourceProcessGuid || EventData.SourceProcessGUID,
 pid=EventData.ProcessId || EventData.SourceProcessId,
 executable=EventData.Image || EventData.SourceImage || EventData.Destination,
 command_line=EventData.CommandLine,
 working_directory=EventData.CurrentDirectory,
 parent=dict(
 pid=EventData.ParentProcessId,
 entity_id= EventData.ParentProcessGuid,
 executable=EventData.ParentImage,
 command_line=EventData.ParentCommandLine,
 args=commandline_split(command=EventData.ParentCommandLine),
 args_count=len(list=commandline_split(command=EventData.ParentCommandLine)),
 name=pathspec(parse=EventData.ParentImage, path_type="windows").Basename
 ),
 thread=dict(
 id= EventData.SourceThreadId || 0
 ),
 pe=if(condition=System.EventID.Value != 7, then=dict(
 original_file_name=EventData.OriginalFileName || "",
 company=EventData.Company || "",
 description=EventData.Description || "",
 file_version=EventData.FileVersion || "",
 product= EventData.Product || ""
 )),
 args=commandline_split(command=EventData.CommandLine),
 args_count=len(list=commandline_split(command=EventData.CommandLine)),
 name=pathspec(parse=EventData.Image, path_type="windows").Basename
 )
 )

 LET _EventToECSNetwork(System, EventData) = dict(
 network=dict(
 transport=EventData.Protocol,
 protocol=if(condition=System.EventID.Value = 22, then="dns", else=EventData.DestinationPortName || EventData.SourcePortName),
 direction=if(condition= EventData.Initiated, then="egress", else="ingress"),
 type=if(condition= EventData.SourceIsIpv6, then="ipv6", else="ipv4")
 ),
 source=dict(
 ip=EventData.SourceIp,
 domain=EventData.SourceHostname,
 port=EventData.SourcePort
 ),
 destination=dict(
 ip=EventData.DestinationIp,
 domain=EventData.DestinationHostname,
 port=EventData.DestinationPort
 ),
 dns=dict(
 answers=ParseDNSAnswers(X=EventData.QueryResults).Field,
 question=dict(
 name=EventData.QueryName
 ),
 status=get(item=DnsStatusLookup, field=str(str=EventData.QueryStatus))
 )
 )

 LET _ParseRegData(X) = if(condition=X =~ "^DWORD",
 then=dict(
 strings=[str(str=int(int= parse_string_with_regex(string=X, regex="\\((.+?)\\)").g1)),],
 type="DWORD"),
 else=if(condition=X =~ "^Binary Data",
 then=dict(
 strings=["Binary Data",],
 type="REG_BINARY"),
 else=if(condition=X =~ "^QWORD",
 then=dict(
 strings=[str(str=int(int= regex_replace(re="-0x", replace="",
 source=parse_string_with_regex(string=X, regex="\\((.+?)\\)").g1))),],
 type="QWORD"),
 else=dict(strings=X, type=parse_string_with_regex(string=X, regex="(^[^\\S]+)").g1)
 )
 ))

 LET _EventToECSRegistry(System, EventData) = dict(
 process=dict(
 entity_id=EventData.ProcessGuid || EventData.SourceProcessGuid || EventData.SourceProcessGUID,
 pid=EventData.ProcessId || EventData.SourceProcessId,
 executable=EventData.Image || EventData.SourceImage || EventData.Destination,
 name=pathspec(parse=EventData.Image, path_type="windows").Basename
 ),
 registry=dict(
 hive=pathspec(parse=EventData.TargetObject, path_type="registry")[0],
 key=pathspec(parse=EventData.TargetObject, path_type="registry")[1:],
 path=EventData.TargetObject,
 value=pathspec(parse=EventData.TargetObject, path_type="registry").Basename,
 data= _ParseRegData(X=EventData.Details)
 )
 )

 LET _EventToECSFile(System, EventData) = dict(
 file=dict(
 path=EventData.TargetFilename || EventData.Device || EventData.ImageLoaded,
 directory=pathspec(parse=EventData.TargetFilename || EventData.Device || EventData.ImageLoaded, path_type="windows").Dirname,
 name=EventData.PipeName || pathspec(parse=EventData.TargetFilename || EventData.Device || EventData.ImageLoaded, path_type="windows").Basename,
 code_signature=dict(
 subject_name= EventData.Signature || "",
 status = EventData.SignatureStatus || "",
 signed=if(condition=EventData.Signed, then=TRUE, else=FALSE),
 valid=EventData.SignatureStatus = "Valid"
 ),
 process=dict(
 entity_id=EventData.ProcessGuid || EventData.SourceProcessGuid || EventData.SourceProcessGUID,
 pid=EventData.ProcessId || EventData.SourceProcessId,
 executable=EventData.Image || EventData.SourceImage || EventData.Destination,
 name=pathspec(parse=EventData.Image, path_type="windows").Basename,
 hash=ParseHashes(Hashes=EventData.Hash)
 ),
 pe=dict(
 original_file_name=EventData.OriginalFileName || "",
 company=EventData.Company || "",
 description=EventData.Description || "",
 file_version=EventData.FileVersion || "",
 product=EventData.Product || ""
 ),
 sysmon=dict(
 file=dict(
 archived=if(condition=EventData.Archived =~ "true", then=TRUE, else=FALSE),
 is_executable=if(condition=EventData.is_executable, then=TRUE, else=FALSE)
 )
 )
 )
 )

 LET SysmonEventToECS(System, EventData) = _EventToECSBase(System=System, EventData=EventData) + if(
 condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "process",
 then=_EventToECSProcess(System=System, EventData=EventData),
 else=if(
 condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "network",
 then=_EventToECSNetwork(System=System, EventData=EventData),
 else=if(
 condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "registry",
 then=_EventToECSRegistry(System=System, EventData=EventData),
 else=if(
 condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "file",
 then=_EventToECSFile(System=System, EventData=EventData),
 else=dict()))))

sources:
 - query: |
 SELECT * FROM foreach(row={
 SELECT * FROM foreach(row={
 SELECT OSPath FROM glob(globs=LogFileGlob)
 }, query={
 SELECT SysmonEventToECS(System=System, EventData=EventData) AS ECS
 FROM parse_evtx(filename=OSPath)
 })
 }, column="ECS")

 notebook:
 - type: vql_suggestion
 name: "Upload to Elastic"
 template: |
 /*
 * Modify the Elastic parameters to upload this dataset.
 * You might need to add authentication to Elastic.
 */
 LET ElasicAddress = "http://localhost:9200"

 // Uncomment this when you are ready to upload the data
 LET X = SELECT *
 FROM elastic_upload(
 addresses=ElasicAddress,
 index="winlogbeat-velo",
 action="create",
 query={
 SELECT timestamp(epoch=now()) AS `@timestamp`,
 ClientId,
 client_info(client_id=ClientId).Hostname AS Hostname,
 *
 FROM source(artifact="Elastic.EventLogs.Sysmon")
 LIMIT 10
 })

&lt;/code>&lt;/pre></description></item><item><title>Elastic.Events.Clients</title><link>https://docs.velociraptor.app/artifact_references/pages/elastic.events.clients/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/elastic.events.clients/</guid><description>&lt;p>This server monitoring artifact will watch a selection of client or
server monitoring artifacts for new events and push those to an
elastic index.&lt;/p>
&lt;p>NOTE: You must ensure you are collecting these artifacts from the
clients by adding them to the &amp;ldquo;Client Events&amp;rdquo; GUI, or for server
artifacts, the &amp;ldquo;Server Events&amp;rdquo; GUI.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Elastic.Events.Upload
aliases:
- Elastic.Events.Clients

description: |
 This server monitoring artifact will watch a selection of client or
 server monitoring artifacts for new events and push those to an
 elastic index.

 NOTE: You must ensure you are collecting these artifacts from the
 clients by adding them to the "Client Events" GUI, or for server
 artifacts, the "Server Events" GUI.

type: SERVER_EVENT

parameters:
 - name: ElasticAddresses
 default: http://127.0.0.1:9200/
 - name: Username
 - name: Password
 - name: APIKey
 - name: ClientArtifactsToWatch
 type: artifactset
 artifact_type: CLIENT_EVENT
 default: |
 Artifact
 Windows.Detection.PsexecService
 Windows.Events.ProcessCreation
 Windows.Events.ServiceCreation
 - name: ServerArtifactsToWatch
 type: artifactset
 artifact_type: SERVER_EVENT
 default: |
 Artifact
 Server.Audit.Logs
 - name: DisableSSLSecurity
 type: bool
 description: Disable SSL certificate verification
 - name: Threads
 type: int
 description: Number of threads to upload with
 - name: ChunkSize
 type: int
 description: Batch this many rows for each upload.
 - name: CloudID
 description: The cloud id if needed
 - name: RootCA
 description: |
 A root CA certificate in PEM for trusting TLS protected Elastic
 servers.

sources:
 - query: |
 LET artifacts_to_watch = SELECT * FROM chain(
 a={SELECT Artifact FROM ClientArtifactsToWatch},
 b={SELECT Artifact FROM ServerArtifactsToWatch})
 WHERE NOT Artifact =~ "Elastic.Events.Upload"
 AND log(message="Uploading artifact " + Artifact + " to Elastic")

 LET s = scope()

 LET events = SELECT * FROM foreach(
 row=artifacts_to_watch,
 async=TRUE, // Required for event queries in foreach()
 query={
 SELECT *, "Artifact_" + Artifact as _index,
 Artifact,
 client_info(client_id=s.ClientId || "server").os_info.hostname AS Hostname,
 timestamp(epoch=now()) AS timestamp
 FROM watch_monitoring(artifact=Artifact)
 })

 SELECT * FROM elastic_upload(
 query=events,
 threads=Threads,
 chunk_size=ChunkSize,
 addresses=split(string=ElasticAddresses, sep=","),
 index="velociraptor",
 password=Password,
 username=Username,
 cloud_id=CloudID,
 api_key=APIKey,
 root_ca=RootCA,
 disable_ssl_security=DisableSSLSecurity,
 type="ClientEvents")

&lt;/code>&lt;/pre></description></item><item><title>Elastic.Events.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/elastic.events.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/elastic.events.upload/</guid><description>&lt;p>This server monitoring artifact will watch a selection of client or
server monitoring artifacts for new events and push those to an
elastic index.&lt;/p>
&lt;p>NOTE: You must ensure you are collecting these artifacts from the
clients by adding them to the &amp;ldquo;Client Events&amp;rdquo; GUI, or for server
artifacts, the &amp;ldquo;Server Events&amp;rdquo; GUI.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Elastic.Events.Upload
aliases:
- Elastic.Events.Clients

description: |
 This server monitoring artifact will watch a selection of client or
 server monitoring artifacts for new events and push those to an
 elastic index.

 NOTE: You must ensure you are collecting these artifacts from the
 clients by adding them to the "Client Events" GUI, or for server
 artifacts, the "Server Events" GUI.

type: SERVER_EVENT

parameters:
 - name: ElasticAddresses
 default: http://127.0.0.1:9200/
 - name: Username
 - name: Password
 - name: APIKey
 - name: ClientArtifactsToWatch
 type: artifactset
 artifact_type: CLIENT_EVENT
 default: |
 Artifact
 Windows.Detection.PsexecService
 Windows.Events.ProcessCreation
 Windows.Events.ServiceCreation
 - name: ServerArtifactsToWatch
 type: artifactset
 artifact_type: SERVER_EVENT
 default: |
 Artifact
 Server.Audit.Logs
 - name: DisableSSLSecurity
 type: bool
 description: Disable SSL certificate verification
 - name: Threads
 type: int
 description: Number of threads to upload with
 - name: ChunkSize
 type: int
 description: Batch this many rows for each upload.
 - name: CloudID
 description: The cloud id if needed
 - name: RootCA
 description: |
 A root CA certificate in PEM for trusting TLS protected Elastic
 servers.

sources:
 - query: |
 LET artifacts_to_watch = SELECT * FROM chain(
 a={SELECT Artifact FROM ClientArtifactsToWatch},
 b={SELECT Artifact FROM ServerArtifactsToWatch})
 WHERE NOT Artifact =~ "Elastic.Events.Upload"
 AND log(message="Uploading artifact " + Artifact + " to Elastic")

 LET s = scope()

 LET events = SELECT * FROM foreach(
 row=artifacts_to_watch,
 async=TRUE, // Required for event queries in foreach()
 query={
 SELECT *, "Artifact_" + Artifact as _index,
 Artifact,
 client_info(client_id=s.ClientId || "server").os_info.hostname AS Hostname,
 timestamp(epoch=now()) AS timestamp
 FROM watch_monitoring(artifact=Artifact)
 })

 SELECT * FROM elastic_upload(
 query=events,
 threads=Threads,
 chunk_size=ChunkSize,
 addresses=split(string=ElasticAddresses, sep=","),
 index="velociraptor",
 password=Password,
 username=Username,
 cloud_id=CloudID,
 api_key=APIKey,
 root_ca=RootCA,
 disable_ssl_security=DisableSSLSecurity,
 type="ClientEvents")

&lt;/code>&lt;/pre></description></item><item><title>Elastic.Flows.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/elastic.flows.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/elastic.flows.upload/</guid><description>&lt;p>This server side event monitoring artifact waits for new artifacts
to be collected from endpoints and automatically uploads those to an
elastic server.&lt;/p>
&lt;p>We use the artifact name as the name of the index. This allows users
to adjust the index size/lifetime according to the artifact it is
holding.&lt;/p>
&lt;p>NOTE: Elastic is a database and still must have a stable
schema. This means that artifacts that produce inconsistent columns
and types will &lt;strong>NOT&lt;/strong> work as expected. What will happen is that
the first row that is inserted will create the Elastic database
schema (In Elastic terminology &amp;ldquo;mapping&amp;rdquo;) and then any subsequent
row with a different type for these fields will be rejected by
Elastic.&lt;/p>
&lt;p>In particular this does not work with event logs because event logs
have a varied schema (The EventData field is a free form field
depending on the event log itself). Therefore forwarding event log
data to Elastic with this artifact will cause Elastic to drop many
events!! This artifact is not suitable for forwarding Windows Event
Logs!&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Elastic.Flows.Upload
description: |
 This server side event monitoring artifact waits for new artifacts
 to be collected from endpoints and automatically uploads those to an
 elastic server.

 We use the artifact name as the name of the index. This allows users
 to adjust the index size/lifetime according to the artifact it is
 holding.

 NOTE: Elastic is a database and still must have a stable
 schema. This means that artifacts that produce inconsistent columns
 and types will **NOT** work as expected. What will happen is that
 the first row that is inserted will create the Elastic database
 schema (In Elastic terminology "mapping") and then any subsequent
 row with a different type for these fields will be rejected by
 Elastic.

 In particular this does not work with event logs because event logs
 have a varied schema (The EventData field is a free form field
 depending on the event log itself). Therefore forwarding event log
 data to Elastic with this artifact will cause Elastic to drop many
 events!! This artifact is not suitable for forwarding Windows Event
 Logs!

type: SERVER_EVENT

parameters:
 - name: ArtifactNameRegex
 default: .
 type: regex
 description: Only upload these artifacts to elastic
 - name: elasticAddresses
 default: http://127.0.0.1:9200/
 - name: Username
 - name: Password
 - name: APIKey
 - name: DisableSSLSecurity
 type: bool
 description: Disable SSL certificate verification
 - name: Threads
 type: int
 description: Number of threads to upload with
 - name: ChunkSize
 type: int
 description: Batch this many rows for each upload.
 - name: CloudID
 description: The cloud id if needed
 - name: RootCA
 description: |
 A root CA certificate in PEM for trusting TLS protected Elastic
 servers.

sources:
 - query: |
 LET completions = SELECT * FROM watch_monitoring(
 artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactNameRegex
 LET organization &amp;lt;= org().name

 LET documents = SELECT * FROM foreach(row=completions,
 query={
 SELECT * FROM foreach(
 row=Flow.artifacts_with_results,
 query={
 SELECT *, _value AS Artifact,
 client_info(client_id=ClientId).os_info.hostname AS Hostname,
 timestamp(epoch=now()) AS timestamp,
 ClientId, Flow.session_id AS FlowId,
 "artifact_" + regex_replace(source=_value,
 re='[/.]', replace='_') as _index,
 organization as Organization
 FROM source(
 client_id=ClientId,
 flow_id=Flow.session_id,
 artifact=_value)
 })
 })

 SELECT * FROM elastic_upload(
 query=documents,
 threads=Threads,
 chunk_size=ChunkSize,
 addresses=split(string=elasticAddresses, sep=","),
 index="velociraptor",
 password=Password,
 username=Username,
 cloud_id=CloudID,
 api_key=APIKey,
 root_ca=RootCA,
 disable_ssl_security=DisableSSLSecurity,
 type="artifact")

&lt;/code>&lt;/pre></description></item><item><title>Generic.Applications.Chrome.SessionStorage</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.applications.chrome.sessionstorage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.applications.chrome.sessionstorage/</guid><description>&lt;p>Session storage allows a web site to store permanent data in the
user&amp;rsquo;s browser.&lt;/p>
&lt;p>This artifact parses this data from the browser cache. Each website
has maintains a mapping between keys and values. The data is stored
per website and can vary.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Applications.Chrome.SessionStorage
description: |
 Session storage allows a web site to store permanent data in the
 user's browser.

 This artifact parses this data from the browser cache. Each website
 has maintains a mapping between keys and values. The data is stored
 per website and can vary.

parameters:
- name: SessionGlobs
 type: csv
 default: |
 Glob
 C:/Users/*/AppData/Local/Google/Chrome/User Data/*/Session Storage
 C:/Users/*/AppData/Local/BraveSoftware/Brave*/User Data/*/Session Storage
 C:/Users/*/AppData/Local/Microsoft/Edge/User Data/*/Session Storage
 /home/*/.config/google-chrome/*/Session Storage
 /home/*/.config/chrome-remote-desktop/chrome-profile/*/Session Storage
 /Users/*/Library/Application Support/BraveSoftware/Brave*/*/Session Storage
 /Users/*/Library/Application Support/Google/Chrome/*/Session Storage
 /Users/*/Library/Application Support/Microsoft Edge/*/Session Storage

- name: Accessor
- name: AlsoUpload
 type: bool
 description: If selected we also upload the Session Storage directory.

sources:
- query: |
 LET _ &amp;lt;= log(message="Glob %v", args= [SessionGlobs.Glob, ])
 LET _GetMapping(Data, ID) = to_dict(item={
 SELECT _key AS RawKey,
 parse_string_with_regex(string=_key,
 regex='map-([^-]+)-(?P&amp;lt;Key&amp;gt;.+)').Key AS _key,
 utf16(string=_value) AS _value
 FROM items(item=Data)
 WHERE RawKey =~ format(format="map-%v", args=ID)
 })

 LET DumpSessionStorate(Data) =
 SELECT parse_string_with_regex(string=_key,
 regex='''namespace-(?P&amp;lt;GUID&amp;gt;[^-]+)-(?P&amp;lt;URL&amp;gt;.+)''') AS Parsed,
 _value, _GetMapping(Data=Data, ID=_value) AS Mapping
 FROM items(item=Data)
 WHERE Parsed.URL

 LET hits = SELECT OSPath, to_dict(item={

 -- Load the whole thing into memory since we need to make
 -- several passes on it.
 SELECT Key AS _key, Value AS _value FROM leveldb(file=OSPath, accessor= Accessor)
 }) AS Data
 FROM glob(globs= SessionGlobs.Glob, accessor= Accessor)

 SELECT * FROM foreach(row={
 SELECT OSPath, Data, if(condition=AlsoUpload, then={
 SELECT upload(file=OSPath) AS Upload
 FROM glob(globs="*", root=OSPath, accessor= Accessor)
 }) AS Upload
 FROM hits
 WHERE log(message="Processing %v", args=OSPath)

 }, query={
 SELECT OSPath,
 Parsed.GUID AS GUID,
 Parsed.URL AS URL,
 Mapping
 FROM DumpSessionStorate(Data=Data)
 })

&lt;/code>&lt;/pre></description></item><item><title>Generic.Applications.Office.Keywords</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.applications.office.keywords/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.applications.office.keywords/</guid><description>&lt;p>Microsoft Office documents among other document format (such as
LibraOffice) are actually stored in zip files. The zip file contains
the document encoded as XML in several zip members.&lt;/p>
&lt;p>This makes it difficult to search for keywords within office
documents because the ZIP files are typically compressed.&lt;/p>
&lt;p>This artifact searches for office documents by file extension and
glob then uses the zip filesystem accessor to launch a YARA scan
again the uncompressed data of the document. Keywords are more
likely to match when scanning the decompressed XML data.&lt;/p>
&lt;p>The artifact returns a context around the keyword hit.&lt;/p>
&lt;p>NOTE: The InternalMtime column shows the creation time of the zip
member within the document which may represent when the document was
initially created.&lt;/p>
&lt;p>See
&lt;a href="https://en.wikipedia.org/wiki/List_of_Microsoft_Office_filename_extensions" target="_blank" >https://en.wikipedia.org/wiki/List_of_Microsoft_Office_filename_extensions&lt;/a>

&lt;a href="https://wiki.openoffice.org/wiki/Documentation/OOo3_User_Guides/Getting_Started/File_formats" target="_blank" >https://wiki.openoffice.org/wiki/Documentation/OOo3_User_Guides/Getting_Started/File_formats&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Applications.Office.Keywords
description: |
 Microsoft Office documents among other document format (such as
 LibraOffice) are actually stored in zip files. The zip file contains
 the document encoded as XML in several zip members.

 This makes it difficult to search for keywords within office
 documents because the ZIP files are typically compressed.

 This artifact searches for office documents by file extension and
 glob then uses the zip filesystem accessor to launch a YARA scan
 again the uncompressed data of the document. Keywords are more
 likely to match when scanning the decompressed XML data.

 The artifact returns a context around the keyword hit.

 NOTE: The InternalMtime column shows the creation time of the zip
 member within the document which may represent when the document was
 initially created.

 See
 https://en.wikipedia.org/wiki/List_of_Microsoft_Office_filename_extensions
 https://wiki.openoffice.org/wiki/Documentation/OOo3_User_Guides/Getting_Started/File_formats

parameters:
 - name: documentGlobs
 default: /*.{docx,docm,dotx,dotm,docb,xlsx,xlsm,xltx,xltm,pptx,pptm,potx,potm,ppam,ppsx,ppsm,sldx,sldm,odt,ott,oth,odm}
 - name: searchGlob
 default: C:\Users\**
 - name: yaraRule
 type: yara
 default: |
 rule Hit {
 strings:
 $a = "secret" wide nocase
 $b = "secret" nocase

 condition:
 any of them
 }

sources:
 - query: |
 LET office_docs = SELECT OSPath AS OfficePath,
 Mtime as OfficeMtime,
 Size as OfficeSize
 FROM glob(globs=searchGlob + documentGlobs)

 // A list of zip members inside the doc that have some content.
 LET document_parts = SELECT OfficePath,
 OSPath AS ZipMemberPath
 FROM glob(
 globs="/**",
 root=pathspec(DelegatePath=OfficePath),
 accessor='zip')
 WHERE not IsDir and Size &amp;gt; 0

 // For each document, scan all its parts for the keyword.
 SELECT OfficePath,
 OfficeMtime,
 OfficeSize,
 File.ModTime as InternalMtime,
 String.HexData as HexContext,
 File.OSPath AS OSPath
 FROM foreach(
 row=office_docs,
 query={
 SELECT File, String, OfficePath,
 OfficeMtime, OfficeSize
 FROM yara(
 rules=yaraRule,
 files=document_parts.ZipMemberPath,
 context=200,
 accessor='zip')
 })

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.CleanupTemp</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.cleanuptemp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.cleanuptemp/</guid><description>&lt;p>This artifact cleans up the temp folder in the Velociraptor client.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.CleanupTemp
description: |
 This artifact cleans up the temp folder in the Velociraptor client.

parameters:
 - name: TempGlob
 default: "%TEMP%/**"
 description: Glob to find all the files in the temp folder.
 - name: AgeSeconds
 default: 600
 type: int
 description: Any files older than this many seconds will be removed.
 - name: ReadllyDoIt
 type: bool

required_permissions:
 - FILESYSTEM_WRITE

sources:
 - query: |
 LET Threshold &amp;lt;= timestamp(epoch=now() - AgeSeconds )
 SELECT OSPath, Size, Mtime,
 if(condition=ReadllyDoIt, then=rm(filename=OSPath)) AS Removed
 FROM glob(globs=expand(path=TempGlob))
 WHERE NOT IsDir AND Mtime &amp;lt; Threshold

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.DiskSpace</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.diskspace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.diskspace/</guid><description>&lt;p>This artifact reports the amount of free disk space. It is designed
to work equally on all architectures:&lt;/p>
&lt;ol>
&lt;li>On Linux and MacOS we call &lt;code>df -h&lt;/code>.&lt;/li>
&lt;li>On Windows we use WMI&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.DiskSpace
description: |
 This artifact reports the amount of free disk space. It is designed
 to work equally on all architectures:

 1. On Linux and MacOS we call `df -h`.
 2. On Windows we use WMI

implied_permissions:
 - EXECVE

sources:
- query: |
 LET NonWindows = SELECT * FROM foreach(row={
 SELECT regex_replace(source=Stdout, re="( on| +)", replace=" ") AS Stdout
 FROM execve(argv=["df", "-h"], length=10000)
 }, query={
 SELECT * FROM parse_csv(accessor="data", filename=Stdout, separator=" ")
 })

 -- WMI returns these as strings, we need to convert to ints
 LET wmi_query = SELECT *,
 int(int=FreeSpace) AS FreeSpace,
 int(int=Size) AS Size
 FROM wmi(query="SELECT * FROM Win32_LogicalDisk")

 LET Windows = SELECT DeviceID, Description,
 VolumeName, VolumeSerialNumber,
 humanize(bytes=Size) AS Size,
 humanize(bytes=FreeSpace) AS FreeSpace,
 int(int=FreeSpace / Size * 100) AS `Free%`
 FROM wmi_query

 SELECT * FROM if(condition={
 SELECT OS FROM info() WHERE OS =~ "windows"
 },
 then={ SELECT * FROM Windows},
 else={ SELECT * FROM NonWindows})

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.DiskUsage</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.diskusage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.diskusage/</guid><description>&lt;p>This artifact reports the amount of space used by each directory
recursively (Similar to the &lt;code>du&lt;/code> command).&lt;/p>
&lt;p>Unlike the &lt;code>du&lt;/code> command, this artifact can filter only certain file
name patterns.&lt;/p>
&lt;p>If you change the &lt;code>TopLevelDirectory&lt;/code> to the drive letter
(e.g. &lt;code>C:\\&lt;/code>) it may take a while to complete as it will need to
examine every file on the drive.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.DiskUsage
description: |
 This artifact reports the amount of space used by each directory
 recursively (Similar to the `du` command).

 Unlike the `du` command, this artifact can filter only certain file
 name patterns.

 If you change the `TopLevelDirectory` to the drive letter
 (e.g. `C:\\`) it may take a while to complete as it will need to
 examine every file on the drive.

parameters:
 - name: TopLevelDirectory
 default: C:/Program Files
 description: The top level directory to start calculating disk usage.

 - name: FilenameGlob
 default: '*'
 description: A Glob expression for considering files

 - name: DirectoryGlob
 default: '*'
 description: A Glob expression for considering directories to recurse into.

sources:
 - query: |
 LET Res &amp;lt;= dict()

 LET _DirInfo(DirPath) = SELECT DirPath, Size, sum(item=Size) AS TotalSize
 FROM chain(a={
 SELECT Size FROM glob(globs=FilenameGlob, root=DirPath)
 WHERE NOT IsDir
 }, b={
 SELECT * FROM foreach(row={
 SELECT OSPath FROM glob(globs=DirectoryGlob, root=DirPath)
 WHERE IsDir
 },
 query={
 SELECT TotalSize AS Size FROM DirInfo(DirPath=OSPath)
 })
 })
 GROUP BY 1 -- Needed for sum()

 LET DirInfo(DirPath) = SELECT * FROM _DirInfo(DirPath=DirPath)
 WHERE set(item=Res, field=DirPath,
 value=dict(DirPath=DirPath, TotalSize=TotalSize))

 -- Recurse into the TopLevelDirectory and rely on the set()
 -- above to store the results.
 LET _ &amp;lt;= SELECT * FROM DirInfo(DirPath=TopLevelDirectory)

 SELECT *, humanize(bytes=TotalSize) AS TotalSizeHuman
 FROM foreach(row={
 SELECT * FROM items(item=Res)
 }, column="_value")
 ORDER BY TotalSize DESC

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.Info</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.info/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.info/</guid><description>&lt;p>Collect basic information about the client.&lt;/p>
&lt;p>This artifact is collected when any new client is enrolled into the
system. Velociraptor will watch for this artifact and populate its
internal indexes from this artifact as well.&lt;/p>
&lt;p>You can edit this artifact to enhance the client&amp;rsquo;s interrogation
information as required, by adding new sources.&lt;/p>
&lt;p>NOTE: Do not modify the BasicInformation source since it is used to
interrogate the clients.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.Info
description: |
 Collect basic information about the client.

 This artifact is collected when any new client is enrolled into the
 system. Velociraptor will watch for this artifact and populate its
 internal indexes from this artifact as well.

 You can edit this artifact to enhance the client's interrogation
 information as required, by adding new sources.

 NOTE: Do not modify the BasicInformation source since it is used to
 interrogate the clients.

sources:
 - name: BasicInformation
 description: |
 This source is used internally to populate agent info. Do not
 modify or remove this query.
 query: |
 LET Interfaces = SELECT HardwareAddrString AS MAC
 FROM interfaces()
 WHERE HardwareAddr

 SELECT config.Version.Name AS Name,
 config.Version.BuildTime as BuildTime,
 config.Version.Version as Version,
 config.Version.ci_build_url AS build_url,
 config.Version.install_time as install_time,
 config.Labels AS Labels,
 Hostname, OS, Architecture,
 Platform, PlatformVersion, KernelVersion, Fqdn,
 Interfaces.MAC AS MACAddresses
 FROM info()

 - name: DetailedInfo
 query: |
 LET Info = SELECT * FROM info()
 SELECT _key AS Param, _value AS Value FROM items(item=Info[0])

 - name: LinuxInfo
 description: Linux specific information about the host
 precondition: SELECT OS From info() where OS = 'linux'
 query: |
 SELECT if(condition=version(function='sysinfo') != NULL, then=sysinfo()) AS `Computer Info`,
 { SELECT Name, HardwareAddrString AS MACAddress,
 Up, PointToPoint,
 AddrsString AS IPAddresses
 FROM interfaces() WHERE HardwareAddr} AS `Network Info`
 FROM scope()

 - name: WindowsInfo
 description: Windows specific information about the host
 precondition: SELECT OS From info() where OS = 'windows'
 query: |
 LET DomainLookup &amp;lt;= dict(
 `0`='Standalone Workstation',
 `1`='Member Workstation',
 `2`='Standalone Server',
 `3`='Member Server',
 `4`='Backup Domain Controller',
 `5`='Primary Domain Controller')

 SELECT
 {
 SELECT DNSHostName, Name, Domain, TotalPhysicalMemory,
 get(item=DomainLookup,
 field=str(str=DomainRole), default="Unknown") AS DomainRole
 FROM wmi(
 query='SELECT * FROM win32_computersystem')
 } AS `Computer Info`,
 {
 SELECT Caption,
 join(array=IPAddress, sep=", ") AS IPAddresses,
 join(array=IPSubnet, sep=", ") AS IPSubnet,
 MACAddress,
 join(array=DefaultIPGateway, sep=", ") AS DefaultIPGateway,
 DNSHostName,
 join(array=DNSServerSearchOrder, sep=", ") AS DNSServerSearchOrder
 FROM wmi(
 query="SELECT * from Win32_NetworkAdapterConfiguration" )
 WHERE IPAddress
 } AS `Network Info`
 FROM scope()

 notebook:
 - type: vql_suggestion
 name: "Enumerate Domain Roles"
 template: |
 /*
 # Enumerate Domain Roles

 Search all clients' enrollment information for their domain roles.
 */
 --
 -- Remove the below comments to label Domain Controllers
 SELECT *--, label(client_id=client_id, labels="DomainController", op="set") AS Label
 FROM foreach(row={
 SELECT * FROM clients()
 }, query={
 SELECT
 `Computer Info`.Name AS Name, client_id,
 `Computer Info`.DomainRole AS DomainRole
 FROM source(client_id=client_id,
 flow_id=last_interrogate_flow_id,
 source="WindowsInfo")
 })
 -- WHERE DomainRole =~ "Controller"

 - name: Users
 precondition: SELECT OS From info() where OS = 'windows'
 query: |
 SELECT Name, Description, Mtime AS LastLogin
 FROM Artifact.Windows.Sys.Users()

reports:
 - type: CLIENT
 template: |
 {{ $client_info := Query "SELECT * FROM clients(client_id=ClientId) LIMIT 1" | Expand }}

 {{ $flow_id := Query "SELECT timestamp(epoch=active_time / 1000000) AS Timestamp FROM flows(client_id=ClientId, flow_id=FlowId)" | Expand }}

 # {{ Get $client_info "0.os_info.fqdn" }} ( {{ Get $client_info "0.client_id" }} ) @ {{ Get $flow_id "0.Timestamp" }}

 {{ Query "SELECT * FROM source(source='BasicInformation')" | Table }}

 # Memory and CPU footprint over the past 24 hours

 {{ define "resources" }}
 SELECT * FROM sample(
 n=4,
 query={
 SELECT Timestamp,
 rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
 RSS / 1000000 AS MemoryUse
 FROM source(artifact="Generic.Client.Stats",
 client_id=ClientId,
 start_time=now() - 86400)
 WHERE CPUPercent &amp;gt;= 0
 })
 {{ end }}

 {{ define "computerinfo" }}
 LET X &amp;lt;= SELECT *
 FROM source(source="LinuxInfo')
 LIMIT 1

 SELECT humanize(bytes=TotalPhysicalMemory) AS TotalPhysicalMemory,
 humanize(bytes=TotalFreeMemory) AS TotalFreeMemory,
 humanize(bytes=TotalSharedMemory) AS TotalSharedMemory,
 humanize(bytes=TotalSwap) AS TotalSwap,
 humanize(bytes=FreeSwap) AS FreeSwap
 FROM foreach(row=X[0].`Computer Info`)
 {{ end }}

 &amp;lt;div&amp;gt;
 {{ Query "resources" | TimeChart "RSS.yaxis" 2 }}
 &amp;lt;/div&amp;gt;

 {{ $windows_info := Query "SELECT * FROM source(source='WindowsInfo')" }}
 {{ if $windows_info | Expand }}
 # Windows agent information
 {{ $windows_info | Table }}
 {{ end }}

 {{ $linux_info := Query "LET X &amp;lt;= SELECT * FROM source(source='LinuxInfo') LIMIT 1 SELECT * FROM X" }}
 {{ if Query "SELECT * FROM source(source='LinuxInfo')" | Expand }}
 # Linux agent information

 ### Network Info
 {{ Query "SELECT * FROM foreach(row=X[0].`Network Info`)" | Table }}

 ### Computer Info
 {{ Query "computerinfo" | Table }}

 {{ end }}

 # Active Users
 {{ Query "SELECT * FROM source(source='Users')" | Table }}


column_types:
 - name: BuildTime
 type: timestamp
 - name: LastLogin
 type: timestamp

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.LocalLogs</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.locallogs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.locallogs/</guid><description>&lt;p>Write client logs locally in an encrypted container. This helps when
we need to access what the client was doing in the past.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.LocalLogs
description: |
 Write client logs locally in an encrypted container. This helps when
 we need to access what the client was doing in the past.

type: CLIENT_EVENT

parameters:
- name: LocalFilename
 default: "%TEMP%/locallogs.log"
 description: The local filename that will be written (Env variables will be expanded).
- name: MaxRows
 type: int
 default: "100"
 description: Flush the file when we cache this many rows.
- name: MaxWait
 default: "60"
 type: int
 description: Flush the file at least every this many seconds.
- name: MaxSize
 default: "100000000"
 type: int
 description: Truncate the file once it reaches this length.
- name: AlsoForward
 type: bool
 description: |
 By default we do not forward any of the logs to the server but
 this allows logs to be forwarded as well as written locally.
- name: Component
 default: generic
 description: The log component to forward (default "generic")
 type: choices
 choices:
 - generic
 - client
 - frontend
 - gui
 - api

sources:
- query: |
 LET _ &amp;lt;= log(message="Writing local log to " + expand(path=LocalFilename))

 SELECT * FROM write_crypto_file(
 max_rows=MaxRows, max_wait=MaxWait, max_size=MaxSize,
 filename=expand(path=LocalFilename),
 query={
 SELECT timestamp(epoch=now()) AS Timestamp, *
 FROM logging(component=Component)
 })
 WHERE AlsoForward

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.LocalLogsRetrieve</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.locallogsretrieve/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.locallogsretrieve/</guid><description>&lt;p>Retrives the locally written logs.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.LocalLogsRetrieve
description: |
 Retrives the locally written logs.

type: CLIENT

parameters:
- name: LocalFilename
 default: "%TEMP%/locallogs.log"
 description: The local filename that will be retrieved (Env variables will be expanded).

sources:
- query: |
 SELECT upload(file=expand(path=LocalFilename)) AS Upload
 FROM scope()
 notebook:
 - type: vql
 name: Decrypt logs
 template: |
 /*
 # Retrieved local logs from endpoint
 */

 SELECT * FROM foreach(row={
 SELECT * FROM uploads(client_id=ClientId, flow_id=FlowId)
 }, query={
 SELECT * FROM read_crypto_file(filename=vfs_path, accessor="fs")
 })

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.Profile</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.profile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.profile/</guid><description>&lt;p>This artifact collects profiling information about the running
client. This is useful when you notice a high CPU load in the client
and want to know why.&lt;/p>
&lt;p>The following options are most useful:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Goroutines: This shows the backtraces of all currently running
goroutines. It will generally show most of the code working in the
current running set of queries.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Heap: This shows all allocations currently in use and where they
are allocated from. This is useful if the client is taking too
much memory.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Profile: This takes a CPU profile of the running process for the
number of seconds specified in the Duration parameter. You can
read profiles by using:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>go tool pprof -callgrind -output=profile.grind profile.bin
kcachegrind profile.grind
&lt;/code>&lt;/pre>
&lt;p>Note that this really only makes sense when another query is running
at the same time since this artifacts itself will not be doing very
much other than just measuring the state of the process.&lt;/p>
&lt;p>NOTE: As of 0.7.0 release, this artifact will also collect
goroutines and heap profiles as distinct sources in a more readable
way.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.Profile
description: |
 This artifact collects profiling information about the running
 client. This is useful when you notice a high CPU load in the client
 and want to know why.

 The following options are most useful:

 1. Goroutines: This shows the backtraces of all currently running
 goroutines. It will generally show most of the code working in the
 current running set of queries.

 2. Heap: This shows all allocations currently in use and where they
 are allocated from. This is useful if the client is taking too
 much memory.

 3. Profile: This takes a CPU profile of the running process for the
 number of seconds specified in the Duration parameter. You can
 read profiles by using:

 ```
 go tool pprof -callgrind -output=profile.grind profile.bin
 kcachegrind profile.grind
 ```

 Note that this really only makes sense when another query is running
 at the same time since this artifacts itself will not be doing very
 much other than just measuring the state of the process.

 NOTE: As of 0.7.0 release, this artifact will also collect
 goroutines and heap profiles as distinct sources in a more readable
 way.

parameters:
 - name: Allocs
 description: A sampling of all past memory allocations
 type: bool
 default: Y
 - name: Block
 description: Stack traces that led to blocking on synchronization primitives
 type: bool
 - name: Goroutine
 description: Stack traces of all current goroutines
 type: bool
 default: Y
 - name: Heap
 description: A sampling of memory allocations of live objects
 type: bool
 - name: Mutex
 description: Stack traces of holders of contended mutexes
 type: bool
 - name: Profile
 description: CPU profile
 type: bool
 - name: Trace
 description: CPU trace
 type: bool
 - name: Logs
 description: Get logs
 type: bool
 - name: QueryLogs
 description: Get recent queries logs
 type: bool
 - name: Metrics
 description: Get client metrics
 type: bool
 - name: Verbose
 description: Print more detail
 type: bool
 - name: Duration
 description: Duration of sampling for Profile and Trace.
 default: "30"

export: |
 LET CleanUp(Name) = regex_replace(
 re="www.velocidex.com/golang/velociraptor/",
 replace="", source=Name)

sources:
 - query: |
 LET X = scope()

 SELECT *, X.OSPath &amp;amp;&amp;amp; X.Type &amp;amp;&amp;amp; upload(name=X.Type + ".bin", file=X.OSPath) AS File
 FROM profile(allocs=Allocs, block=Block, goroutine=Goroutine,
 heap=Heap, mutex=Mutex, profile=Profile, trace=Trace,
 logs=Logs, queries=QueryLogs, metrics=Metrics,
 debug=if(condition=Verbose, then=2, else=1),
 duration=atoi(string=Duration))

 - name: Goroutines
 query: |
 -- Only show our own code. This removed unnecessary library
 -- calls and cleans up the output.
 SELECT *, {
 SELECT format(format="%v (%v:%v)",
 args=[CleanUp(Name=Name), basename(path=File), Line])
 FROM CallStack
 WHERE File =~ 'velociraptor|vfilter|go-ntfs'
 LIMIT 10
 } AS CallStack
 FROM profile_goroutines()
 WHERE CallStack

 - name: Memory
 query: |
 SELECT InUseBytes, InUseObjects, {
 SELECT format(format="%v (%v:%v)",
 args=[CleanUp(Name=Name), basename(path=File), Line])
 FROM CallStack
 WHERE File =~ 'velociraptor|vfilter|go-ntfs'
 LIMIT 10
 } AS CallStack
 FROM profile_memory()
 ORDER BY InUseBytes DESC

 - name: Logs
 query: |
 SELECT * FROM profile(logs=TRUE)

 - name: RunningQueries
 query: |
 SELECT Line.Start AS Timestamp, Line.Query AS Query
 FROM profile(queries=TRUE)
 WHERE NOT Line.Duration

 - name: AllQueries
 query: |
 SELECT Line.Start AS Timestamp, int(int = Line.Duration / 1000000) AS DurationSec, Line.Query AS Query
 FROM profile(queries=TRUE)

 - name: Metrics
 query: |
 SELECT *
 FROM profile(metrics=TRUE)

 - name: Everything
 query: SELECT * FROM profile(type='.+')

column_types:
 - name: InUseBytes
 type: mb

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.Rekey</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.rekey/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.rekey/</guid><description>&lt;p>This artifact forces the client to regenerate its client id.&lt;/p>
&lt;p>This is normally not needed! You will only need to use this artifact in very
specific situations, such as when the Velociraptor client was accidentally
incorporated into a VM image with an existing writeback file. This will cause
multiple cloned systems to connect with the same client id, and the server
will then reject those clients with a HTTP &amp;ldquo;409 Rejected&amp;rdquo; message.&lt;/p>
&lt;p>If this happens, you can use the &lt;code>Server.Monitor.ClientConflict&lt;/code> artifact to
schedule collection of this artifact against rejected clients automatically.&lt;/p>
&lt;p>The &lt;code>Wait&lt;/code> parameter controls how long we wait before restarting the client.
Reduce this number if you need to rekey a lot of clients quickly.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.Rekey
description: |
 This artifact forces the client to regenerate its client id.

 This is normally not needed! You will only need to use this artifact in very
 specific situations, such as when the Velociraptor client was accidentally
 incorporated into a VM image with an existing writeback file. This will cause
 multiple cloned systems to connect with the same client id, and the server
 will then reject those clients with a HTTP "409 Rejected" message.

 If this happens, you can use the `Server.Monitor.ClientConflict` artifact to
 schedule collection of this artifact against rejected clients automatically.

 The `Wait` parameter controls how long we wait before restarting the client.
 Reduce this number if you need to rekey a lot of clients quickly.

required_permissions:
 - EXECVE

parameters:
 - name: Wait
 description: Wait this long before restarting the client.
 type: int
 default: '10'

sources:
 - query:
 SELECT rekey(wait=Wait) FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.Stats</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.stats/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.stats/</guid><description>&lt;p>An Event artifact which generates client&amp;rsquo;s CPU and memory statistics.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.Stats
description: An Event artifact which generates client's CPU and memory statistics.
parameters:
 - name: Frequency
 description: Return stats every this many seconds.
 type: int
 default: "10"
type: CLIENT_EVENT

sources:
 - precondition: SELECT OS From info() where OS = 'windows'
 query: |
 SELECT *, rate(x=CPU, y=Timestamp) AS CPUPercent
 FROM foreach(
 row={
 SELECT UnixNano
 FROM clock(period=Frequency)
 },
 query={
 SELECT UnixNano / 1000000000 as Timestamp,
 User + System as CPU,
 Memory.WorkingSetSize as RSS
 FROM pslist(pid=getpid())
 })

 notebook:
 - type: vql_suggestion
 name: Graph CPU usage
 template: |
 /*
 # Events from Generic.Client.Stats
 */
 LET resources = SELECT Timestamp, rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
 RSS / 1000000 AS MemoryUse
 FROM source(start_time=StartTime, end_time=EndTime)
 WHERE CPUPercent &amp;gt;= 0
 /*
 {{ Query "SELECT * FROM resources" | LineChart "xaxis_mode" "time" "RSS.yaxis" 2 }}
 */
 SELECT * FROM resources
 LIMIT 50

 - precondition: SELECT OS From info() where OS != 'windows'
 query: |
 SELECT *, rate(x=CPU, y=Timestamp) AS CPUPercent
 FROM foreach(
 row={
 SELECT UnixNano
 FROM clock(period=Frequency)
 },
 query={
 SELECT UnixNano / 1000000000 as Timestamp,
 Times.system + Times.user as CPU,
 MemoryInfo.RSS as RSS
 FROM pslist(pid=getpid())
 })


reports:
 - type: SERVER_EVENT
 template: |
 {{ define "resources" }}
 SELECT Timestamp, rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
 RSS / 1000000 AS MemoryUse
 FROM source()
 WHERE CPUPercent &amp;gt;= 0
 {{ end }}

 {{ Query "resources" | LineChart "xaxis_mode" "time" "RSS.yaxis" 2 }}

 - type: MONITORING_DAILY
 template: |
 {{ define "resources" }}
 SELECT Timestamp, rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
 RSS / 1000000 AS MemoryUse
 FROM source()
 WHERE CPUPercent &amp;gt;= 0
 {{ end }}

 {{ $client_info := Query "SELECT * FROM clients(client_id=ClientId) LIMIT 1" }}

 # Client Footprint for {{ Get $client_info "0.os_info.fqdn" }}

 The client has a client ID of {{ Get $client_info "0.client_id" }}.
 Clients report the Velociraptor process footprint to the
 server every 10 seconds. The data includes the total CPU
 utilization, and the resident memory size used by the client.

 The following graph shows the total utilization. Memory
 utilization is meausred in `Mb` while CPU Utilization is
 measured by `Percent of one core`.

 We would expect the client to use around 1-5% of one core when
 idle, but if a heavy hunt is running this might climb
 substantially.

 &amp;lt;div&amp;gt;
 {{ Query "resources" | LineChart "xaxis_mode" "time" "RSS.yaxis" 2 }}
 &amp;lt;/div&amp;gt;

 ## VQL Query

 The following VQL query was used to plot the graph above.

 ```sql
 {{ template "resources" }}
 ```

 &amp;gt; To learn about managing end point performance with Velociraptor see
 the [blog post](https://docs.velociraptor.velocidex.com/blog/html/2019/02/10/velociraptor_performance.html).

column_types:
 - name: Timestamp
 type: timestamp

 - name: ClientId
 type: client_id

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.Trace</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.trace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.trace/</guid><description>&lt;p>This artifact collects profiling information about the running
client. The artifact is automatically added when the GUI selects a
non zero Trace frequency.&lt;/p>
&lt;p>NOTE: You can also add the artifact directly, but then you will need
to cancel the collection manually since it will continue to run
until the timeout is reached.&lt;/p>
&lt;p>Minimum Version: 0.6.8&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.Trace
description: |
 This artifact collects profiling information about the running
 client. The artifact is automatically added when the GUI selects a
 non zero Trace frequency.

 NOTE: You can also add the artifact directly, but then you will need
 to cancel the collection manually since it will continue to run
 until the timeout is reached.

 Minimum Version: 0.6.8

parameters:
- name: FrequencySec
 type: int
 default: 10

sources:
- query: |
 SELECT * FROM if(condition=version(function="trace"),
 then={
 SELECT trace() AS TraceFile
 FROM clock(start=0, period=FrequencySec)
 })

&lt;/code>&lt;/pre></description></item><item><title>Generic.Client.VQL</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.client.vql/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.client.vql/</guid><description>&lt;p>Run arbitrary VQL on the endpoint.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Client.VQL
description: |
 Run arbitrary VQL on the endpoint.

required_permissions:
 - IMPERSONATION

parameters:
 - name: Command
 default: SELECT * FROM info()

sources:
 - query: |
 SELECT * FROM query(query=Command, env=dict(config=config))

&lt;/code>&lt;/pre></description></item><item><title>Generic.Collectors.File</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.collectors.file/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.collectors.file/</guid><description>&lt;p>Collects files using a set of globs. All globs must be on the same
device. The globs will be searched in one pass - so you can provide
many globs at the same time.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Collectors.File
description: |
 Collects files using a set of globs. All globs must be on the same
 device. The globs will be searched in one pass - so you can provide
 many globs at the same time.

aliases:
 - Windows.Collectors.File

parameters:
 - name: collectionSpec
 description: |
 A CSV file with a Glob column with all the globs to collect.
 NOTE: Globs must not have a leading device.
 type: csv
 default: |
 Glob
 Users\*\NTUser.dat

 - name: Root
 description: |
 On Windows, this is the device to apply all the glob on
 (e.g. `C:`). On *NIX, this should be a path to a subdirectory or
 /.
 default: "C:"

 - name: Accessor
 default: auto
 description: |
 On Windows, this can be changed to `ntfs`.

 - name: NTFS_CACHE_TIME
 type: int
 description: How often to flush the NTFS cache. (Default is never).
 default: "1000000"

 - name: UPLOAD_IS_RESUMABLE
 type: bool
 default: Y
 description: If set the uploads can be resumed if the flow times out or errors.

 - name: MaxFileSize
 type: int
 default: 18446744073709551615
 description: |
 The max size in bytes of the individual files to collect.
 Set to 0 to disable it.


sources:
 - name: All Matches Metadata
 query: |
 LET RootPath &amp;lt;= pathspec(Path=Root, accessor=Accessor)

 -- Generate the collection globs for each device
 LET specs = SELECT RootPath + Glob AS Glob
 FROM collectionSpec
 WHERE log(message=format(format="Processing Device %v with %v: glob is %v",
 args=[Root, Accessor, Glob]))

 -- Join all the collection rules into a single Glob plugin. This ensure we
 -- only make one pass over the filesystem. We only want LFNs.
 LET hits = SELECT OSPath AS SourceFile,
 Size,
 Btime AS Created,
 Ctime AS Changed,
 Mtime AS Modified,
 Atime AS LastAccessed
 FROM glob(globs=specs.Glob, accessor=Accessor)
 WHERE NOT IsDir
 AND log(message="Found " + SourceFile)
 AND ( Size &amp;lt;= MaxFileSize OR
 ( log(message="Skipping file " + SourceFile + " Due to MaxFileSize")
 AND FALSE ))

 -- Pass all the results to the next query. This will serialize
 -- to disk if there are too many results.
 LET all_results &amp;lt;= SELECT Created,
 Changed,
 LastAccessed,
 Modified,
 Size,
 SourceFile
 FROM hits

 SELECT *
 FROM all_results


 - name: Uploads
 query: |
 -- Upload the files. Split into workers so the files are uploaded in parallel.
 LET uploaded_files = SELECT *
 FROM foreach(row={
 SELECT *
 FROM all_results
 },
 workers=30,
 query={
 SELECT Created,
 Changed,
 LastAccessed,
 Modified,
 SourceFile,
 Size,
 upload(file=SourceFile, accessor=Accessor, mtime=Modified) AS Upload
 FROM scope()
 })

 -- Separate the hashes into their own column.
 SELECT now() AS CopiedOnTimestamp,
 SourceFile,
 Upload.Path AS DestinationFile,
 Size AS FileSize,
 Upload.sha256 AS SourceFileSha256,
 Created,
 Changed,
 Modified,
 LastAccessed
 FROM uploaded_files

&lt;/code>&lt;/pre></description></item><item><title>Generic.Detection.HashHunter</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.detection.hashhunter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.detection.hashhunter/</guid><description>&lt;p>This artifact enables searching for hashes.&lt;/p>
&lt;p>The artifact takes a glob targeting input, then generates a hash for each
file in scope to compare to several types of hash lists provided by the user.&lt;/p>
&lt;p>Note: this artifacts filters are cumulative so a hash based hit will return
no results if the file is filtered out by other filters.
For most performant searches use path, size and and date filters. By default
the artifact uses the &amp;lsquo;auto&amp;rsquo; data accessor but can also be changed as desired.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Detection.HashHunter
author: "Matt Green - @mgreen27"
description: |
 This artifact enables searching for hashes.

 The artifact takes a glob targeting input, then generates a hash for each
 file in scope to compare to several types of hash lists provided by the user.

 Note: this artifacts filters are cumulative so a hash based hit will return
 no results if the file is filtered out by other filters.
 For most performant searches use path, size and and date filters. By default
 the artifact uses the 'auto' data accessor but can also be changed as desired.

parameters:
 - name: TargetGlob
 description: Glob to target.
 default: "C:/Users/**/*"
 - name: Accessor
 description: Velociraptor accessor to use. Changing to ntfs will increase scan time.
 default: auto
 - name: DateAfter
 description: Search for binaries with timestamps after this date. YYYY-MM-DDTmm:hh:ssZ
 type: timestamp
 - name: DateBefore
 description: Search for binaries with timestamps before this date. YYYY-MM-DDTmm:hh:ssZ
 type: timestamp
 - name: SizeMax
 description: Return binaries only under this size in bytes.
 type: int64
 default: 4294967296
 - name: SizeMin
 description: Return binaries only over this size in bytes.
 type: int64
 default: 0
 - name: MD5List
 description: MD5 hash list to hunt for. New MD5 hash on each line
 default:
 - name: SHA1List
 description: SHA1 hash list to hunt for. New SHA1 hash on each line
 default:
 - name: SHA256List
 description: SHA256 hash list to hunt for. New SHA256 hash on each line
 default:

sources:
 - query: |
 -- setup hash lists
 LET MD5List &amp;lt;= if(condition= MD5List,
 then= split(sep='\\s+',string=MD5List), else=Null)
 LET SHA1List &amp;lt;= if(condition= SHA1List,
 then= split(sep='\\s+',string=SHA1List), else=Null)
 LET SHA256List &amp;lt;= if(condition= SHA256List,
 then= split(sep='\\s+',string=SHA256List), else=Null)

 -- set hash selector for optimized hash calculation
 LET HashSelector &amp;lt;= SELECT * FROM chain(
 a={ SELECT "MD5" AS Hash FROM scope() WHERE MD5List },
 b={ SELECT "SHA1" AS Hash FROM scope() WHERE SHA1List },
 c={ SELECT "SHA256" AS Hash FROM scope() WHERE SHA256List })

 -- firstly find files in scope with performance
 LET find_files = SELECT * FROM if(condition=DateBefore AND DateAfter,
 then={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=TargetGlob,accessor=Accessor,nosymlink='True')
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 AND ( Mtime &amp;lt; DateBefore OR Ctime &amp;lt; DateBefore OR Btime &amp;lt; DateBefore )
 AND ( Mtime &amp;gt; DateAfter OR Ctime &amp;gt; DateAfter OR Btime &amp;gt; DateAfter )
 },
 else={ SELECT * FROM if(condition=DateBefore,
 then={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=OSPath,accessor=Accessor)
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 AND ( Mtime &amp;lt; DateBefore OR Ctime &amp;lt; DateBefore OR Btime &amp;lt; DateBefore )
 },
 else={ SELECT * FROM if(condition=DateAfter,
 then={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=TargetGlob,accessor=Accessor)
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 AND ( Mtime &amp;gt; DateAfter OR Ctime &amp;gt; DateAfter OR Btime &amp;gt; DateAfter )
 },
 else={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=TargetGlob,accessor=Accessor)
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 })})})


 -- lookup hash and run finl filters
 SELECT OSPath,Name,Size,
 dict(Mtime=Mtime,Atime=Atime,Ctime=Ctime,Btime=Btime) as Timestamps,
 hash(path=OSPath,hashselect=HashSelector.Hash) as Hash
 FROM if(condition= HashSelector.Hash, then= find_files)
 WHERE
 ( Hash.MD5 in MD5List OR Hash.SHA1 in SHA1List OR Hash.SHA256 in SHA256List )
&lt;/code>&lt;/pre></description></item><item><title>Generic.Detection.Logs</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.detection.logs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.detection.logs/</guid><description>&lt;p>This artifact enables grep of Logs to hunt for strings of interest. Default
target glob includes /var/log/, Apache and Windows IIS paths.&lt;/p>
&lt;p>Parameters include SearchRegex and WhitelistRegex as regex terms and will
return the whole line to assist with scoping.&lt;/p>
&lt;p>IIS and Apache Groks are available as notebook suggestions - please feel free to PR
additions!&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Detection.Logs
author: "Matt Green - @mgreen27, Apache groks thanks to Harsh Jaroli and Krishna Patel"
description: |
 This artifact enables grep of Logs to hunt for strings of interest. Default
 target glob includes /var/log/, Apache and Windows IIS paths.

 Parameters include SearchRegex and WhitelistRegex as regex terms and will
 return the whole line to assist with scoping.

 IIS and Apache Groks are available as notebook suggestions - please feel free to PR
 additions!


parameters:
 - name: TargetGlob
 default: '/{/var/log/**,*:/inetpub/logs/**/,{/var/log/httpd,/var/log/apache2,/var/log/nginx,C:/Apache/logs}/{access.log,access_log}*}'
 - name: SearchRegex
 description: "Regex of strings to search in line."
 default: 'PUT '
 type: regex
 - name: WhitelistRegex
 description: "Regex of strings to leave out of output."
 default:
 type: regex

sources:
 - query: |
 LET files = SELECT OSPath FROM glob(globs=TargetGlob)

 SELECT * FROM foreach(row=files,
 query={
 SELECT Line, OSPath 
 FROM parse_lines(filename=OSPath)
 WHERE
 Line =~ SearchRegex
 AND NOT if(condition= WhitelistRegex,
 then= Line =~ WhitelistRegex,
 else= FALSE)
 })

 notebook:
 - type: vql_suggestion
 name: IIS Groks
 template: |
 /*
 ### IIS grok

 Note: IIS doesn't have a standard logging format so we have added some
 suggestions. Comment in preferred or add / modify your own.
 */

 LET target_grok = "%{TIMESTAMP_ISO8601:LogTimeStamp} %{IPORHOST:Site} %{WORD:Method} %{URIPATH:UriPath} %{NOTSPACE:QueryString} %{NUMBER:Port} %{NOTSPACE:Username} %{IPORHOST:Clienthost} %{NOTSPACE:Useragent} %{NOTSPACE:Referrer} %{NUMBER:Response} %{NUMBER:Subresponse} %{NUMBER:Win32status} %{NUMBER:Timetaken:int}"
 --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:timetaken:int}"
 --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:iisSite} %{NOTSPACE:computername} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:protocol} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{IPORHOST:cshost} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:bytessent:int} %{NUMBER:bytesrecvd:int} %{NUMBER:timetaken:int}"


 LET parsed = SELECT ClientId as _ClientId, Line as _Raw,
 grok(data=Line,grok=target_grok) as GrokParsed
 FROM source()
 WHERE GrokParsed

 SELECT * FROM foreach(row=parsed,
 query={ SELECT *, _Raw FROM GrokParsed })
 
 - type: vql_suggestion
 name: Apache Groks
 template: |
 /*
 ### Apache Grok
 */

 LET target_grok = '''%{IPORHOST:client} - - \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:status} %{NUMBER:response_size}'''
 
 LET parsed = SELECT ClientId as _ClientId, Line as _Raw,
 grok(data=Line,grok=target_grok) as GrokParsed
 FROM source()
 WHERE GrokParsed

 SELECT * FROM foreach(row=parsed,
 query={ SELECT *, _Raw FROM GrokParsed })

&lt;/code>&lt;/pre></description></item><item><title>Generic.Detection.Yara.Glob</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.detection.yara.glob/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.detection.yara.glob/</guid><description>&lt;p>This artifact returns a list of target files then runs YARA over the target
list.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>Url link to a YARA rule.&lt;/li>
&lt;li>or a Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above.&lt;/p>
&lt;p>The artifact uses Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with YARA hits.&lt;/p>
&lt;p>Some examples of path glob may include:&lt;/p>
&lt;ul>
&lt;li>Specific binary: &lt;code>/usr/bin/ls&lt;/code>&lt;/li>
&lt;li>Wildcards: &lt;code>/var/www/*.js&lt;/code>&lt;/li>
&lt;li>More wildcards: &lt;code>/var/www/**/*.js&lt;/code>&lt;/li>
&lt;li>Multiple extensions: &lt;code>/var/www/*\.{php,aspx,js,html}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:/Users/**/*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:\Users\**\*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
 This artifact returns a list of target files then runs YARA over the target
 list.

 There are 2 kinds of YARA rules that can be deployed:

 1. Url link to a YARA rule.
 2. or a Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above.

 The artifact uses Glob for search so relevant filters can be applied
 including Glob, Size and date. Date filters will target files with a timestamp
 before LatestTime and after EarliestTime. The artifact also has an option to
 upload any files with YARA hits.

 Some examples of path glob may include:

 * Specific binary: `/usr/bin/ls`
 * Wildcards: `/var/www/*.js`
 * More wildcards: `/var/www/**/*.js`
 * Multiple extensions: `/var/www/*\.{php,aspx,js,html}`
 * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
 * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

 NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
 This will NOT follow any symlinks and may cause unexpected results if
 unknowingly targeting a folder with symlinks.
 If upload is selected NumberOfHits is redundant and not advised as hits are
 grouped by path to ensure files only downloaded once.

aliases:
 - Windows.Detection.Yara.Glob
 - Linux.Detection.Yara.Glob
 - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
 - name: PathGlob
 description: Only file names that match this glob will be scanned.
 default: /usr/bin/ls
 - name: SizeMax
 description: maximum size of target file.
 type: int64
 - name: SizeMin
 description: minimum size of target file.
 type: int64
 - name: UploadHits
 type: bool
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: YaraUrl
 description: If configured will attempt to download Yara rules form Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule IsELF:TestRule {
 meta:
 author = "the internet"
 date = "2021-05-03"
 description = "A simple ELF rule to test yara features"
 condition:
 uint32(0) == 0x464c457f
 }
 - name: NumberOfHits
 description: This artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int

sources:
 - query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- time testing
 LET time_test(stamp) =
 if(condition= DateBefore AND DateAfter,
 then= stamp &amp;lt; DateBefore AND stamp &amp;gt; DateAfter,
 else=
 if(condition=DateBefore,
 then= stamp &amp;lt; DateBefore,
 else=
 if(condition= DateAfter,
 then= stamp &amp;gt; DateAfter,
 else= True
 )))

 -- first find all matching glob
 LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
 FROM glob(globs=PathGlob,nosymlink='True')
 WHERE
 NOT IsDir AND NOT IsLink
 AND if(condition=SizeMin,
 then= SizeMin &amp;lt; Size,
 else= True)
 AND if(condition=SizeMax,
 then=SizeMax &amp;gt; Size,
 else= True)
 AND
 ( time_test(stamp=Mtime)
 OR time_test(stamp=Atime)
 OR time_test(stamp=Ctime)
 OR time_test(stamp=Btime))

 -- scan files and prepare hit metadata
 LET hits = SELECT * FROM foreach(row=files,
 query={
 SELECT
 OSPath,
 File.Size as Size,
 Mtime, Atime, Ctime, Btime,
 Rule, Tags, Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 upload( accessor='scope',
 file='String.Data',
 name=format(format="%v-%v-%v",
 args=[
 OSPath,
 if(condition= String.Offset - ContextBytes &amp;lt; 0,
 then= 0,
 else= String.Offset - ContextBytes),
 if(condition= String.Offset + ContextBytes &amp;gt; Size,
 then= Size,
 else= String.Offset + ContextBytes) ]
 )) as HitContext
 FROM yara(rules=yara_rules,files=OSPath,
 context=ContextBytes,number=NumberOfHits)
 })

 -- upload files if selected
 LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

 -- return rows
 SELECT * FROM if(condition= UploadHits,
 then= upload_hits,
 else= hits )

column_types:
 - name: HitContext
 type: preview_upload
&lt;/code>&lt;/pre></description></item><item><title>Generic.Detection.Yara.Zip</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.detection.yara.zip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.detection.yara.zip/</guid><description>&lt;p>This artifact enables running YARA on embedded compressed files.&lt;/p>
&lt;p>The artifact:&lt;/p>
&lt;ul>
&lt;li>firstly searches for compressed zip files (PK header)&lt;/li>
&lt;li>then applies YARA on files inside.&lt;/li>
&lt;li>files matching ZipFilenameRegex are recursively searched as above.&lt;/li>
&lt;/ul>
&lt;p>The artifact is optimized to recursively search through embedded zip,
jar,war and ear files by extracting any discovered containers.
Select UploadHits to upload Discovered file for further analysis. It is
recommended to increase default artifact timeout for large servers or target
glob.&lt;/p>
&lt;p>Some examples of path glob may include:&lt;/p>
&lt;ul>
&lt;li>Specific container: &lt;code>/path/here/file.zip&lt;/code>&lt;/li>
&lt;li>Wildcards: &lt;code>/var/www/*.{jar,war,ear}&lt;/code>&lt;/li>
&lt;li>More wildcards: &lt;code>/var/www/**/*.jar&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:/**/*.zip&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>NOTE: this artifact runs the glob plugin with the nosymlink switch
turned on. This will NOT follow any symlinks and may cause
unexpected results if unknowingly targeting a folder with
symlinks. YARA is not applied to the containers, only contained contents
that are not containers.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Detection.Yara.Zip
author: "Matt Green - @mgreen27"
description: |
 This artifact enables running YARA on embedded compressed files.

 The artifact:

 * firstly searches for compressed zip files (PK header)
 * then applies YARA on files inside.
 * files matching ZipFilenameRegex are recursively searched as above.

 The artifact is optimized to recursively search through embedded zip,
 jar,war and ear files by extracting any discovered containers.
 Select UploadHits to upload Discovered file for further analysis. It is
 recommended to increase default artifact timeout for large servers or target
 glob.

 Some examples of path glob may include:

 * Specific container: `/path/here/file.zip`
 * Wildcards: `/var/www/*.{jar,war,ear}`
 * More wildcards: `/var/www/**/*.jar`
 * Windows: `C:/**/*.zip`

 NOTE: this artifact runs the glob plugin with the nosymlink switch
 turned on. This will NOT follow any symlinks and may cause
 unexpected results if unknowingly targeting a folder with
 symlinks. YARA is not applied to the containers, only contained contents
 that are not containers.

parameters:
 - name: TargetGlob
 default: "**/*.{zip,jar,war,ear}"
 - name: ZipFilenameRegex
 default: ".(zip|jar|war|ear)$"
 description: Regex of FileName inside container files we would like to recursively scan.
 - name: MaxRecursions
 description: Number of recursions to allow checking inside archives. Default is 10 layers.
 default: 10
 type: int
 - name: UploadHits
 description: Select to upload hits to server.
 type: bool
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule IsPE:TestRule {
 meta:
 author = "the internet"
 date = "2021-03-04"
 description = "A simple PE rule to test yara features"
 condition:
 uint16(0) == 0x5A4D and
 uint32(uint32(0x3C)) == 0x00004550
 }
 - name: NumberOfHits
 description: THis artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int

sources:
 - query: |
 -- this section glob searches and confirms we are looking at zip container
 LET target_files = SELECT *,
 read_file(filename=OSPath,offset=0,length=2) as _Header
 FROM glob(globs=TargetGlob,nosymlink=True)
 WHERE _Header = 'PK'

 -- recursive search function
 LET Recurse(Container, File, Accessor, RecursionRounds) = SELECT * FROM if(
 condition=RecursionRounds &amp;lt; MaxRecursions,
 then={
 SELECT * FROM foreach(
 row={
 SELECT *
 FROM glob(accessor='zip',
 root=pathspec(DelegatePath=File, DelegateAccessor=Accessor),
 globs='**')
 WHERE NOT IsDir AND Size &amp;gt; 0
 },
 query={
 SELECT *
 FROM if(condition=Name =~ ZipFilenameRegex,
 then={
 SELECT *
 FROM Recurse(
 Container = Container,
 File=OSPath,
 Accessor="zip",
 RecursionRounds = RecursionRounds + 1)
 },
 else={
 SELECT
 Container,
 OSPath.HumanString as ExtractedPath,
 OSPath.Path as FilePath,
 hash(accessor='zip',path=OSPath) as Hash,
 File.Size AS Size,
 Mtime, Atime, Ctime, Btime,
 Rule, Tags, Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 if(condition=String.Data,
 then=upload(
 accessor='scope',
 file='String.Data',
 name=format(format="%v_%v",
 args=[ OSPath.HumanString, String.Offset ]
 ))) as HitContext
 FROM yara(accessor='zip',files=OSPath,rules=YaraRule,
 context=ContextBytes, number=NumberOfHits)
 })
 })
 })

 LET hits = SELECT * FROM foreach(row=target_files,
 query={
 SELECT *
 FROM Recurse(Container=OSPath,File=OSPath, Accessor="auto", RecursionRounds=0)
 })

 -- upload files that have hit
 LET upload_hits = SELECT *, upload(file=Container) as ContainerUpload FROM hits

 -- display rows
 SELECT * FROM if(condition=UploadHits,
 then= upload_hits,
 else= hits)

column_types:
 - name: HitContext
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Generic.Forensic.Carving.URLs</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.carving.urls/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.carving.urls/</guid><description>&lt;p>Carve URLs from files located in a glob. Note that we do not parse
any files - we simply carve anything that looks like a URL.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Forensic.Carving.URLs
description: |
 Carve URLs from files located in a glob. Note that we do not parse
 any files - we simply carve anything that looks like a URL.


parameters:
 - name: UrlGlob
 default: |
 ["C:/Documents and Settings/*/Local Settings/Application Data/Google/Chrome/User Data/**",
 "C:/Users/*/AppData/Local/Google/Chrome/User Data/**",
 "C:/Documents and Settings/*/Local Settings/History/**",
 "C:/Documents and Settings/*/Local Settings/Temporary Internet Files/**",
 "C:/Users/*/AppData/Local/Microsoft/Windows/WebCache/**",
 "C:/Users/*/AppData/Local/Microsoft/Windows/INetCache/**",
 "C:/Users/*/AppData/Local/Microsoft/Windows/INetCookies/**",
 "C:/Users/*/AppData/Roaming/Mozilla/Firefox/Profiles/**",
 "C:/Documents and Settings/*/Application Data/Mozilla/Firefox/Profiles/**"
 ]

sources:
 - query: |
 LET matching = SELECT OSPath FROM glob(
 globs=parse_json_array(data=UrlGlob))

 SELECT OSPath, URL FROM foreach(
 row=matching,
 query={
 SELECT OSPath,
 URL FROM parse_records_with_regex(file=OSPath,
 regex="(?P&amp;lt;URL&amp;gt;https?:\\/\\/[\\w\\.-]+[\\/\\w \\.-]*)")
 })

&lt;/code>&lt;/pre></description></item><item><title>Generic.Forensic.HashLookup</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.hashlookup/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.hashlookup/</guid><description>&lt;p>This artifact is a server event artifact that collects hashes from
various sources into a central location. It is possible to follow
this artifact (e.g. with an external program using the API) to
lookup the hashes with an external service.&lt;/p>
&lt;p>You can also send hashes to this artifact yourself by using the
&lt;code>send_event()&lt;/code> VQL function. For example, the following will add
hashes from the results of another artifact.&lt;/p>
&lt;pre>&lt;code class="language-vql">SELECT *, send_event(
 artifact=&amp;quot;Generic.Forensic.HashLookup&amp;quot;,
 row=dict(SHA256=Sha256, ClientId=ClientId))
FROM source()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Forensic.HashLookup
description: |
 This artifact is a server event artifact that collects hashes from
 various sources into a central location. It is possible to follow
 this artifact (e.g. with an external program using the API) to
 lookup the hashes with an external service.

 You can also send hashes to this artifact yourself by using the
 `send_event()` VQL function. For example, the following will add
 hashes from the results of another artifact.

 ```vql
 SELECT *, send_event(
 artifact="Generic.Forensic.HashLookup",
 row=dict(SHA256=Sha256, ClientId=ClientId))
 FROM source()
 ```

type: SERVER_EVENT

sources:
 - query: |
 // You can add more queries to this chain to automatically
 // collect more hashes.
 SELECT ClientId, SHA256 FROM chain(
 a={
 SELECT * FROM foreach(
 row={
 SELECT ClientId, FlowId
 FROM watch_monitoring(artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ "System.VFS.DownloadFile"
 }, query={
 SELECT ClientId, Sha256 AS SHA256
 FROM source(
 artifact="System.VFS.DownloadFile",
 client_id=ClientId, flow_id=FlowId)
 })
 }, async=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Generic.Forensic.LocalHashes.Glob</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.localhashes.glob/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.localhashes.glob/</guid><description>&lt;p>This artifact maintains a local (client side) database of file
hashes. It is then possible to query this database by using the
&lt;code>Generic.Forensic.LocalHashes.Query&lt;/code> artifact&lt;/p>
&lt;p>Maintaining hashes client side allows Velociraptor to answer the
query - which machine has this hash on our network extremely
quickly. Velociraptor only needs to lookup the each client&amp;rsquo;s local
database of file hashes.&lt;/p>
&lt;p>Maintaining this database case be done by using this artifact or by using
the &lt;code>Windows.Forensics.LocalHashes.Usn&lt;/code> artifact.&lt;/p>
&lt;p>This artifact simply crawls the filesystem hashing files as
specified by the glob expression, and adds them to the local hash
database. You can rate limit this artifact by using the ops/sec setting
to perform a slow update of the local file hash database.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Forensic.LocalHashes.Glob
description: |
 This artifact maintains a local (client side) database of file
 hashes. It is then possible to query this database by using the
 `Generic.Forensic.LocalHashes.Query` artifact

 Maintaining hashes client side allows Velociraptor to answer the
 query - which machine has this hash on our network extremely
 quickly. Velociraptor only needs to lookup the each client's local
 database of file hashes.

 Maintaining this database case be done by using this artifact or by using
 the `Windows.Forensics.LocalHashes.Usn` artifact.

 This artifact simply crawls the filesystem hashing files as
 specified by the glob expression, and adds them to the local hash
 database. You can rate limit this artifact by using the ops/sec setting
 to perform a slow update of the local file hash database.

parameters:
 - name: HashGlob
 description: Search for files according to this glob and hash them.
 default: C:/Users/**/*.exe

 - name: HashDb
 description: Name of the local hash database
 default: hashdb.sqlite

 - name: SuppressOutput
 description: If this is set, the artifact does not return any rows to the server but will still update the local database.
 type: bool

sources:
 - query: |
 LET hash_db &amp;lt;= SELECT OSPath
 FROM Artifact.Generic.Forensic.LocalHashes.Init(HashDb=HashDb)

 LET path &amp;lt;= hash_db[0].OSPath

 LET _ &amp;lt;= log(message="Will use local hash database " + path)

 // Crawl the files and calculate their hashes
 LET files = SELECT OSPath, Size, hash(path=OSPath).MD5 AS Hash
 FROM glob(globs=HashGlob)
 WHERE Mode.IsRegular

 LET insertion = SELECT OSPath, Hash, Size, {
 SELECT * FROM sqlite(file=path,
 query="INSERT into hashes (path, md5, timestamp, size) values (?,?,?,?)",
 args=[OSPath.String, Hash, now(), Size])
 } AS Insert
 FROM files
 WHERE Insert OR TRUE

 SELECT OSPath, Hash, Size
 FROM insertion
 WHERE NOT SuppressOutput

&lt;/code>&lt;/pre></description></item><item><title>Generic.Forensic.LocalHashes.Init</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.localhashes.init/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.localhashes.init/</guid><description>&lt;p>This artifact creates an SQLite database on the endpoint to hold
local file hashes. These hashes can then be queried quickly.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Forensic.LocalHashes.Init
description: |
 This artifact creates an SQLite database on the endpoint to hold
 local file hashes. These hashes can then be queried quickly.

parameters:
 - name: HashDb
 description: Name of the local hash database
 default: hashdb.sqlite

implied_permissions:
 - FILESYSTEM_WRITE

sources:
 - query: |
 LET SQL = "
 CREATE table if not exists hashes(path text, md5 varchar(16), size bigint, timestamp bigint)
 create index if not exists hashidx on hashes(md5)
 create index if not exists pathidx on hashes(path)
 create unique index if not exists uniqueidx on hashes(path, md5)
 "

 LET hash_db &amp;lt;= path_join(components=[dirname(path=tempfile()), HashDb])

 LET _ &amp;lt;= log(message="Will use local hash database " + hash_db)

 // SQL to create the initial database.
 LET _ &amp;lt;= SELECT * FROM foreach(
 row={
 SELECT Line FROM parse_lines(filename=SQL, accessor="data")
 WHERE Line
 }, query={
 SELECT * FROM sqlite(file=hash_db, query=Line)
 })

 SELECT hash_db AS OSPath FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Generic.Forensic.LocalHashes.Query</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.localhashes.query/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.localhashes.query/</guid><description>&lt;p>This artifact maintains a local (client side) database of file
hashes. It is then possible to query this database by using the
Generic.Forensic.LocalHashes.Query artifact.&lt;/p>
&lt;p>NOTE: This artifact expects a CSV file with one hash per line. On
the command line you can encode carriage return by using PowerShell
like this:&lt;/p>
&lt;pre>&lt;code>.\velociraptor.exe -v artifacts collect Generic.Forensic.LocalHashes.Query --args &amp;quot;Hashes=Hash`ne6c1ce56e6729a0b077c0f2384726b30&amp;quot;
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Forensic.LocalHashes.Query
description: |
 This artifact maintains a local (client side) database of file
 hashes. It is then possible to query this database by using the
 Generic.Forensic.LocalHashes.Query artifact.

 NOTE: This artifact expects a CSV file with one hash per line. On
 the command line you can encode carriage return by using PowerShell
 like this:

 ```
 .\velociraptor.exe -v artifacts collect Generic.Forensic.LocalHashes.Query --args "Hashes=Hash`ne6c1ce56e6729a0b077c0f2384726b30"
 ```

parameters:
 - name: Hashes
 description: The hash to query for.
 type: csv
 default: |
 Hash
 XXX

 - name: CommaDelimitedHashes
 description: A set of comma delimited hashes
 default:

 - name: HashDb
 description: Name of the local hash database
 default: hashdb.sqlite

sources:
 - query: |
 LET hash_db &amp;lt;= SELECT OSPath
 FROM Artifact.Generic.Forensic.LocalHashes.Init(HashDb=HashDb)

 -- Check hashes from the CSV or comma delimited input
 LET hashes = SELECT Hash FROM chain(
 a={
 SELECT lowcase(string=strip(string=Hash)) AS Hash
 FROM Hashes
 }, b={
 SELECT * FROM foreach(row=split(string=CommaDelimitedHashes, sep=","),
 query={
 SELECT lowcase(string=strip(string=_value)) AS Hash FROM scope()
 })
 })

 SELECT * FROM foreach(row=hashes,
 query={
 SELECT path AS Path, md5 AS MD5, size AS Size,
 timestamp(epoch=time) AS Timestamp
 FROM sqlite(file=hash_db[0].OSPath,
 query="SELECT path, md5, size, timestamp AS time FROM hashes WHERE md5 = ?",
 args=Hash)
 })

&lt;/code>&lt;/pre></description></item><item><title>Generic.Forensic.Timeline</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.timeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.forensic.timeline/</guid><description>&lt;p>This artifact generates a timeline of a file glob in bodyfile
format. We currently do not calculate the md5 because it is quite
expensive.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Forensic.Timeline
description: |
 This artifact generates a timeline of a file glob in bodyfile
 format. We currently do not calculate the md5 because it is quite
 expensive.

parameters:
 - name: timelineGlob
 default: C:\Users\**
 - name: timelineAccessor
 default: file

sources:
 # For NTFS accessors we write the MFT id as the inode. On windows
 # the file accessor does not give the inode at all.
 - precondition:
 SELECT OS From info() where OS = 'windows' AND timelineAccessor = 'ntfs'
 query: |
 SELECT 0 AS Md5, OSPath,
 Sys.mft as Inode,
 Mode.String AS Mode, 0 as Uid, 0 as Gid, Size,
 Atime, Mtime, Ctime
 FROM glob(globs=timelineGlob, accessor=timelineAccessor)

 # For linux we can get the Inode from Sys.Ino
 - precondition:
 SELECT * From scope() where timelineAccessor = 'file'
 query: |
 SELECT 0 AS Md5, OSPath,
 Sys.Ino as Inode,
 Mode.String AS Mode, Sys.Uid AS Uid, Sys.Gid AS Gid, Size,
 Atime, Mtime, Ctime
 FROM glob(globs=timelineGlob, accessor=timelineAccessor)

&lt;/code>&lt;/pre></description></item><item><title>Generic.Network.InterfaceAddresses</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.network.interfaceaddresses/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.network.interfaceaddresses/</guid><description>&lt;p>Network interfaces and relevant metadata. This artifact works on all
supported OSs.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Network.InterfaceAddresses
description: |
 Network interfaces and relevant metadata. This artifact works on all
 supported OSs.

aliases:
 - Windows.Network.InterfaceAddresses

sources:
 - query: |
 LET interface_address =
 SELECT Index, MTU, Name,
 HardwareAddr.String AS HardwareAddr,
 Flags, Addrs
 from interfaces()

 SELECT Index, MTU, Name, HardwareAddr,
 Flags, Addrs.IP as IP, Addrs.Mask.String as Mask
 FROM flatten(query=interface_address)

&lt;/code>&lt;/pre></description></item><item><title>Generic.System.EfiSignatures</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.system.efisignatures/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.system.efisignatures/</guid><description>&lt;p>Collect Efi Signature information from the client.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.System.EfiSignatures
description: |
 Collect Efi Signature information from the client.

type: CLIENT
export: |
 -- GUIDs are taken from
 -- https://github.com/chipsec/chipsec/blob/main/chipsec/hal/uefi_common.py
 LET PROFILE = '''[
 ["EfiSignatures", 0, [
 ["__tmp", 0, "uint32"],
 ["__Signatures", 0, "Union", {
 "selector": "x=&amp;gt;x.__tmp &amp;lt; 257",
 "choices": {
 "true": "EfiSignaturesListAttrib",
 "false": "EfiSignaturesList"
 }
 }],
 ["Signatures", 0, "Value", {"value": "x=&amp;gt;x.__Signatures.Signatures"}]
 ]],
 ["EfiSignaturesListAttrib", 0, [
 ["__Attributes", 0, "uint32"],
 ["Signatures", 4, "Array", {"type": "Signature", "count": 1000}]
 ]],
 ["EfiSignaturesList", 0, [
 ["Signatures", 0, "Array", {"type": "Signature", "count": 1000}]
 ]],
 ["Signature", "x=&amp;gt;x.__ListSize", [
 ["__Type", 0, "GUID"],
 ["Type", 0, "Value", {"value": "x=&amp;gt;x.__Type.Value"}],
 ["__ListSize", 16, "uint32"],
 ["__HeaderSize", 20, "uint32"],
 ["Payload", 24, "Union", {
 "selector": "x=&amp;gt;x.Type",
 "choices": {
 "{a5c059a1-94e4-4aa7-87b5-ab155c2bf072}": "Cert",
 "{c1c41626-504c-4092-aca9-41f936934328}": "HashList"
 }
 }]
 ]],
 ["Cert", "x=&amp;gt;x.__SignatureSize + 4", [
 ["__SignatureSize", 0, "uint32"],
 ["__Owner", 4, "GUID"],
 ["Owner", 0, "Value", {"value": "x=&amp;gt;x.__Owner.Value"}],
 ["__Data", 20, "String", {"length": "x=&amp;gt;x.__SignatureSize - 16", "term": "", "max_length": 10000}],
 ["Cert", 0, "Value", {"value": "x=&amp;gt;parse_x509(data=x.__Data)[0]"}]
 ]],
 ["HashList", 0, [
 ["__SignatureSize", 0, "uint32"],
 ["Hashes", 4, "Array", {"type": "Hash", "count": 1000, "sentinel": "x=&amp;gt;x.Owner = '{00000000-0000-0000-0000-000000000000}'"}]
 ]],
 ["Hash", 48, [
 ["__Owner", 0, "GUID"],
 ["Owner", 0, "Value", {"value": "x=&amp;gt;x.__Owner.Value"}],
 ["__Data", 16, "String", {"length": 32, "term": ""}],
 ["Hash", 0, "Value", {"value": "x=&amp;gt;format(format='%048x', args=[x.__Data])"}]
 ]],
 ["GUID", 16, [
 ["__D1", 0, "uint32"],
 ["__D2", 4, "uint16"],
 ["__D3", 6, "uint16"],
 ["__D4", 8, "String", {"term": "", "length": 2}],
 ["__D5", 10, "String", {"term": "", "length": 6}],
 ["Value", 0, "Value", {
 "value": "x=&amp;gt;format(format='{%08x-%04x-%04x-%02x-%02x}', args=[x.__D1, x.__D2, x.__D3, x.__D4, x.__D5])"
 }]
 ]]
 ]'''

 LET GetSignatures(Namespace, Name) = Select Name as Name,
 parse_binary(accessor="data", filename=Value,
 profile=PROFILE, struct="EfiSignatures").Signatures as Signatures
 FROM efivariables(namespace=Namespace, name=Name, value=True)

sources:
 - name: Certificates
 query: |
 LET PK = Select * FROM foreach(
 row=GetSignatures(Namespace="{8be4df61-93ca-11d2-aa0d-00e098032b8c}", Name="PK"),
 query={
 Select * From foreach(
 row=Signatures,
 query={
 Select Name, Owner, Cert as Certificate From Payload
 })
 })
 LET DB = Select * FROM foreach(
 row=GetSignatures(Namespace="{d719b2cb-3d3a-4596-a3bc-dad00e67656f}", Name="db"),
 query={
 Select * From foreach(
 row=Signatures,
 query={
 Select Name, Owner, Cert as Certificate From Payload
 })
 })

 Select * from chain(
 a={ Select * From PK },
 b={ Select * From DB })

 - name: Hashes
 query: |
 Select * FROM foreach(
 row=GetSignatures(Namespace="{d719b2cb-3d3a-4596-a3bc-dad00e67656f}", Name="dbx"),
 query={
 Select * From foreach(
 row=Signatures,
 query={
 Select * FROM foreach(
 row=Payload.Hashes,
 query={
 Select Name, Owner, Hash From scope()
 })
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Generic.System.HostsFile</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.system.hostsfile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.system.hostsfile/</guid><description>&lt;p>The system hosts file maps hostnames to IP addresses. In some cases,
entries in this file take precedence and overrides the results from
the system DNS service.&lt;/p>
&lt;p>The file is a simple text file, with one line per IP address. Each
whitespace-separated word following the IP address is a hostname.
The Linux man page refers to the the first hostname as &lt;em>canonical_hostname&lt;/em>,
and any following words as &lt;em>aliases&lt;/em>. They are treated the same by this
artifact.&lt;/p>
&lt;p>The hosts file is typically present on all Linux-based systems (including macOS),
with entries for localhost. The same file format is also supported on Windows.&lt;/p>
&lt;p>The source &lt;em>Hosts&lt;/em> returns each line in each hosts file that matches
the glob parameters for address and hostname. The hostname and aliases
are combined in a single column &lt;em>Hostnames&lt;/em>. Columns returned:&lt;/p>
&lt;ul>
&lt;li>OSPath&lt;/li>
&lt;li>Hostnames&lt;/li>
&lt;li>Comment&lt;/li>
&lt;/ul>
&lt;p>Only comments that follows the hostname on the same line are captured in Comment.
Comments on their own lines are ignored.&lt;/p>
&lt;p>A second source &lt;em>HostsFlattened&lt;/em> provides a flattened result, with each row
containing an IP address and a single hostname.&lt;/p>
&lt;p>This artifact also exports a function &lt;code>parse_hostsfile()&lt;/code> that returns Hostname
and Aliases individually.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.System.HostsFile
description: |
 The system hosts file maps hostnames to IP addresses. In some cases,
 entries in this file take precedence and overrides the results from
 the system DNS service.

 The file is a simple text file, with one line per IP address. Each
 whitespace-separated word following the IP address is a hostname.
 The Linux man page refers to the the first hostname as *canonical_hostname*,
 and any following words as *aliases*. They are treated the same by this
 artifact.

 The hosts file is typically present on all Linux-based systems (including macOS),
 with entries for localhost. The same file format is also supported on Windows.

 The source *Hosts* returns each line in each hosts file that matches
 the glob parameters for address and hostname. The hostname and aliases
 are combined in a single column *Hostnames*. Columns returned:

 - OSPath
 - Hostnames
 - Comment

 Only comments that follows the hostname on the same line are captured in Comment.
 Comments on their own lines are ignored.

 A second source *HostsFlattened* provides a flattened result, with each row
 containing an IP address and a single hostname.

 This artifact also exports a function `parse_hostsfile()` that returns Hostname
 and Aliases individually.

reference:
 - https://manpages.debian.org/bookworm/manpages/hosts.5.en.html

export: |
 LET _parse_hostsfile(OSPath) = SELECT parse_string_with_regex(
 string=Line,
 regex='''^[\t ]*(?P&amp;lt;Address&amp;gt;[^\s#]+)[\t ]+(?P&amp;lt;Hostname&amp;gt;[^\s#]+)(?P&amp;lt;Aliases&amp;gt;[^#\n\r]+)?(?:[\t ]*#(?P&amp;lt;Comment&amp;gt;.+))?''') AS Parsed
 FROM parse_lines(filename=OSPath)
 WHERE Parsed.Address

 LET parse_hostsfile(OSPath) = SELECT Parsed.Address AS Address,
 Parsed.Hostname AS Hostname,
 filter(list=split(sep='''\s+''', string=Parsed.Aliases), regex='.+') AS Aliases,

 /* Remove any whitespace between comment character and comment: */
 regex_replace(re='''^\s+''', source=Parsed.Comment, replace='$1') AS Comment
 FROM _parse_hostsfile(OSPath=OSPath)

 LET Files = SELECT OSPath FROM glob(globs=hostsFileGlobs.HostsFileGlobs)

 LET HostsFiles = SELECT * FROM foreach(row=Files, query={
 SELECT OSPath, Address, Hostname, Aliases, Comment
 FROM parse_hostsfile(OSPath=OSPath)
 })

parameters:
 - name: hostsFileGlobs
 description: Globs to find hosts files
 type: csv
 default: |
 HostsFileGlobs
 C:\Windows\System32\drivers\etc\hosts
 /etc/hosts
 - name: HostnameRegex
 description: Hostname or aliases to match
 default: .
 type: regex
 - name: AddressRegex
 description: IP addresses to match
 default: .
 type: regex

sources:
 - name: Hosts
 query: |
 SELECT OSPath, Address,
 (Hostname, ) + Aliases AS Hostname,
 Comment
 FROM HostsFiles
 WHERE Hostname =~ HostnameRegex
 AND Address =~ AddressRegex

 - name: HostsFlattened
 query: |
 SELECT OSPath, Address, Hostname, Comment
 FROM flatten(query={
 SELECT OSPath, Address, (Hostname, ) + Aliases AS Hostname, Comment
 FROM HostsFiles
 })
 WHERE Address =~ AddressRegex
 AND Hostname =~ HostnameRegex

&lt;/code>&lt;/pre></description></item><item><title>Generic.System.ProcessSiblings</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.system.processsiblings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.system.processsiblings/</guid><description>&lt;p>This artifact queries the process tracker to display all known
sibling processes of the target process (i.e. all other processes
from the same parent).&lt;/p>
&lt;p>This is useful to reveal the complete interaction that included
the process in question (e.g. previous shell commands etc).&lt;/p>
&lt;p>Minimum Version: 0.6.6&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.System.ProcessSiblings
description: |
 This artifact queries the process tracker to display all known
 sibling processes of the target process (i.e. all other processes
 from the same parent).

 This is useful to reveal the complete interaction that included
 the process in question (e.g. previous shell commands etc).

 Minimum Version: 0.6.6

parameters:
 - name: CommandlineRegex
 default: .
 description: Target process by this command line
 type: regex

 - name: PidFilter
 description: Filter pids by this regex
 default: .
 type: regex

 - name: IncludePstree
 type: bool

sources:
 - query: |
 LET GetDetails(Records) = SELECT
 Id AS ChildPid,
 Data.CommandLine AS CommandLine,
 Data.Username AS Username,
 StartTime, EndTime
 FROM Records
 ORDER BY StartTime

 SELECT * FROM foreach(row={
 SELECT Pid, Ppid, Name
 FROM process_tracker_pslist()
 WHERE CommandLine =~ CommandlineRegex
 AND Pid =~ PidFilter
 }, query={
 SELECT Pid,Ppid, Name, ChildPid,
 CommandLine, Username, StartTime, EndTime,
 if(condition=IncludePstree, then=process_tracker_tree(id=Ppid)) AS ParentTree
 FROM foreach(row=GetDetails(
 Records=process_tracker_children(id=Ppid)))
 })

column_types:
 - name: ParentTree
 type: tree

&lt;/code>&lt;/pre></description></item><item><title>Generic.System.Pstree</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.system.pstree/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.system.pstree/</guid><description>&lt;p>This artifact displays the call chain for every process on the
system by traversing the process&amp;rsquo;s parent ID.&lt;/p>
&lt;p>It is useful for establishing where a process came from - for
example, if a PowerShell process is spawned from Winword (event via
several intermediary processes) it could mean word was
compromised.&lt;/p>
&lt;p>A more accurate call chain will be available when the
Windows.Events.TrackProcesses artifact is collected (required
Sysmon) or Windows.Events.TrackProcessesBasic (does not require
Sysmon)&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.System.Pstree
description: |
 This artifact displays the call chain for every process on the
 system by traversing the process's parent ID.

 It is useful for establishing where a process came from - for
 example, if a PowerShell process is spawned from Winword (event via
 several intermediary processes) it could mean word was
 compromised.

 A more accurate call chain will be available when the
 Windows.Events.TrackProcesses artifact is collected (required
 Sysmon) or Windows.Events.TrackProcessesBasic (does not require
 Sysmon)

parameters:
 - name: CommandlineRegex
 default: .
 type: regex

 - name: PidFilter
 description: Filter pids by this regex
 default: .
 type: regex

 - name: CallChainFilter
 default: .
 type: regex

 - name: CallChainSep
 default: " -&amp;gt; "

 - name: IncludePstree
 type: bool

sources:
 - query: |
 SELECT Pid, Ppid, Name, Username, Exe, CommandLine, StartTime, EndTime,
 join(array=process_tracker_callchain(id=Pid).Data.Name, sep=CallChainSep) AS CallChain,
 if(condition=IncludePstree, then=process_tracker_tree(id=Pid)) AS PSTree
 FROM process_tracker_pslist()
 WHERE CommandLine =~ CommandlineRegex
 AND CallChain =~ CallChainFilter
 AND Pid =~ PidFilter

column_types:
 - name: PSTree
 type: tree

&lt;/code>&lt;/pre></description></item><item><title>Generic.Utils.DeadDiskRemapping</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.utils.deaddiskremapping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.utils.deaddiskremapping/</guid><description>&lt;p>Calculate a remapping configuration from a dead disk image.&lt;/p>
&lt;p>The artifact uses some heuristics to calculate a suitable remapping
configuration for a dead disk image:&lt;/p>
&lt;p>The following cases are handled:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If ImagePath is a directory to a mounted partition then we
generate directory remapping. This is suitable for handling images
with filesystems that Velociraptor cannot yet directly handle.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If the ImagePath points to a file which starts with the NTFS
signature we assume this is a partition image and not a disk
image.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If the ImagePath is a full disk image we assume it has a partition
table at the front, we then enumerate all the partitions and look
for an NTFS partition with a &lt;code>Windows&lt;/code> directory at the top
level. We assume this is the windows drive and remap it to the C:
drive.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Utils.DeadDiskRemapping
description: |
 Calculate a remapping configuration from a dead disk image.

 The artifact uses some heuristics to calculate a suitable remapping
 configuration for a dead disk image:

 The following cases are handled:

 * If ImagePath is a directory to a mounted partition then we
 generate directory remapping. This is suitable for handling images
 with filesystems that Velociraptor cannot yet directly handle.

 * If the ImagePath points to a file which starts with the NTFS
 signature we assume this is a partition image and not a disk
 image.

 * If the ImagePath is a full disk image we assume it has a partition
 table at the front, we then enumerate all the partitions and look
 for an NTFS partition with a `Windows` directory at the top
 level. We assume this is the windows drive and remap it to the C:
 drive.

type: SERVER

parameters:
 - name: ImagePath
 default: /tmp/image.dd
 description: Path to the image file to inspect.

 - name: Accessor
 description: |
 Accessor to read the image with.

 If not provided guess based on image file extension.

 - name: Hostname
 default: Virtual Host

 - name: Upload
 type: bool
 default: "Y"
 description: If specified we upload the generated YAML

 - name: CommonRemapping
 description: Common clauses for all remapping in YAML
 default: |
 remappings:
 - type: permissions
 permissions:
 - COLLECT_CLIENT
 - FILESYSTEM_READ
 - FILESYSTEM_WRITE
 - READ_RESULTS
 - MACHINE_STATE
 - SERVER_ADMIN
 - COLLECT_SERVER
 - EXECVE
 - type: impersonation
 os: windows
 hostname: {{ .Hostname }}
 env:
 - key: SystemRoot
 value: C:\Windows
 - key: WinDir
 value: C:\Windows
 disabled_functions:
 - amsi
 - lookupSID
 - token
 disabled_plugins:
 - execve
 - http_client
 - users
 - certificates
 - handles
 - pslist
 - interfaces
 - modules
 - netstat
 - partitions
 - proc_dump
 - proc_yara
 - vad
 - winobj
 - wmi
 - type: shadow
 from:
 accessor: zip
 "on":
 accessor: zip
 - type: shadow
 from:
 accessor: raw_reg
 "on":
 accessor: raw_reg
 - type: shadow
 from:
 accessor: data
 "on":
 accessor: data

export: |
 -- Searches for a partition with a Windows directory, Unless this
 -- is a partition image.
 LET _FindWindowsPartition(ImagePath, Accessor) = SELECT *
 FROM switch(
 a={
 SELECT 0 AS StartOffset, Accessor, ImagePath AS PartitionPath
 FROM stat(filename=ImagePath)
 WHERE IsDir
 },
 b={
 SELECT 0 AS StartOffset, Accessor, ImagePath AS PartitionPath
 FROM scope()
 WHERE read_file(accessor=Accessor, filename=ImagePath, length=4, offset=3) = "NTFS"
 AND log(message="Detected NTFS signature at offset 0 - " +
 "assuming this is a Windows partition image")
 },
 c={
 SELECT StartOffset, Accessor, _PartitionPath AS PartitionPath
 FROM Artifact.Windows.Forensics.PartitionTable(
 ImagePath=ImagePath,
 Accessor=GuessAccessor(ImagePath=ImagePath))
 WHERE log(level="DEBUG", dedup=-1,
 message="Searching for Windows directory: %#x-%#x (%v) %v - Magic %v",
 args=[StartOffset, EndOffset, Size, name, Magic])
 AND TopLevelDirectory =~ "Windows"
 AND log(message="&amp;lt;green&amp;gt;Found Windows Partition&amp;lt;/&amp;gt; at offset %#x with top level directory %v",
 args=[StartOffset, TopLevelDirectory])
 LIMIT 1
 })

 -- Guess the correct accessor based on the file extension. This
 -- allows us to handle several image formats.
 LET GuessAccessor(ImagePath) = Accessor ||
 if(condition=ImagePath =~ 'vmdk$', then='vmdk') ||
 if(condition=ImagePath =~ 'vhdx$', then='vhdx') ||
 if(condition=ImagePath =~ 'e01$', then='ewf')

 LET _MapHiveToKey(Hive, Key, Name, ImagePath) = log(dedup=-1,
 message="&amp;lt;green&amp;gt;Adding hive %v&amp;lt;/&amp;gt;", args=Hive) &amp;amp;&amp;amp;
 dict(type="mount",
 `description`=Name,
 `from`=dict(accessor="raw_reg",
 path_type="registry",
 prefix=pathspec(
 Path="/",
 DelegateAccessor="raw_ntfs",
 Delegate=ImagePath + Hive)),
 on=dict(accessor="registry", prefix=Key, path_type="registry"))

 LET _MapDirHiveToKey(Hive, Key, Name) = log(dedup=-1,
 message="&amp;lt;green&amp;gt;Adding hive %v&amp;lt;/&amp;gt;", args=Hive) &amp;amp;&amp;amp;
 dict(type="mount",
 `description`=Name,
 `from`=dict(accessor="raw_reg",
 path_type="registry",
 prefix=pathspec(
 Path="/",
 DelegateAccessor="file",
 DelegatePath=Hive)),
 on=dict(accessor="registry", prefix=Key, path_type="registry"))

 -- Look for user hives and map them in HKEY_USERS
 LET _FindUserHives(ImagePath) = SELECT _MapHiveToKey(
 Name="Map User hive for " + OSPath[-2],
 Hive=OSPath,
 Key="HKEY_USERS\\" + OSPath[-2],
 ImagePath=ImagePath
 ) AS Map
 FROM glob(globs='/Users/*/NTUser.DAT',
 accessor="raw_ntfs",
 root=ImagePath)
 WHERE log(dedup=-1, message="&amp;lt;green&amp;gt;Found User Hive at %v&amp;lt;/&amp;gt;", args=OSPath.Path)

 LET _FindDirUserHives(ImagePath) = SELECT _MapDirHiveToKey(
 Name="Map User hive for " + OSPath[-2],
 Hive=OSPath,
 Key="HKEY_USERS\\" + OSPath[-2]) AS Map
 FROM glob(globs='/Users/*/NTUser.DAT',
 root=ImagePath)
 WHERE log(dedup=-1, message="&amp;lt;green&amp;gt;Found User Hive at %v&amp;lt;/&amp;gt;", args=OSPath.Path)

 LET CalculateWindowsMappings(ImagePath) = Remappings.remappings + (
 dict(type="mount",
 `from`=dict(accessor="raw_ntfs", prefix=ImagePath),
 on=dict(accessor="ntfs", prefix="\\\\.\\C:", path_type="ntfs")
 ),
 dict(type="mount",
 `from`=dict(accessor="raw_ntfs", prefix=ImagePath),
 on=dict(accessor="file", prefix="C:", path_type="windows")
 ),
 dict(type="mount",
 `from`=dict(accessor="raw_ntfs", prefix=ImagePath),
 on=dict(accessor="auto", prefix="C:", path_type="windows")
 ),
 _MapHiveToKey(Name="Map Software Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/SOFTWARE",
 Key="HKEY_LOCAL_MACHINE/Software"),
 _MapHiveToKey(Name="Map Security Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/Security",
 Key="HKEY_LOCAL_MACHINE/Security"),
 _MapHiveToKey(Name="Map System Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/System",
 Key="HKEY_LOCAL_MACHINE/System"),
 _MapHiveToKey(Name="Map SAM Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/SAM",
 Key="SAM"),
 _MapHiveToKey(Name="Map Amcache Hive",
 ImagePath=ImagePath,
 Hive="/Windows/appcompat/Programs/Amcache.hve",
 Key="Amcache")
 ) + _FindUserHives(ImagePath=WindowsPartition.PartitionPath).Map

 LET CalculateWindowsDirMappings(ImagePath) = Remappings.remappings + (
 dict(type="mount",
 description="Mount Directory " + ImagePath + " on C: drive",
 `from`=dict(accessor="file", prefix=ImagePath),
 on=dict(accessor="ntfs", prefix="\\\\.\\C:", path_type="ntfs")
 ),
 dict(type="mount",
 `from`=dict(accessor="file", prefix=ImagePath),
 on=dict(accessor="file", prefix="C:", path_type="windows")
 ),
 dict(type="mount",
 `from`=dict(accessor="file", prefix=ImagePath),
 on=dict(accessor="auto", prefix="C:", path_type="windows")
 ),
 _MapDirHiveToKey(Name="Map Software Hive",
 Hive="/Windows/System32/Config/SOFTWARE",
 Key="HKEY_LOCAL_MACHINE/Software"),
 _MapDirHiveToKey(Name="Map Security Hive",
 Hive="/Windows/System32/Config/Security",
 Key="HKEY_LOCAL_MACHINE/Security"),
 _MapDirHiveToKey(Name="Map System Hive",
 Hive="/Windows/System32/Config/System",
 Key="HKEY_LOCAL_MACHINE/System"),
 _MapDirHiveToKey(Name="Map SAM Hive",
 Hive="/Windows/System32/Config/SAM",
 Key="SAM"),
 _MapDirHiveToKey(Name="Map Amcache Hive",
 Hive="/Windows/appcompat/Programs/Amcache.hve",
 Key="Amcache")
 ) + _FindDirUserHives(ImagePath=ImagePath).Map

sources:
- query: |
 LET WindowsPartition &amp;lt;=
 _FindWindowsPartition(ImagePath=ImagePath, Accessor=Accessor)[0]

 LET Remappings &amp;lt;= parse_yaml(
 filename=template(template=CommonRemapping,
 expansion=dict(Hostname=Hostname)),
 accessor="data")

 -- Select the type of mapping to calculate depending on what ImagePath is.
 LET CalculateMappings =
 ( stat(filename=ImagePath).IsDir &amp;amp;&amp;amp;
 CalculateWindowsDirMappings(ImagePath=ImagePath) ) ||
 ( WindowsPartition.PartitionPath &amp;amp;&amp;amp;
 CalculateWindowsMappings(ImagePath=WindowsPartition.PartitionPath) ) ||
 log(message="&amp;lt;red&amp;gt;No suitable mapping found&amp;lt;/&amp;gt;")

 LET YamlText = serialize(format="yaml",
 item=dict(remappings=CalculateMappings))

 SELECT if(condition=Upload,
 then=upload(accessor="data", file=YamlText, name="remapping.yaml"),
 else=YamlText) AS Remapping
 FROM scope()

column_types:
- name: Remapping
 type: upload_preview

&lt;/code>&lt;/pre></description></item><item><title>Generic.Utils.FetchBinary</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.utils.fetchbinary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.utils.fetchbinary/</guid><description>&lt;p>A utility artifact which fetches a binary from a URL and caches it on disk.
We verify the hash of the binary on disk and if it does not match we fetch it again
from the source URL.&lt;/p>
&lt;p>This artifact is designed to be called from other artifacts. The
binary path will be emitted in the OSPath column.&lt;/p>
&lt;p>As a result of launching an artifact with declared &amp;ldquo;tools&amp;rdquo;
field, the server will populate the following environment
variables.&lt;/p>
&lt;p>Tool_&lt;ToolName>&lt;em>HASH - The hash of the binary
Tool&lt;/em>&lt;ToolName>&lt;em>FILENAME - The filename to store it.
Tool&lt;/em>&lt;ToolName>&lt;em>URL - The URL to fetch the binary from.
Tool&lt;/em>&lt;ToolName>_URLs - A set of possible URLs to fetch the binary from.&lt;/p>
&lt;p>Older server versions only supported a single URL but current
versions send a set of URLs to try in order.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Utils.FetchBinary
description: |
 A utility artifact which fetches a binary from a URL and caches it on disk.
 We verify the hash of the binary on disk and if it does not match we fetch it again
 from the source URL.

 This artifact is designed to be called from other artifacts. The
 binary path will be emitted in the OSPath column.

 As a result of launching an artifact with declared "tools"
 field, the server will populate the following environment
 variables.

 Tool_&amp;lt;ToolName&amp;gt;_HASH - The hash of the binary
 Tool_&amp;lt;ToolName&amp;gt;_FILENAME - The filename to store it.
 Tool_&amp;lt;ToolName&amp;gt;_URL - The URL to fetch the binary from.
 Tool_&amp;lt;ToolName&amp;gt;_URLs - A set of possible URLs to fetch the binary from.

 Older server versions only supported a single URL but current
 versions send a set of URLs to try in order.

parameters:
 - name: ToolName
 default: Autorun_amd64

 - name: IsExecutable
 type: bool
 default: Y
 description: Set to Y if the file needs to be executable (on windows it will have .exe extension)

 - name: SleepDuration
 default: "20"
 type: int
 description: A time to sleep before fetching the binary.

 - name: ToolInfo
 type: hidden
 description: A dict containing the tool information (deprecated).

 - name: TemporaryOnly
 type: bool
 description: |
 If true we use a temporary directory to hold the binary and
 remove it afterwards

implied_permissions:
 - SERVER_ADMIN
 - FILESYSTEM_WRITE
 - NETWORK

sources:
 - query: |
 LET S = scope()

 -- 1GB max
 LET HASH_MAX_SIZE &amp;lt;= S.HASH_MAX_SIZE || 1000000000

 -- Optionally accepts multiple download URLs from the server
 LET ParseUrls(Url) = parse_json_array(data=Url || '[]')

 LET args &amp;lt;= dict(
 ToolHash=get(field="Tool_" + ToolName + "_HASH"),
 ToolFilename=get(field="Tool_" + ToolName + "_FILENAME"),
 ToolURL=get(field="Tool_" + ToolName + "_URL"),
 ToolURLs=ParseUrls(Url=get(field="Tool_" + ToolName + "_URLs")))

 LET _ &amp;lt;= if(condition=NOT args.ToolFilename,
 then=log(level="ERROR",
 message="Tool %v not configured by the server. Did you define it as an artifact tool? %v", args=[ToolName, args]))

 // By default the temp directory is created inside a trusted directory.
 LET TempDir &amp;lt;= tempdir(remove_last=TRUE)

 // Where store the file. If the user specified TemporaryOnly we
 // remove it with the tempdir, otherwise we store it in the trusted
 // directory.
 LET binpath &amp;lt;= if(condition=TemporaryOnly, then=TempDir, else=dirname(path=TempDir))

 // Where we should save the file - use the filename as specified by the server.
 LET ToolPath &amp;lt;= path_join(components=[binpath, args.ToolFilename || "Unknown"])

 // Download the file from the binary URL and store in the local
 // binary cache.
 // If http_client support multiple URLs use them.
 LET download_multiple = SELECT * FROM if(condition=args.ToolURLs
 AND version(plugin="http_client") &amp;gt; 2
 AND log(
 message="URLs for %v are at %v. The tool has a hash of %v", args=[
 args.ToolFilename , args.ToolURLs, args.ToolHash
 ])
 AND args.ToolHash,
 then={
 SELECT hash(path=Content) as Hash,
 args.ToolFilename AS Name,
 "Downloaded" AS DownloadStatus,
 copy(filename=Content, dest=ToolPath,
 permissions=if(condition=IsExecutable, then="x")) AS OSPath
 FROM http_client(url=args.ToolURLs, tempfile_extension=".tmp")
 WHERE log(message=format(format="downloaded hash of %v: %v, expected %v", args=[
 Content, Hash.SHA256, args.ToolHash]))
 AND Hash.SHA256 = args.ToolHash
 })

 // Download the file from the binary URL and store in the local
 // binary cache. Used for old clients with http_client that only supports one URL.
 LET download_single = SELECT * FROM if(condition=log(
 message="URL for " + args.ToolFilename +
 " is at " + args.ToolURL + " and has hash of " + args.ToolHash)
 AND args.ToolHash AND args.ToolURL,
 then={
 SELECT hash(path=Content) as Hash,
 args.ToolFilename AS Name,
 "Downloaded" AS DownloadStatus,
 copy(filename=Content, dest=ToolPath,
 permissions=if(condition=IsExecutable, then="x")) AS OSPath
 FROM http_client(url=args.ToolURL, tempfile_extension=".tmp")
 WHERE log(message=format(format="downloaded hash of %v: %v, expected %v", args=[
 Content, Hash.SHA256, args.ToolHash]))
 AND Hash.SHA256 = args.ToolHash
 }, else={
 SELECT * FROM scope()
 WHERE NOT log(message="No valid setup - is tool " + ToolName +
 " configured in the server inventory?")
 })

 // Check if the existing file in the binary file cache matches
 // the hash.
 LET existing = SELECT OSPath, hash(path=OSPath) AS Hash, Name,
 "Cached" AS DownloadStatus
 FROM stat(filename=ToolPath)
 WHERE log(message=format(format="Local hash of %v: %v, expected %v", args=[
 OSPath, Hash.SHA256, args.ToolHash]))
 AND Hash.SHA256 = args.ToolHash

 // Find the required_tool either in the local cache or
 // download it (and put it in the cache for next time). If we
 // have to download the file we sleep for a random time to
 // stagger server bandwidth load.
 SELECT *, OSPath AS FullPath
 FROM switch(
 b=existing,
 c={
 SELECT rand(range=SleepDuration) AS timeout
 FROM scope()
 WHERE args AND args.ToolURL AND
 log(message=format(format='Sleeping %v Seconds',
 args=[timeout])) AND sleep(time=timeout) AND FALSE
 },
 d=download_multiple,
 e=download_single)

&lt;/code>&lt;/pre></description></item><item><title>Generic.Utils.SendEmail</title><link>https://docs.velociraptor.app/artifact_references/pages/generic.utils.sendemail/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/generic.utils.sendemail/</guid><description>&lt;p>A Utility artifact for sending emails.&lt;/p>
&lt;p>This artifact handles the challenges of MIME, encodings and other pitfalls
of sending anything but simple plain-text emails. It will, among other things,&lt;/p>
&lt;ul>
&lt;li>Let you provide both HTML and plain-text email bodies, letting the email
client pick either HTML or plain-text, depending on what it supports (utilising
&amp;ldquo;multipart/alternative&amp;rdquo;)&lt;/li>
&lt;li>Text is encoded as Base64 (unless disabled), split into 76-character-wide
lines in order to conform with RFC standards&lt;/li>
&lt;li>Attachments are supported and automatically encoded&lt;/li>
&lt;li>The whole email is sent as a multi-part message&lt;/li>
&lt;/ul>
&lt;p>All of the functions used to create the final body of the email are exported
and are available for further customisation when sending an email.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Utils.SendEmail
author: Andreas Misje – @misje
description: |
 A Utility artifact for sending emails.

 This artifact handles the challenges of MIME, encodings and other pitfalls
 of sending anything but simple plain-text emails. It will, among other things,

 - Let you provide both HTML and plain-text email bodies, letting the email
 client pick either HTML or plain-text, depending on what it supports (utilising
 "multipart/alternative")
 - Text is encoded as Base64 (unless disabled), split into 76-character-wide
 lines in order to conform with RFC standards
 - Attachments are supported and automatically encoded
 - The whole email is sent as a multi-part message

 All of the functions used to create the final body of the email are exported
 and are available for further customisation when sending an email.

type: SERVER

parameters:
- name: Secret
 description: The name of the secret to use to send the mail with.

- name: Recipients
 type: json_array
 default: '["noone@example.org"]'
 description: Where to send the mail to.

- name: Sender
 description: The sender address (from).

- name: FilesToUpload
 type: csv
 description: Files to upload, optionally renamed.
 default: |
 Path,Filename

- name: PlainTextMessage
 description: A plain-text message.

- name: HTMLMessage
 description: An HTML-formatted message.

- name: EncodeText
 type: bool
 default: true
 description: |
 Base64-encode plain-text and HTML. If disabled, ensure to keep lines within
 998 octets, or encode the data manually and include an encoding header.

- name: Subject
 default: A message from Velociraptor

- name: Period
 type: int
 default: 10
 description: |
 Refuse to send mails more often than this interval (in seconds). This throttling
 is applied to the whole server.

export: |
 LET _RandomString = SELECT format(format="%c", args=20 + rand(range=107)) AS Ch
 FROM range(end=1000)
 WHERE Ch =~ "[A-Za-z0-9'()+_,./:=?]"
 LIMIT 70

 -- Create a random string suitable as a MIME boundary:
 LET RandomString = join(array=_RandomString.Ch)

 -- Base64-encode data and split the result into 76-character long lines (as per
 -- RFC 2045 6.8). Note that a "Content-Transfer-Encoding: base64" header is
 -- needed for this message to interpreted correctly:
 LET EncodeData(Data) = regex_replace(re="(.{76})",
 replace="$1\r\n",
 source=base64encode(string=Data))

 -- Wrap Sections in boundaries. Header may be used to create a sub-boundary,
 -- useful for multipart/alternative:
 LET WrapInBoundary(Boundary, Sections, Header) = template(
 template="{{ if .header }}{{ .header }}; boundary={{ .boundary }}\r\n\r\n{{ end }}{{ range .sections }}--{{ $.boundary }}\r\n{{ . }}{{ end }}--{{ $.boundary }}--\r\n",
 expansion=dict(
 boundary=Boundary,
 sections=Sections,
 header=Header))

 -- Add content type ("plain" or "html") and newlines to text. If Encode is set,
 -- encode the text in Base64 and add a suitable transfer header:
 LET WrapText(Value, Type, Encode) = if(
 condition=Value,
 then=format(
 format='Content-Type: text/%s; charset="utf-8"%s\r\n\r\n%v\r\n',
 args=[Type, if(condition=get(field='Encode', default=false),
 then="\r\nContent-Transfer-Encoding: base64",
 else=""), if(
 condition=get(field='Encode', default=false),
 then=EncodeData(Data=Value),
 else=Value)]))

 -- Wrap text (plain, HTML or both) in multipart/alternative, letting clients
 -- pick either HTML or plain-text, depending on what they support. If just
 -- one of Plain/HTML is specified, multipart/alternative is not used:
 LET WrapAlternative(Plain, HTML) = if(
 condition=Plain
 AND HTML,
 then=WrapInBoundary(Header="Content-Type: multipart/alternative",
 Boundary=RandomString,
 Sections=(Plain, HTML)),
 else=Plain || HTML)

 -- Encodes the file as base64:
 LET EncodeFile(Filename) = EncodeData(Data=read_file(filename=Filename))

 -- A Helper function to embed a file content from disk.
 LET AttachFile(Path, Filename) = template(
 template='Content-Type: application/octet-stream; name="{{ .name }}"\r\nContent-Disposition: attachment; filename="{{ .filename }}"\r\nContent-Transfer-Encoding: base64\r\n\r\n{{ .data }}\r\n\r\n',
 expansion=dict(
 name=regex_replace(source=basename(path=Filename),
 re='''\..+$''',
 replace=''),
 filename=basename(path=Filename),
 data=EncodeFile(Filename=Path)))

 -- Call AttachFile() for each file in Files that exist. Files must be an array
 -- of dicts with the members "Path" and an optional "Filename", which is used
 -- to replace the attachment filename. Useful for temporary files:
 LET AttachFiles(Files) = array(_={
 SELECT AttachFile(
 Path=Path,
 Filename=get(field='Filename', default= Path)) AS Part
 FROM foreach(row=Files)
 WHERE (stat(filename=Path).OSPath
 AND log(message="Attaching %v", args=Path, dedup=-1, level='INFO')) OR NOT
 log(message="Fail to attach %v", args=Path, dedup=-1, level='WARN')
 })

sources:
- query: |
 LET Texts &amp;lt;= WrapAlternative(Plain=WrapText(
 Value=PlainTextMessage,
 Type='plain',
 Encode=EncodeText),
 HTML=WrapText(Value=HTMLMessage,
 Type='html',
 Encode=EncodeText))

 LET Texts &amp;lt;= if(condition=Texts, then=[Texts], else=[])

 LET Boundary &amp;lt;= RandomString

 LET Headers &amp;lt;= dict(`Content-Type`='multipart/mixed; boundary=' + Boundary)

 -- Build the email parts - first the text message, then the attachments.
 LET Message &amp;lt;= WrapInBoundary(Header="",
 Boundary=Boundary,
 Sections=Texts + AttachFiles(Files=FilesToUpload).Part)

 -- Send the mail
 SELECT mail(secret=Secret,
 `to`=Recipients,
 `from`=Sender,
 period=Period,
 subject=Subject,
 headers=Headers,
 `body`=Message) AS Mail
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Linux.Applications.Chrome.Extensions</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.applications.chrome.extensions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.applications.chrome.extensions/</guid><description>&lt;p>Fetch Chrome extensions.&lt;/p>
&lt;p>Chrome extensions are installed into the user&amp;rsquo;s home directory. We
search for manifest.json files in a known path within each system
user&amp;rsquo;s home directory. We then parse the manifest file as JSON.&lt;/p>
&lt;p>Many extensions use locale packs to resolve strings like name and
description. In this case we detect the default locale and load
those locale files. We then resolve the extension&amp;rsquo;s name and
description from there.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Applications.Chrome.Extensions
description: |
 Fetch Chrome extensions.

 Chrome extensions are installed into the user's home directory. We
 search for manifest.json files in a known path within each system
 user's home directory. We then parse the manifest file as JSON.

 Many extensions use locale packs to resolve strings like name and
 description. In this case we detect the default locale and load
 those locale files. We then resolve the extension's name and
 description from there.

parameters:
 - name: extensionGlobs
 default: /.config/google-chrome/*/Extensions/*/*/manifest.json
sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'

 query: |
 /* For each user on the system, search for extension manifests
 in their home directory. */
 LET extension_manifests = SELECT * from foreach(
 row={
 SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
 },
 query={
 SELECT OSPath, Mtime, Ctime, User, Uid
 FROM glob(
 globs=extensionGlobs,
 root=Homedir)
 })

 /* If the Manifest declares a default_locale then we
 load and parse the messages file. In this case the
 messages are actually stored in the locale file
 instead of the main manifest.json file.
 */
 LET maybe_read_locale_file =
 SELECT * from if(
 condition={
 select * from scope() where Manifest.default_locale
 },
 then={
 SELECT Manifest,
 Uid, User,
 Filename as LocaleFilename,
 ManifestFilename,
 parse_json(data=Data) AS LocaleManifest
 FROM read_file(
 -- Munge the filename to get the messages.json path.
 filenames=regex_replace(
 source=ManifestFilename,
 replace="/_locales/" + Manifest.default_locale +
 "/messages.json",
 re="/manifest.json$"))
 },
 else={
 -- Just fill in empty Locale results.
 SELECT Manifest,
 Uid, User,
 "" AS LocaleFilename,
 "" AS ManifestFilename,
 "" AS LocaleManifest
 FROM scope()
 })

 LET parse_json_files = SELECT * from foreach(
 row={
 SELECT Filename as ManifestFilename,
 Uid, User,
 parse_json(data=Data) as Manifest
 FROM read_file(filenames=OSPath)
 },
 query=maybe_read_locale_file)

 LET parsed_manifest_files = SELECT * from foreach(
 row=extension_manifests,
 query=parse_json_files)

 SELECT Uid, User,

 /* If the manifest name contains __MSG_ then the real
 name is stored in the locale manifest. This condition
 resolves the Name column either to the main manifest or
 the locale manifest.
 */
 if(condition="__MSG_" in Manifest.name,
 then=get(item=LocaleManifest,
 member=regex_replace(
 source=Manifest.name,
 replace="$1",
 re="(?:__MSG_(.+)__)")).message,
 else=Manifest.name) as Name,

 if(condition="__MSG_" in Manifest.description,
 then=get(item=LocaleManifest,
 member=regex_replace(
 source=Manifest.description,
 replace="$1",
 re="(?:__MSG_(.+)__)")).message,
 else=Manifest.description) as Description,

 /* Get the Identifier and Version from the manifest filename */
 regex_replace(
 source=ManifestFilename,
 replace="$1",
 re="(?:.+Extensions/([^/]+)/([^/]+)/manifest.json)$") AS Identifier,
 regex_replace(
 source=ManifestFilename,
 replace="$2",
 re="(?:.+Extensions/([^/]+)/([^/]+)/manifest.json)$") AS Version,

 Manifest.author as Author,
 Manifest.background.persistent AS Persistent,
 regex_replace(
 source=ManifestFilename,
 replace="$1",
 re="(.+Extensions/.+/)manifest.json$") AS Path,

 Manifest.oauth2.scopes as Scopes,
 Manifest.permissions as Permissions,
 Manifest.key as Key

 FROM parsed_manifest_files

&lt;/code>&lt;/pre></description></item><item><title>Linux.Applications.Chrome.Extensions.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.applications.chrome.extensions.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.applications.chrome.extensions.upload/</guid><description>&lt;p>Upload all users chrome extension.&lt;/p>
&lt;p>We don&amp;rsquo;t bother actually parsing anything here, we just grab all the
extension files in user&amp;rsquo;s home directory.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Applications.Chrome.Extensions.Upload
description: |
 Upload all users chrome extension.

 We don't bother actually parsing anything here, we just grab all the
 extension files in user's home directory.

parameters:
 - name: extensionGlobs
 default: /.config/google-chrome/*/Extensions/**
sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 query: |
 -- For each user on the system, search for extension files
 -- in their home directory and upload them.
 SELECT * from foreach(
 row={
 SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
 },
 query={
 SELECT OSPath, Mtime, Ctime, User, Uid,
 upload(file=OSPath) as Upload
 FROM glob(globs=extensionGlobs, root=Homedir)
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Applications.Docker.Info</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.applications.docker.info/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.applications.docker.info/</guid><description>&lt;p>Get Dockers info by connecting to its socket.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Applications.Docker.Info
description: Get Dockers info by connecting to its socket.
parameters:
 - name: dockerSocket
 description: |
 Docker server socket. You will normally need to be root to connect.
 default: /var/run/docker.sock

implied_permissions:
- NETWORK

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 query: |
 LET data = SELECT parse_json(data=Content) as JSON
 FROM http_client(url=dockerSocket + ":unix/info")

 SELECT JSON.ID as ID,
 JSON.Containers as Containers,
 JSON.ContainersRunning as ContainersRunning,
 JSON.ContainersPaused as ContainersPaused,
 JSON.ContainersStopped as ContainersStopped,
 JSON.Images as Images,
 JSON.Driver as Driver,
 JSON.MemoryLimit as MemoryLimit,
 JSON.SwapLimit as SwapLimit,
 JSON.KernelMemory as KernelMemory,
 JSON.CpuCfsPeriod as CpuCfsPeriod,
 JSON.CpuCfsQuota as CpuCfsQuota,
 JSON.CPUShares as CPUShares,
 JSON.CPUSet as CPUSet,
 JSON.IPv4Forwarding as IPv4Forwarding,
 JSON.BridgeNfIptables as BridgeNfIptables,
 JSON.BridgeNfIp6tables as BridgeNfIp6tables,
 JSON.OomKillDisable as OomKillDisable,
 JSON.LoggingDriver as LoggingDriver,
 JSON.CgroupDriver as CgroupDriver,
 JSON.KernelVersion as KernelVersion,
 JSON.OperatingSystem as OperatingSystem,
 JSON.OSType as OSType,
 JSON.Architecture as Architecture,
 JSON.NCPU as NCPU,
 JSON.MemTotal as MemTotal,
 JSON.HttpProxy as HttpProxy,
 JSON.HttpsProxy as HttpsProxy,
 JSON.NoProxy as NoProxy,
 JSON.Name as Name,
 JSON.ServerVersion as ServerVersion,
 JSON.DockerRootDir as DockerRootDir
 FROM data

&lt;/code>&lt;/pre></description></item><item><title>Linux.Applications.Docker.Version</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.applications.docker.version/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.applications.docker.version/</guid><description>&lt;p>Get Dockers version by connecting to its socket.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Applications.Docker.Version
description: Get Dockers version by connecting to its socket.

parameters:
 - name: dockerSocket
 description: |
 Docker server socket. You will normally need to be root to connect.
 default: /var/run/docker.sock

implied_permissions:
- NETWORK

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 query: |
 LET data = SELECT parse_json(data=Content) as JSON
 FROM http_client(url=dockerSocket + ":unix/version")

 SELECT JSON.Version as Version,
 JSON.ApiVersion as ApiVersion,
 JSON.MinAPIVersion as MinAPIVersion,
 JSON.GitCommit as GitCommit,
 JSON.GoVersion as GoVersion,
 JSON.Os as Os,
 JSON.Arch as Arch,
 JSON.KernelVersion as KernelVersion,
 JSON.BuildTime as BuildTime
 FROM data

&lt;/code>&lt;/pre></description></item><item><title>Linux.Debian.AptSources</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.debian.aptsources/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.debian.aptsources/</guid><description>&lt;p>Parse Debian apt sources.&lt;/p>
&lt;p>This Artifact searches for all apt sources files and parses all
fields in both one–line &lt;code>*.list&lt;/code> files and &lt;code>*.sources&lt;/code> files
(deb822-style format). The results are presented both in a readable
table and a flattened version for parsing.&lt;/p>
&lt;p>&lt;code>*.list&lt;/code> files contains lines of the form&lt;/p>
&lt;pre>&lt;code>deb http://us.archive.ubuntu.com/ubuntu/ bionic main restricted
deb-src [arch=amd64,i386 signed-by=/usr/share/keyrings/foo.gpg] https://foo.bar.baz/ubuntu/main jammy main restricted universe multiverse # Comment
&lt;/code>&lt;/pre>
&lt;p>deb indicates a source for binary packages, and deb-src instructs APT where
to find source code for packages.&lt;/p>
&lt;p>&lt;code>*.sources&lt;/code> files (deb822-style format) are in the form of key–value
lines, and as opposed to the one–line format, they may contain
multiple URIs, components and types (deb/deb-src), along with
embedded GPG keys. Example:&lt;/p>
&lt;pre>&lt;code>Types: deb deb-src
URIs: file:/home/apt/debian http://foo.bar.baz/main
Suites: unstable
Components: main contrib non-free
&lt;/code>&lt;/pre>
&lt;p>The exported function &lt;code>parse_aptsources(OSPath, flatten)&lt;/code> parses
both formats and returns an (optionally flattened) table with&lt;/p>
&lt;ul>
&lt;li>OSPath&lt;/li>
&lt;li>Types (deb/deb-src)&lt;/li>
&lt;li>Components (e.g. main/contrib/non-free/restricted,universe)&lt;/li>
&lt;li>Suites (e.g. unstable/bookworm/jammy)&lt;/li>
&lt;li>_URIBase (.e.g us.archive.ubuntu.com/ubuntu/)&lt;/li>
&lt;li>_Transport (e.g. http/https/file/cdrom/ftp)&lt;/li>
&lt;li>URIs (e.g. &lt;a href="http://us.archive.ubuntu.com/ubuntu/" target="_blank" >http://us.archive.ubuntu.com/ubuntu/&lt;/a>
)&lt;/li>
&lt;/ul>
&lt;p>Any option is added to an individual column. The most common options
are&lt;/p>
&lt;ul>
&lt;li>Architectures (e.g. amd64/i386/armel)&lt;/li>
&lt;li>Signed-By (e.g. /usr/share/keyrings/osquery.gpg)&lt;/li>
&lt;/ul>
&lt;p>All known option names are transformed to the plural PascalCase
variants as listed in the sources.list man page. Any undocumented
options will still be included in the results, with names unchanged.
Options in the one-line format of the form &amp;ldquo;lang+=de&amp;rdquo;/&amp;ldquo;arch-=i386&amp;rdquo;
will be put in columns like &amp;ldquo;Languages-Add&amp;rdquo;/&amp;ldquo;Architectures-Remove&amp;rdquo;,
matching the option names having the same effect in deb822.&lt;/p>
&lt;p>Entries in deb822 sources files may be disabled by including
&amp;ldquo;Enabled: no&amp;rdquo; instead of commenting out all lines. If this field
is not present with a &amp;ldquo;false&amp;rdquo; value, the entry is enabled. Use the
exported functions DebTrue()/DebFalse() to correctly parse all
accepted true/false strings, or use the VQL suggestion &amp;ldquo;Only enabled
sources&amp;rdquo; to filter on this column (true), if present.&lt;/p>
&lt;p>If the GPG key is embedded in a .sources file, the whole GPG key
will be included in the cell. Otherwise the value will be a file
path. Use the VQL suggestion &amp;ldquo;Hide embedded GPG keys&amp;rdquo; to replace
embedded GPG keys with &amp;ldquo;(embedded)&amp;rdquo; in the results. To
inspect the keys themselves (files or embedded data), use the
exchange artifact Linux.Debian.GPGKeys.&lt;/p>
&lt;p>If the function parameter &amp;ldquo;flatten&amp;rdquo; is False, multi–value fields
(like Components) will be combined in a single space-separated
string in each row.&lt;/p>
&lt;p>In addition to the two apt sources tables, a third table correlates
information from InRelease and Release files to provide additional
metadata. The modification timestamps may tell when the package
lists where last updated.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Debian.AptSources
description: |
 Parse Debian apt sources.

 This Artifact searches for all apt sources files and parses all
 fields in both one–line `*.list` files and `*.sources` files
 (deb822-style format). The results are presented both in a readable
 table and a flattened version for parsing.

 `*.list` files contains lines of the form

 ```
 deb http://us.archive.ubuntu.com/ubuntu/ bionic main restricted
 deb-src [arch=amd64,i386 signed-by=/usr/share/keyrings/foo.gpg] https://foo.bar.baz/ubuntu/main jammy main restricted universe multiverse # Comment
 ```

 deb indicates a source for binary packages, and deb-src instructs APT where
 to find source code for packages.

 `*.sources` files (deb822-style format) are in the form of key–value
 lines, and as opposed to the one–line format, they may contain
 multiple URIs, components and types (deb/deb-src), along with
 embedded GPG keys. Example:

 ```
 Types: deb deb-src
 URIs: file:/home/apt/debian http://foo.bar.baz/main
 Suites: unstable
 Components: main contrib non-free
 ```

 The exported function `parse_aptsources(OSPath, flatten)` parses
 both formats and returns an (optionally flattened) table with

 - OSPath
 - Types (deb/deb-src)
 - Components (e.g. main/contrib/non-free/restricted,universe)
 - Suites (e.g. unstable/bookworm/jammy)
 - _URIBase (.e.g us.archive.ubuntu.com/ubuntu/)
 - _Transport (e.g. http/https/file/cdrom/ftp)
 - URIs (e.g. http://us.archive.ubuntu.com/ubuntu/)

 Any option is added to an individual column. The most common options
 are

 - Architectures (e.g. amd64/i386/armel)
 - Signed-By (e.g. /usr/share/keyrings/osquery.gpg)

 All known option names are transformed to the plural PascalCase
 variants as listed in the sources.list man page. Any undocumented
 options will still be included in the results, with names unchanged.
 Options in the one-line format of the form "lang+=de"/"arch-=i386"
 will be put in columns like "Languages-Add"/"Architectures-Remove",
 matching the option names having the same effect in deb822.

 Entries in deb822 sources files may be disabled by including
 "Enabled: no" instead of commenting out all lines. If this field
 is not present with a "false" value, the entry is enabled. Use the
 exported functions DebTrue()/DebFalse() to correctly parse all
 accepted true/false strings, or use the VQL suggestion "Only enabled
 sources" to filter on this column (true), if present.

 If the GPG key is embedded in a .sources file, the whole GPG key
 will be included in the cell. Otherwise the value will be a file
 path. Use the VQL suggestion "Hide embedded GPG keys" to replace
 embedded GPG keys with "(embedded)" in the results. To
 inspect the keys themselves (files or embedded data), use the
 exchange artifact Linux.Debian.GPGKeys.

 If the function parameter "flatten" is False, multi–value fields
 (like Components) will be combined in a single space-separated
 string in each row.

 In addition to the two apt sources tables, a third table correlates
 information from InRelease and Release files to provide additional
 metadata. The modification timestamps may tell when the package
 lists where last updated.

reference:
 - https://manpages.debian.org/bookworm/apt/sources.list.5.en.html
 - https://manpages.debian.org/bookworm/dpkg-dev/deb822.5.en.html
 - https://salsa.debian.org/apt-team/apt/-/blob/main/apt-pkg/sourcelist.cc
 - https://wiki.debian.org/DebianRepository/Format#A.22Release.22_files

export: |
 /* Remove whitespace from the beginning and end of a string: */
 LET Trim(string) = regex_transform(source=string, map=dict(
 `(?m)^\\s+`='',
 `(?m)\\s+$`=''
 ))

 /* Replace any repeating whitespace with a single space: */
 LET Simplify(string) = regex_replace(source=string, re='''\s+''', replace=' ')

 /* The syntax in lists (deb822) and sources (one-line) files varies a bit,
 and deb822 is case-insensitive. Normalise all known fields (as per
 the man page): */
 LET NormaliseOpts(string) = regex_transform(source=string, map=dict(
 `(?i)types|type`='Types',
 `(?i)uris|uri`='URIs',
 `(?i)suites|suite`='Suites',
 `(?i)components|component`='Components',
 `(?i)architectures$|arch$`='Architectures',
 `(?i)architectures-add`='Architectures-Add',
 `(?i)architectures-remove`='Architectures-Remove',
 `(?i)languages$|lang$`='Languages',
 `(?i)languages-add`='Languages-Add',
 `(?i)languages-remove`='Languages-Remove',
 `(?i)targets$|target$`='Targets',
 `(?i)targets-add`='Targets-Add',
 `(?i)targets-remove`='Targets-Remove',
 `(?i)pdiffs`='PDiffs',
 `(?i)by-hash`='By-Hash',
 `(?i)allow-insecure`='Allow-Insecure',
 `(?i)allow-weak`='Allow-Weak',
 `(?i)allow-downgrade-to-insecure`='Allow-Downgrade-To-Insecure',
 `(?i)trusted`='Trusted',
 `(?i)signed-by`='Signed-By',
 `(?i)check-valid-until`='Check-Valid-Until',
 `(?i)valid-until-min`='Valid-Until-Min',
 `(?i)valid-until-max`='Valid-Until-Max',
 `(?i)check-date`='Check-Date',
 `(?i)date-max-future`='Date-Max-Future',
 `(?i)inrelease-path`='InRelease-Path',
 `(?i)enabled`='Enabled'
 ))

 LET DebTrue(string) = if(
 condition=string=~'(?i)^(?:yes|true|with|on|enable)$',
 then=true, else=false)
 LET DebFalse(string) = if(
 condition=string=~'(?i)^(?:no|false|without|off|disable)$',
 then=true, else=false)

 /* Extract Key–Value pairs from option string. If assignment is -=/+=,
 the -/+ operator is captured in Op: */
 LET OptStringToKeyValues__(string) = SELECT *
 FROM parse_records_with_regex(
 regex='''(?P&amp;lt;Key&amp;gt;[^ ]+?)(?P&amp;lt;Op&amp;gt;-|\+)?=(?P&amp;lt;Value&amp;gt;[^ ]+)''',
 accessor='data', file=string
 )

 /* Since option values may have multiple words, split them and flatten
 the results for further processing: */
 LET OptStringToKeyValues_(string) = SELECT *
 FROM flatten(query={
 SELECT Key,
 Op,
 split(sep_string=',', string=Value) AS Value
 FROM OptStringToKeyValues__(string=string)
 })

 /* Since options may be repeated, enumerate and group all values
 per key and operation: */
 LET OptStringToKeyValues(string) = SELECT Key,
 Op,
 enumerate(items=Value) AS Value
 FROM OptStringToKeyValues_(string=string)
 GROUP BY Key, Op

 /* When an option is specified with +/-, represent this by appending
 -Add/-Remove to the option name. These names match the syntax in
 the deb822 format (i.e. "arch-=i386" == "Arhitectures-Remove: i386").
 The purpose of these assignments is to keep the default values
 (rather than overriding them), but add or remove one or several
 values: */
 LET OpName(op) = if(condition=op='+',then='-Add',else=
 if(condition=op='-',then='-Remove',else=''))

 /* Convert a string of key–value pairs to a dict, and use consistent
 option names: */
 LET OptStringToDict(string, flatten) = to_dict(item={
 SELECT NormaliseOpts(string=Key)+OpName(op=Op) AS _key,
 if(condition=flatten, then=Value,
 else=join(array=Value, sep=' ')) AS _value
 FROM OptStringToKeyValues(string=string)
 })

 /* Parse a one-line deb sources.list file with options as a single string: */
 LET DebOneLine_Opts(OSPath) = SELECT OSPath, Type AS Types,
 Simplify(string=Options) AS Options, URI AS URIs,
 Transport AS _Transport, URIBase AS _URIBase, Suite AS Suites,
 Simplify(string=Trim(string=Components)) AS Components
 FROM parse_records_with_regex(
 file=OSPath,
 /* This regex attemps to cover most of the ways a sources
 line can be written without being overly complex. Quotes
 ("" and []) are actually allowed to certain degree by the
 apt source code, but this is considered obscure syntax and
 is not expected to be found in the wild. The exception is
 "cdrom:[word word…]", which is capture correctly in order
 to not end up with incorrectly captured words: */
 regex='''(?m)^\s*(?P&amp;lt;Type&amp;gt;deb(-src)?)(?:\s+\[(?P&amp;lt;Options&amp;gt;[^\]#]+)(?:#[^\]]+)?\])?\s+"?(?P&amp;lt;URI&amp;gt;(?P&amp;lt;Transport&amp;gt;[^:]+):(?://)?(?P&amp;lt;URIBase&amp;gt;\[.+?\]|\S+?))"?\s+(?P&amp;lt;Suite&amp;gt;\S+)\s+(?P&amp;lt;Components&amp;gt;[^\n#]+)'''
 )

 /* Parse a one-line deb sources.list file and output a dict: */
 LET DebOneLine_Dict(OSPath, flatten) = SELECT OSPath, *
 FROM foreach(row=DebOneLine_Opts(OSPath=OSPath),
 query={SELECT _value +
 OptStringToDict(string=Options, flatten=flatten) AS Contents
 FROM items(item={SELECT Types, URIs, _Transport, _URIBase, Suites,
 if(condition=flatten, then=split(sep_string=' ',
 string=Components), else=Components) AS Components
 FROM scope()
 })
 })

 /* Parse a one-line deb sources.list file with options in individual columns: */
 LET DebOneLine(OSPath) = SELECT OSPath, * FROM foreach(
 row=DebOneLine_Dict(OSPath=OSPath, flatten=false),
 column='Contents'
 )

 /* Parse a one-line deb sources.list file with options in individual
 columns and flatten: */
 LET DebOneLine_Flattened(OSPath) = SELECT OSPath, * FROM flatten(
 query={SELECT * FROM foreach(
 row=DebOneLine_Dict(OSPath=OSPath, flatten=true),
 column='Contents'
 )
 })

 /* Extract the transport/protocol and base from a URI: */
 LET URIComponents(URI) = parse_string_with_regex(
 regex='''(?P&amp;lt;Transport&amp;gt;[^:]+):(?://)?(?P&amp;lt;URIBase&amp;gt;[^\s]+)''',
 string=URI
 )

 /* Although the documentation says to use whitespace and not comma
 for multi-values in deb822, comma still appears to be supported,
 and this use is seen in the wild. Treat these values correctly.
 Note that this does not affect all keys, like suites and
 components:
 */
 LET MaybeReplaceComma(key, value) = if(
 condition=key=~'(?i)^(?:arch|lang|targets)',
 then=regex_replace(re='\s*,\s*', source=value, replace=' '),
 else=value)

 /* Parse a deb822 sources file section into a series of key–value pairs.
 Notes about the format:
 - Keys must be at the beginning of the line (no whitespace allowed)
 - Keys are case-insensitive
 - Keys may be repeated. Values are not overridden, but combined
 - Special keys that end in -Add/-Remove uses the default values,
 but add or remove individual values. These keys are treated as
 individual option names.
 - Comments may only appear at the beginning of the line
 - Multiple values are separated by whitespace, not comma. However,
 some multi-value fields separated by comma are still split, even
 if this is not mentioned in the documentation.
 - Values may be multi-line (like when containing an embedded GPG key),
 but following lines must be prefixed by whitespace. Multilines
 may contain comments (prefixed by whitespace or not). Empty lines
 part of a multi-line value must be prefixed by whitespace and "."
 - A file may contain multiple entries, separated by empty lines.
 A file must be split into sections, fed individually to this function
 */
 LET Deb822_KeyValues___(section) = SELECT Key,
 /* Signed-By is special (it could be an embedded GPG key),and
 shouldn't be split: */
 if(condition=NormaliseOpts(string=Key)!='Signed-By',
 then=split(sep_string=' ',
 string=MaybeReplaceComma(key=Key,
 value=Simplify(string=Trim(string=Value)))),
 else=Value) AS Value
 FROM parse_records_with_regex(
 accessor='data',
 /* A key is anything but whitespace up to a colon
 Values can continue on several lines, but only if the following
 lines are indented with whitespace
 */
 regex='''(?m)^(?P&amp;lt;Key&amp;gt;[^#:\s]+)\s*:[^\S\n]*(?P&amp;lt;Value&amp;gt;[^\n]*(?:\n[^\S\n]+[^\n]+)*)''',
 /* Before parsing the key–values, remove all comments from the file
 (otherwise forming a regex without lookarounds would be very
 difficult, if not impossible), Luckily, comments follow strict
 rules and must start with ^#.
 */
 file=regex_replace(
 re='''(?m)^#.+\n''',
 source=section
 )
 )

 LET Deb822_KeyValues__(section) = SELECT * FROM flatten(query={
 SELECT * FROM Deb822_KeyValues___(section=section)
 })

 LET Deb822_KeyValues_(section) = SELECT Key,
 enumerate(items=Value) AS Value
 FROM Deb822_KeyValues__(section=section)
 GROUP BY Key

 /* Parse a deb822 sources file section into a dict with consistent option
 names: */
 LET Deb822_KeyValues(section, flatten) = SELECT to_dict(
 item={
 SELECT NormaliseOpts(string=Key) as _key,
 if(condition=flatten, then=Value,
 else=join(array=Value, sep=' ')) AS _value
 FROM Deb822_KeyValues_(section=section)
 }) AS Contents
 FROM scope()

 /* Split paragraphs in a file (separated by one or several empty
 lines) into rows. ('regex' is just anything that is illegal in Deb822Sections
 to prevent splitting data into records.): */
 LET Deb822Sections(OSPath) = SELECT OSPath,* FROM split_records(
 filenames=OSPath,
 columns='Section',
 regex='^ #', record_regex='''\n{2,}'''
 )

 LET Deb822_Flattened_(OSPath) = SELECT * FROM foreach(
 row=Deb822Sections(OSPath=OSPath),
 query={SELECT OSPath, * FROM flatten(query={
 SELECT * FROM foreach(
 row=Deb822_KeyValues(section=Section, flatten=true),
 column='Contents'
 )
 })}
 )
 /* DEB822_Sections() may produce empty rows. Exclude these by filtering
 for a required column, like URIs: */
 WHERE URIs

 /* Parse a deb822 sources file with options in individual columns.
 Note that, as opposed to DebOneLine and Deb822_Flattened, this
 function does not return the columns _URIBase and _Transport, since
 this format supports mulitple URIs to be specified: */
 LET Deb822(OSPath) = SELECT * FROM foreach(
 row=Deb822Sections(OSPath=OSPath),
 query={SELECT OSPath, * FROM foreach(
 row=Deb822_KeyValues(section=Section, flatten=false),
 column='Contents'
 )}
 )
 WHERE URIs

 /* Parse a deb822 sources file with options in individual columns, flattened: */
 LET Deb822_Flattened(OSPath) = SELECT * FROM flatten(query={
 SELECT OSPath, *, URIComponents(URI=URIs).URIBase AS _URIBase,
 URIComponents(URI=URIs).Transport AS _Transport
 FROM Deb822_Flattened_(OSPath=OSPath)
 })

 /* Parse an apt sources/list file */
 LET parse_aptsources(OSPath, flatten) = if(
 condition=OSPath=~'.list$',
 then=if(condition=flatten,
 then=DebOneLine_Flattened(OSPath=OSPath),
 else=DebOneLine(OSPath=OSPath)
 ),
 else=if(condition=flatten,
 then=Deb822_Flattened(OSPath=OSPath),
 else=Deb822(OSPath=OSPath)
 )
 )

 LET files = SELECT OSPath FROM glob(
 globs=linuxAptSourcesGlobs.ListGlobs)

 LET deb_sources = SELECT * FROM foreach(row=files,
 query={SELECT * FROM parse_aptsources(OSPath=OSPath, flatten=true)}
 )

parameters:
 - name: linuxAptSourcesGlobs
 description: Globs to find apt source *.list and .sources files.
 type: csv
 default: |
 ListGlobs
 /etc/apt/sources.list
 /etc/apt/sources.list.d/*.list
 /etc/apt/sources.list.d/*.sources
 - name: aptCacheDirectory
 description: Location of the apt cache directory.
 default: /var/lib/apt/lists/

precondition:
 SELECT OS From info() where OS = 'linux'

sources:
 - name: Sources
 query: |
 /* Output sources in a readable format: */
 SELECT * FROM foreach(row=files,
 query={SELECT * FROM parse_aptsources(OSPath=OSPath, flatten=false)}
 )
 notebook:
 - type: vql_suggestion
 name: Only enabled sources
 template: |
 /*
 # Sources (enabled only)
 */
 SELECT * FROM source()
 WHERE Enabled =~ '(?i)^(?:yes|true|with|on|enable)$' || true

 - type: vql_suggestion
 name: Trusted sources (apt-secure bypassed)
 template: |
 /*
 # "Trusted" sources (apt-secure bypassed)

 When the Trusted option is true, apt does not verify the GPG
 signature of the Release files of the repository, and it also
 doe not warn about this.
 */
 SELECT * FROM source()
 WHERE Trusted =~ '(?i)^(?:yes|true|with|on|enable)$' || false

 - type: vql_suggestion
 name: Hide embedded GPG keys
 template: |
 /*
 # Sources (embedded GPG keys hidden)
 */
 SELECT *, if(condition=get(field='Signed-By')=~'BEGIN PGP PUBLIC KEY',
 then='(embedded)', else=get(field='Signed-By')) AS `Signed-By`
 FROM source()

 - name: SourcesFlattened
 query: |
 /* Output sources flattened for ease of analysis: */
 SELECT * FROM deb_sources

 - name: SourcesCacheFiles
 query: |
 /* We try to get at the Release file in /var/lib/apt/ by munging
 the components and URL.
 Strip the last component off, convert / and space to _ and
 add _Release/_InRelease to get the filename.
 */
 LET parsed_apt_lines = SELECT get(field='Architectures', default='') AS Architectures, URIs,
 _URIBase + " " + Suites + " " + Components as Name, Types,
 OSPath as Source, aptCacheDirectory + regex_replace(
 replace="_",
 re="_+",
 source=regex_replace(
 replace="_", re="[ /]",
 source=_URIBase + "_dists_" + Suites
 )) as cache_file
 FROM deb_sources
 GROUP BY URIs, Suites

 /* This runs if the file was found. Reads the entire file into
 memory and parses the same record using multiple regular expressions.
 */
 LET parsed_cache_files(file) = SELECT Name, Architectures, URIs, Types,
 Source, parse_string_with_regex(
 string=regex_replace(source=Record,
 re='(?m)^Version: GnuPG v.+$', replace=''
 ),
 regex=["Codename: (?P&amp;lt;Release&amp;gt;[^\\n]+)",
 "Version: (?P&amp;lt;Version&amp;gt;[^\\n]+)",
 "Origin: (?P&amp;lt;Origin&amp;gt;[^\\n]+)",
 "Architectures: (?P&amp;lt;Architectures&amp;gt;[^\\n]+)",
 "Components: (?P&amp;lt;Components&amp;gt;[^\\n]+)"]) as Record
 FROM parse_records_with_regex(file=file, regex="(?sm)(?P&amp;lt;Record&amp;gt;.+)")

 // Foreach row in the parsed cache file, collect the FileInfo too.
 LET add_stat_to_parsed_cache_file(file) = SELECT * from foreach(
 query={
 SELECT OSPath, Mtime, Ctime, Atime, Record, Types,
 Name, Architectures, URIs, Source from stat(filename=file)
 }, row=parsed_cache_files(file=file))
 WHERE Record
 GROUP BY OSPath

 /* For each row in the parsed file, run the appropriate query
 depending on if the cache file exists.
 If the cache file is not found, we just copy the lines we
 parsed from the source file and fill in empty values for
 stat.
 */
 LET parse_cache_or_pass = SELECT * from if(
 condition={
 SELECT * from stat(filename=cache_file + '_InRelease')
 },
 then=add_stat_to_parsed_cache_file(file=cache_file + '_InRelease'),
 else={SELECT * FROM if(
 condition={
 SELECT * from stat(filename=cache_file + '_Release')
 },
 then=add_stat_to_parsed_cache_file(file=cache_file + '_Release'),
 else={
 SELECT Source, NULL AS OSPath, Null as Mtime, Null as Ctime,
 Null as Atime, Types,
 Null as Record, Architectures, URIs, Name from scope()
 })
 })

 -- For each parsed apt .list file line produce some output.
 SELECT * from foreach(
 row={
 SELECT * FROM parsed_apt_lines
 },
 query={
 SELECT * FROM parse_cache_or_pass
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Debian.Packages</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.debian.packages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.debian.packages/</guid><description>&lt;p>List all packages installed on the system, both deb packages and &amp;ldquo;snaps&amp;rdquo;.
The installed deb package information is fetched from the DPKG status file,
while the snap package list is fetched from the snap daemon through a UNIX
socket HTTP call (since detailed snap package information is not easily
in files).&lt;/p>
&lt;p>The following columns are parsed from the DPKG status file:&lt;/p>
&lt;ul>
&lt;li>Package&lt;/li>
&lt;li>InstalledSize&lt;/li>
&lt;li>Version&lt;/li>
&lt;li>Source&lt;/li>
&lt;li>_Description&lt;/li>
&lt;li>Architecture&lt;/li>
&lt;/ul>
&lt;p>The following columns are parsed from the snap package response (/v2/snaps):&lt;/p>
&lt;ul>
&lt;li>Name&lt;/li>
&lt;li>_Summary&lt;/li>
&lt;li>_Description&lt;/li>
&lt;li>InstalledSize&lt;/li>
&lt;li>Publisher&lt;/li>
&lt;li>InstalledAt&lt;/li>
&lt;li>Version&lt;/li>
&lt;li>Channel&lt;/li>
&lt;/ul>
&lt;p>Both package sources provide more information than this and, and the artifact
can easily be modified to include more details.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Debian.Packages
description: |
 List all packages installed on the system, both deb packages and "snaps".
 The installed deb package information is fetched from the DPKG status file,
 while the snap package list is fetched from the snap daemon through a UNIX
 socket HTTP call (since detailed snap package information is not easily
 in files).

 The following columns are parsed from the DPKG status file:

 - Package
 - InstalledSize
 - Version
 - Source
 - _Description
 - Architecture

 The following columns are parsed from the snap package response (/v2/snaps):

 - Name
 - _Summary
 - _Description
 - InstalledSize
 - Publisher
 - InstalledAt
 - Version
 - Channel

 Both package sources provide more information than this and, and the artifact
 can easily be modified to include more details.

parameters:
 - name: linuxDpkgStatus
 description: The DPKG status file to read deb package information from
 default: /var/lib/dpkg/status
 - name: snapdSocket
 description: |
 The location of the snap deamon UNIX socket, used for fetching the snap
 list through a HTTP API call. If snap is not used, the failed query
 response will simply be ignored.
 default: /run/snapd.socket

implied_permissions:
- NETWORK

precondition: |
 SELECT OS
 FROM info()
 WHERE OS = 'linux'

sources:
 - name: DebPackages
 notebook:
 - type: none

 query: |
 LET ColumnTypes &amp;lt;= dict(`_Description`='nobreak')

 /* First pass - split file into records starting with
 Package and ending with \n\n.
 Then parse each record using multiple regular expressions.
 */
 LET packages = SELECT parse_string_with_regex(
 string=Record,
 regex=['Package:\\s(?P&amp;lt;Package&amp;gt;.+)',
 'Installed-Size:\\s(?P&amp;lt;InstalledSize&amp;gt;.+)',
 'Version:\\s(?P&amp;lt;Version&amp;gt;.+)',
 'Source:\\s(?P&amp;lt;Source&amp;gt;.+)',
 '''Description:\s+(?P&amp;lt;Description&amp;gt;.+(\n\s+.+)*)''',
 'Architecture:\\s(?P&amp;lt;Architecture&amp;gt;.+)']) AS Record
 FROM parse_records_with_regex(file=linuxDpkgStatus,
 regex='(?sm)^(?P&amp;lt;Record&amp;gt;Package:.+?)\\n\\n')

 SELECT Record.Package AS Package,
 humanize(bytes=atoi(string=Record.InstalledSize)) AS InstalledSize,
 Record.Version AS Version,
 Record.Source AS Source,
 regex_replace(source=Record.Description,
 re='''^\s+\.$''') AS _Description,
 Record.Architecture AS Architecture
 FROM packages

 - name: Snaps
 query: |
 LET ColumnTypes &amp;lt;= dict(`_Summary`='nobreak', `_Description`='nobreak')

 LET SnapSocketCheck = SELECT
 parse_json(data=Content).result AS Result
 FROM http_client(url=snapdSocket + ':unix/v2/snaps')
 WHERE Response = 200
 OR NOT log(message="Error fetching snap: %v", args=Content)

 SELECT * FROM foreach(
 row=SnapSocketCheck,
 query={
 SELECT name AS Name,
 summary AS _Summary,
 description AS _Description,
 humanize(bytes=`installed-size`) AS InstalledSize,
 publisher.`display-name` AS Publisher,
 timestamp(string=`install-date`) AS InstalledAt,
 version AS Version,
 channel AS Channel,
 id AS PackageId
 FROM foreach(row=Result)
 })

 notebook:
 - type: vql
 template: |
 /*
 ## Combined results
 */
 LET ColumnTypes &amp;lt;= dict(`_Description`='nobreak')

 SELECT *
 FROM chain(
 debs={
 SELECT Package AS Name,
 'deb' AS Type,
 InstalledSize,
 Version,
 _Description,
 Architecture
 FROM source(artifact="Linux.Debian.Packages/DebPackages")
 },
 snaps={
 SELECT Name,
 'snap' AS Type,
 InstalledSize,
 Version,
 _Description,
 NULL AS Architecture
 FROM source(artifact="Linux.Debian.Packages/Snaps")
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Detection.AnomalousFiles</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.detection.anomalousfiles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.detection.anomalousfiles/</guid><description>&lt;p>Detects anomalous files in a Linux filesystem.&lt;/p>
&lt;p>An anomalous file is considered one that matches at least one criteria:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Hidden (prefixed with a dot);&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Large, with a size over a specified limit; or&lt;/p>
&lt;/li>
&lt;li>
&lt;p>With SUID bit set.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Detection.AnomalousFiles

description: |
 Detects anomalous files in a Linux filesystem.

 An anomalous file is considered one that matches at least one criteria:

 - Hidden (prefixed with a dot);

 - Large, with a size over a specified limit; or

 - With SUID bit set.

author: George-Andrei Iosif (@iosifache)

type: CLIENT

parameters:
 - name: MaxNormalSize
 description: Size (in bytes) above which a file is considered large
 type: int
 default: 10485760
 - name: PathsToSearch
 description: Paths to search, separated by comma
 type: str
 default: "/home/**,tmp/**"

sources:
 - precondition: |
 SELECT OS
 FROM info()
 WHERE OS = 'linux'

 query: |
 SELECT Fqdn AS Host,
 OSPath,
 substr(str=Name, start=0, end=1) = "." AS IsHidden,
 Size,
 Size &amp;gt; MaxNormalSize AS IsLarge,
 Mode.String AS Mode,
 Mode =~ "^u" as HasSUID
 FROM glob(globs=split(string=PathsToSearch, sep_string=","))
 WHERE IsHidden OR IsLarge OR HasSUID

&lt;/code>&lt;/pre></description></item><item><title>Linux.Detection.Yara.Glob</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.detection.yara.glob/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.detection.yara.glob/</guid><description>&lt;p>This artifact returns a list of target files then runs YARA over the target
list.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>Url link to a YARA rule.&lt;/li>
&lt;li>or a Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above.&lt;/p>
&lt;p>The artifact uses Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with YARA hits.&lt;/p>
&lt;p>Some examples of path glob may include:&lt;/p>
&lt;ul>
&lt;li>Specific binary: &lt;code>/usr/bin/ls&lt;/code>&lt;/li>
&lt;li>Wildcards: &lt;code>/var/www/*.js&lt;/code>&lt;/li>
&lt;li>More wildcards: &lt;code>/var/www/**/*.js&lt;/code>&lt;/li>
&lt;li>Multiple extensions: &lt;code>/var/www/*\.{php,aspx,js,html}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:/Users/**/*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:\Users\**\*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
 This artifact returns a list of target files then runs YARA over the target
 list.

 There are 2 kinds of YARA rules that can be deployed:

 1. Url link to a YARA rule.
 2. or a Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above.

 The artifact uses Glob for search so relevant filters can be applied
 including Glob, Size and date. Date filters will target files with a timestamp
 before LatestTime and after EarliestTime. The artifact also has an option to
 upload any files with YARA hits.

 Some examples of path glob may include:

 * Specific binary: `/usr/bin/ls`
 * Wildcards: `/var/www/*.js`
 * More wildcards: `/var/www/**/*.js`
 * Multiple extensions: `/var/www/*\.{php,aspx,js,html}`
 * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
 * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

 NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
 This will NOT follow any symlinks and may cause unexpected results if
 unknowingly targeting a folder with symlinks.
 If upload is selected NumberOfHits is redundant and not advised as hits are
 grouped by path to ensure files only downloaded once.

aliases:
 - Windows.Detection.Yara.Glob
 - Linux.Detection.Yara.Glob
 - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
 - name: PathGlob
 description: Only file names that match this glob will be scanned.
 default: /usr/bin/ls
 - name: SizeMax
 description: maximum size of target file.
 type: int64
 - name: SizeMin
 description: minimum size of target file.
 type: int64
 - name: UploadHits
 type: bool
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: YaraUrl
 description: If configured will attempt to download Yara rules form Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule IsELF:TestRule {
 meta:
 author = "the internet"
 date = "2021-05-03"
 description = "A simple ELF rule to test yara features"
 condition:
 uint32(0) == 0x464c457f
 }
 - name: NumberOfHits
 description: This artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int

sources:
 - query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- time testing
 LET time_test(stamp) =
 if(condition= DateBefore AND DateAfter,
 then= stamp &amp;lt; DateBefore AND stamp &amp;gt; DateAfter,
 else=
 if(condition=DateBefore,
 then= stamp &amp;lt; DateBefore,
 else=
 if(condition= DateAfter,
 then= stamp &amp;gt; DateAfter,
 else= True
 )))

 -- first find all matching glob
 LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
 FROM glob(globs=PathGlob,nosymlink='True')
 WHERE
 NOT IsDir AND NOT IsLink
 AND if(condition=SizeMin,
 then= SizeMin &amp;lt; Size,
 else= True)
 AND if(condition=SizeMax,
 then=SizeMax &amp;gt; Size,
 else= True)
 AND
 ( time_test(stamp=Mtime)
 OR time_test(stamp=Atime)
 OR time_test(stamp=Ctime)
 OR time_test(stamp=Btime))

 -- scan files and prepare hit metadata
 LET hits = SELECT * FROM foreach(row=files,
 query={
 SELECT
 OSPath,
 File.Size as Size,
 Mtime, Atime, Ctime, Btime,
 Rule, Tags, Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 upload( accessor='scope',
 file='String.Data',
 name=format(format="%v-%v-%v",
 args=[
 OSPath,
 if(condition= String.Offset - ContextBytes &amp;lt; 0,
 then= 0,
 else= String.Offset - ContextBytes),
 if(condition= String.Offset + ContextBytes &amp;gt; Size,
 then= Size,
 else= String.Offset + ContextBytes) ]
 )) as HitContext
 FROM yara(rules=yara_rules,files=OSPath,
 context=ContextBytes,number=NumberOfHits)
 })

 -- upload files if selected
 LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

 -- return rows
 SELECT * FROM if(condition= UploadHits,
 then= upload_hits,
 else= hits )

column_types:
 - name: HitContext
 type: preview_upload
&lt;/code>&lt;/pre></description></item><item><title>Linux.Detection.Yara.Process</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.detection.yara.process/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.detection.yara.process/</guid><description>&lt;p>This artifact enables running YARA over processes in memory.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>Url link to a YARA rule.&lt;/li>
&lt;li>A Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above. The
default is Cobalt Strike opcodes.&lt;/p>
&lt;p>Regex parameters can be applied for process name and pid for targeting. The
artifact also has an option to upload any process with YARA hits.&lt;/p>
&lt;p>Note: the YARA scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Detection.Yara.Process
author: Matt Green - @mgreen27
description: |
 This artifact enables running YARA over processes in memory.

 There are 2 kinds of YARA rules that can be deployed:

 1. Url link to a YARA rule.
 2. A Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above. The
 default is Cobalt Strike opcodes.

 Regex parameters can be applied for process name and pid for targeting. The
 artifact also has an option to upload any process with YARA hits.

 Note: the YARA scan will stop after one hit. Multi-string rules will also only
 show one string in returned rows.

aliases:
- MacOS.Detection.Yara.Process

type: CLIENT
parameters:
 - name: ProcessRegex
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: UploadHits
 type: bool
 - name: YaraUrl
 description: If configured will attempt to download Yara rules from Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule keyword_search {
 strings:
 $a = "velociraptor" ascii

 condition:
 any of them
 }
 - name: NumberOfHits
 description: THis artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int
 - name: ExePathWhitelist
 description: Regex of ProcessPaths to exclude
 type: regex


sources:
 - precondition:
 SELECT OS From info() where OS = 'linux' OR OS = 'darwin'

 query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- find velociraptor process
 LET me = SELECT Pid FROM pslist(pid=getpid())

 -- find all processes and add filters
 LET processes = SELECT
 Name as ProcessName,
 CommandLine, Pid
 FROM pslist()
 WHERE
 Name =~ ProcessRegex
 AND format(format="%d", args=Pid) =~ PidRegex
 AND NOT Pid in me.Pid
 AND NOT if(condition=ExePathWhitelist,
 then= Exe=~ExePathWhitelist)
 AND log(message=format(format="Scanning pid %v: %v", args=[
 Pid, CommandLine]))

 -- scan processes in scope with our rule, limit 1 hit
 LET hits = SELECT * FROM foreach(
 row=processes,
 query={
 SELECT
 ProcessName,
 CommandLine,
 Pid,
 Rule,
 Tag,
 Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 if(condition=String.Data,
 then=upload(
 accessor='scope',
 file='String.Data',
 name=format(format="%v-%v_%v_%v",
 args=[ ProcessName, Pid, String.Offset, ContextBytes ]
 ))) as HitContext
 FROM proc_yara(
 pid=Pid,
 rules=yara_rules,
 context=ContextBytes,
 number=NumberOfHits
 )
 })

 -- upload hits using the process accessor
 LET upload_hits = SELECT *,
 upload(
 accessor="process",
 file=format(format="/%v", args=Pid),
 name=pathspec(Path=format(format='%v-%v.dmp',
 args= [ ProcessName, Pid ]))) as ProcessDump
 FROM hits
 WHERE log(message=format(format='Will upload %v: %v', args=[Pid, ProcessName]))

 -- return rows
 SELECT * FROM if(condition=UploadHits,
 then=upload_hits,
 else=hits)

column_types:
 - name: HitContext
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.DNS</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.dns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.dns/</guid><description>&lt;p>This artifact uses eBPF to track DNS requests from various processes.&lt;/p>
&lt;p>NOTE: This event is generated from network traffic - it is unable to
view DoH traffic.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.DNS
description: |
 This artifact uses eBPF to track DNS requests from various processes.

 NOTE: This event is generated from network traffic - it is unable to
 view DoH traffic.

type: CLIENT_EVENT

precondition: |
 SELECT OS From info() where OS = 'linux'

parameters:
 - name: ExcludeDestIP
 description: Only show events with a different DestIP
 type: regex
 default: "Change this to your default DNS Server IP"
 - name: Records
 description: Only show events matching these DNS records
 type: regex
 default: .
 - name: ProcessNameFilter
 description: Filter Events by Process Name
 type: regex
 default: .
 - name: IncludeDNSDetails
 type: bool
 description: If set we include more details like HTTP Headers
 - name: IncludeProcessInfo
 type: bool
 description: If set we include more process information.

sources:
 - query: |
 SELECT System.Timestamp AS Timestamp,
 System.ProcessName AS ProcessName,
 System.ProcessID AS Pid,
 if(condition=IncludeProcessInfo,
 then=process_tracker_get(id=System.ProcessID).Data) AS ProcessInfo,
 EventData.src AS src_ip,
 EventData.src_port AS src_port,
 EventData.dst AS dest_ip,
 EventData.dst_port AS dest_port,
 EventData.proto_dns.questions.name AS name,
 EventData.proto_dns.questions.type AS type,
 EventData.proto_dns.answers.IP AS IP,
 if(condition=IncludeDNSDetails,
 then=EventData) AS _DNSData
 FROM delay(delay=2, query={
 SELECT * FROM watch_ebpf(events="net_packet_dns")
 })
 WHERE NOT dest_ip =~ ExcludeDestIP
 AND if(condition=Records, then=EventData.proto_dns =~ Records, else=TRUE)
 AND ProcessName =~ ProcessNameFilter

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.EBPF</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.ebpf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.ebpf/</guid><description>&lt;p>This artifact forwards EBPF events generated on the endpoint.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.EBPF
description: |
 This artifact forwards EBPF events generated on the endpoint.

precondition: |
 SELECT OS From info() where OS = 'linux'

type: CLIENT_EVENT

parameters:
 - name: Events
 description: Events to forward
 type: csv
 default: |
 Event,Desc,Enabled
 bpf_attach,A bpf program is attached,Y
 chdir,Process changes directory,N
 fchownat,File ownership is changed,Y
 file_modification,A process changes the ctime of a file,N
 kill,Kill another process,Y
 magic_write,Intercepts file writes to capture the header magic,N
 mkdir,Process makes new directory,N
 module_free,A module is unloaded from the kernel,Y
 mount,A filesystem is mounted,Y
 openat,A process is opening a file (noisy),N
 openat2,A process is opening a file (noisy),N
 sched_process_exec,A process starts,Y
 sched_process_exit,A process ends,Y
 security_file_open,Files are opened,Y
 security_inode_mknod,A new node is created with mknod (e.g. fifo or device file),Y
 security_inode_rename,File is being renamed,N
 security_inode_symlink,Create a symlink,Y
 security_kernel_post_read_file,Fires when the kernel reads a file (e.g. module),Y
 security_socket_accept,A process accepted a connection,Y
 security_socket_bind,A process bind to a local port,Y
 security_socket_connect,A process is making a connection,Y
 setxattr,Setting and extended attribute to a file,Y
 umount2,A filesystem is being unmounted,Y
 unlink,A file is deleted,Y

sources:
 - query: |
 LET SelectedEvents &amp;lt;= SELECT * FROM Events WHERE Enabled =~ "Y"

 SELECT * FROM watch_ebpf(events=SelectedEvents.Event)

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.HTTPConnections</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.httpconnections/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.httpconnections/</guid><description>&lt;p>This artifact uses eBPF to track HTTP and parse connections from
various processes.&lt;/p>
&lt;p>NOTE: This event is generated from network traffic - it is unable to
view TLS encrypted data.&lt;/p>
&lt;p>If the process tracker is enabled we also show more information
about the process.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.HTTPConnections
description: |
 This artifact uses eBPF to track HTTP and parse connections from
 various processes.

 NOTE: This event is generated from network traffic - it is unable to
 view TLS encrypted data.

 If the process tracker is enabled we also show more information
 about the process.

type: CLIENT_EVENT

precondition: |
 SELECT OS From info() where OS = 'linux'

parameters:
 - name: HostFilter
 description: Filter Events by Host header
 type: regex
 default: .
 - name: URLFilter
 description: Filter Events by URL
 type: regex
 default: .
 - name: ProcessNameFilter
 description: Filter Events by Process Name
 type: regex
 default: .
 - name: IncludeHeaders
 type: bool
 description: If set we include more details like HTTP Headers
 - name: IncludeProcessInfo
 type: bool
 description: If set we include more process information.

sources:
 - query: |
 SELECT System.Timestamp AS Timestamp,
 System.ProcessName AS ProcessName,
 System.ProcessID AS Pid,
 if(condition=IncludeProcessInfo,
 then=process_tracker_get(id=System.ProcessID).Data) AS ProcessInfo,
 EventData.metadata.src_ip AS src_ip,
 EventData.metadata.src_port AS src_port,
 EventData.metadata.dst_ip AS dest_ip,
 EventData.metadata.dst_port AS dest_port,
 EventData.http_request.host AS host,
 EventData.http_request.uri_path AS uri_path,
 if(condition=IncludeHeaders,
 then=EventData.http_request) AS _HTTPRequest
 FROM watch_ebpf(events="net_packet_http_request")
 WHERE host =~ HostFilter
 AND uri_path =~ URLFilter
 AND ProcessName =~ ProcessNameFilter

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.Journal</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.journal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.journal/</guid><description>&lt;p>Watches the binary journal logs. Systemd uses a binary log format to
store logs.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.Journal
description: |
 Watches the binary journal logs. Systemd uses a binary log format to
 store logs.

type: CLIENT_EVENT

parameters:
- name: JournalGlob
 type: glob
 description: A Glob expression for finding journal files.
 default: /{run,var}/log/journal/*/*.journal

sources:
- query: |
 SELECT * FROM foreach(row={
 SELECT OSPath FROM glob(globs=JournalGlob)
 }, query={
 SELECT *
 FROM watch_journald(filename=OSPath)
 }, workers=100)

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.ProcessExecutions</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.processexecutions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.processexecutions/</guid><description>&lt;p>This artifact collects process execution logs from the Linux kernel.&lt;/p>
&lt;p>This artifact relies on the presence of &lt;code>auditctl&lt;/code> usually included
in the auditd package. On Ubuntu you can install it by using:&lt;/p>
&lt;pre>&lt;code>apt-get install auditd
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.ProcessExecutions
description: |
 This artifact collects process execution logs from the Linux kernel.

 This artifact relies on the presence of `auditctl` usually included
 in the auditd package. On Ubuntu you can install it by using:

 ```
 apt-get install auditd
 ```

precondition: SELECT OS From info() where OS = 'linux'

type: CLIENT_EVENT

required_permissions:
 - EXECVE

parameters:
 - name: pathToAuditctl
 default: /sbin/auditctl
 description: We depend on auditctl to install the correct process execution rules.

sources:
 - query: |
 // Install the auditd rule if possible.
 LET _ &amp;lt;= SELECT * FROM execve(argv=[pathToAuditctl, "-a",
 "exit,always", "-F", "arch=b64", "-S", "execve", "-k", "procmon"])

 LET exec_log = SELECT timestamp(string=Timestamp) AS Time, Sequence,
 atoi(string=Process.PID) AS Pid,
 atoi(string=Process.PPID) AS Ppid,
 Process.PPID AS PPID,
 atoi(string=Summary.Actor.Primary) AS UserId,
 Process.Title AS CmdLine,
 Process.Exe AS Exe,
 Process.CWD AS CWD
 FROM audit()
 WHERE "procmon" in Tags AND Result = 'success'

 // Cache Uid -&amp;gt; Username mapping.
 LET users &amp;lt;= SELECT User, atoi(string=Uid) AS Uid
 FROM Artifact.Linux.Sys.Users()

 // Enrich the original artifact with more data.
 SELECT Time, Pid, Ppid, UserId,
 { SELECT User from users WHERE Uid = UserId} AS User,
 regex_replace(source=read_file(filename= "/proc/" + PPID + "/cmdline"),
 replace=" ", re="[\\0]") AS Parent,
 CmdLine,
 Exe, CWD
 FROM exec_log

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.SSHBruteforce</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.sshbruteforce/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.sshbruteforce/</guid><description>&lt;p>A monitoring artifact which detects a successful SSH login preceded by some
failed attempts within the last hour.&lt;/p>
&lt;p>This is particularly important in the case of SSH brute force attacks. If one
of the brute force password attempts succeeded, the password guessing program
will likely report the success and move on. This alert might provide
sufficient time for admins to lock down the account before attackers can
exploit the weak password.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.SSHBruteforce
description: |
 A monitoring artifact which detects a successful SSH login preceded by some
 failed attempts within the last hour.

 This is particularly important in the case of SSH brute force attacks. If one
 of the brute force password attempts succeeded, the password guessing program
 will likely report the success and move on. This alert might provide
 sufficient time for admins to lock down the account before attackers can
 exploit the weak password.

reference:
 - https://www.elastic.co/blog/grokking-the-linux-authorization-logs

type: CLIENT_EVENT

parameters:
 - name: syslogAuthLogPath
 default: /var/log/auth.log

 - name: SSHGrok
 description: A Grok expression for parsing SSH auth lines.
 default: &amp;gt;-
 %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: %{DATA:event} %{DATA:method} for (invalid user )?%{DATA:user} from %{IPORHOST:ip} port %{NUMBER:port} ssh2(: %{GREEDYDATA:system.auth.ssh.signature})?

 - name: MinimumFailedLogins
 description: Minimum number of failed logins before a successful login.
 default: 2

sources:
 - query: |
 -- Basic syslog parsing via GROK expressions.
 LET failed_login = SELECT grok(grok=SSHGrok, data=Line) AS FailedEvent,
 Line as FailedLine
 FROM watch_syslog(filename=syslogAuthLogPath)
 WHERE FailedEvent.program = "sshd" AND FailedEvent.event = "Failed"
 AND FailedEvent.method = "password"

 LET last_failed_events = SELECT * FROM fifo(
 query=failed_login, max_rows=50, max_age=3600)

 LET _ &amp;lt;= SELECT * FROM last_failed_events

 LET success_login = SELECT grok(grok=SSHGrok, data=Line) AS Event, Line
 FROM watch_syslog(filename=syslogAuthLogPath)
 WHERE Event.program = "sshd" AND Event.event = "Accepted"
 AND Event.method = "password"

 SELECT Event, Line, {
 SELECT FailedLine FROM last_failed_events
 WHERE Event.user = FailedEvent.user
 } AS Failures
 FROM success_login
 WHERE len(list=Failures) &amp;gt; int(int=MinimumFailedLogins)

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.SSHLogin</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.sshlogin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.sshlogin/</guid><description>&lt;p>This monitoring artifact watches the auth.log file for new
successful SSH login events and relays them back to the server.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.SSHLogin
description: |
 This monitoring artifact watches the auth.log file for new
 successful SSH login events and relays them back to the server.

reference:
 - https://www.elastic.co/blog/grokking-the-linux-authorization-logs

type: CLIENT_EVENT

parameters:
 - name: syslogAuthLogPath
 default: /var/log/auth.log

 - name: SSHGrok
 description: A Grok expression for parsing SSH auth lines.
 default: &amp;gt;-
 %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: %{DATA:event} %{DATA:method} for (invalid user )?%{DATA:user} from %{IPORHOST:ip} port %{NUMBER:port} ssh2(: %{GREEDYDATA:system.auth.ssh.signature})?

sources:
 - query: |
 -- Basic syslog parsing via GROK expressions.
 LET success_login = SELECT grok(grok=SSHGrok, data=Line) AS Event, Line
 FROM watch_syslog(filename=syslogAuthLogPath)
 WHERE Event.program = "sshd" AND Event.event = "Accepted"

 SELECT timestamp(string=Event.timestamp) AS Time,
 Event.user AS User,
 Event.method AS Method,
 Event.IP AS SourceIP,
 Event.pid AS Pid
 FROM success_login

&lt;/code>&lt;/pre></description></item><item><title>Linux.Events.TrackProcesses</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.events.trackprocesses/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.events.trackprocesses/</guid><description>&lt;p>This artifact uses eBPF and pslist to keep track of running
processes by using the Velociraptor process tracker.&lt;/p>
&lt;p>The process tracker keeps track of exited processes, and resolves
process call chains from it in memory cache.&lt;/p>
&lt;p>This event artifact enables the global process tracker and makes it
possible to run many other artifacts that depend on the process
tracker.&lt;/p>
&lt;p>NOTE: Unlike &lt;code>Windows.Events.TrackProcesses&lt;/code>, the eBPF program is
already built into Velociraptor so this artifact does not depend on
external tools.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Events.TrackProcesses
description: |
 This artifact uses eBPF and pslist to keep track of running
 processes by using the Velociraptor process tracker.

 The process tracker keeps track of exited processes, and resolves
 process call chains from it in memory cache.

 This event artifact enables the global process tracker and makes it
 possible to run many other artifacts that depend on the process
 tracker.

 NOTE: Unlike `Windows.Events.TrackProcesses`, the eBPF program is
 already built into Velociraptor so this artifact does not depend on
 external tools.

precondition: |
 SELECT OS From info() where OS = 'linux'

type: CLIENT_EVENT

parameters:
 - name: AlsoForwardUpdates
 type: bool
 description: Upload all tracker state updates to the server
 - name: MaxSize
 type: int64
 description: Maximum size of the in-memory process cache (default 10k)

sources:
 - query: |
 LET SyncQuery = SELECT
 Pid AS id,
 Ppid AS parent_id,
 CreateTime AS start_time,
 dict(Name=Name,
 Username=Username,
 Exe=Exe,
 CreateTime=CreateTime,
 CommandLine=CommandLine) AS data
 FROM pslist()

 LET UpdateQuery = SELECT * FROM foreach(
 row={
 SELECT * FROM watch_ebpf(events=["sched_process_exit", "sched_process_exec"])
 }, query={
 SELECT * FROM switch(a={
 SELECT System.ProcessID AS id,
 System.ParentProcessID AS parent_id,
 "start" AS update_type,
 dict(Pid=System.ProcessID,
 Ppid=System.ParentProcessID,
 Name=System.ProcessName,
 Username=System.UserID,
 Exe=EventData.cmdpath,
 CommandLine=join(array=EventData.argv, sep=" ")) AS data,

 System.Timestamp AS start_time,
 NULL AS end_time
 FROM scope()
 WHERE System.EventName =~ "exec"
 }, end={
 SELECT System.ProcessID AS id,
 NULL AS parent_id,
 "exit" AS update_type,
 dict() AS data,
 NULL AS start_time,
 System.Timestamp AS end_time
 FROM scope()
 WHERE System.EventName =~ "exit"
 })
 })

 LET Tracker &amp;lt;= process_tracker(max_size=MaxSize,
 sync_query=SyncQuery, update_query=UpdateQuery, sync_period=60000)

 SELECT * FROM process_tracker_updates()
 WHERE update_type = "stats" OR AlsoForwardUpdates

&lt;/code>&lt;/pre></description></item><item><title>Linux.Forensics.ImmutableFiles</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.forensics.immutablefiles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.forensics.immutablefiles/</guid><description>&lt;p>Searches the filesystem for immutable files.&lt;/p>
&lt;p>Attackers sometimes enable immutable files in Linux. This prevents files from
being modified. However this is sometimes a strong signal.&lt;/p>
&lt;p>NOTE: We use the ext4 accessor to parse the low level filesystem.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Forensics.ImmutableFiles
description: |
 Searches the filesystem for immutable files.

 Attackers sometimes enable immutable files in Linux. This prevents files from
 being modified. However this is sometimes a strong signal.

 NOTE: We use the ext4 accessor to parse the low level filesystem.

precondition: |
 SELECT * FROM info() where OS = 'linux'

parameters:
 - name: SearchFilesGlob
 default: /home/*
 description: Use a glob to define the files that will be searched.
 - name: OneFilesystem
 default: N
 type: bool
 description: When set we do not follow a link to go on to a different filesystem.

 - name: DoNotFollowSymlinks
 type: bool
 default: N
 description: If specified we are allowed to follow symlinks while globbing

column_types:
 - name: ATime
 type: timestamp
 - name: MTime
 type: timestamp
 - name: CTime
 type: timestamp


sources:
- query: |
 SELECT OSPath,
 Sys.mft as Inode,
 Mode.String AS Mode, Size,
 Mtime AS MTime,
 Atime AS ATime,
 Ctime AS CTime,
 IsDir, Mode, Data
 FROM glob(globs=SearchFilesGlob,
 one_filesystem=OneFilesystem,
 accessor="ext4", nosymlink=DoNotFollowSymlinks)
 WHERE Data.Flags =~ "IMMUTABLE"

&lt;/code>&lt;/pre></description></item><item><title>Linux.Forensics.Journal</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.forensics.journal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.forensics.journal/</guid><description>&lt;p>Parses the binary journal logs. Systemd uses a binary log format to
store logs.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Forensics.Journal
description: |
 Parses the binary journal logs. Systemd uses a binary log format to
 store logs.

parameters:
- name: JournalGlob
 type: glob
 description: A Glob expression for finding journal files.
 default: /{run,var}/log/journal/*/*.journal
- name: IdentifierRegex
 type: regex
 description: "Regex of event source e.g sshd or kernel"
- name: IocRegex
 type: regex
 description: "IOC Regex in event data"
- name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
- name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
- name: AlsoUpload
 type: bool
 description: If set we also upload the raw files.

sources:
- name: Uploads
 query: |
 SELECT *
 FROM if(condition=AlsoUpload,
 then={
 SELECT OSPath,
 upload(file=OSPath) AS Upload
 FROM glob(globs=JournalGlob)
 })


- query: |
 LET standard = SELECT *
 FROM foreach(row={
 SELECT OSPath
 FROM glob(globs=JournalGlob)
 },
 query={
 SELECT *
 FROM parse_journald(filename=OSPath,
 start_time=DateAfter,
 end_time=DateBefore)
 })
 
 LET identifier_only = SELECT *
 FROM foreach(row={
 SELECT OSPath
 FROM glob(globs=JournalGlob)
 },
 query={
 SELECT *
 FROM parse_journald(filename=OSPath,
 start_time=DateAfter,
 end_time=DateBefore)
 WHERE EventData.SYSLOG_IDENTIFIER =~ IdentifierRegex
 })
 
 LET all_regex = SELECT *
 FROM foreach(row={
 SELECT OSPath
 FROM glob(globs=JournalGlob)
 },
 query={
 SELECT *
 FROM parse_journald(filename=OSPath,
 start_time=DateAfter,
 end_time=DateBefore)
 WHERE EventData.SYSLOG_IDENTIFIER =~ IdentifierRegex
 AND format(format='%s_%s_%s',
 args=[EventData, System._CMDLINE, System._EXE]) =~
 IocRegex
 })
 
 LET ioc_only = SELECT *
 FROM foreach(row={
 SELECT OSPath
 FROM glob(globs=JournalGlob)
 },
 query={
 SELECT *
 FROM parse_journald(filename=OSPath,
 start_time=DateAfter,
 end_time=DateBefore)
 WHERE format(format='%s_%s_%s',
 args=[EventData, System._CMDLINE,
 System._EXE]) =~ IocRegex
 })
 
 SELECT *
 FROM if(condition=IdentifierRegex
 AND IocRegex,
 then=all_regex,
 else=if(condition=IdentifierRegex,
 then=identifier_only,
 else=if(condition=IocRegex, then=ioc_only, else=standard)))

 notebook:
 - type: vql_suggestion
 name: Simplified syslog-like view
 template: |
 /*
 # Simplified log view
 */
 LET ColumnTypes&amp;lt;=dict(`_ClientId`='client')

 SELECT System.Timestamp AS Timestamp,
 ClientId AS _ClientId,
 client_info(client_id=ClientId).os_info.hostname AS Hostname,
 EventData.SYSLOG_IDENTIFIER AS Unit,
 EventData.MESSAGE AS Message
 FROM source()

&lt;/code>&lt;/pre></description></item><item><title>Linux.Mounts</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.mounts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.mounts/</guid><description>&lt;p>List mounted filesystems by reading /proc/mounts&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Mounts
description: List mounted filesystems by reading /proc/mounts

parameters:
 - name: ProcMounts
 default: /proc/mounts

precondition: |
 SELECT OS From info() where OS = 'linux'

sources:
 - query: |
 SELECT Device, Mount, FSType, split(string=Opts, sep=",") As Options
 FROM parse_records_with_regex(
 file=ProcMounts,
 regex='(?m)^(?P&amp;lt;Device&amp;gt;[^ ]+) (?P&amp;lt;Mount&amp;gt;[^ ]+) (?P&amp;lt;FSType&amp;gt;[^ ]+) '+
 '(?P&amp;lt;Opts&amp;gt;[^ ]+)')


reports:
 - type: CLIENT
 template: |
 # Mounted filesystems

 {{ Query "SELECT * FROM source()" | Table }}

&lt;/code>&lt;/pre></description></item><item><title>Linux.Network.Netstat</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.network.netstat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.network.netstat/</guid><description>&lt;p>This artifact will parse /proc and reveal information
about current network connections.&lt;/p>
&lt;p>We also extract corresponding process information.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Network.Netstat
description: |
 This artifact will parse /proc and reveal information
 about current network connections.

 We also extract corresponding process information.

type: CLIENT

parameters:
 - name: StateRegex
 type: regex
 default: "LISTEN|ESTAB"
 description: Only show these states

precondition:
 SELECT OS From info() where OS = 'linux'

sources:
 - name: TCP4
 query: |
 // Extract the port as an int (part after the :)
 LET GetPort(X) = int(int="0x" + regex_replace(source=X, re=".+:", replace=""))

 // Remove the part after the :: for the IPv6 address
 LET _GetIP6Part(X) = regex_replace(source=X, re="::.+", replace="")

 // Insert a : between each 4 digits - IPv6 addresses look like
 // 0000:0000:0000:0000:0000:0000:0000:0000
 LET ParseIP6(addr) = ip(parse=_GetIP6Part(
 X=regex_replace(re="(....)",
 replace="$1:",
 source=addr)))

 // Extract the first 4 hex digits in reverse order
 LET _ParseIP4(X) = SELECT int(int="0x" + _value) AS I,
 _key
 FROM items(item=split(sep=":",
 string=regex_replace(
 source=X,
 re="(..)",
 replace="$1:")))
 WHERE _key &amp;lt; 4
 ORDER BY _key DESC

 // Join them on a . and parse as an IP address
 LET ParseIP4(addr) = ip(parse=join(array=_ParseIP4(X=addr).I, sep="."))

 -- https://elixir.bootlin.com/linux/latest/source/include/net/tcp_states.h#L14
 LET StateLookup &amp;lt;= dict(`01`="Established",
 `02`="Syn Sent",
 `06`="Time Wait",
 -- No owner process
 `0A`="Listening")

 -- Enumerate all the sockets and cache them in memory for
 -- reverse lookup. The following is basically lsof.
 LET X = SELECT
 OSPath[1] AS Pid,
 Data.Link AS Filename,
 parse_string_with_regex(
 string=Data.Link,
 regex="(?P&amp;lt;Type&amp;gt;socket|pipe):\\[(?P&amp;lt;inode&amp;gt;[0-9]+)\\]") AS Details
 FROM glob(globs="/proc/*/fd/*")

 LET _ &amp;lt;= log(message="Scanning all process handles")

 LET AllSockets &amp;lt;= SELECT
 atoi(string=Pid) AS Pid,
 read_file(filename="/proc/" + Pid + "/comm") AS Command,
 read_file(filename="/proc/" + Pid + "/cmdline") AS CommandLine,
 Filename,
 Details.Type AS Type,
 Details.inode AS Inode
 FROM X
 WHERE Type =~ "socket"

 LET GetProcByInode(inode) = SELECT *
 FROM AllSockets
 WHERE Inode = inode
 LIMIT 1

 -- Parse the TCP table and refer back to the socket
 -- so we can print process info.
 SELECT inode,
 get(item=StateLookup, field=st) AS State,
 uid,
 GetProcByInode(inode=inode)[0] AS ProcessInfo,
 ParseIP4(addr=local_address) AS LocalAddr,
 GetPort(X=local_address) AS LocalPort,
 ParseIP4(addr=rem_address) AS RemoteAddr,
 GetPort(X=rem_address) AS RemotePort
 FROM split_records(
 columns=["_", "sl", "local_address", "rem_address", "st", "queues", "tr_tm_when", "retransmit", "uid", "timeout", "inode"],
 filenames="/proc/net/tcp",
 regex=" +")
 WHERE sl =~ ":"
 AND State =~ StateRegex

 - name: TCP6
 query: |
 -- Parse the TCP6 table and refer back to the socket
 -- so we can print process info.
 SELECT "TCP6" AS Type,
 inode,
 get(item=StateLookup, field=st) AS State,
 uid,
 GetProcByInode(inode=inode)[0] AS ProcessInfo,
 ParseIP6(addr=local_address) AS LocalAddr,
 GetPort(X=local_address) AS LocalPort,
 ParseIP6(addr=rem_address) AS RemoteAddr,
 GetPort(X=rem_address) AS RemotePort
 FROM split_records(
 columns=["_", "sl", "local_address", "rem_address", "st", "queues", "tr_tm_when", "retransmit", "uid", "timeout", "inode"],
 filenames="/proc/net/tcp6",
 regex=" +")
 WHERE sl =~ ":"
 AND State =~ StateRegex

&lt;/code>&lt;/pre></description></item><item><title>Linux.Network.NetstatEnriched</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.network.netstatenriched/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.network.netstatenriched/</guid><description>&lt;p>Report network connections, and enrich with process information.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Network.NetstatEnriched
description: |
 Report network connections, and enrich with process information.

type: CLIENT

precondition:
 SELECT OS From info() where OS = 'linux'

parameters:
 - name: IPRegex
 description: "regex search over IP address fields."
 default: "."
 type: regex
 - name: PortRegex
 description: "regex search over port fields."
 default: "."
 type: regex
 - name: ProcessNameRegex
 description: "regex search over source process name"
 default: "."
 type: regex
 - name: UsernameRegex
 description: "regex search over source process user context"
 default: "."
 type: regex
 - name: ConnectionStatusRegex
 description: "regex search over connection status"
 default: "LISTEN|ESTAB"
 type: regex
 - name: ProcessPathRegex
 description: "regex search over source process path"
 default: "."
 type: regex
 - name: CommandLineRegex
 description: "regex search over source process commandline"
 default: "."
 type: regex
 - name: CallChainRegex
 description: "regex search over the process callchain"
 default: "."
 type: regex


sources:
 - query: |
 SELECT Laddr.IP AS Laddr,
 Laddr.Port AS Lport,
 Raddr.IP AS Raddr,
 Raddr.Port AS Rport,
 Pid,
 Status,
 process_tracker_get(id=Pid).Data AS ProcInfo,
 join(array=process_tracker_callchain(id=Pid).Data.Name, sep=" -&amp;gt; ") AS CallChain,
 process_tracker_tree(id=Pid) AS ChildrenTree
 FROM connections()
 WHERE Status =~ ConnectionStatusRegex
 AND Raddr =~ IPRegex
 AND ( Lport =~ PortRegex OR Rport =~ PortRegex )
 AND ProcInfo.Name =~ ProcessNameRegex
 AND ProcInfo.Username =~ UsernameRegex
 AND ProcInfo.Exe =~ ProcessPathRegex
 AND ProcInfo.CommandLine =~ CommandLineRegex
 AND CallChain =~ CallChainRegex

column_types:
 - name: ChildrenTree
 type: tree

&lt;/code>&lt;/pre></description></item><item><title>Linux.Network.PacketCapture</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.network.packetcapture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.network.packetcapture/</guid><description>&lt;p>This artifact uses tcpdump to natively capture packets.&lt;/p>
&lt;p>The &lt;code>Duration&lt;/code> parameter is used to define how long (in seconds) the capture should be. Specific interfaces can be defined by using the &lt;code>Interface&lt;/code> parameter, otherwise the artifact defaults to an interface assignment of &lt;code>any&lt;/code>.&lt;/p>
&lt;p>A &lt;code>BPF&lt;/code> (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.&lt;/p>
&lt;p>Read more about BPF expressions here: &lt;a href="https://biot.com/capstats/bpf.html" target="_blank" >https://biot.com/capstats/bpf.html&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Network.PacketCapture
author: Wes Lambert, @therealwlambert
description: |
 This artifact uses tcpdump to natively capture packets.

 The `Duration` parameter is used to define how long (in seconds) the capture should be. Specific interfaces can be defined by using the `Interface` parameter, otherwise the artifact defaults to an interface assignment of `any`.

 A `BPF` (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.

 Read more about BPF expressions here: https://biot.com/capstats/bpf.html

required_permissions:
 - EXECVE

implied_permissions:
 - FILESYSTEM_WRITE

parameters:
 - name: Duration
 type: integer
 description: Duration (in seconds) of PCAP to be recorded.
 default: 10

 - name: Interface
 type: string
 default: any

 - name: BPF
 type: string
 default:

precondition:
 SELECT * FROM info() where OS = 'linux'

sources:
 - query: |
 LET pcap &amp;lt;= tempfile(extension=".pcap")
 SELECT *, upload(file=pcap) AS PCAP
 FROM execve(argv=['bash', '-c', format(format='''(tcpdump -nni %v -w %v %v) &amp;amp; sleep %v; kill $!''', args=[Interface, pcap, BPF, Duration])], length=1000000)

&lt;/code>&lt;/pre></description></item><item><title>Linux.OSQuery.Generic</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.osquery.generic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.osquery.generic/</guid><description>&lt;p>OSQuery is an excellent tool for querying system state across the
three supported Velociraptor platform (Windows/Linux/MacOS).&lt;/p>
&lt;p>You can read more about OSQuery on &lt;a href="https://osquery.io/" target="_blank" >https://osquery.io/&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.OSQuery.Generic
description: |
 OSQuery is an excellent tool for querying system state across the
 three supported Velociraptor platform (Windows/Linux/MacOS).

 You can read more about OSQuery on https://osquery.io/

reference:
 - https://osquery.io/
 - https://github.com/osquery/osquery

# I am not actually sure if OSQuery allows arbitrary command execution via SQL?
required_permissions:
 - EXECVE

precondition: SELECT OS From info() where OS = 'linux'

tools:
 - name: OSQueryLinux
 github_project: Velocidex/OSQuery-Releases
 github_asset_regex: linux-amd64

parameters:
 - name: Query
 default: "SELECT * FROM osquery_info"

sources:
 - query: |
 LET binary &amp;lt;= SELECT OSPath
 FROM Artifact.Generic.Utils.FetchBinary(ToolName="OSQueryLinux")

 LET result = SELECT * FROM execve(
 argv=[binary[0].OSPath, "--json", Query],
 length=1000000)

 SELECT * FROM foreach(row=result,
 query={
 SELECT * FROM parse_json_array(data=Stdout)
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Proc.Arp</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.proc.arp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.proc.arp/</guid><description>&lt;p>ARP table via /proc/net/arp.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Proc.Arp
description: ARP table via /proc/net/arp.
parameters:
 - name: ProcNetArp
 default: /proc/net/arp
sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'

 query: |
 SELECT * from split_records(
 filenames=ProcNetArp,
 regex='\\s{3,20}',
 first_row_is_headers=true)

&lt;/code>&lt;/pre></description></item><item><title>Linux.Proc.Modules</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.proc.modules/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.proc.modules/</guid><description>&lt;p>Module listing via /proc/modules.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Proc.Modules
description: Module listing via /proc/modules.
parameters:
 - name: ProcModules
 default: /proc/modules

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'

 query: |
 SELECT Name,
 atoi(string=Size) As Size,
 atoi(string=UseCount) As UseCount,
 parse_string_with_regex(regex='''(?P&amp;lt;UsedBy&amp;gt;.*),''', string=UsedBy).UsedBy AS UsedBy,
 Status, 
 Address
 FROM split_records(
 filenames=ProcModules,
 regex='\\s+',
 columns=['Name', 'Size', 'UseCount', 'UsedBy', 'Status', 'Address'])

&lt;/code>&lt;/pre></description></item><item><title>Linux.Remediation.Quarantine</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.remediation.quarantine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.remediation.quarantine/</guid><description>&lt;p>Applies network quarantine to a Linux system using nftables.&lt;/p>
&lt;p>It expects the target system to have nftables installed, and uses the
associated &lt;code>nft&lt;/code> CLI tool.&lt;/p>
&lt;p>The artifact will create a table, with the default name
&lt;code>vrr_quarantine_table&lt;/code>, which contains three chains: One for inbound traffic,
one for outbound traffic, and the other for forwarding traffic. The chains
will cut off all traffic except those for DNS lookup and to the Velociraptor
server.&lt;/p>
&lt;p>To unquarantine the system, set the &lt;code>RemovePolicy&lt;/code> parameter to &lt;code>True&lt;/code>.&lt;/p>
&lt;p>The parameter &lt;code>ForbiddenTestURL&lt;/code> is used to test if the quarantine is working
as expected, so set it to a URL that should not be reachable from a
quarantined system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Remediation.Quarantine
description: |
 Applies network quarantine to a Linux system using nftables.

 It expects the target system to have nftables installed, and uses the
 associated `nft` CLI tool.

 The artifact will create a table, with the default name
 `vrr_quarantine_table`, which contains three chains: One for inbound traffic,
 one for outbound traffic, and the other for forwarding traffic. The chains
 will cut off all traffic except those for DNS lookup and to the Velociraptor
 server.

 To unquarantine the system, set the `RemovePolicy` parameter to `True`.

 The parameter `ForbiddenTestURL` is used to test if the quarantine is working
 as expected, so set it to a URL that should not be reachable from a
 quarantined system.

precondition: SELECT OS From info() where OS = 'linux'

type: CLIENT

required_permissions:
 - EXECVE
 - NETWORK

parameters:
 - name: pathToNFT
 default: /usr/sbin/nft
 description: We depend on nft to manage the tables, chains, and rules.

 - name: TableName
 default: vrr_quarantine_table
 description: Name of the quarantine table

 - name: ForbiddenTestURL
 default: https://www.google.com
 description: URL for forbidden connection check

 - name: MessageBox
 description: |
 Optional message box notification to send to logged in users. 256
 character limit.

 - name: RemovePolicy
 type: bool
 description: Tickbox to remove policy.

sources:
 - query: |
 LET State &amp;lt;= dict(installed=FALSE)

 LET SetInstalled = set(item=State, field="installed", value=TRUE)

 LET ClearInstalled = set(item=State, field="installed", value=FALSE) || TRUE

 LET run_command(Cmd, Message) = SELECT
 timestamp(epoch=now()) AS Time,
 format(format="Running %v: %v, Returned %v %v",
 args=[Cmd, Stdout || Stderr, ReturnCode,
 Message || ""]) AS Result
 FROM execve(argv=Cmd, length=10000)

 // If a MessageBox configured truncate to 256 character limit
 LET MessageBox &amp;lt;= parse_string_with_regex(regex='^(?P&amp;lt;Message&amp;gt;.{0,255}).*',
 string=MessageBox).Message

 // Parse a URL to get domain name.
 LET get_domain(URL) = split(string=url(parse=URL).Host, sep=":")[0]

 LET get_port(URL) = if(condition=url(parse=URL).Host =~ ":",
 then=split(string=url(parse=URL).Host, sep=":")[1],
 else=if(condition=url(parse=URL).Scheme = "https",
 then="443",
 else="80"))

 LET add_to_in_chain(DstAddr, DstPort) = (pathToNFT, 'add', 'rule', 'inet',
 TableName, 'inbound_chain', 'ip', 'saddr', host(name=DstAddr)[0],
 'tcp', 'sport', '{', DstPort, '}', 'ct', 'state', 'established', 'accept')

 LET add_to_out_chain(DstAddr, DstPort) = (pathToNFT, 'add', 'rule', 'inet',
 TableName, 'outbound_chain', 'ip', 'daddr', host(name=DstAddr)[0],
 'tcp', 'dport', '{', DstPort, '}', 'ct', 'state', 'established,new', 'accept')

 // extract Velociraptor config for policy
 LET extracted_config &amp;lt;= SELECT get_domain(URL=_value) AS DstAddr,
 get_port(URL=_value) AS DstPort,
 'VelociraptorFrontEnd' AS Description,
 _value AS URL
 FROM foreach(row=config.server_urls)

 LET send_message_box(Msg) = SELECT timestamp(epoch=now()) AS Time,
 Result
 FROM if(condition=MessageBox,
 then={
 SELECT Msg + ' MessageBox sent.' AS Result
 FROM execve(argv=['wall', MessageBox])
 },
 else={
 SELECT Msg AS Result
 FROM scope()
 })

 // delete table
 LET delete_table_cmd = (pathToNFT, 'delete', 'table', 'inet',
 TableName)

 // add table
 LET add_table_cmd = (pathToNFT, 'add', 'table', 'inet',
 TableName)

 // add inbound chain
 LET add_inbound_chain_cmd = (pathToNFT, 'add', 'chain', 'inet',
 TableName, 'inbound_chain', '{', 'type', 'filter', 'hook', 'input', 'priority', '0\;', 'policy', 'drop\;', '}')

 // add udp rule inbound chain to allow DNS lookups
 LET add_udp_rule_to_inbound_chain_cmd = (pathToNFT, 'add', 'rule', 'inet',
 TableName, 'inbound_chain', 'udp', 'sport', 'domain', 'ct', 'state', 'established', 'accept')

 // add localhost inbound rule to allow DNS lookups (needed on some ubuntu systems)
 // This is where systemd-resolved listens for local dns cache
 LET add_localhost_rule_to_inbound_chain_cmd = (pathToNFT, 'add', 'rule', 'inet',
 TableName, 'inbound_chain', 'ip', 'daddr', '127.0.0.53', 'accept')

 // add outbound chain
 LET add_outbound_chain_cmd = (pathToNFT, 'add', 'chain', 'inet',
 TableName, 'outbound_chain', '{', 'type', 'filter', 'hook', 'output', 'priority', '0\;', 'policy', 'drop\;', '}')

 // add tcp rule outbound chain to allow DNS traffics
 LET add_tcp_rule_to_outbound_chain_cmd = (pathToNFT, 'add', 'rule', 'inet',
 TableName, 'outbound_chain', 'tcp', 'dport', '{', '53', '}', 'ct', 'state', 'new,established', 'accept')

 // add udp rule outbound chain to allow DNS and DHCP traffics
 LET add_udp_rule_to_outbound_chain_cmd = (pathToNFT, 'add', 'rule', 'inet',
 TableName, 'outbound_chain', 'udp', 'dport', '{', '53,67,68', '}', 'ct', 'state', 'new,established', 'accept')

 // add localhost outbound rule to allow DNS lookups (needed on some ubuntu systems)
 LET add_localhost_rule_to_outbound_chain_cmd = (pathToNFT, 'add', 'rule', 'inet',
 TableName, 'outbound_chain', 'ip', 'saddr', '127.0.0.53', 'accept')

 // add forward chain
 LET add_forward_chain_cmd = (pathToNFT, 'add', 'chain', 'inet',
 TableName, 'forward_chain', '{', 'type', 'filter', 'hook', 'forward', 'priority', '0\;', 'policy', 'drop\;', '}')

 // delete quarantine table
 LET delete_quarantine_table = SELECT timestamp(epoch=now()) AS Time,
 TableName + ' table removed.' AS Result
 FROM execve(argv=delete_table_cmd, length=10000)
 WHERE ClearInstalled

 // add tcp rule to inbound_chain to allow connections from Velociraptor
 // FIXME(gye): may need to add IPv6 rules if DstAddr is an IPv6 address
 LET add_velociraptor_rule_to_inbound_chain = SELECT *
 FROM foreach(row={
 SELECT DstAddr,
 DstPort,
 add_to_in_chain(DstAddr=DstAddr, DstPort=DstPort) AS cmd
 FROM extracted_config
 },
 query={
 SELECT *
 FROM run_command(Cmd=cmd,
 Message='Added tcp rule to inbound_chain in ' +
 TableName + ' table.')
 })

 // add tcp rule to inbound_chain to allow connections from Velociraptor
 // FIXME(gye): may need to add IPv6 rules if DstAddr is an IPv6 address
 LET add_velociraptor_rule_to_outbound_chain = SELECT *
 FROM foreach(row={
 SELECT DstAddr,
 DstPort,
 add_to_out_chain(DstAddr=DstAddr, DstPort=DstPort) AS cmd
 FROM extracted_config
 },
 query={
 SELECT *
 FROM run_command(Cmd=cmd,
 Message='Added tcp rule to inbound_chain in ' +
 TableName + ' table.')
 })

 // test connection to a frontend server
 LET test_connection = SELECT *
 FROM foreach(row={
 SELECT DstAddr,
 DstPort,
 URL + 'server.pem' AS pem_url
 FROM extracted_config
 WHERE log(message="Will check connectivity with " + pem_url, dedup=-1)
 },
 query={
 SELECT format(format="Testing connectivity with %v: %v",
 args=[Url, Response]) AS Result
 FROM http_client(url=pem_url)
 WHERE Response = 200 AND log(dedup=-1,
 message="got %v for url %v", args=[Response, Url])
 LIMIT 1
 })

 // test connection to the ForbiddenTestURL - if the connection
 // can not be made, this will run in the http_client timeout that
 // can not be set manually. thus, the artifact will run for
 // approx. 2 minutes. Returns true if we are able to connect.
 LET test_forbidden_connection = SELECT *
 FROM http_client(url=log(message="Testing forbidden connection to " +
 ForbiddenTestURL,
 dedup=-1)
 &amp;amp;&amp;amp; ForbiddenTestURL)
 WHERE NOT Response =~ '^5..$' AND log(dedup=-1,
 message="got %v for url %v", args=[Response, Url])
 LIMIT 1

 // final checks to keep or remove policy
 // first check if connection to velociraptor server can be made
 LET final_check_allowed = SELECT *
 FROM if(
 condition=test_connection,
 then=send_message_box(Msg=TableName + ' connection test successful.'),
 else={
 SELECT *
 FROM run_command(
 Cmd=log(
 dedup=-1,
 message="%v failed connection test. Removing quarantine table.",
 args=TableName,
 level="ERROR")
 &amp;amp;&amp;amp; delete_table_cmd,
 Message=TableName + ' failed connection test. Removing quarantine table.')
 WHERE ClearInstalled
 })

 // then check if connection to ForbiddenTestURL can NOT be made
 // TODO(gyee): for now we are using the wall commmand to send the message.
 // Will need to look into using libnotify instead.
 LET final_check_forbidden = SELECT *
 FROM if(
 condition=State.installed
 AND test_forbidden_connection,
 then={
 SELECT *
 FROM run_command(
 Cmd=log(
 dedup=-1,
 message="%v failed forbidden connection test - connection to %v could be established. Removing quarantine table.",
 args=[TableName, ForbiddenTestURL],
 level="ERROR")
 &amp;amp;&amp;amp; delete_table_cmd,
 Message=TableName + ' failed forbidden connection test. Removing quarantine table.')
 WHERE ClearInstalled
 },
 else=send_message_box(
 Msg=TableName + ' forbidden connection test successful.'))

 LET check_nft_cmd = (pathToNFT, "--version")

 // Execute content
 LET doit = SELECT *
 FROM if(condition=RemovePolicy,
 then={
 SELECT *
 FROM delete_quarantine_table
 },
 else={
 SELECT *
 FROM chain(
 a=delete_quarantine_table,
 b={
 SELECT *
 FROM run_command(Cmd=add_table_cmd,
 Message=SetInstalled
 &amp;amp;&amp;amp; TableName + ' added.')
 },
 c={
 SELECT *
 FROM run_command(
 Cmd=add_inbound_chain_cmd,
 Message='Added inbound_chain to ' + TableName + ' table.')
 },
 d=add_velociraptor_rule_to_inbound_chain,
 e=run_command(Cmd=add_udp_rule_to_inbound_chain_cmd,
 Message='Added udp rule to inbound_chain in ' +
 TableName + ' table.'),
 f=run_command(Cmd=add_localhost_rule_to_inbound_chain_cmd,
 Message='Added localhost rule to inbound_chain in ' +
 TableName + ' table.'),
 g=run_command(
 Cmd=add_outbound_chain_cmd,
 Message='Added outbound_chain to ' + TableName + ' table.'),
 h=add_velociraptor_rule_to_outbound_chain,
 i=run_command(Cmd=add_tcp_rule_to_outbound_chain_cmd,
 Message='Added tcp rule to outbound_chain in ' +
 TableName + ' table.'),
 j=run_command(Cmd=add_udp_rule_to_outbound_chain_cmd,
 Message='Added udp rule to outbound_chain in ' +
 TableName + ' table.'),
 k=run_command(Cmd=add_localhost_rule_to_outbound_chain_cmd,
 Message='Added localhost rule to outbound_chain in ' +
 TableName + ' table.'),
 l=run_command(
 Cmd=add_forward_chain_cmd,
 Message='Added forward_chain to ' + TableName + ' table.'),
 m={
 SELECT *
 FROM final_check_allowed
 },
 n={
 SELECT *
 FROM if(condition=State.installed,
 then=final_check_forbidden)
 })
 })

 SELECT *
 FROM if(condition={
 SELECT *
 FROM run_command(Cmd=check_nft_cmd, Message='Check for ' + pathToNFT)
 WHERE Result =~ "nftables"
 },
 then=doit,
 else={
 SELECT *
 FROM scope()
 WHERE log(level="ERROR",
 message="nftables is not installed - quarantine not supported")
 AND FALSE
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.RHEL.Packages</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.rhel.packages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.rhel.packages/</guid><description>&lt;p>Parse packages installed from dnf or yum&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.RHEL.Packages
description: |
 Parse packages installed from dnf or yum

implied_permissions:
 - EXECVE

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'

 query: |
 LET Data &amp;lt;= SELECT * FROM switch(
 a={ SELECT Stdout FROM execve(argv=["dnf", "--quiet", "list", "installed"], length=10000000) WHERE Stdout },
 b={ SELECT Stdout FROM execve(argv=["yum", "--quiet", "list", "installed"], length=10000000) WHERE Stdout },
 c={SELECT "" AS Stdout FROM scope() WHERE log(level="ERROR",message="Could not retrieve package list") })

 // Sometimes lines overflow to the next line, correct for that
 LET Normalized &amp;lt;= regex_replace(source=Data[0].Stdout, re='''(?sm)\n\s''', replace="")
 LET Parsed = SELECT parse_string_with_regex(string=Line, regex='''([^\s]+)\s+([^\s]+)\s+([^\s]+)''') AS Parsed
 FROM parse_lines(accessor="data", filename=Normalized)

 SELECT Parsed.g1 AS Package, Parsed.g2 AS Version, Parsed.g3 AS Repository
 FROM Parsed
 WHERE Repository =~ "^@"

&lt;/code>&lt;/pre></description></item><item><title>Linux.Search.FileFinder</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.search.filefinder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.search.filefinder/</guid><description>&lt;p>Find files on the filesystem using the filename or content.&lt;/p>
&lt;h2 id="performance-note">Performance Note&lt;/h2>
&lt;p>This artifact can be quite expensive, especially if we search file
content. It will require opening each file and reading its entire
content. To minimize the impact on the endpoint we recommend this
artifact is collected with a rate limited way (about 20-50 ops per
second).&lt;/p>
&lt;p>This artifact is useful in the following scenarios:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>We need to locate all the places on our network where customer
data has been copied.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We’ve identified malware in a data breach, named using short
random strings in specific folders and need to search for other
instances across the network.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We believe our user account credentials have been dumped and
need to locate them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We need to search for exposed credit card data to satisfy PCI
requirements.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We have a sample of data that has been disclosed and need to
locate other similar files&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Search.FileFinder
description: |
 Find files on the filesystem using the filename or content.


 ## Performance Note

 This artifact can be quite expensive, especially if we search file
 content. It will require opening each file and reading its entire
 content. To minimize the impact on the endpoint we recommend this
 artifact is collected with a rate limited way (about 20-50 ops per
 second).

 This artifact is useful in the following scenarios:

 * We need to locate all the places on our network where customer
 data has been copied.

 * We’ve identified malware in a data breach, named using short
 random strings in specific folders and need to search for other
 instances across the network.

 * We believe our user account credentials have been dumped and
 need to locate them.

 * We need to search for exposed credit card data to satisfy PCI
 requirements.

 * We have a sample of data that has been disclosed and need to
 locate other similar files


precondition:
 SELECT * FROM info() where OS = 'linux'

parameters:
 - name: SearchFilesGlob
 default: /home/*
 description: Use a glob to define the files that will be searched.

 - name: SearchFilesGlobTable
 type: csv
 default: |
 Glob
 /home/someuser/*
 description: Alternative specify multiple globs in a table

 - name: YaraRule
 type: yara
 default:
 description: A yara rule to search for matching files.

 - name: Upload_File
 default: N
 type: bool

 - name: Calculate_Hash
 default: N
 type: bool

 - name: MoreRecentThan
 default: ""
 type: timestamp

 - name: ModifiedBefore
 default: ""
 type: timestamp

 - name: ExcludePathRegex
 default: "^/(proc|sys|run|snap)"
 type: regex
 description: If this regex matches the path of any directory we do not even descend inside of it.

 - name: LocalFilesystemOnly
 default: Y
 type: bool
 description: When set we stay on local attached filesystems including loop, attached disk, cdrom, device mapper, and excluding proc, nfs etc.

 - name: OneFilesystem
 default: N
 type: bool
 description: When set we do not follow a link to go on to a different filesystem.

 - name: DoNotFollowSymlinks
 type: bool
 default: N
 description: If specified we are allowed to follow symlinks while globbing

 - name: ROOT
 type: hidden
 description: The root from which to start searching.

 - name: ACCESSOR
 type: hidden
 default: "file"

 - name: UPLOAD_IS_RESUMABLE
 type: bool
 default: Y
 description: If set the uploads can be resumed if the flow times out or errors.

sources:
- query: |
 -- This list comes from cat /proc/devices and represents actual
 -- devices. Most virtual devices like /proc, fuse and network
 -- filesystems have a major number of 0.
 LET LocalDeviceMajor &amp;lt;= (
 253,
 7, -- loop
 8, -- sd
 9, -- md
 11, -- sr
 65, -- sd
 66, -- sd
 67, -- sd
 68, -- sd
 69, -- sd
 70, -- sd
 71, -- sd
 128, -- sd
 129, -- sd
 130, -- sd
 131, -- sd
 132, -- sd
 133, -- sd
 134, -- sd
 135, -- sd
 202, -- xvd
 253, -- device-mapper
 254, -- mdp
 259, -- blkext
 )

 LET RecursionCallback = if(
 condition=LocalFilesystemOnly,
 then=if(condition=ExcludePathRegex,
 then="x=&amp;gt;x.Data.DevMajor IN LocalDeviceMajor AND NOT x.OSPath =~ ExcludePathRegex",
 else="x=&amp;gt;x.Data.DevMajor IN LocalDeviceMajor"),
 else=if(condition=ExcludePathRegex,
 then="x=&amp;gt;NOT x.OSPath =~ ExcludePathRegex",
 else=""))

 LET file_search = SELECT OSPath,
 Sys.mft as Inode,
 Mode.String AS Mode, Size,
 Mtime AS MTime,
 Atime AS ATime,
 Ctime AS CTime,
 IsDir, Mode, Data
 FROM glob(globs=SearchFilesGlobTable.Glob + SearchFilesGlob,
 recursion_callback=RecursionCallback,
 root=ROOT,
 one_filesystem=OneFilesystem,
 accessor=ACCESSOR, nosymlink=DoNotFollowSymlinks)

 LET more_recent = SELECT * FROM if(
 condition=MoreRecentThan,
 then={
 SELECT * FROM file_search
 WHERE MTime &amp;gt; MoreRecentThan
 }, else={
 SELECT * FROM file_search
 })

 LET modified_before = SELECT * FROM if(
 condition=ModifiedBefore,
 then={
 SELECT * FROM more_recent
 WHERE MTime &amp;lt; ModifiedBefore
 AND MTime &amp;gt; MoreRecentThan
 }, else={
 SELECT * FROM more_recent
 })

 LET keyword_search = SELECT * FROM if(
 condition=YaraRule,
 then={
 SELECT * FROM foreach(
 row={
 SELECT * FROM modified_before
 WHERE Mode.IsRegular
 },
 query={
 SELECT OSPath, Inode, Mode,
 Size, ATime, MTime, CTime,
 str(str=String.Data) As Keywords

 FROM yara(files=OSPath,
 key="A",
 rules=YaraRule,
 accessor=ACCESSOR)
 })
 }, else={
 SELECT *, NULL AS Keywords FROM modified_before
 })

 SELECT OSPath, Inode, Mode, Size, ATime,
 MTime, CTime, Keywords,
 if(condition=Upload_File and Mode.IsRegular,
 then=upload(file=OSPath,
 accessor=ACCESSOR)) AS Upload,
 if(condition=Calculate_Hash and Mode.IsRegular,
 then=hash(path=OSPath,
 accessor=ACCESSOR)) AS Hash
 FROM keyword_search

column_types:
 - name: ATime
 type: timestamp
 - name: MTime
 type: timestamp
 - name: CTime
 type: timestamp
 - name: Upload
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Linux.Ssh.AuthorizedKeys</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.ssh.authorizedkeys/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.ssh.authorizedkeys/</guid><description>&lt;p>Finds and parses SSH authorized keys files.&lt;/p>
&lt;p>From &lt;code>man authorized_keys&lt;/code>:&lt;/p>
&lt;p>&lt;code>AUTHORIZED_KEYS FILE FORMAT&lt;/code>: Each line of the file contains one
key (empty lines and lines starting with a ‘#’ are ignored as
comments). Public keys consist of the following space-separated
fields: options, keytype, base64-encoded key, comment. The options
field is optional.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Ssh.AuthorizedKeys
description: |
 Finds and parses SSH authorized keys files.

 From `man authorized_keys`:

 `AUTHORIZED_KEYS FILE FORMAT`: Each line of the file contains one
 key (empty lines and lines starting with a ‘#’ are ignored as
 comments). Public keys consist of the following space-separated
 fields: options, keytype, base64-encoded key, comment. The options
 field is optional.

parameters:
 - name: sshKeyFiles
 default: '.ssh/authorized_keys*'
 description: Glob of authorized_keys file relative to a user's home directory.
 - name: keyTypes
 type: regex
 description: A regex to identify supported key types
 default: "sk-ecdsa-sha2-nistp256|ecdsa-sha2-nistp256|ecdsa-sha2-nistp384|ecdsa-sha2-nistp521|sk-ssh-ed25519|ssh-ed25519|ssh-dss|ssh-rsa"

 - name: AlsoUpload
 type: bool
 description: Also upload the raw files for closer inspection.

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'

 query: |
 -- Find all eligible files.
 LET authorized_keys = SELECT * from foreach(
 row={
 SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
 },
 query={
 SELECT OSPath,
 if(condition=AlsoUpload, then=upload(file=OSPath)) AS _Upload,
 Mtime, Ctime, User, Uid
 FROM glob(root=Homedir, globs=sshKeyFiles)
 WHERE log(message="Parsing file %v", args=OSPath, dedup=-1)
 })

 -- Split each line into parts considering possible quoting
 LET Parse(OSPath) =
 -- Pad a bit so index does not wrap.
 SELECT ParseParts(Parts=commandline_split(command=Line, bash_style=TRUE) + ("", "", "", "", "")) AS Parsed
 FROM parse_lines(filename=OSPath)
 WHERE NOT Line =~ "^#" AND Parsed.keytype =~ keyTypes

 -- The option may or may not be there - determine by the key regex
 LET ParseParts(Parts) = if(condition= Parts[0] =~ keyTypes,
 -- No options
 then=dict(options="", keytype=Parts[0], base64key=Parts[1], comment=Parts[2] || ""),

 -- The line has options
 else=dict(options=ParseOptions(Opts=Parts[0]),
 keytype=Parts[1], base64key=Parts[2], comment=Parts[3] || ""))

 -- Option can have value or just be bare
 LET ParseOptions(Opts) = split(string=Opts, sep_string=",")

 SELECT * FROM foreach(row=authorized_keys,
 query={
 SELECT Uid, User, OSPath, _Upload, *
 FROM foreach(column="Parsed", row= Parse(OSPath=OSPath))
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Ssh.KnownHosts</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.ssh.knownhosts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.ssh.knownhosts/</guid><description>&lt;p>Finds and parses SSH known hosts files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Ssh.KnownHosts
description: Finds and parses SSH known hosts files.
parameters:
 - name: sshKnownHostsFiles
 default: '.ssh/known_hosts*'

precondition: SELECT OS From info() where OS = 'linux'

sources:
 - query: |
 // For each user on the system, search for known_hosts files.
 LET authorized_keys = SELECT * from foreach(
 row={
 SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
 },
 query={
 SELECT OSPath, Mtime, Ctime, User, Uid
 FROM glob(
 globs=sshKnownHostsFiles,
 root=Homedir)
 })

 // For each known_hosts file, extract each line on a different row.
 SELECT * from foreach(
 row=authorized_keys,
 query={
 SELECT Uid, User, OSPath, Hostname, Type, PublicKey
 FROM split_records(
 filenames=OSPath, regex=" ", record_regex="\n",
 columns=["Hostname", "Type", "PublicKey"])
 /* Ignore comment lines. */
 WHERE not Hostname =~ "^[^#]+#"
 })

 - name: HostPublicKeys
 query: |
 LET Me &amp;lt;= SELECT * FROM info()

 SELECT * FROM foreach(row={
 SELECT OSPath
 FROM glob(globs="/etc/ssh/ssh_host*.pub")
 }, query={
 SELECT *, Me[0].Fqdn AS Fqdn
 FROM split_records(columns=["Type", "PublicKey", "KeyName"],
 filenames=OSPath,
 regex=" +")
 })

 notebook:
 - type: vql_suggestion
 name: "Resolve Known Hosts"
 template: |
 /*
 # Resolve Hostnames

 This query resolves the public keys in the known hosts file
 with the collected public keys from all hosts.

 This works best when this cell applies to a hunt collection
 from a wide number of hosts. It helps to resolve the
 hostnames from known hosts to real host names (these are
 usually hashed within the file).

 This artifact helps to establish historical SSH access from
 one machine to another machine.
 */

 LET lookup &amp;lt;= memoize(
 key="PublicKey",
 query={
 SELECT *
 FROM source(artifact="Linux.Ssh.KnownHosts/HostPublicKeys")
 })

 SELECT *, get(item=lookup, field=PublicKey) AS Hostname
 FROM source(artifact="Linux.Ssh.KnownHosts")

&lt;/code>&lt;/pre></description></item><item><title>Linux.Ssh.PrivateKeys</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.ssh.privatekeys/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.ssh.privatekeys/</guid><description>&lt;p>SSH Private keys can be either encrypted or unencrypted. Unencrypted
private keys are more risky because an attacker can use them without
needing to unlock them with a password.&lt;/p>
&lt;p>In particular, AWS instances are usually accessed by way of an SSH
key pair generated by the AWS console. This key is not encrypted by
default and it is possible that administrators simply save the key
on their systems without encrypting it.&lt;/p>
&lt;p>This artifact searches for private keys in the usual locations and
also records if they are encrypted or not. Not all key types are
supported&lt;/p>
&lt;p>NOTE: To encrypt your private key run:&lt;/p>
&lt;pre>&lt;code>ssh-keygen -p -f my_private_key
&lt;/code>&lt;/pre>
&lt;p>Change the glob to /** if you would like to search the entire filesystem.
Be aware, this is an expensive operation.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Ssh.PrivateKeys
description: |
 SSH Private keys can be either encrypted or unencrypted. Unencrypted
 private keys are more risky because an attacker can use them without
 needing to unlock them with a password.

 In particular, AWS instances are usually accessed by way of an SSH
 key pair generated by the AWS console. This key is not encrypted by
 default and it is possible that administrators simply save the key
 on their systems without encrypting it.

 This artifact searches for private keys in the usual locations and
 also records if they are encrypted or not. Not all key types are
 supported

 NOTE: To encrypt your private key run:

 ```
 ssh-keygen -p -f my_private_key
 ```

 Change the glob to /** if you would like to search the entire filesystem.
 Be aware, this is an expensive operation.

reference:
 - https://attack.mitre.org/techniques/T1145/
 - https://coolaj86.com/articles/the-openssh-private-key-format/
 - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html

precondition: SELECT OS From info() where OS = 'linux'

parameters:
 - name: KeyGlobs
 default: /home/*/.ssh/{*.pem,id_rsa,id_dsa}

 - name: ExcludePathRegex
 default: "^/(proc|sys|run|snap)"
 type: regex
 description: If this regex matches the path of any directory we do not even descend inside of it.

 - name: LocalFilesystemOnly
 default: Y
 type: bool
 description: |
 When set, we stay on local attached filesystems including loop, attached
 disk, cdrom, device mapper, and excluding proc, nfs etc. When set, it can
 potentially miss keys in some Linux distros. If not sure, or if being run
 across multiple distros, then we recommend that you not set it.

sources:
 - query: |
 -- For new OpenSSH format
 LET SSHProfile = '''[
 ["Header", 0, [
 ["Magic", 0, "String", {
 "length": 100,
 }],
 ["cipher_length", 15, "uint32b"],
 ["cipher", 19, "String", {
 "length": "x=&amp;gt;x.cipher_length",
 }]
 ]]]
 '''

 -- Device major numbers considered local. See Linux.Search.FileFinder
 LET LocalDeviceMajor &amp;lt;= (NULL,
 253, 7, 8, 9, 11, 65, 66, 67, 68, 69, 70,
 71, 128, 129, 130, 131, 132, 133, 134, 135, 202, 253, 254, 259)

 -- By default set to 'True', to only search local filesystems.
 LET RecursionCallback = if(
 condition=LocalFilesystemOnly,
 then=if(condition=ExcludePathRegex,
 then="x=&amp;gt;x.Data.DevMajor IN LocalDeviceMajor AND NOT x.OSPath =~ ExcludePathRegex",
 else="x=&amp;gt;x.Data.DevMajor IN LocalDeviceMajor"),
 else=if(condition=ExcludePathRegex,
 then="x=&amp;gt;NOT x.OSPath =~ ExcludePathRegex",
 else=""))

 LET _Hits = SELECT OSPath,
 read_file(filename=OSPath, length=20240) AS Data
 FROM glob(globs=KeyGlobs, recursion_callback=RecursionCallback)
 WHERE Size &amp;lt; 20000

 LET Hits = SELECT OSPath, Data,
 base64decode(
 string=parse_string_with_regex(
 string=Data,
 regex="(?sm)KEY-----(.+)-----END").g1) || "" AS Decoded,
 parse_string_with_regex(
 string=Data,
 regex="(BEGIN.* PRIVATE KEY)").g1 AS Header,
 read_file(filename=OSPath.Dirname + (OSPath.Basename + ".pub") ) AS PublicKey
 FROM _Hits
 WHERE Header

 LET OpenSSHKeyParser(OSPath, Decoded) = SELECT OSPath,
 parse_binary(accessor="data", filename=Decoded,
 profile=SSHProfile, struct="Header") AS Parsed
 FROM scope()

 -- Support both types of ssh keys dependingg on the header
 SELECT * FROM foreach(row={SELECT * FROM Hits},
 query={
 SELECT * FROM switch(
 a={
 -- new format
 SELECT OSPath,
 Parsed.Magic AS KeyType,
 Parsed.cipher AS Cipher,
 Header, PublicKey
 FROM OpenSSHKeyParser(OSPath= OSPath, Decoded=Decoded)
 WHERE Header =~ "BEGIN OPENSSH PRIVATE KEY"
 },
 a2={
 -- encrypted rsa key from e.g. putty
 SELECT OSPath,
 "PKCS8" AS KeyType,
 parse_string_with_regex(string=Data,
 regex="DEK-Info: ([-a-zA-Z0-9]+)").g1 AS Cipher,
 Header, PublicKey
 FROM scope()
 WHERE Header =~ "BEGIN RSA PRIVATE KEY"
 AND "Proc-Type: 4,ENCRYPTED" in Data
 },
 b={
 -- unencrypted rsa key from e.g. AWS
 SELECT OSPath,
 "PKCS8" AS KeyType,
 "none" AS Cipher,
 Header, PublicKey
 FROM scope()
 WHERE Header =~ "BEGIN (RSA )?PRIVATE KEY"
 },
 c={
 -- old format encrypted
 SELECT OSPath,
 "PKCS8" AS KeyType,
 "PKCS#5" AS Cipher,
 Header, PublicKey
 FROM scope()
 WHERE Header =~ "BEGIN ENCRYPTED PRIVATE KEY"
 },
 d={
 -- catch all for unknown keys
 SELECT OSPath,
 "Unknown" AS KeyType,
 "Unknown" AS Cipher,
 Header, PublicKey
 FROM scope()
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.SuSE.Packages</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.suse.packages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.suse.packages/</guid><description>&lt;p>Parse list of installed packages from zypper output&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.SuSE.Packages
author: Hilko Bengen &amp;lt;bengen@hilluzination.de&amp;gt;
description: |
 Parse list of installed packages from zypper output

implied_permissions:
 - EXECVE

sources:
 - precondition: |
 SELECT OS From info() WHERE OS = 'linux'

 query: |
 LET zypper_output = SELECT *
 FROM execve(
 length=1000000,
 argv=["zypper", "--xmlout", "search", "--installed-only", "--details", "--type=package"])

 LET xml = parse_xml(
 file=str(str=zypper_output.Stdout),
 accessor="data")

 SELECT *
 FROM foreach(
 row=xml.stream.`search-result`.`solvable-list`.solvable,
 query={
 SELECT Attrname AS Package,
 Attredition AS Version,
 Attrarch AS Architecture,
 Attrrepository AS Repository
 FROM _value
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.ACPITables</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.acpitables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.acpitables/</guid><description>&lt;p>Firmware ACPI functional table common metadata and content.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.ACPITables
description: Firmware ACPI functional table common metadata and content.
reference:
 - https://osquery.io/schema/3.2.6#acpi_tables
parameters:
 - name: kLinuxACPIPath
 default: /sys/firmware/acpi/tables
sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 query: |
 LET hashes = SELECT Name, Size, hash(path=OSPath) as Hash
 FROM glob(globs="*", root=kLinuxACPIPath)

 SELECT Name, Size, Hash.MD5, Hash.SHA1, Hash.SHA256 from hashes

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.BashHistory</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.bashhistory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.bashhistory/</guid><description>&lt;p>This artifact enables grep-like searching of Bash and alternate shell history
files.&lt;/p>
&lt;p>It can also be used to target other files located in the user profile such as:&lt;/p>
&lt;ul>
&lt;li>&lt;code>*_profile&lt;/code> and &lt;code>*rc&lt;/code> files.&lt;/li>
&lt;li>shell history: &lt;code>/{root,home/*}/.*_history&lt;/code>&lt;/li>
&lt;li>profile: &lt;code>/{root,home/*}/.*_profile&lt;/code>&lt;/li>
&lt;li>&lt;code>*rc&lt;/code> file: &lt;code>/{root,home/*}/.*rc&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Tags: .bash_history .bash_profile .bashrc&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.BashHistory
author: "Matt Green - @mgreen27"
description: |
 This artifact enables grep-like searching of Bash and alternate shell history
 files.

 It can also be used to target other files located in the user profile such as:

 - `*_profile` and `*rc` files.
 - shell history: `/{root,home/*}/.*_history`
 - profile: `/{root,home/*}/.*_profile`
 - `*rc` file: `/{root,home/*}/.*rc`

 Tags: .bash_history .bash_profile .bashrc


parameters:
 - name: TargetGlob
 default: /{root,home/*}/.*_history
 - name: SearchRegex
 type: regex
 description: "Regex of strings to search in line."
 default: '.'
 - name: WhitelistRegex
 type: regex
 description: "Regex of strings to leave out of output."
 default:

sources:
 - query: |
 LET files = SELECT OSPath FROM glob(globs=TargetGlob)

 SELECT * FROM foreach(row=files,
 query={
 SELECT Line, OSPath FROM parse_lines(filename=OSPath)
 WHERE
 Line =~ SearchRegex
 AND NOT if(condition= WhitelistRegex,
 then= Line =~ WhitelistRegex,
 else= FALSE)
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.BashShell</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.bashshell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.bashshell/</guid><description>&lt;p>This artifact allows running arbitrary commands through the system
shell.&lt;/p>
&lt;p>Since Velociraptor typically runs as root, the commands will also
run as root.&lt;/p>
&lt;p>This is a very powerful artifact since it allows for arbitrary
command execution on the endpoints. Therefore this artifact requires
elevated permissions (specifically the &lt;code>EXECVE&lt;/code>
permission). Typically it is only available with the &lt;code>administrator&lt;/code>
role.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.BashShell
description: |
 This artifact allows running arbitrary commands through the system
 shell.

 Since Velociraptor typically runs as root, the commands will also
 run as root.

 This is a very powerful artifact since it allows for arbitrary
 command execution on the endpoints. Therefore this artifact requires
 elevated permissions (specifically the `EXECVE`
 permission). Typically it is only available with the `administrator`
 role.

required_permissions:
 - EXECVE

parameters:
 - name: Command
 default: "ls -l /"

sources:
 - query: |
 LET SizeLimit &amp;lt;= 4096
 SELECT if(condition=len(list=Stdout) &amp;lt; SizeLimit,
 then=Stdout) AS Stdout,
 if(condition=len(list=Stdout) &amp;gt;= SizeLimit,
 then=upload(accessor="data",
 file=Stdout, name="Stdout")) AS StdoutUpload
 FROM execve(argv=["/bin/bash", "-c", Command],
 length=10000000)

column_types:
- name: StdoutUpload
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.CPUTime</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.cputime/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.cputime/</guid><description>&lt;p>Displays information from /proc/stat file about the time the cpu
cores spent in different parts of the system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.CPUTime
description: |
 Displays information from /proc/stat file about the time the cpu
 cores spent in different parts of the system.
parameters:
 - name: procStat
 default: /proc/stat
sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 query: |
 LET raw = SELECT * FROM split_records(
 filenames=procStat,
 regex=' +',
 columns=['core', 'user', 'nice', 'system',
 'idle', 'iowait', 'irq', 'softirq',
 'steal', 'guest', 'guest_nice'])
 WHERE core =~ 'cpu.+'

 SELECT core AS Core,
 atoi(string=user) as User,
 atoi(string=nice) as Nice,
 atoi(string=system) as System,
 atoi(string=idle) as Idle,
 atoi(string=iowait) as IOWait,
 atoi(string=irq) as IRQ,
 atoi(string=softirq) as SoftIRQ,
 atoi(string=steal) as Steal,
 atoi(string=guest) as Guest,
 atoi(string=guest_nice) as GuestNice FROM raw

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.Crontab</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.crontab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.crontab/</guid><description>&lt;p>Displays parsed information from crontab.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.Crontab
description: |
 Displays parsed information from crontab.
parameters:
 - name: cronTabGlob
 default: /etc/crontab,/etc/cron.d/**,/var/at/tabs/**,/var/spool/cron/**,/var/spool/cron/crontabs/**
 - name: cronTabScripts
 default: /etc/cron.daily/*,/etc/cron.hourly/*,/etc/cron.monthly/*,/etc/cron.weekly/*
 - name: Length
 default: 10000
 type: int

precondition: SELECT OS From info() where OS = 'linux'

sources:
 - name: CronTabs
 query: |
 LET raw = SELECT * FROM foreach(
 row={
 SELECT OSPath from glob(globs=split(string=cronTabGlob, sep=","))
 },
 query={
 SELECT OSPath, data, parse_string_with_regex(
 string=data,
 regex=[
 /* Regex for event (Starts with @) */
 "^(?P&amp;lt;Event&amp;gt;@[a-zA-Z]+)\\s+(?P&amp;lt;Command&amp;gt;.+)",

 /* Regex for regular command. */
 "^(?P&amp;lt;Minute&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;Hour&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;DayOfMonth&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;Month&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;DayOfWeek&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;User&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;Command&amp;gt;.+)$"]) as Record

 /* Read lines from the file and filter ones that start with "#" */
 FROM split_records(
 filenames=OSPath,
 regex="\n", columns=["data"]) WHERE not data =~ "^\\s*#"
 }) WHERE Record.Command

 SELECT Record.Event AS Event,
 Record.User AS User,
 Record.Minute AS Minute,
 Record.Hour AS Hour,
 Record.DayOfMonth AS DayOfMonth,
 Record.Month AS Month,
 Record.DayOfWeek AS DayOfWeek,
 Record.Command AS Command,
 OSPath AS Path
 FROM raw
 - name: CronScripts
 query: |
 SELECT Mtime, OSPath, read_file(filename=OSPath,length=Length) AS Content
 FROM glob(globs=split(string=cronTabScripts, sep=","))
 - name: Uploaded
 query: |
 SELECT OSPath, upload(file=OSPath) AS Upload
 FROM glob(globs=split(string=cronTabGlob + "," + cronTabScripts, sep=","))

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.Groups</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.groups/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.groups/</guid><description>&lt;p>Get system group IDs, names and memberships from /etc/group&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.Groups
author: Andreas Misje – @misje
description: Get system group IDs, names and memberships from /etc/group
parameters:
 - name: GroupFile
 default: /etc/group
 description: The location of the group file

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 query: |
 SELECT Group, int(int=GID) AS GID, filter(regex='.+',
 list=split(sep_string=',', string=Members)) AS Members
 FROM split_records(
 filenames=GroupFile,
 regex=':', record_regex='\r?\n',
 columns=['Group', 'Password', 'GID', 'Members'])

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.LastUserLogin</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.lastuserlogin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.lastuserlogin/</guid><description>&lt;p>Finds and parses system WTMP files.&lt;/p>
&lt;p>These indicate when users last logged in.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.LastUserLogin
description: |
 Finds and parses system WTMP files.

 These indicate when users last logged in.

parameters:
 - name: wtmpGlobs
 default: /var/log/wtmp*

 - name: MaxCount
 default: 10000
 type: int64

 - name: LoginType
 type: choices
 default: Interactive Sessions
 choices:
 - Interactive Sessions
 - All Sessions
 description: |
 Per default, we are only interested in interactive sessions, if
 you want to see more, choose the second option


 - name: recent_x_days
 default: 100000
 type: int
 description: |
 show all logs within the last X days (default 14 days)

 - name: excluded_users
 type: regex
 default: "ansible|LOGIN"
 description: |
 List of Users (regex), you are not interested in

export: |
 LET FilterLookup = dict(
 `Interactive Sessions`="USER_PROCESS|LOGIN_PROCESS",
 `All Sessions`="RUN_LVL|BOOT_TIME|INIT_PROCESS|LOGIN_PROCESS|USER_PROCESS")

 LET wtmpProfile &amp;lt;= '''
 [
 ["Header", 0, [

 ["records", 0, "Array", {
 "type": "utmp",
 "count": "x=&amp;gt;MaxCount",
 "max_count": 100000,
 }],
 ]],
 ["utmp", 384, [
 ["ut_type", 0, "Enumeration", {
 "type": "short int",
 "choices": {
 "0": "EMPTY",
 "1": "RUN_LVL",
 "2": "BOOT_TIME",
 "5": "INIT_PROCESS",
 "6": "LOGIN_PROCESS",
 "7": "USER_PROCESS",
 "8": "DEAD_PROCESS"
 }
 }],
 ["ut_pid", 4, "int"],
 ["ut_terminal", 8, "String", {"length": 32}],
 ["ut_terminal_identifier", 40, "String", {"length": 4}],
 ["ut_user", 44, "String", {"length": 32}],
 ["ut_hostname", 76, "String", {"length": 256}],
 ["ut_termination_status", 332, "int"],
 ["ut_exit_status", 334, "int"],
 ["ut_session", 336, "int"],
 ["ut_timestamp", 340, "Timestamp", {
 "type": "uint32",
 }],
 ["ut_ip_address", 348, "int64"],
 ]]
 ]]
 ]'''

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'

 query: |
 LET LoginType &amp;lt;= get(item=FilterLookup, field=LoginType) || LoginType
 LET start_time &amp;lt;= timestamp(epoch=now() - recent_x_days * 3600 * 24)

 LET _ &amp;lt;= log(message="Start time %v", args=start_time)

 LET parsed = SELECT OSPath, parse_binary(
 filename=OSPath,
 profile=wtmpProfile,
 struct="Header"
 ) AS Parsed
 FROM glob(globs=split(string=wtmpGlobs, sep=","))

 // To combine Login/Logout into one Table, we create a
 // logout table first
 LET logout_table &amp;lt;= SELECT * FROM foreach(row=parsed,
 query={
 SELECT * FROM foreach(row=Parsed.records,
 query={
 SELECT ut_type AS logout_Type,
 ut_pid as logout_PID,
 ut_terminal as logout_Terminal,
 ut_timestamp as logout_time
 FROM scope()
 WHERE logout_Type = "DEAD_PROCESS"
 AND logout_time &amp;gt; start_time
 })
 })
 Order by logout_time DESC

 SELECT * FROM foreach(row=parsed,
 query={
 SELECT * FROM foreach(row=Parsed.records,
 query={
 SELECT OSPath,
 ut_type AS login_Type,
 ut_terminal_identifier AS login_ID,
 ut_pid as login_PID,
 ut_hostname as login_Host,
 ut_user as login_User,
 ip(netaddr4_le=ut_ip_address) AS login_IpAddr,
 ut_terminal as login_Terminal,
 ut_timestamp as login_time, {
 SELECT logout_time
 FROM logout_table
 WHERE ut_pid = logout_PID
 AND ut_terminal = logout_Terminal
 AND ut_timestamp &amp;lt; logout_time
 LIMIT 1
 } AS logout_time
 FROM scope()
 WHERE login_Type =~ LoginType
 AND NOT login_User =~ excluded_users
 AND login_time &amp;gt; start_time
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.LogGrep</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.loggrep/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.loggrep/</guid><description>&lt;p>This artifact enables zgrep-like searching of Linux logs, including gzipped
log files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.LogGrep
author: "Matt Green - @mgreen27"
description: |
 This artifact enables zgrep-like searching of Linux logs, including gzipped
 log files.

parameters:
 - name: TargetGlob
 default: /var/log/**
 - name: GrepRegex
 type: regex
 description: "Regex of strings to search in line."
 default: 'malware\.php'
 - name: WhitelistRegex
 type: regex
 description: "Regex of strings to leave out of output."
 default:

sources:
 - query: |
 LET files = SELECT OSPath FROM glob(globs=TargetGlob)
 WHERE NOT IsDir

 SELECT * FROM foreach(row=files,
 query={
 SELECT Line, OSPath FROM parse_lines(filename=OSPath)
 WHERE
 Line =~ GrepRegex
 AND NOT if(condition= WhitelistRegex,
 then= Line =~ WhitelistRegex,
 else= FALSE)
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.LogHunter</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.loghunter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.loghunter/</guid><description>&lt;p>Allows grep-like searching of Linux, MacOS and Windows logs.&lt;/p>
&lt;p>Parameters include &lt;code>SearchRegex&lt;/code> and &lt;code>WhitelistRegex&lt;/code> as regex terms.&lt;/p>
&lt;p>Also included is a Path exclusion regex (&lt;code>ExcludePathRegex&lt;/code>) to refine results
and automatically exclude hits in commonly unwanted locations such as &lt;code>/proc&lt;/code>.&lt;/p>
&lt;p>NOTE: The &lt;code>nosymlink&lt;/code> feature of glob is set so unexpected results may occur
if your targets includes symlink files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.LogHunter
author: "Matt Green - @mgreen27"
description: |
 Allows grep-like searching of Linux, MacOS and Windows logs.

 Parameters include `SearchRegex` and `WhitelistRegex` as regex terms.

 Also included is a Path exclusion regex (`ExcludePathRegex`) to refine results
 and automatically exclude hits in commonly unwanted locations such as `/proc`.

 NOTE: The `nosymlink` feature of glob is set so unexpected results may occur
 if your targets includes symlink files.

parameters:
 - name: TargetFiles
 default: '/var/log/**'
 - name: SearchRegex
 description: "Regex pattern to match in log lines."
 default: ' POST '
 type: regex
 - name: FilterRegex
 description: "Regex pattern to exclude matched lines from output."
 default:
 type: regex
 - name: ExcludeDirectoryRegex
 type: regex
 description: "Do not descend into directories that match this regex pattern."
 default: "^/(shared|proc|snap)"
 - name: ExcludePathRegex
 description: "Regex pattern describing paths to exclude from scanning."
 default: '\.journal$'
 type: regex

sources:
 - query: |
 LET RecursionCB &amp;lt;= if(condition= ExcludeDirectoryRegex,
 then="x =&amp;gt; NOT x.OSPath =~ ExcludeDirectoryRegex",
 else="x =&amp;gt; NOT x.OSPath =~ '^/proc' ")

 LET files = SELECT OSPath
 FROM glob(globs=TargetFiles,
 nosymlink=TRUE,
 recursion_callback=RecursionCB)
 WHERE NOT IsDir AND NOT OSPath =~ ExcludePathRegex
 AND log(message="Scanning %v", args=OSPath)

 LET hits = SELECT * FROM foreach(row=files,
 query={
 SELECT OSPath, Line FROM parse_lines(filename=OSPath)
 WHERE Line =~ SearchRegex
 })

 SELECT * FROM if(condition=FilterRegex,
 then={
 SELECT * FROM hits
 WHERE NOT Line =~ FilterRegex
 },
 else={
 SELECT * FROM hits
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.Maps</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.maps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.maps/</guid><description>&lt;p>A running binary may link other binaries into its address
space. These shared objects contain exported functions which may be
used by the binary.&lt;/p>
&lt;p>This artifact parses the /proc/&lt;pid>/maps to emit all mapped files
into the process.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.Maps
description: |
 A running binary may link other binaries into its address
 space. These shared objects contain exported functions which may be
 used by the binary.

 This artifact parses the /proc/&amp;lt;pid&amp;gt;/maps to emit all mapped files
 into the process.

precondition: SELECT OS From info() where OS = 'linux'

parameters:
 - name: processRegex
 description: A regex applied to process names.
 default: .
 type: regex

sources:
 - query: |
 LET processes = SELECT Pid, Name, Username
 FROM pslist()
 WHERE Name =~ processRegex

 SELECT Pid, Name, Username,
 "0x" + Record.Start AS StartHex,
 "0x" + Record.End AS EndHex,
 Record.Perm AS Perm,
 atoi(string="0x" + Record.Size) AS Size,
 "0x" + Record.Size AS SizeHex,
 Record.Filename AS Filename,
 if(condition=Record.Deleted, then=TRUE, else=FALSE) AS Deleted
 FROM foreach(
 row=processes,
 query={
 SELECT parse_string_with_regex(
 string=Line,
 regex="(?P&amp;lt;Start&amp;gt;^[^-]+)-(?P&amp;lt;End&amp;gt;[^\\s]+)\\s+(?P&amp;lt;Perm&amp;gt;[^\\s]+)\\s+(?P&amp;lt;Size&amp;gt;[^\\s]+)\\s+[^\\s]+\\s+(?P&amp;lt;PermInt&amp;gt;[^\\s]+)\\s+(?P&amp;lt;Filename&amp;gt;.+?)(?P&amp;lt;Deleted&amp;gt; \\(deleted\\))?$") AS Record,
 Pid, Name, Username
 FROM parse_lines(
 filename=format(format="/proc/%d/maps", args=[Pid]),
 accessor='file'
 )
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.Pslist</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.pslist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.pslist/</guid><description>&lt;p>List processes and their running binaries.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.Pslist
description: |
 List processes and their running binaries.

aliases:
 - MacOS.Sys.Pslist

parameters:
 - name: processRegex
 default: .
 type: regex

precondition: |
 SELECT OS From info() where OS =~ 'linux|darwin'

sources:
 - query: |
 SELECT Pid, Ppid, Name, CommandLine, Exe,
 hash(path=Exe) as Hash,
 Username, timestamp(epoch=CreateTime/1000) AS CreatedTime,
 MemoryInfo.RSS AS RSS,
 Exe =~ "\\(deleted\\)$" AS Deleted
 FROM process_tracker_pslist()
 WHERE Name =~ processRegex

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.Services</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.services/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.services/</guid><description>&lt;p>Parse services from systemctl&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.Services
description: Parse services from systemctl

implied_permissions:
 - EXECVE

sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 queries:
 - |
 LET services = SELECT Stdout FROM execve(argv=['systemctl', 'list-units', '--type=service'])

 LET all_services = SELECT grok(grok="%{NOTSPACE:Unit}%{SPACE}%{NOTSPACE:Load}%{SPACE}%{NOTSPACE:Active}%{SPACE}%{NOTSPACE:Sub}%{SPACE}%{GREEDYDATA:Description}", data=Line) AS Parsed
 FROM parse_lines(accessor="data", filename=services.Stdout)

 SELECT * FROM foreach(row=all_services, column="Parsed") WHERE Unit =~ ".service"

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.SUID</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.suid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.suid/</guid><description>&lt;p>Searches for applications that have the &lt;code>setuid&lt;/code> or &lt;code>setgid&lt;/code> bits set.&lt;/p>
&lt;p>When the &lt;code>setuid&lt;/code> or &lt;code>setgid&lt;/code> bits are set on Linux or macOS for an
application, this means that the application will run with the
privileges of the owning user or group respectively. Normally an
application is run in the current user’s context, regardless of
which user or group owns the application. There are instances where
programs need to be executed in an elevated context to function
properly, but the user running them doesn’t need the elevated
privileges. Instead of creating an entry in the &lt;code>sudoers&lt;/code> file, which
must be done by root, any user can specify the &lt;code>setuid&lt;/code> or &lt;code>setgid&lt;/code> flag
to be set for their own applications. These bits are indicated with
an &amp;ldquo;s&amp;rdquo; instead of an &amp;ldquo;x&amp;rdquo; when viewing a file&amp;rsquo;s attributes via &lt;code>ls -l&lt;/code>. The &lt;code>chmod&lt;/code> program can set these bits with via bitmasking, &lt;code>chmod 4777 [file]&lt;/code> or via shorthand naming, &lt;code>chmod u+s [file]&lt;/code>.&lt;/p>
&lt;p>An adversary can take advantage of this to either do a shell escape
or exploit a vulnerability in an application with the setsuid or
setgid bits to get code running in a different user&amp;rsquo;s
context. Additionally, adversaries can use this mechanism on their
own malware to ensure that they&amp;rsquo;re able to execute in elevated
contexts in the future.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.SUID
aliases:
 - MacOS.Sys.SUID
description: |
 Searches for applications that have the `setuid` or `setgid` bits set.

 When the `setuid` or `setgid` bits are set on Linux or macOS for an
 application, this means that the application will run with the
 privileges of the owning user or group respectively. Normally an
 application is run in the current user’s context, regardless of
 which user or group owns the application. There are instances where
 programs need to be executed in an elevated context to function
 properly, but the user running them doesn’t need the elevated
 privileges. Instead of creating an entry in the `sudoers` file, which
 must be done by root, any user can specify the `setuid` or `setgid` flag
 to be set for their own applications. These bits are indicated with
 an "s" instead of an "x" when viewing a file's attributes via `ls
 -l`. The `chmod` program can set these bits with via bitmasking, `chmod
 4777 [file]` or via shorthand naming, `chmod u+s [file]`.

 An adversary can take advantage of this to either do a shell escape
 or exploit a vulnerability in an application with the setsuid or
 setgid bits to get code running in a different user's
 context. Additionally, adversaries can use this mechanism on their
 own malware to ensure that they're able to execute in elevated
 contexts in the future.

reference:
 - https://attack.mitre.org/techniques/T1166/

parameters:
 - name: GlobExpression
 default: /usr/**

sources:
 - query: |
 SELECT Mode.String AS Mode,
 OSPath, Size,
 Mtime,
 Sys.Uid AS OwnerID,
 Sys.Gid AS GroupID
 FROM glob(globs=GlobExpression) WHERE Mode =~ '^g|u'

&lt;/code>&lt;/pre></description></item><item><title>Linux.Sys.Users</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.sys.users/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.sys.users/</guid><description>&lt;p>Get User specific information like homedir, group, etc. from &lt;code>/etc/passwd&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.Users
description: Get User specific information like homedir, group, etc. from `/etc/passwd`.
parameters:
 - name: PasswordFile
 default: /etc/passwd
 description: The location of the password file.
sources:
 - precondition: |
 SELECT OS From info() where OS = 'linux'
 query: |
 SELECT User, Description, Uid, Gid, Homedir, Shell
 FROM split_records(
 filenames=PasswordFile,
 regex=":", record_regex="\r?\n",
 columns=["User", "X", "Uid", "Gid", "Description", "Homedir", "Shell"])

&lt;/code>&lt;/pre></description></item><item><title>Linux.Syslog.SSHLogin</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.syslog.sshlogin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.syslog.sshlogin/</guid><description>&lt;p>Parses the auth logs to determine all SSH login attempts.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Syslog.SSHLogin
description: |
 Parses the auth logs to determine all SSH login attempts.

reference:
 - https://www.elastic.co/blog/grokking-the-linux-authorization-logs

type: CLIENT

parameters:
 - name: syslogAuthLogPath
 default: /var/log/{auth.log,secure}*

 - name: SSHGrok
 description: A Grok expression for parsing SSH auth lines.
 default: &amp;gt;-
 %{SYSLOGTIMESTAMP:Timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: %{DATA:event} %{DATA:method} for (invalid user )?%{DATA:user} from %{IPORHOST:ip} port %{NUMBER:port} ssh2(: %{GREEDYDATA:system.auth.ssh.signature})?

sources:
 - query: |
 // Basic syslog parsing via GROK expressions.
 SELECT timestamp(string=Event.Timestamp) AS Time,
 Event.ip AS IP,
 Event.event AS Result,
 Event.method AS Method,
 Event.user AS AttemptedUser,
 OSPath
 FROM foreach(
 row={
 SELECT OSPath FROM glob(globs=syslogAuthLogPath)
 }, query={
 SELECT grok(grok=SSHGrok, data=Line) AS Event, OSPath
 FROM parse_lines(filename=OSPath)
 WHERE Event.program = "sshd"
 })

&lt;/code>&lt;/pre></description></item><item><title>Linux.Triage.ProcessMemory</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.triage.processmemory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.triage.processmemory/</guid><description>&lt;p>Dump process memory and upload to the server&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Triage.ProcessMemory
description: |
 Dump process memory and upload to the server

precondition: SELECT OS From info() where OS = 'linux'

parameters:
 - name: processPid
 type: int
 default: 2215

column_types:
 - name: CrashDump
 type: preview_upload

sources:
 - query: |
 SELECT Name as ProcessName, CommandLine, Pid,
 upload(file=format(format="/%d", args=processPid),
 accessor="process") as CrashDump
 FROM pslist(pid=processPid)

&lt;/code>&lt;/pre></description></item><item><title>Linux.Users.InteractiveUsers</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.users.interactiveusers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.users.interactiveusers/</guid><description>&lt;p>Gets the interactive users from a Linux host.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Users.InteractiveUsers

description: |
 Gets the interactive users from a Linux host.

author: George-Andrei Iosif (@iosifache)

type: CLIENT

parameters:
 - name: NonInteractiveExecutables
 description: Non-interactive executables that may appear in user's details
 type: str
 default: "/usr/sbin/nologin,/bin/false,/sbin/nologin,/bin/sync"

sources:
 - precondition: |
 SELECT OS
 FROM info()
 WHERE OS = 'linux'

 query: |
 SELECT Fqdn AS Host,
 User,
 Description,
 Uid,
 Gid,
 Homedir,
 Shell 
 FROM Artifact.Linux.Sys.Users()
 WHERE NOT Shell IN split(string=NonInteractiveExecutables, sep_string=",")

&lt;/code>&lt;/pre></description></item><item><title>Linux.Users.RootUsers</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.users.rootusers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.users.rootusers/</guid><description>&lt;p>Detects users added in the &lt;code>sudo&lt;/code> group.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Users.RootUsers

description: |
 Detects users added in the `sudo` group.

author: George-Andrei Iosif (@iosifache)

type: CLIENT

implied_permissions:
 - EXECVE

sources:
 - precondition: |
 SELECT OS
 FROM info()
 WHERE OS = 'linux'

 query: |
 SELECT *
 FROM foreach(
 row={
 SELECT *
 FROM Artifact.Linux.Sys.Users()
 },
 query={
 SELECT Fqdn AS Host,
 User,
 Description,
 Uid,
 Gid,
 Homedir,
 Shell
 FROM execve(argv=["id", "-Gn", User])
 WHERE ReturnCode = 0 AND Stdout =~ "root"
 }
 )

&lt;/code>&lt;/pre></description></item><item><title>Linux.Utils.InstallDeb</title><link>https://docs.velociraptor.app/artifact_references/pages/linux.utils.installdeb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/linux.utils.installdeb/</guid><description>&lt;p>Install a deb package and configure it with debconf answers.&lt;/p>
&lt;p>The package may either be specified by name, as an uploaded file or as a
&amp;ldquo;tool&amp;rdquo;. If the package already exists, it may be optionally reconfigured with
debconf answers.&lt;/p>
&lt;p>There are three ways to specify a package (listed in order of preference if
all are set):&lt;/p>
&lt;ul>
&lt;li>
&lt;p>DebFile: An uploaded deb package.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DebTool: A deb package provided as a tool, specified by tool name. Since
this is a utility artifact meant to be called by other artifacts, the
tool should be specified in the artifact calling this artifact.
Alternatively, configure the tool by using
&lt;a href="https://docs.velociraptor.app/vql_reference/server/inventory_add/" target="_blank" >VQL&lt;/a>
.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DebName: The name of the package to install, or an absolute path to a deb
file to install. Each word is considered as a package name or file name.
&lt;code>apt-get&lt;/code> interprets the package name, and allows you to specify a
specific version, architecture, or even install and remove packages in
the same go:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;foo&amp;rdquo;: installs foo&lt;/li>
&lt;li>&amp;ldquo;foo bar- baz=1.0.0-1 qux:arm64&amp;rdquo;: installs foo, removes bar, installs
a specific version of baz and a specific architecture of qux&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Utils.InstallDeb
author: Andreas Misje – @misje
description: |
 Install a deb package and configure it with debconf answers.

 The package may either be specified by name, as an uploaded file or as a
 "tool". If the package already exists, it may be optionally reconfigured with
 debconf answers.

 There are three ways to specify a package (listed in order of preference if
 all are set):

 - DebFile: An uploaded deb package.

 - DebTool: A deb package provided as a tool, specified by tool name. Since
 this is a utility artifact meant to be called by other artifacts, the
 tool should be specified in the artifact calling this artifact.
 Alternatively, configure the tool by using
 [VQL](https://docs.velociraptor.app/vql_reference/server/inventory_add/).

 - DebName: The name of the package to install, or an absolute path to a deb
 file to install. Each word is considered as a package name or file name.
 `apt-get` interprets the package name, and allows you to specify a
 specific version, architecture, or even install and remove packages in
 the same go:

 - "foo": installs foo
 - "foo bar- baz=1.0.0-1 qux:arm64": installs foo, removes bar, installs
 a specific version of baz and a specific architecture of qux

type: CLIENT

required_permissions:
 - EXECVE
 - FILESYSTEM_WRITE

reference:
 - https://manpages.debian.org/bookworm/debconf-doc/debconf-devel.7.en.html#Type

parameters:
 - name: DebName
 description: |
 Package to install (by name). Ignored if DebFile or DebTool is set. An
 absolute path to a deb file that already exists on the system is also
 accepted.

 - name: DebFile
 description: |
 Package to install (by file). Remember to click "Upload"! When set,
 DebName and DebTool is ignored. Use DebName with an absolute file path
 if the file already exists on the system and does not need to be
 uploaded.
 type: upload_file

 - name: DebTool
 description: |
 Package to install as a tool (tool name). The tool must be configured
 manually by using VQL or in another artifact (calling this artifact).
 Ignored if DebFile is set.

 - name: ToolSleepDuration
 description: |
 Maximum number of seconds to sleep before downloading the package. Only
 relevant if DebTool is set.
 type: int
 default: 20

 - name: UpdateSources
 description: |
 Run `apt-get update` before installing the package. This is not necessary
 if the package has no dependencies, and it should be disabled if there
 is no Internet.
 type: bool
 default: True

 - name: ForceConfNew
 type: bool
 description: |
 Use the configuration delivered by the package instead of keeping the
 local changes.

 - name: Reinstall
 type: bool
 description: |
 Reinstall the package if it is already installed. This is only useful
 if you know or suspect that the package installation is broken. This
 also reconfigures the package.

 - name: UpgradeOnly
 type: bool
 description: |
 Do not install the package; only upgrade it if it is already installed.

 - name: ReconfigureIfInstalled
 type: bool
 description: |
 If the package is already installed, run pre-seed debconf and
 `dpkg-reconfigure` instead.

 - name: DebConfValues
 type: csv
 description: |
 debconf is a system used by many packages for interactive configuration.
 When using a non-interactive frontend (like this artifact), answers may
 by provided as a "pre-seed" file. Example line:

 "wireshark-common/install-setuid,boolean,false"
 default: |
 Key,Type,Value

column_types:
 - name: Stdout
 type: nobreak

 - name: Stderr
 type: nobreak

sources:
 - precondition:
 SELECT OS From info() where OS = 'linux'

 query: |
 LET Tool = SELECT OSPath
 FROM Artifact.Generic.Utils.FetchBinary(ToolName=DebTool,
 TemporaryOnly=true,
 SleepDuration=ToolSleepDuration)
 LET Package &amp;lt;= if(
 condition=DebTool,
 then=Tool[0].OSPath,
 else=if(
 condition=DebFile,
 /* apt requires file names to end in an architecture name, so
 create a copy ending in "_amd64.deb". The architecture chosen
 here, amd64, does not need to match the architecture of neither
 the package or the system:
 */
 then=copy(dest=tempdir() + '/package_amd64.deb',
 filename=DebFile),
 else=DebName))

 /* The file name is lost from the uploaded file, so extract it from the
 package instead (apt has certain requirements for the file name):
 */
 LET PackageInfo = SELECT Stdout
 FROM execve(argv=['/usr/bin/dpkg-deb', '--field', Package, 'Package'])

 LET PackageName = if(condition=DebTool OR DebFile,
 // remove "\n":
 then=PackageInfo[0].Stdout[:-1], else=DebName)

 /* The file format is "package_name question type answer": */
 LET PreSeedLines = SELECT join(sep=' ',
 array=(PackageName, Key, Type, Value)) AS Line
 FROM DebConfValues

 LET PreSeedFile &amp;lt;= tempfile(data=join(sep='\n', array=PreSeedLines.Line))

 LET AptEnv = dict(
 DEBIAN_FRONTEND='noninteractive',
 DEBCONF_NOWARNINGS='yes')

 LET AptOpts &amp;lt;= ('-f', '-y', '-o', 'Debug::pkgProblemResolver=yes',
 '--no-install-recommends') +
 if(condition=ForceConfNew,
 then=('-o', 'Dpkg::Options::=--force-confnew'), else=[]) +
 if(condition=Reinstall, then=('--reinstall', ), else=[]) +
 if(condition=UpgradeOnly, then=('--only-upgrade', ), else=[])

 LET PreSeed = SELECT 'Pre-seed debconf' AS Step, *
 FROM if(condition=DebConfValues, then={
 SELECT *
 FROM execve(argv=['/usr/bin/debconf-set-selections', PreSeedFile, ])
 WHERE log(message='Pre-seeding %v', dedup= -1,
 args=PackageName,
 level='INFO')
 AND (NOT ReturnCode OR log(level='ERROR',
 message='%v failed: %v', args=(Step, Stderr)))
 })

 /* Install regardless of whether package is installed or not, handing all
 the (arch-specific) version comparison logic to apt:
 */
 LET Install &amp;lt;= SELECT * FROM chain(
 a_update={
 SELECT 'Updating index' AS Step, *
 FROM if(condition=UpdateSources, then={
 SELECT *
 FROM execve(argv=['/usr/bin/apt-get', '-y', 'update'])
 WHERE log(message='Updating package index before installing',
 level='INFO')
 })
 },
 b_debconf=PreSeed,
 c_install={
 SELECT 'Installing package' AS Step, *
 FROM execve(
 argv=('/usr/bin/apt-get', ) + AptOpts +
 if(condition=Package = DebName,
 then=('install', ) + split(sep='''\s+''', string=Package),
 else=('install', Package)),
 env=AptEnv)
 WHERE log(message='Installing deb package %v',
 args=PackageName,
 dedup= -1,
 level='INFO')
 })
 WHERE NOT ReturnCode OR log(level='ERROR',
 message='%v failed: %v',
 args=(Step, Stderr))

 SELECT * FROM chain(
 a_install=Install,
 b_reconfigure={
 SELECT * FROM if(
 condition=ReconfigureIfInstalled AND (
 Reinstall OR Install.Stdout =~ 'Skipping|already the newest version'),
 then={
 SELECT 'Reconfiguring package' AS Step, *
 FROM execve(argv=['/usr/sbin/dpkg-reconfigure', PackageName, ],
 env=AptEnv)
 WHERE log(message='Reconfiguring deb package %v',
 args=PackageName,
 dedup= -1,
 level='INFO')
 AND (NOT ReturnCode OR log(level='ERROR',
 message='%v failed: %v',
 args=(Step, Stderr)))
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>LogScale.Events.Clients</title><link>https://docs.velociraptor.app/artifact_references/pages/logscale.events.clients/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/logscale.events.clients/</guid><description>&lt;p>This server side event monitoring artifact will watch a selection of client
monitoring artifacts for new events and push those to a LogScale (formerly
Humio) ingestion endpoint&lt;/p>
&lt;p>NOTE: You must ensure you are collecting these artifacts from the
clients by adding them to the &amp;ldquo;Client Events&amp;rdquo; GUI.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: LogScale.Events.Clients
description: |
 This server side event monitoring artifact will watch a selection of client
 monitoring artifacts for new events and push those to a LogScale (formerly
 Humio) ingestion endpoint

 NOTE: You must ensure you are collecting these artifacts from the
 clients by adding them to the "Client Events" GUI.

type: SERVER_EVENT

parameters:
 - name: ingestApiBase
 description: API Base Url for LogScale server
 type: string
 default: https://cloud.community.humio.com/api
 - name: ingestToken
 description: Ingest token for API
 type: string
 - name: tagFields
 description: Comma-separated list of field names to use as tags in the message; Can be renamed with &amp;lt;oldname&amp;gt;=&amp;lt;newname&amp;gt;.
 default:
 type: string
 - name: numThreads
 description: Number of threads to start up to post events
 type: int
 default: 1
 - name: httpTimeout
 description: Timeout (in seconds) for http connection attempts
 type: int
 default: 10
 - name: batchingTimeoutMs
 description: Timeout (in ms) to batch events prior to sending
 type: int
 default: 30000
 - name: eventBatchSize
 description: Count of events to batch prior to sending
 type: int
 default: 2000
 - name: statsInterval
 description: Interval to post statistics to log (in seconds, 0 to disable)
 type: int
 default: 600
 - name: debug
 description: Enable verbose logging
 type: bool
 default: false
 - name: Artifacts
 type: artifactset
 artifact_type: CLIENT_EVENT
 description: Client artifacts to monitor

sources:
 - query: |
 LET artifacts_to_watch = SELECT Artifact FROM Artifacts
 WHERE log(message="Uploading artifact " + Artifact + " to LogScale")

 LET events = SELECT * FROM foreach(
 row=artifacts_to_watch,
 async=TRUE, // Required for event queries in foreach()
 query={
 SELECT *, Artifact, timestamp(epoch=now()) AS timestamp
 FROM watch_monitoring(artifact=Artifact)
 })

 SELECT * FROM logscale_upload(
 query=events,
 apibaseurl=ingestApiBase,
 ingest_token=ingestToken,
 threads=numThreads,
 tag_fields=split(string=tagFields, sep=","),
 batching_timeout_ms=batchingTimeoutMs,
 event_batch_size=eventBatchSize,
 http_timeout=httpTimeout,
 debug=debug,
 stats_interval=statsInterval)

&lt;/code>&lt;/pre></description></item><item><title>LogScale.Flows.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/logscale.flows.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/logscale.flows.upload/</guid><description>&lt;p>This server side event monitoring artifact waits for new artifacts
to be collected from endpoints and automatically posts those to a
LogScale (formerly Humio) ingestion endpoint.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: LogScale.Flows.Upload
description: |
 This server side event monitoring artifact waits for new artifacts
 to be collected from endpoints and automatically posts those to a
 LogScale (formerly Humio) ingestion endpoint.

type: SERVER_EVENT

parameters:
 - name: ingestApiBase
 description: API Base Url for LogScale server
 type: string
 default: https://cloud.community.humio.com/api
 - name: ingestToken
 description: Ingest token for API
 type: string
 - name: tagFields
 description: Comma-separated list of field names to use as tags in the message; Can be renamed with &amp;lt;oldname&amp;gt;=&amp;lt;newname&amp;gt;.
 default:
 type: string
 - name: numThreads
 description: Number of threads to start up to post events
 type: int
 default: 1
 - name: httpTimeout
 description: Timeout (in seconds) for http connection attempts
 type: int
 default: 10
 - name: batchingTimeoutMs
 description: Timeout to batch events prior to sending
 type: int
 default: 30000
 - name: eventBatchSize
 description: Count of events to batch prior to sending
 type: int
 default: 2000
 - name: statsInterval
 description: Interval to post statistics to log (in seconds, 0 to disable)
 type: int
 default: 600
 - name: debug
 description: Enable verbose logging
 type: bool
 default: false
 - name: ArtifactNameRegex
 default: .
 type: regex
 description: Only upload these artifacts to elastic

sources:
 - query: |
 LET completions = SELECT * FROM watch_monitoring(
 artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

 LET documents = SELECT * FROM foreach(row=completions,
 query={
 SELECT * FROM foreach(
 row=Flow.artifacts_with_results,
 query={
 SELECT *, _value AS Artifact,
 timestamp(epoch=now()) AS timestamp,
 ClientId, Flow.session_id AS FlowId
 FROM source(
 client_id=ClientId,
 flow_id=Flow.session_id,
 artifact=_value)
 })
 })

 SELECT * FROM logscale_upload(
 query=documents,
 apibaseurl=ingestApiBase,
 ingest_token=ingestToken,
 threads=numThreads,
 tag_fields=split(string=tagFields, sep=","),
 batching_timeout_ms=batchingTimeoutMs,
 event_batch_size=eventBatchSize,
 http_timeout=httpTimeout,
 debug=debug,
 stats_interval=statsInterval)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Applications.Chrome.History</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.applications.chrome.history/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.applications.chrome.history/</guid><description>&lt;p>Read all User&amp;rsquo;s chrome history.&lt;/p>
&lt;h2 id="notes">NOTES:&lt;/h2>
&lt;p>This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Applications.Chrome.History
description: |
 Read all User's chrome history.

 ## NOTES:

 This artifact is deprecated in favor of
 Generic.Forensic.SQLiteHunter and will be removed in future


parameters:
 - name: historyGlobs
 default: /Users/*/Library/Application Support/Google/Chrome/*/History
 - name: urlSQLQuery
 default: |
 SELECT url as visited_url, title, visit_count,
 typed_count, last_visit_time
 FROM urls
 - name: userRegex
 default: .

precondition: SELECT OS From info() where OS = 'darwin'

sources:
 - query: |
 LET history_files = SELECT
 parse_string_with_regex(regex="/Users/(?P&amp;lt;User&amp;gt;[^/]+)", string=OSPath).User AS User,
 OSPath, Mtime
 FROM glob(globs=historyGlobs)

 SELECT * FROM foreach(row=history_files,
 query={
 SELECT User, OSPath,
 Mtime,
 visited_url,
 title, visit_count, typed_count,
 timestamp(winfiletime=last_visit_time * 10) as last_visit_time
 FROM sqlite(
 file=OSPath,
 query=urlSQLQuery)
 })

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Applications.MRU</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.applications.mru/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.applications.mru/</guid><description>&lt;p>Parse the MRU from MacOS users&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Applications.MRU
description: |
 Parse the MRU from MacOS users

reference:
 - https://mac-alias.readthedocs.io/en/latest/bookmark_fmt.html
 - https://github.com/al45tair/mac_alias
 - https://www.mac4n6.com/blog/2016/7/10/new-script-macmru-most-recently-used-plist-parser

type: CLIENT

parameters:
 - name: FinderPlistPath
 default: /Users/*/Library/Preferences/com.apple.finder.plist

export: |
 -- Parser for MAC Bookmark format
 LET type_lookup &amp;lt;= dict(
 `0x100`="__DataString",
 `0x200`="__DataData",
 `0x300`="__DataUint32",
 `0x400`="__DataDate",
 `0x500`="__DataBool",
 `0x600`="__DataArray",
 `0x700`="__DataDict",
 `0x800`="__DataUUID",
 `0x900`="__DataURL"
 )

 LET MRULookup &amp;lt;= dict(
 `0x2040`="Volume Bookmark",
 `0x2002`="Volume Path",
 `0x2020`="Volume Flags",
 `0x2030`="Volume is Root FS",
 `0x2011`="Volume UUID",
 `0x2012`="Volume Size",
 `0x2013`="Volume Creation Date",
 `0x2005`="Volume URL",
 `0x2040`="Volume Bookmark",
 `0x2050`="Volume Mount Point",
 `0xf080`="Security Extension",
 `0xf081`="Security Extension",
 `0x1004`="Target Path",
 `0x1005`="Target CNID Path",
 `0xc001`="Containing Folder Index",
 `0x1040`="Target Creation Date",
 `0x1010`="Target Flags",
 `0x1020`="Target Filename",
 `0xc011`="Creator Username",
 `0xc012`="Creator UID"
 )

 LET BookmarkProfile = '''[
 ["Header", 0, [
 ["Magic", 0, "String", {
 length: 4,
 }],
 ["Size", 4, "uint32"],
 ["HeaderSize", 12, "uint32"],
 ["TOCOffset", "x=&amp;gt;x.HeaderSize", "uint32"],
 ["TOC", "x=&amp;gt;x.TOCOffset + x.HeaderSize", "TOC"]
 ]],
 ["TOC", 0, [
 ["SizeOfTOC", 0, "uint32"],
 ["Magic", 4, "uint32"],
 ["TOCId", 8, "uint32"],
 ["NextTOC", 12, "uint32"],
 ["TOCCount", 16, "uint32"],
 ["Items", 20, "Array", {
 type: "TOCItem",
 count: "x=&amp;gt;x.TOCCount",
 }]
 ]],
 ["__TOCArrayPtr", 4, [
 ["Offset", 0, "uint32"],
 ["Item", 0, "Profile", {
 type: "TOCValue",
 offset: "x=&amp;gt;x.Offset + 48"
 }]
 ]],
 ["TOCValue", 0, [
 ["MyOffset", 0, "Value", {
 value: "x=&amp;gt;x.StartOf",
 }],
 ["length", 0, "uint32"],
 ["subtype", 4, "BitField", {
 type: "uint32",
 start_bit: 0,
 end_bit: 8,
 }],
 ["data_type", 4, "BitField", {
 type: "uint32",
 start_bit: 8,
 end_bit: 32,
 }],
 ["data", 0, "Value", {
 value: "x=&amp;gt;get(item=x, field=get(item=type_lookup, field=format(format='%#x', args=x.data_type)))",
 }],
 ["__DataString", 8, "String", {
 length: "x=&amp;gt;x.length",
 term: "",
 }],
 ["__DataData", 0, "Value", {
 value: "x=&amp;gt;format(format='%x', args=x.__DataStr)",
 }],
 ["__DataDateFloat", 8, "float64be"],
 ["__DataDate", 0, "Value", {
 value: "x=&amp;gt;timestamp(cocoatime=x.__DataDateFloat)",
 }],
 ["__DataUint32", 8, "uint32"],
 ["__DataBool", 0, "Value", {
 value: "x=&amp;gt;if(condition=x.subtype, then=TRUE, else=FALSE)",
 }],
 ["__DataURL", 0, "Value", {
 value: "x=&amp;gt;x.__DataString",
 }],
 ["__DataArrayOffsets", 8, "Array", {
 count: "x=&amp;gt;x.length / 4",
 type: "__TOCArrayPtr"
 }],
 ["__DataArray", 0, "Value", {
 value: "x=&amp;gt;x.__DataArrayOffsets.Item.data",
 }],
 ]],
 ["TOCItem", 12, [
 ["ID", 0, "uint32"],
 ["Offset", 4, "uint32"],
 ["TOCValue", "x=&amp;gt;x.Offset + 48 - x.StartOf", "TOCValue"],
 ]]
 ]
 '''

 LET ParseBookmark(Bookmark) =
 SELECT _value.name AS Name,
 get(item=MRULookup, field=format(format="%#x", args=ID)) AS Field,
 format(format="%#x", args=ID) AS FieldID,
 format(format="%#x", args=TOCValue.data_type) AS data_type,
 regex_replace(re="__Data", replace="",
 source=get(item=type_lookup,
 field=format(format="%#x",
 args=TOCValue.data_type))) AS type,
 TOCValue.data AS data

 FROM foreach(row=parse_binary(
 accessor="data", filename=Bookmark,
 profile=BookmarkProfile, struct="Header").TOC.Items)

sources:
 - query: |
 -- Parse the Plist file
 SELECT * FROM foreach(row={
 SELECT OSPath FROM glob(globs=FinderPlistPath)
 }, query={
 SELECT * FROM foreach(row={
 SELECT FXRecentFolders FROM plist(file=OSPath)
 }, query={
 SELECT *
 FROM foreach(row=FXRecentFolders, query={
 SELECT *, OSPath
 FROM ParseBookmark(Bookmark=_value.`file-bookmark`)
 })
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Detection.Autoruns</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.detection.autoruns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.detection.autoruns/</guid><description>&lt;p>This artifact collects evidence of autoruns. We also capture the files and upload them.&lt;/p>
&lt;p>This code is based on
&lt;a href="https://github.com/CrowdStrike/automactc/blob/master/modules/mod_autoruns_v102.py" target="_blank" >https://github.com/CrowdStrike/automactc/blob/master/modules/mod_autoruns_v102.py&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Detection.Autoruns
description: |
 This artifact collects evidence of autoruns. We also capture the files and upload them.

 This code is based on
 https://github.com/CrowdStrike/automactc/blob/master/modules/mod_autoruns_v102.py

precondition: SELECT OS FROM info() WHERE OS =~ 'darwin'

parameters:
- name: sandboxed_loginitems
 default: /var/db/com.apple.xpc.launchd/disabled.*.plist

- name: cronTabGlob
 default: /private/var/at//tabs/*

- name: LaunchAgentsDaemonsGlob
 default: |
 ["/System/Library/LaunchAgents/*.plist","/Library/LaunchAgents/*.plist",
 "/Users/*/Library/LaunchAgents/*.plist","/private/var/*/Library/LaunchAgents/*.plist",
 "/System/Library/LaunchAgents/.*.plist","/Library/LaunchAgents/.*.plist",
 "/Users/*/Library/LaunchAgents/.*.plist", "/private/var/*/Library/LaunchAgents/.*.plist",
 "/System/Library/LaunchDaemons/*.plist","/Library/LaunchDaemons/*.plist",
 "/System/Library/LaunchDaemons/.*.plist","/Library/LaunchDaemons/.*.plist"]

- name: ScriptingAdditionsGlobs
 default: |
 ["/System/Library/ScriptingAdditions/*.osax","/Library/ScriptingAdditions/*.osax",
 "/System/Library/ScriptingAdditions/.*.osax","/Library/ScriptingAdditions/.*.osax"]

- name: StartupItemsGlobs
 default: |
 ["/System/Library/StartupItems/*/*","/Library/StartupItems/*/*"]

- name: MiscItemsGlobs
 default: |
 ["/private/etc/periodic.conf", "/private/etc/periodic/*/*", "/private/etc/*.local",
 "/private/etc/rc.common",
 "/private/etc/emond.d/*","/private/etc/emond.d/*/*"]

- name: LoginItemsGlobs
 default: |
 ["/Users/*/Library/Preferences/com.apple.loginitems.plist",
 "/private/var/*/Library/Preferences/com.apple.loginitems.plist"]

sources:
- name: Sandboxed Loginitems
 query: |
 SELECT OSPath,
 Mtime,
 plist(file=OSPath) AS Disabled,
 upload(file=OSPath) AS Upload
 FROM glob(globs=sandboxed_loginitems)

- name: crontabs
 query: |
 LET raw = SELECT * FROM foreach(
 row={
 SELECT OSPath, Name, Mtime,
 upload(file=OSPath) AS Upload
 FROM glob(globs=split(string=cronTabGlob, sep=","))
 },
 query={
 SELECT OSPath, Name, Mtime, Upload,
 data, parse_string_with_regex(
 string=data,
 regex=[
 /* Regex for event (Starts with @) */
 "^(?P&amp;lt;Event&amp;gt;@[a-zA-Z]+)\\s+(?P&amp;lt;Command&amp;gt;.+)",

 /* Regex for regular command. */
 "^(?P&amp;lt;Minute&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;Hour&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;DayOfMonth&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;Month&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;DayOfWeek&amp;gt;[^\\s]+)\\s+"+
 "(?P&amp;lt;Command&amp;gt;.+)$"]) as Record

 /* Read lines from the file and filter ones that start with "#" */
 FROM split_records(
 filenames=OSPath,
 regex="\n", columns=["data"]) WHERE not data =~ "^\\s*#"
 }) WHERE Record.Command

 SELECT Record.Event AS Event,
 Mtime,
 Name AS User,
 Record.Minute AS Minute,
 Record.Hour AS Hour,
 Record.DayOfMonth AS DayOfMonth,
 Record.Month AS Month,
 Record.DayOfWeek AS DayOfWeek,
 Record.Command AS Command,
 OSPath AS Path,
 Upload
 FROM raw

- name: LaunchAgentsDaemons
 query: |

 LET launchd_config = SELECT OSPath, Mtime,
 plist(file=OSPath) AS LaunchdConfig,
 upload(file=OSPath) AS Upload
 FROM glob(globs=parse_json_array(data=LaunchAgentsDaemonsGlob))

 LET programs = SELECT OSPath, Mtime, LaunchdConfig,
 get(member="LaunchdConfig.Program",
 default=get(member="LaunchdConfig.ProgramArguments.0")) AS Program
 FROM launchd_config

 SELECT OSPath, Mtime, LaunchdConfig,
 Program, hash(path=Program) AS Hash,
 upload(file=OSPath) AS Upload
 FROM programs

- name: ScriptingAdditions
 query: |
 SELECT OSPath,
 Mtime,
 upload(file=OSPath) AS Upload
 FROM glob(globs=parse_json_array(data=ScriptingAdditionsGlobs))

- name: StartupItems
 query: |
 SELECT OSPath,
 Mtime,
 upload(file=OSPath) AS Upload
 FROM glob(globs=parse_json_array(data=StartupItemsGlobs))

- name: MiscItems
 query: |
 SELECT OSPath,
 Mtime,
 upload(file=OSPath) AS Upload
 FROM glob(globs=parse_json_array(data=MiscItemsGlobs))

- name: LoginItems
 query: |
 SELECT OSPath,
 Mtime,
 plist(file=OSPath) AS LoginItemConfig,
 upload(file=OSPath) AS Upload
 FROM glob(globs=parse_json_array(data=LoginItemsGlobs))

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Detection.InstallHistory</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.detection.installhistory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.detection.installhistory/</guid><description>&lt;p>This artifact collects entries from the InstallHistory .plist file&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Detection.InstallHistory
description: |
 This artifact collects entries from the InstallHistory .plist file

type: CLIENT

author: Wes Lambert - @therealwlambert

precondition: SELECT OS FROM info() WHERE OS =~ 'darwin'

parameters:
- name: InstallHistoryGlob
 default: /Library/Receipts/InstallHistory.plist

sources:
- name: Install History
 query: |
 LET SWplist = SELECT OSPath FROM glob(globs=InstallHistoryGlob)

 LET SoftwareDetails =
 SELECT * FROM foreach(
 row=plist(file=OSPath),
 query={
 SELECT
 get(member="displayName", default="") AS DisplayName,
 get(member="displayVersion", default="") AS DisplayVersion,
 get(member="processName", default="") AS ProcessName,
 get(member="date", default="") AS InstallDate,
 get(member="contentType", default="") AS ContentType,
 get(member="packageIdentifiers", default="") AS PackageIdentifiers
 FROM scope()
 })
 SELECT * FROM foreach(row=SWplist, query=SoftwareDetails)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Detection.Yara.Glob</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.detection.yara.glob/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.detection.yara.glob/</guid><description>&lt;p>This artifact returns a list of target files then runs YARA over the target
list.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>Url link to a YARA rule.&lt;/li>
&lt;li>or a Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above.&lt;/p>
&lt;p>The artifact uses Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with YARA hits.&lt;/p>
&lt;p>Some examples of path glob may include:&lt;/p>
&lt;ul>
&lt;li>Specific binary: &lt;code>/usr/bin/ls&lt;/code>&lt;/li>
&lt;li>Wildcards: &lt;code>/var/www/*.js&lt;/code>&lt;/li>
&lt;li>More wildcards: &lt;code>/var/www/**/*.js&lt;/code>&lt;/li>
&lt;li>Multiple extensions: &lt;code>/var/www/*\.{php,aspx,js,html}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:/Users/**/*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:\Users\**\*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
 This artifact returns a list of target files then runs YARA over the target
 list.

 There are 2 kinds of YARA rules that can be deployed:

 1. Url link to a YARA rule.
 2. or a Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above.

 The artifact uses Glob for search so relevant filters can be applied
 including Glob, Size and date. Date filters will target files with a timestamp
 before LatestTime and after EarliestTime. The artifact also has an option to
 upload any files with YARA hits.

 Some examples of path glob may include:

 * Specific binary: `/usr/bin/ls`
 * Wildcards: `/var/www/*.js`
 * More wildcards: `/var/www/**/*.js`
 * Multiple extensions: `/var/www/*\.{php,aspx,js,html}`
 * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
 * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

 NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
 This will NOT follow any symlinks and may cause unexpected results if
 unknowingly targeting a folder with symlinks.
 If upload is selected NumberOfHits is redundant and not advised as hits are
 grouped by path to ensure files only downloaded once.

aliases:
 - Windows.Detection.Yara.Glob
 - Linux.Detection.Yara.Glob
 - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
 - name: PathGlob
 description: Only file names that match this glob will be scanned.
 default: /usr/bin/ls
 - name: SizeMax
 description: maximum size of target file.
 type: int64
 - name: SizeMin
 description: minimum size of target file.
 type: int64
 - name: UploadHits
 type: bool
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: YaraUrl
 description: If configured will attempt to download Yara rules form Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule IsELF:TestRule {
 meta:
 author = "the internet"
 date = "2021-05-03"
 description = "A simple ELF rule to test yara features"
 condition:
 uint32(0) == 0x464c457f
 }
 - name: NumberOfHits
 description: This artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int

sources:
 - query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- time testing
 LET time_test(stamp) =
 if(condition= DateBefore AND DateAfter,
 then= stamp &amp;lt; DateBefore AND stamp &amp;gt; DateAfter,
 else=
 if(condition=DateBefore,
 then= stamp &amp;lt; DateBefore,
 else=
 if(condition= DateAfter,
 then= stamp &amp;gt; DateAfter,
 else= True
 )))

 -- first find all matching glob
 LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
 FROM glob(globs=PathGlob,nosymlink='True')
 WHERE
 NOT IsDir AND NOT IsLink
 AND if(condition=SizeMin,
 then= SizeMin &amp;lt; Size,
 else= True)
 AND if(condition=SizeMax,
 then=SizeMax &amp;gt; Size,
 else= True)
 AND
 ( time_test(stamp=Mtime)
 OR time_test(stamp=Atime)
 OR time_test(stamp=Ctime)
 OR time_test(stamp=Btime))

 -- scan files and prepare hit metadata
 LET hits = SELECT * FROM foreach(row=files,
 query={
 SELECT
 OSPath,
 File.Size as Size,
 Mtime, Atime, Ctime, Btime,
 Rule, Tags, Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 upload( accessor='scope',
 file='String.Data',
 name=format(format="%v-%v-%v",
 args=[
 OSPath,
 if(condition= String.Offset - ContextBytes &amp;lt; 0,
 then= 0,
 else= String.Offset - ContextBytes),
 if(condition= String.Offset + ContextBytes &amp;gt; Size,
 then= Size,
 else= String.Offset + ContextBytes) ]
 )) as HitContext
 FROM yara(rules=yara_rules,files=OSPath,
 context=ContextBytes,number=NumberOfHits)
 })

 -- upload files if selected
 LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

 -- return rows
 SELECT * FROM if(condition= UploadHits,
 then= upload_hits,
 else= hits )

column_types:
 - name: HitContext
 type: preview_upload
&lt;/code>&lt;/pre></description></item><item><title>MacOS.Detection.Yara.Process</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.detection.yara.process/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.detection.yara.process/</guid><description>&lt;p>This artifact enables running YARA over processes in memory.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>Url link to a YARA rule.&lt;/li>
&lt;li>A Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above. The
default is Cobalt Strike opcodes.&lt;/p>
&lt;p>Regex parameters can be applied for process name and pid for targeting. The
artifact also has an option to upload any process with YARA hits.&lt;/p>
&lt;p>Note: the YARA scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Detection.Yara.Process
author: Matt Green - @mgreen27
description: |
 This artifact enables running YARA over processes in memory.

 There are 2 kinds of YARA rules that can be deployed:

 1. Url link to a YARA rule.
 2. A Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above. The
 default is Cobalt Strike opcodes.

 Regex parameters can be applied for process name and pid for targeting. The
 artifact also has an option to upload any process with YARA hits.

 Note: the YARA scan will stop after one hit. Multi-string rules will also only
 show one string in returned rows.

aliases:
- MacOS.Detection.Yara.Process

type: CLIENT
parameters:
 - name: ProcessRegex
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: UploadHits
 type: bool
 - name: YaraUrl
 description: If configured will attempt to download Yara rules from Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule keyword_search {
 strings:
 $a = "velociraptor" ascii

 condition:
 any of them
 }
 - name: NumberOfHits
 description: THis artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int
 - name: ExePathWhitelist
 description: Regex of ProcessPaths to exclude
 type: regex


sources:
 - precondition:
 SELECT OS From info() where OS = 'linux' OR OS = 'darwin'

 query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- find velociraptor process
 LET me = SELECT Pid FROM pslist(pid=getpid())

 -- find all processes and add filters
 LET processes = SELECT
 Name as ProcessName,
 CommandLine, Pid
 FROM pslist()
 WHERE
 Name =~ ProcessRegex
 AND format(format="%d", args=Pid) =~ PidRegex
 AND NOT Pid in me.Pid
 AND NOT if(condition=ExePathWhitelist,
 then= Exe=~ExePathWhitelist)
 AND log(message=format(format="Scanning pid %v: %v", args=[
 Pid, CommandLine]))

 -- scan processes in scope with our rule, limit 1 hit
 LET hits = SELECT * FROM foreach(
 row=processes,
 query={
 SELECT
 ProcessName,
 CommandLine,
 Pid,
 Rule,
 Tag,
 Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 if(condition=String.Data,
 then=upload(
 accessor='scope',
 file='String.Data',
 name=format(format="%v-%v_%v_%v",
 args=[ ProcessName, Pid, String.Offset, ContextBytes ]
 ))) as HitContext
 FROM proc_yara(
 pid=Pid,
 rules=yara_rules,
 context=ContextBytes,
 number=NumberOfHits
 )
 })

 -- upload hits using the process accessor
 LET upload_hits = SELECT *,
 upload(
 accessor="process",
 file=format(format="/%v", args=Pid),
 name=pathspec(Path=format(format='%v-%v.dmp',
 args= [ ProcessName, Pid ]))) as ProcessDump
 FROM hits
 WHERE log(message=format(format='Will upload %v: %v', args=[Pid, ProcessName]))

 -- return rows
 SELECT * FROM if(condition=UploadHits,
 then=upload_hits,
 else=hits)

column_types:
 - name: HitContext
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Forensics.AppleDoubleZip</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.forensics.appledoublezip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.forensics.appledoublezip/</guid><description>&lt;p>Search for zip files containing leaked download URLs included by
MacOS users.&lt;/p>
&lt;p>MacOS filesystem can represent extended attributes. Similarly to
Windows&amp;rsquo;s ZoneIdentifier, when a file is downloaded on MacOS it also
receives an extended attribute recording where the file was
downloaded from. (See the &lt;code>Windows.Analysis.EvidenceOfDownload&lt;/code>
artifact)&lt;/p>
&lt;p>What makes MacOS different however, is that when a user adds a file
to a Zip file (in Finder, right click the file and select
&amp;ldquo;compress&amp;rdquo;), MacOS will also record the extended attributes in the
zip file under the __MACOSX folder.&lt;/p>
&lt;p>This is a huge privacy leak because people often do not realize that
the source of downloads for a file is being included inside the zip
file, which they end up sending to other people!&lt;/p>
&lt;p>Therefore this artifact can also work on other platforms because Zip
files created by MacOS users can end up on other systems, and
contain sensitive URLs embedded within them.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Forensics.AppleDoubleZip
description: |
 Search for zip files containing leaked download URLs included by
 MacOS users.

 MacOS filesystem can represent extended attributes. Similarly to
 Windows's ZoneIdentifier, when a file is downloaded on MacOS it also
 receives an extended attribute recording where the file was
 downloaded from. (See the `Windows.Analysis.EvidenceOfDownload`
 artifact)

 What makes MacOS different however, is that when a user adds a file
 to a Zip file (in Finder, right click the file and select
 "compress"), MacOS will also record the extended attributes in the
 zip file under the __MACOSX folder.

 This is a huge privacy leak because people often do not realize that
 the source of downloads for a file is being included inside the zip
 file, which they end up sending to other people!

 Therefore this artifact can also work on other platforms because Zip
 files created by MacOS users can end up on other systems, and
 contain sensitive URLs embedded within them.

reference:
 - https://opensource.apple.com/source/Libc/Libc-391/darwin/copyfile.c
 - https://datatracker.ietf.org/doc/html/rfc1740

parameters:
 - name: ZipGlob
 description: Where to search for zip files.
 default: /Users/*/Downloads/*.zip

export: |
 -- Offsets are aligned to 4 bytes
 LET Align(value) = value + value - int(int=value / 4) * 4

 LET Profile = '''[
 ["Header", 0, [
 ["Magic", 0, "uint32b"],
 ["Version", 4, "uint32b"],
 ["Filler", 8, "String", {
 length: 16,
 }],
 ["Count", 24, "uint16b"],
 ["Items", 26, "Array", {
 count: "x=&amp;gt;x.Count",
 type: "Entry",
 }],
 ["attr_header", 84, "attr_header"]
 ]],
 ["Entry", 12, [
 ["ID", 0, "uint32b"],
 ["Offset", 4, "uint32b"],
 ["Length", 8, "uint32b"],
 ["Value", 0, "Profile", {
 type: "ASFinderInfo",
 offset: "x=&amp;gt;x.Offset",
 }]
 ]],
 ["attr_header", 0, [

 # Should be ATTR
 ["Magic", 0, "String", {
 length: 4,
 }],

 ["total_size", 8, "uint32b"],
 ["data_start", 12, "uint32b"],
 ["data_length",16, "uint32b"],
 ["flags", 32, "uint16b"],
 ["num_attr", 34, "uint16b"],
 ["attrs", 36, "Array", {
 count: "x=&amp;gt;x.num_attr",
 type: "attr_t",
 }]
 ]],
 ["attr_t", "x=&amp;gt;Align(value=x.name_length + 11)", [
 ["offset", 0, "uint32b"],
 ["length", 4, "uint32b"],
 ["flags", 8, "uint16b"],
 ["name_length", 10, "uint8"],
 ["name", 11, "String", {
 length: "x=&amp;gt;x.name_length",
 }],
 ["data", 0, "Profile", {
 type: "String",
 type_options: {
 term: "",
 length: "x=&amp;gt;x.length",
 },
 offset: "x=&amp;gt;x.offset",
 }]
 ]]
 ]
 '''

 LET ParseData(data) = if(condition=data =~ "^bplist",
 then=plist(accessor="data", file=data), else=data)

 LET ParseAppleDouble(double_data) = SELECT name AS Key, ParseData(data=data) AS Value
 FROM foreach(row=parse_binary(
 filename=double_data, accessor="data",
 profile=Profile, struct="Header").attr_header.attrs)

sources:
 - query: |
 LET DoubleFiles = SELECT * FROM foreach(row={
 SELECT OSPath AS ZipPath
 FROM glob(globs=ZipGlob)
 }, query={
 SELECT OSPath, pathspec(parse=OSPath) AS PathSpec
 FROM glob(
 globs="__MACOSX/**",
 accessor="zip",
 root=pathspec(DelegatePath=ZipPath))
 })

 SELECT * FROM foreach(row=DoubleFiles,
 query={
 SELECT PathSpec.DelegatePath AS ZipFile,
 PathSpec.Path AS Member,
 Key, Value
 FROM ParseAppleDouble(double_data=read_file(filename=OSPath, accessor="zip"))
 })

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Forensics.FSEvents</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.forensics.fsevents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.forensics.fsevents/</guid><description>&lt;p>This artifact parses the FSEvents log files.&lt;/p>
&lt;p>We can filter on Path, Flags or use time box on source file.&lt;/p>
&lt;p>An interesting hunt may be filter for Entries of plist files modified or
created on a specific date. Malware often creates plist files in
/Library/LaunchAgents, Library/Preferences, /Library/LaunchDaemons, or
/Library/Internet Plugins.&lt;/p>
&lt;h4 id="notes">NOTES&lt;/h4>
&lt;ul>
&lt;li>FSEvents do not have timestamps so we specify source file Mtime and
Btime.&lt;/li>
&lt;li>The default timeout is only 600 seconds - you will probably need to
increase it to allow the collection to finish.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Forensics.FSEvents
description: |
 This artifact parses the FSEvents log files.

 We can filter on Path, Flags or use time box on source file.

 An interesting hunt may be filter for Entries of plist files modified or
 created on a specific date. Malware often creates plist files in
 /Library/LaunchAgents, Library/Preferences, /Library/LaunchDaemons, or
 /Library/Internet Plugins.

 #### NOTES

 - FSEvents do not have timestamps so we specify source file Mtime and
 Btime.
 - The default timeout is only 600 seconds - you will probably need to
 increase it to allow the collection to finish.

author: |
 Mike Cohen, Matt Green - @mgreen27, Yogesh Khatri (@swiftforensics), CyberCX

reference:
- https://www.osdfcon.org/presentations/2017/Ibrahim-Understanding-MacOS-File-Ststem-Events-with-FSEvents-Parser.pdf
- https://www.crowdstrike.com/blog/using-os-x-fsevents-discover-deleted-malicious-artifact/

type: CLIENT

parameters:
 - name: GlobTable
 type: csv
 default: |
 Glob
 /.fseventsd/*
 /System/Volumes/Data/.fseventsd/*
 - name: Glob
 type: string
 description: Instead of providing the globs in a table, a single glob may be given.
 - name: PathRegex
 description: Filter the path by this regexp
 default: .
 type: regex
 - name: FlagsRegex
 description: Filter by flags
 type: regex
 default: .
 - name: DateAfter
 type: timestamp
 description: "search for source files with Btime after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for source files with Mtime before this date. YYYY-MM-DDTmm:hh:ssZ"

export: |
 LET FSEventProfile = '''[
 ["FSEventsProfile", 0, [
 ["Entries", 0, "Array", {
 type: "Header",
 count: 10000,
 }],
 ]],
 ["Header", "x=&amp;gt;x.Info.StreamSize", [
 ["Version", 0, "Enumeration", {
 type: "unsigned int",
 choices: {
 "1145852721": "V1",
 "1145852722": "V2",
 "1145852723": "V3"
 }
 }],
 ["Info", 8, "Union", {
 selector: "x=&amp;gt;x.Version",
 choices: {
 "V1": "FS1",
 "V2": "FS2",
 "V3": "FS3",
 }
 }],
 ]],
 ["FS1", "x=&amp;gt;x.StreamSize - 8", [
 ["StreamSize", 0, uint32],
 ["Items", 4, "Array", {
 count: 10000,
 max_count: 10000,
 type: FSEventEntry1,
 sentinel: "x=&amp;gt;this.EndOf &amp;lt; x.EndOf",
 }],
 ]],
 ["FS2", "x=&amp;gt;x.StreamSize - 8", [
 ["StreamSize", 0, uint32],
 ["Items", 4, "Array", {
 count: 10000,
 max_count: 10000,
 type: FSEventEntry2,
 sentinel: "x=&amp;gt;this.EndOf &amp;lt; x.EndOf",
 }],
 ]],
 ["FS3", "x=&amp;gt;x.StreamSize - 8", [
 ["StreamSize", 0, uint32],
 ["Items", 4, "Array", {
 count: 10000,
 max_count: 2336,
 type: FSEventEntry3,
 sentinel: "x=&amp;gt;this.EndOf &amp;lt; x.EndOf",
 }],
 ]],
 ["FSEventEntry1", "x=&amp;gt;len(list=x.path) + 13", [
 ["path", 0, "String"],
 ["id", "x=&amp;gt;len(list=x.path) + 1", "uint64"],
 ["flags", "x=&amp;gt;len(list=x.path) + 9", "Flags", {
 type: "uint32",
 bitmap: {
 FSE_CREATE_FILE: 0,
 FSE_DELETE: 1,
 FSE_STAT_CHANGED: 2,
 FSE_RENAME: 3,
 FSE_CONTENT_MODIFIED: 4,
 FSE_EXCHANGE: 5,
 FSE_FINDER_INFO_CHANGED: 6,
 FSE_CREATE_DIR: 7,
 FSE_CHOWN: 8,
 FSE_XATTR_MODIFIED: 9,
 FSE_XATTR_REMOVED: 10,
 FSE_DOCID_CREATED: 11,
 FSE_DOCID_CHANGED: 12,
 FSE_UNMOUNT_PENDING: 13,
 FSE_CLONE: 14,
 FSE_MODE_CLONE: 16,
 FSE_TRUNCATED_PATH: 17,
 FSE_REMOTE_DIR_EVENT: 18,
 FSE_MODE_LAST_HLINK: 19,
 FSE_MODE_HLINK: 20,
 IsSymbolicLink: 22,
 IsFile: 23,
 IsDirectory: 24,
 Mount: 25,
 Unmount: 26,
 EndOfTransaction: 29
 }
 }],
 ["file_id", 0, "Value", {"value": ""}],
 ]],
 ["FSEventEntry2", "x=&amp;gt;len(list=x.path) + 21", [
 ["path", 0, "String"],
 ["id", "x=&amp;gt;len(list=x.path) + 1", "uint64"],
 ["flags", "x=&amp;gt;len(list=x.path) + 9", "Flags", {
 type: "uint32",
 bitmap: {
 FSE_CREATE_FILE: 0,
 FSE_DELETE: 1,
 FSE_STAT_CHANGED: 2,
 FSE_RENAME: 3,
 FSE_CONTENT_MODIFIED: 4,
 FSE_EXCHANGE: 5,
 FSE_FINDER_INFO_CHANGED: 6,
 FSE_CREATE_DIR: 7,
 FSE_CHOWN: 8,
 FSE_XATTR_MODIFIED: 9,
 FSE_XATTR_REMOVED: 10,
 FSE_DOCID_CREATED: 11,
 FSE_DOCID_CHANGED: 12,
 FSE_UNMOUNT_PENDING: 13,
 FSE_CLONE: 14,
 FSE_MODE_CLONE: 16,
 FSE_TRUNCATED_PATH: 17,
 FSE_REMOTE_DIR_EVENT: 18,
 FSE_MODE_LAST_HLINK: 19,
 FSE_MODE_HLINK: 20,
 IsSymbolicLink: 22,
 IsFile: 23,
 IsDirectory: 24,
 Mount: 25,
 Unmount: 26,
 EndOfTransaction: 29
 }
 }],
 ["file_id", "x=&amp;gt;len(list=x.path) + 13", "int64"],
 ]],
 ["FSEventEntry3", "x=&amp;gt;len(list=x.path) + 25", [
 ["path", 0, "String"],
 ["id", "x=&amp;gt;len(list=x.path) + 1", "uint64"],
 ["flags", "x=&amp;gt;len(list=x.path) + 9", "Flags", {
 type: "uint32",
 bitmap: {
 FSE_CREATE_FILE: 0,
 FSE_DELETE: 1,
 FSE_STAT_CHANGED: 2,
 FSE_RENAME: 3,
 FSE_CONTENT_MODIFIED: 4,
 FSE_EXCHANGE: 5,
 FSE_FINDER_INFO_CHANGED: 6,
 FSE_CREATE_DIR: 7,
 FSE_CHOWN: 8,
 FSE_XATTR_MODIFIED: 9,
 FSE_XATTR_REMOVED: 10,
 FSE_DOCID_CREATED: 11,
 FSE_DOCID_CHANGED: 12,
 FSE_UNMOUNT_PENDING: 13,
 FSE_CLONE: 14,
 FSE_MODE_CLONE: 16,
 FSE_TRUNCATED_PATH: 17,
 FSE_REMOTE_DIR_EVENT: 18,
 FSE_MODE_LAST_HLINK: 19,
 FSE_MODE_HLINK: 20,
 IsSymbolicLink: 22,
 IsFile: 23,
 IsDirectory: 24,
 Mount: 25,
 Unmount: 26,
 EndOfTransaction: 29
 }
 }],
 ["file_id", "x=&amp;gt;len(list=x.path) + 13", "int64"],
 ["unknown_id", "x=&amp;gt;len(list=x.path) + 21", "int32"],
 ]],
 ]'''

sources:
 - query: |
 LET files = SELECT OSPath, Mtime, Btime
 FROM glob(globs=(Glob || GlobTable.Glob))
 WHERE if(condition=DateAfter, then= Btime &amp;gt; DateAfter, else= True )
 AND if(condition=DateBefore, then= Mtime &amp;lt; DateBefore, else= True )
 AND log(message=OSPath)

 LET x = SELECT * FROM foreach(row=files,
 query={
 SELECT
 Version,
 Info.Items as items,
 OSPath.Basename as SourceFile,
 Mtime as SourceMtime,
 Btime as SourceBtime
 FROM
 foreach(row=parse_binary(
 filename=read_file(filename=OSPath, accessor="gzip", length=1000000),
 accessor="data",
 profile=FSEventProfile, struct="FSEventsProfile").Entries)
 })
 WHERE EntryPath =~ PathRegex AND EntryFlags =~ FlagsRegex

 SELECT
 items.path as EntryPath,
 items.id as EntryId,
 join(array=items.flags, sep=", ") AS EntryFlags,
 items.file_id as FileId,
 SourceFile,
 SourceMtime,
 SourceBtime,
 Version
 FROM
 flatten(query=x)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Network.Netstat</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.network.netstat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.network.netstat/</guid><description>&lt;p>Report network connections, and enrich with process information.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Network.Netstat
description: |
 Report network connections, and enrich with process information.

type: CLIENT

precondition:
 SELECT OS From info() where OS = 'darwin'

parameters:
 - name: IPRegex
 description: "regex search over IP address fields."
 default: "."
 type: regex
 - name: PortRegex
 description: "regex search over port fields."
 default: "."
 type: regex
 - name: ProcessNameRegex
 description: "regex search over source process name"
 default: "."
 type: regex
 - name: UsernameRegex
 description: "regex search over source process user context"
 default: "."
 type: regex
 - name: ConnectionStatusRegex
 description: "regex search over connection status"
 default: "LISTEN|ESTAB"
 type: regex
 - name: ProcessPathRegex
 description: "regex search over source process path"
 default: "."
 type: regex
 - name: CommandLineRegex
 description: "regex search over source process commandline"
 default: "."
 type: regex
 - name: CallChainRegex
 description: "regex search over the process callchain"
 default: "."
 type: regex
 - name: AlsoCollectFullProcessTree
 type: bool

sources:
 - query: |
 SELECT Laddr.IP AS Laddr,
 Laddr.Port AS Lport,
 Raddr.IP AS Raddr,
 Raddr.Port AS Rport,
 Pid,
 Status, TypeString AS Type,
 process_tracker_get(id=Pid).Data AS ProcInfo,
 join(array=process_tracker_callchain(id=Pid).Data.Name,
 sep=" -&amp;gt; ") AS CallChain,
 if(condition=AlsoCollectFullProcessTree,
 then=process_tracker_tree(id=Pid)) AS ChildrenTree
 FROM netstat()
 WHERE Status =~ ConnectionStatusRegex
 AND Raddr =~ IPRegex
 AND ( Lport =~ PortRegex OR Rport =~ PortRegex )
 AND ProcInfo.Name =~ ProcessNameRegex
 AND ProcInfo.Username =~ UsernameRegex
 AND ProcInfo.Exe =~ ProcessPathRegex
 AND ProcInfo.CommandLine =~ CommandLineRegex
 AND CallChain =~ CallChainRegex

column_types:
 - name: ChildrenTree
 type: tree

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Network.PacketCapture</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.network.packetcapture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.network.packetcapture/</guid><description>&lt;p>This artifact uses tcpdump to natively capture packets.&lt;/p>
&lt;p>The &lt;code>Duration&lt;/code> parameter is used to define how long (in seconds) the capture should be. Specific interfaces can be defined by using the &lt;code>Interface&lt;/code> parameter, otherwise the artifact defaults to an interface assignment of &lt;code>any&lt;/code>.&lt;/p>
&lt;p>A &lt;code>BPF&lt;/code> (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.&lt;/p>
&lt;p>Read more about BPF expressions here: &lt;a href="https://biot.com/capstats/bpf.html" target="_blank" >https://biot.com/capstats/bpf.html&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Network.PacketCapture
author: Wes Lambert, @therealwlambert
description: |
 This artifact uses tcpdump to natively capture packets.

 The `Duration` parameter is used to define how long (in seconds) the capture should be. Specific interfaces can be defined by using the `Interface` parameter, otherwise the artifact defaults to an interface assignment of `any`.

 A `BPF` (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.

 Read more about BPF expressions here: https://biot.com/capstats/bpf.html

required_permissions:
 - EXECVE

implied_permissions:
 - FILESYSTEM_WRITE

parameters:
 - name: Duration
 type: integer
 description: Duration (in seconds) of PCAP to be recorded.
 default: 10

 - name: Interface
 type: string
 default: any

 - name: BPF
 type: string
 default:

precondition:
 SELECT * FROM info() where OS = 'darwin'

sources:
 - query: |
 LET pcap &amp;lt;= tempfile(extension=".pcap")
 SELECT *, upload(file=pcap) AS PCAP
 FROM execve(argv=['bash', '-c', format(format='''(tcpdump -nni %v -w %v %v) &amp;amp; sleep %v; kill $!''', args=[Interface, pcap, BPF, Duration])], length=1000000)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.OSQuery.Generic</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.osquery.generic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.osquery.generic/</guid><description>&lt;p>OSQuery is an excellent tool for querying system state across the
three supported Velociraptor platform (Windows/Linux/MacOS).&lt;/p>
&lt;p>You can read more about OSQuery on &lt;a href="https://osquery.io/" target="_blank" >https://osquery.io/&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.OSQuery.Generic
description: |
 OSQuery is an excellent tool for querying system state across the
 three supported Velociraptor platform (Windows/Linux/MacOS).

 You can read more about OSQuery on https://osquery.io/

reference:
 - https://osquery.io/
 - https://github.com/osquery/osquery

# I am not actually sure if OSQuery allows arbitrary command execution via SQL?
required_permissions:
 - EXECVE

precondition: SELECT OS From info() where OS = 'darwin'

tools:
 - name: OSQueryDarwin
 github_project: Velocidex/OSQuery-Releases
 github_asset_regex: darwin-amd64

parameters:
 - name: Query
 default: "SELECT * FROM osquery_info"

sources:
 - query: |
 LET binary &amp;lt;= SELECT OSPath
 FROM Artifact.Generic.Utils.FetchBinary(ToolName="OSQueryDarwin")

 LET result = SELECT * FROM execve(
 argv=[binary[0].OSPath, "--json", Query],
 length=1000000)

 SELECT * FROM foreach(row=result,
 query={
 SELECT * FROM parse_json_array(data=Stdout)
 })

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Search.FileFinder</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.search.filefinder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.search.filefinder/</guid><description>&lt;p>Find files on the filesystem using the filename or content.&lt;/p>
&lt;h2 id="performance-note">Performance Note&lt;/h2>
&lt;p>This artifact can be quite expensive, especially if we search file
content. It will require opening each file and reading its entire
content. To minimize the impact on the endpoint we recommend this
artifact is collected with a rate limited way (about 20-50 ops per
second).&lt;/p>
&lt;p>This artifact is useful in the following scenarios:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>We need to locate all the places on our network where customer
data has been copied.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We’ve identified malware in a data breach, named using short
random strings in specific folders and need to search for other
instances across the network.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We believe our user account credentials have been dumped and
need to locate them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We need to search for exposed credit card data to satisfy PCI
requirements.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We have a sample of data that has been disclosed and need to
locate other similar files&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.Search.FileFinder
description: |
 Find files on the filesystem using the filename or content.


 ## Performance Note

 This artifact can be quite expensive, especially if we search file
 content. It will require opening each file and reading its entire
 content. To minimize the impact on the endpoint we recommend this
 artifact is collected with a rate limited way (about 20-50 ops per
 second).

 This artifact is useful in the following scenarios:

 * We need to locate all the places on our network where customer
 data has been copied.

 * We’ve identified malware in a data breach, named using short
 random strings in specific folders and need to search for other
 instances across the network.

 * We believe our user account credentials have been dumped and
 need to locate them.

 * We need to search for exposed credit card data to satisfy PCI
 requirements.

 * We have a sample of data that has been disclosed and need to
 locate other similar files


precondition:
 SELECT * FROM info() where OS = 'darwin'

parameters:
 - name: SearchFilesGlob
 default: /Users/*
 description: Use a glob to define the files that will be searched (Use ** for recursive).

 - name: SearchFilesGlobTable
 type: csv
 default: |
 Glob
 /Users/someuser/*
 description: Alternative specify multiple globs in a table

 - name: YaraRule
 type: yara
 default:
 description: A yara rule to search for matching files.

 - name: Fetch_Xattr
 default: N
 type: bool

 - name: Upload_File
 default: N
 type: bool

 - name: Calculate_Hash
 default: N
 type: bool

 - name: MoreRecentThan
 default: ""
 type: timestamp

 - name: ModifiedBefore
 default: ""
 type: timestamp

 - name: DoNotFollowSymlinks
 type: bool
 default: Y
 description: If specified we are allowed to follow symlinks while globbing

 - name: UPLOAD_IS_RESUMABLE
 type: bool
 default: Y
 description: If set the uploads can be resumed if the flow times out or errors.

sources:
- query: |
 LET file_search = SELECT OSPath,
 Sys.mft as Inode,
 Mode.String AS Mode, Size,
 Mtime AS MTime,
 Atime AS ATime,
 Ctime AS CTime,
 Btime AS BTime,
 IsDir, Mode
 FROM glob(globs=SearchFilesGlobTable.Glob + SearchFilesGlob,
 accessor="file", nosymlink=DoNotFollowSymlinks)

 LET more_recent = SELECT * FROM if(
 condition=MoreRecentThan,
 then={
 SELECT * FROM file_search
 WHERE MTime &amp;gt; MoreRecentThan
 },
 else={ SELECT * FROM file_search})

 LET modified_before = SELECT * FROM if(
 condition=ModifiedBefore,
 then={
 SELECT * FROM more_recent
 WHERE MTime &amp;lt; ModifiedBefore
 AND MTime &amp;gt; MoreRecentThan
 },
 else={SELECT * FROM more_recent})

 LET keyword_search = SELECT * FROM if(
 condition=YaraRule,
 then={
 SELECT * FROM foreach(
 row={
 SELECT * FROM modified_before
 WHERE Mode.IsRegular
 },
 query={
 SELECT OSPath, Inode, Mode,
 Size, ATime, MTime, CTime, BTime,
 str(str=String.Data) As Keywords

 FROM yara(files=OSPath,
 key="A",
 rules=YaraRule,
 accessor="file")
 })
 },
 else={SELECT * FROM modified_before})

 SELECT OSPath, Inode, Mode, Size, ATime,
 MTime, CTime, BTime, get(field='Keywords') AS Keywords,
 if(condition=Upload_File and Mode.IsRegular,
 then=upload(file=OSPath,
 accessor="file")) AS Upload,
 if(condition=Fetch_Xattr,
 then=xattr(filename=OSPath,
 accessor="file")) AS XAttr,
 if(condition=Calculate_Hash and Mode.IsRegular,
 then=hash(path=OSPath,
 accessor="file")) AS Hash
 FROM keyword_search

column_types:
 - name: ATime
 type: timestamp
 - name: MTime
 type: timestamp
 - name: CTime
 type: timestamp
 - name: BTime
 type: timestamp
 - name: Upload
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Sys.Pslist</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.sys.pslist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.sys.pslist/</guid><description>&lt;p>List processes and their running binaries.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.Pslist
description: |
 List processes and their running binaries.

aliases:
 - MacOS.Sys.Pslist

parameters:
 - name: processRegex
 default: .
 type: regex

precondition: |
 SELECT OS From info() where OS =~ 'linux|darwin'

sources:
 - query: |
 SELECT Pid, Ppid, Name, CommandLine, Exe,
 hash(path=Exe) as Hash,
 Username, timestamp(epoch=CreateTime/1000) AS CreatedTime,
 MemoryInfo.RSS AS RSS,
 Exe =~ "\\(deleted\\)$" AS Deleted
 FROM process_tracker_pslist()
 WHERE Name =~ processRegex

&lt;/code>&lt;/pre></description></item><item><title>MacOS.Sys.SUID</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.sys.suid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.sys.suid/</guid><description>&lt;p>Searches for applications that have the &lt;code>setuid&lt;/code> or &lt;code>setgid&lt;/code> bits set.&lt;/p>
&lt;p>When the &lt;code>setuid&lt;/code> or &lt;code>setgid&lt;/code> bits are set on Linux or macOS for an
application, this means that the application will run with the
privileges of the owning user or group respectively. Normally an
application is run in the current user’s context, regardless of
which user or group owns the application. There are instances where
programs need to be executed in an elevated context to function
properly, but the user running them doesn’t need the elevated
privileges. Instead of creating an entry in the &lt;code>sudoers&lt;/code> file, which
must be done by root, any user can specify the &lt;code>setuid&lt;/code> or &lt;code>setgid&lt;/code> flag
to be set for their own applications. These bits are indicated with
an &amp;ldquo;s&amp;rdquo; instead of an &amp;ldquo;x&amp;rdquo; when viewing a file&amp;rsquo;s attributes via &lt;code>ls -l&lt;/code>. The &lt;code>chmod&lt;/code> program can set these bits with via bitmasking, &lt;code>chmod 4777 [file]&lt;/code> or via shorthand naming, &lt;code>chmod u+s [file]&lt;/code>.&lt;/p>
&lt;p>An adversary can take advantage of this to either do a shell escape
or exploit a vulnerability in an application with the setsuid or
setgid bits to get code running in a different user&amp;rsquo;s
context. Additionally, adversaries can use this mechanism on their
own malware to ensure that they&amp;rsquo;re able to execute in elevated
contexts in the future.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Linux.Sys.SUID
aliases:
 - MacOS.Sys.SUID
description: |
 Searches for applications that have the `setuid` or `setgid` bits set.

 When the `setuid` or `setgid` bits are set on Linux or macOS for an
 application, this means that the application will run with the
 privileges of the owning user or group respectively. Normally an
 application is run in the current user’s context, regardless of
 which user or group owns the application. There are instances where
 programs need to be executed in an elevated context to function
 properly, but the user running them doesn’t need the elevated
 privileges. Instead of creating an entry in the `sudoers` file, which
 must be done by root, any user can specify the `setuid` or `setgid` flag
 to be set for their own applications. These bits are indicated with
 an "s" instead of an "x" when viewing a file's attributes via `ls
 -l`. The `chmod` program can set these bits with via bitmasking, `chmod
 4777 [file]` or via shorthand naming, `chmod u+s [file]`.

 An adversary can take advantage of this to either do a shell escape
 or exploit a vulnerability in an application with the setsuid or
 setgid bits to get code running in a different user's
 context. Additionally, adversaries can use this mechanism on their
 own malware to ensure that they're able to execute in elevated
 contexts in the future.

reference:
 - https://attack.mitre.org/techniques/T1166/

parameters:
 - name: GlobExpression
 default: /usr/**

sources:
 - query: |
 SELECT Mode.String AS Mode,
 OSPath, Size,
 Mtime,
 Sys.Uid AS OwnerID,
 Sys.Gid AS GroupID
 FROM glob(globs=GlobExpression) WHERE Mode =~ '^g|u'

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.Dock</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.dock/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.dock/</guid><description>&lt;p>This artifact examines the contents of the user&amp;rsquo;s dock. The
property list entry for each application represented within the dock
can be modified to point to a malicious application.&lt;/p>
&lt;p>By comparing the application name, CFURLString, and book, we can
gather greater context to assist in determining if an adversary may
have tampered with an entry, or if an entry has been added to
emulate a legitimate application.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.Dock
description: |
 This artifact examines the contents of the user's dock. The
 property list entry for each application represented within the dock
 can be modified to point to a malicious application.

 By comparing the application name, CFURLString, and book, we can
 gather greater context to assist in determining if an adversary may
 have tampered with an entry, or if an entry has been added to
 emulate a legitimate application.

reference:
 - https://specterops.io/so-con2020/event-758922
 - https://attack.mitre.org/techniques/T1547/009/
 - https://attack.mitre.org/techniques/T1647/

author: Wes Lambert - @therealwlambert

type: CLIENT

parameters:
 - name: DockGlob
 default: /Users/*/Library/Preferences/com.apple.dock.plist

sources:
 - query: |
 SELECT * FROM foreach(row={
 SELECT OSPath from glob(globs=DockGlob)
 }, query={
 SELECT OSPath, GUID,
 get(member="tile-data.file-label") AS FileLabel,
 get(member="tile-data.file-data._CFURLString") AS AppLocation,
 timestamp(mactime=get(member="tile-data.file-mod-date")) AS FileModDate,
 timestamp(mactime=get(member="tile-data.parent-mod-date")) AS ParentModDate,
 get(member="tile-data.bundle-identifier") AS BundleIdentifier,
 get(member="tile-data.dock-extra") AS DockExtra,
 base64encode(string=get(member="tile-data.book")) AS Book
 FROM foreach(row=plist(file=OSPath).`persistent-apps`)
 })

column_types:
 - name: Book
 type: base64hex

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.Packages</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.packages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.packages/</guid><description>&lt;p>Parse packages installed on Macs&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.Packages
description: |
 Parse packages installed on Macs

parameters:
 - name: Length
 description: Size (in bytes) of output that will be returned
 type: int
 default: "100000000"

implied_permissions:
 - EXECVE

sources:
 - precondition: |
 SELECT OS From info() where OS = 'darwin'
 query: |
 LET packages = SELECT parse_json(data=Stdout) AS Json
 FROM execve(argv=[
 "system_profiler", "-json", "SPApplicationsDataType"
 ], length=Length)

 SELECT _name AS Name,
 get(field="version") AS Version,
 path AS Path,
 lastModified AS LastModified,
 obtained_from AS ObtainedFrom,
 get(field="signed_by") AS SignedBy,
 arch_kind AS _Architecture
 FROM foreach(
 row=packages[0].Json.SPApplicationsDataType)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.Plist</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.plist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.plist/</guid><description>&lt;p>This artifact collects and/or parses MacOS .plist files. While simple,
this artifact allows users to specify a .plist glob, and have those plist files
returned for quick review. If more advanced parsing is desired, the artifact can be copied
and modified.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.Plist
description: |
 This artifact collects and/or parses MacOS .plist files. While simple,
 this artifact allows users to specify a .plist glob, and have those plist files
 returned for quick review. If more advanced parsing is desired, the artifact can be copied
 and modified.

type: CLIENT

author: Wes Lambert - @therealwlambert

precondition: SELECT OS FROM info() WHERE OS =~ 'darwin'

parameters:
 - name: PlistGlob
 default: /Library/Preferences/*.plist

 - name: Upload_File
 default: N
 type: bool

sources:
 - query: |
 SELECT
 OSPath,
 Mtime,
 plist(file=OSPath) AS Content,
 if(condition=Upload_File,
 then=upload(file=OSPath,
 mtime=Mtime,
 atime=Atime,
 ctime=Ctime,
 btime=Btime)) AS Upload
 FROM glob(globs=PlistGlob)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.QuarantineEvents</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.quarantineevents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.quarantineevents/</guid><description>&lt;p>This artifact parses the QuarantineEventsV2 database, which provides
information on when a file was downloaded from the internet.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.QuarantineEvents
description: |

 This artifact parses the QuarantineEventsV2 database, which provides
 information on when a file was downloaded from the internet.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
- name: QuarantineGlob
 default: /Users/*/Library/Preferences/com.apple.LaunchServices.QuarantineEventsV2

precondition:
 SELECT OS From info() where OS = 'darwin'

sources:
 - query: |
 LET QList = SELECT OSPath
 FROM glob(globs=QuarantineGlob)

 LET QEvents = SELECT *
 FROM sqlite(file=OSPath, query="SELECT * from LSQuarantineEvent")

 // Add delta (978307200 seconds between Cocoa timestamp
 // (2020,1,1) and epoch timestamp (1970,1,1)) to provided Cocoa
 // timestamp

 LET QEventsDetails =
 SELECT * FROM foreach(
 row=QEvents,
 query={ SELECT
 timestamp(epoch=LSQuarantineTimeStamp + 978307200) AS DownloadTime,
 LSQuarantineDataURLString AS DownloadURL,
 LSQuarantineOriginURLString AS Origin,
 LSQuarantineAgentName AS AgentName,
 LSQuarantineAgentBundleIdentifier AS AgentBundle,
 split(string=OSPath, sep='/')[2] AS User,
 LSQuarantineEventIdentifier AS EventUUID
 FROM scope()
 }
 )

 SELECT * FROM foreach(row=QList, query=QEventsDetails)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.TCC</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.tcc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.tcc/</guid><description>&lt;p>This artifact provides details around the TCC (Transparency,
Consent, and Control) database, and can help reveal when access to
system services has been added or modified for an application.&lt;/p>
&lt;p>Note that this artifact has only been tested on macOS Big Sur, and
that the &lt;code>allowed&lt;/code>, and &lt;code>prompt_count&lt;/code> columns will need to be used
in place of the &lt;code>auth_value&lt;/code>, &lt;code>auth_reason&lt;/code>, and &lt;code>auth_version&lt;/code>
columns for Catalina and prior.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.TCC
description: |
 This artifact provides details around the TCC (Transparency,
 Consent, and Control) database, and can help reveal when access to
 system services has been added or modified for an application.

 Note that this artifact has only been tested on macOS Big Sur, and
 that the `allowed`, and `prompt_count` columns will need to be used
 in place of the `auth_value`, `auth_reason`, and `auth_version`
 columns for Catalina and prior.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
- name: TCCGlob
 default: /Library/Application Support/com.apple.TCC/TCC.db,/Users/*/Library/Application Support/com.apple.TCC/TCC.db

precondition:
 SELECT OS From info() where OS = 'darwin'

sources:
 - query: |
 LET TCCList = SELECT OSPath
 FROM glob(globs=split(string=TCCGlob, sep=","))

 LET TCCAccess = SELECT *
 FROM sqlite(file=OSPath, query="SELECT * from access")

 LET TCCAccessDetails =
 SELECT * FROM foreach(
 row=TCCAccess,
 query={ SELECT
 timestamp(epoch=last_modified) AS LastModified,
 service AS Service,
 client AS Client,
 if(condition= client_type= 0, then="Console", else=if(condition= client_type= 1, then="Service/Script", else="Other")) AS ClientType,
 if(condition= auth_value= 2, then="Yes", else="No") AS Allowed,
 if(condition= OSPath =~ "Users", then=path_split(path=OSPath)[-5], else="System") AS User,
 auth_reason AS _AuthReason,
 auth_version AS _AuthVersion,
 csreq AS _CSReq,
 policy_id as _PolicyId,
 indirect_object_identifier_type as _IndirectObjectIdentifierType,
 indirect_object_identifier as IndirectObjectIdentifier,
 indirect_object_code_identity as _IndirectObjectCodeIdentity,
 flags as _Flags,
 OSPath AS _OSPath
 FROM scope()
 }
 )
 SELECT * FROM foreach(row=TCCList, query=TCCAccessDetails)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.TimeMachine</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.timemachine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.timemachine/</guid><description>&lt;p>This artifact collects information about MacOS Time Machine backups.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.TimeMachine
description: |
 This artifact collects information about MacOS Time Machine backups.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
 - name: TimeMachineGlob
 default: /Library/Preferences/com.apple.TimeMachine.plist

sources:
 - query: |
 LET TMPlist = SELECT OSPath FROM glob(globs=TimeMachineGlob)
 LET TMDetails =
 SELECT * FROM foreach(
 row=plist(file=OSPath),
 query={ SELECT
 plist(file=OSPath).LocalizedDiskImageVolumeName AS VolumeName,
 plist(file=OSPath).AutoBackup AS AutoBackup,
 plist(file=OSPath).LastDestinationID AS LastDestination,
 plist(file=OSPath).HostUUIDs[0] AS HostUUID,
 plist(file=OSPath).Destinations AS Destinations
 FROM scope()
 }
 )
 SELECT * FROM foreach(row=TMPlist, query=TMDetails)

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.Users</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.users/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.users/</guid><description>&lt;p>This artifact collects information about the local users on the
system. The information is stored in plist files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.Users
description: |
 This artifact collects information about the local users on the
 system. The information is stored in plist files.

parameters:
 - name: UserPlistGlob
 default: /private/var/db/dslocal/nodes/Default/users/*.plist
 - name: OnlyShowRealUsers
 type: bool
 default: Y

sources:
 - query: |
 LET user_plist = SELECT OSPath FROM glob(globs=UserPlistGlob)
 LET UserDetails(OSPath) =
 SELECT get(member="name.0", default="") AS Name,
 get(member="realname.0", default="") AS RealName,
 get(member="uid.0", default="") AS Uid,
 get(member="gid.0", default="") AS Gid,
 get(member="shell.0", default="") AS UserShell,
 get(member="home.0", default="") AS HomeDir,
 get(member="generateduid.0", default="") AS UUid,
 if(condition=LinkedIdentity,
 then=plist(file=LinkedIdentity[0],
 accessor='data')) as AppleId,
 if(condition=accountPolicyData,
 then=plist(file=accountPolicyData[0],
 accessor='data')) AS AccountPolicyData
 FROM plist(file=OSPath)

 SELECT Name, RealName, Uid, Gid, UUid, UserShell, HomeDir,
 get(item=AppleId, field="appleid.apple.com") AS AppleId,
 timestamp(epoch=AccountPolicyData.creationTime) AS CreationTime,
 AccountPolicyData.failedLoginCount AS FailedLoginCount,
 timestamp(epoch=AccountPolicyData.failedLoginTimestamp) AS FailedLoginTimestamp,
 timestamp(epoch=AccountPolicyData.passwordLastSetTime) AS PasswordLastSetTime
 FROM foreach(row=user_plist, query={
 SELECT * FROM UserDetails(OSPath= OSPath)
 })
 WHERE NOT OnlyShowRealUsers OR NOT UserShell =~ 'false'

&lt;/code>&lt;/pre></description></item><item><title>MacOS.System.Wifi</title><link>https://docs.velociraptor.app/artifact_references/pages/macos.system.wifi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/macos.system.wifi/</guid><description>&lt;p>This artifact looks for all Wifi networks to which a host has
joined. This can be useful in determining where a machine has
been, or if a user has joined an illegitimate or unauthorized
wireless network.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: MacOS.System.Wifi
description: |
 This artifact looks for all Wifi networks to which a host has
 joined. This can be useful in determining where a machine has
 been, or if a user has joined an illegitimate or unauthorized
 wireless network.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
 - name: WifiGlob
 default: /Library/Preferences/SystemConfiguration/com.apple.airport.preferences.plist

precondition:
 SELECT OS From info() where OS = 'darwin'

sources:
 - query: |
 LET WifiPlist = SELECT OSPath from glob(globs=WifiGlob)
 LET KnownNetworksQuery = SELECT get(member="KnownNetworks") as KN
 FROM plist(file=WifiPlist.OSPath)
 WHERE KN

 LET EachNetwork = SELECT * from foreach(
 row=KnownNetworksQuery,
 query={
 SELECT _key AS Network, _value AS Value
 FROM items(item=KN)
 })
 SELECT Network,
 Value.SSIDString AS SSID,
 Value.SecurityType AS SecurityType,
 Value.HiddenNetwork AS HiddenNetwork,
 Value.PersonalHotspot AS PersonalHotspot,
 Value.AddedAt AS AddedAt,
 Value.LastAutoJoinAt AS LastAutoJoinAt,
 Value.LastManualJoinAt AS LastManualJoinAt,
 Value AS _Data
 FROM EachNetwork

&lt;/code>&lt;/pre></description></item><item><title>Network.ExternalIpAddress</title><link>https://docs.velociraptor.app/artifact_references/pages/network.externalipaddress/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/network.externalipaddress/</guid><description>&lt;p>Identifies the external IP address of the endpoint using an external
web service.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Network.ExternalIpAddress
description: |
 Identifies the external IP address of the endpoint using an external
 web service.

required_permissions:
- NETWORK

parameters:
 - name: externalUrl
 default: http://www.myexternalip.com/raw
 description: The URL of the external IP detection site.

sources:
 - precondition: SELECT * from info()
 query: |
 SELECT Content as IP from http_client(url=externalUrl)

&lt;/code>&lt;/pre></description></item><item><title>Notebooks.Default</title><link>https://docs.velociraptor.app/artifact_references/pages/notebooks.default/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/notebooks.default/</guid><description>&lt;p>A default notebook.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Notebooks.Default
description: |
 A default notebook.

type: NOTEBOOK

sources:
 - notebook:
 - type: markdown
 name: Welcome page
 template: |
 # Welcome to Velociraptor notebooks!

 * Update this notebook with any VQL or markdown cells.
 * You can copy cells into this notebook from other collection or hunt notebooks.

 - type: vql_suggestion
 name: A Cell Suggestion
 template: |
 /*
 # This is a cell suggestion
 */
 SELECT * FROM info()

&lt;/code>&lt;/pre></description></item><item><title>Notebooks.Demo</title><link>https://docs.velociraptor.app/artifact_references/pages/notebooks.demo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/notebooks.demo/</guid><description>&lt;p>A notebook demonstrating features of notebooks&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Notebooks.Demo
description: |
 A notebook demonstrating features of notebooks

type: NOTEBOOK

# We can include tools in notebook templates, just like artifacts.
tools:
 - name: Autorun_amd64
 url: https://live.sysinternals.com/tools/autorunsc64.exe

parameters:
 - name: StartDate
 type: timestamp
 - name: AnInteger
 type: int
 default: "5"

sources:
 - notebook:
 - type: vql
 name: Example Query with tool reference
 template: |
 SELECT StartDate, AnInteger, Tool_Autorun_amd64_URL
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Notebooks.Sigma.Studio</title><link>https://docs.velociraptor.app/artifact_references/pages/notebooks.sigma.studio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/notebooks.sigma.studio/</guid><description>&lt;p>A notebook to help develop Sigma rules.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Notebooks.Sigma.Studio
description: |
 A notebook to help develop Sigma rules.

type: NOTEBOOK

tools:
 - name: SigmaProfiles
 url: https://sigma.velocidex.com/profiles.json
 serve_locally: true

parameters:
 - name: BaseType
 description: Write sigma rules to target these base artifacts
 type: choices
 default: Windows
 choices:
 - Windows
 - WindowsEvents
 - Linux
 - LinuxEvents

 - name: Debug
 description: Enable this to match all rules (even if they did not match) to see what detections matched.
 type: bool

 - name: LogSource
 description: The current log source to use.

sources:
 - notebook:
 - type: markdown
 name: Sigma Studio Description
 template: |
 # Sigma Studio

 This notebook is designed to help you write and test Sigma
 Rules for detection within Velociraptor!

 ## What is Sigma?

 Sigma is an open notation for writing detection rules - It
 is supported natively in Velociraptor as described in [our
 blog post](https://docs.velociraptor.app/blog/2024/2024-05-09-detection-engineering/)

 Sigma relies on a set of `Log Sources` (defining possible
 sources for log events) and `Field Mappings` (an agreed upon
 set of field transformations that may be referred to in the
 Sigma rule).

 The Sigma standard does not define those, but they are
 critical for successfully writing Sigma rules. Therefore,
 Velociraptor uses [a standard set of Log Sources and Field
 Mappings](https://sigma.velocidex.com/).

 This is the purpose of this notebook! Making it easy and
 simple to write rules **within the definitions of
 Velociraptor's curated sets**. This means that portability
 of rules to other systems is **not a goal** of this
 notebook.

 ## How to use this notebook?

 1. Before you start, collect the
 `Server.Import.CuratedSigma` artifact to download the
 latest `Sigma Profiles`. A `Sigma Profile` is a machine
 readable definition of log sources and field mappings
 that allows the GUI to guide rule authors.

 2. Collect event samples. Use the relevant `CaptureTestSet`
 artifact (e.g. `Windows.Sigma.Base.CaptureTestSet`) collect
 events from the relevant log source. You can post-process
 the rows and filter in the notebook as usual.

 3. When you are ready to work with a test set, click `export
 to JSON` in the GUI to receive a JSON file with the test
 data.

 4. Upload this test set into this notebook.

 5. Open the `Sigma Editor` within this notebook.

 6. Select the relevant log source from the drop down (you
 will only see supported log sources).

 7. Follow the instructions within the Sigma editor. You can
 name any of the supported fields inside the rule.

 8. Saving the rule will automatically apply the ruleset on
 the test set. This gives visual feedback of how effective
 the rule is.

 9. When you are ready to deploy at scale download the
 ruleset from the notebook and enter it to the base sigma
 artifact (e.g. `Windows.Sigma.Base`).


 After you are familiar with the `Sigma Studio` notebook you
 can delete this instructional cell.

 - type: markdown
 name: Sigma Studio Interactive Cell
 template: |
 {{ define "Setup" }}
 LET ProfileType &amp;lt;= dict(
 Windows="Windows.Sigma.Base",
 Linux="Linux.Sigma.Base",
 WindowsEvents="Windows.Sigma.BaseEvents",
 LinuxEvents="Linux.Sigma.BaseEvents")

 // We need to store the profile in the datastore because it
 // is too large to pass in a HTML tag.
 LET Rows &amp;lt;= SELECT upload(
 accessor='data', file=Content,
 name='profile.json') AS Upload
 FROM http_client(url=Tool_SigmaProfiles_URL)

 // This is where it is.
 LET ProfileComponents &amp;lt;= Rows[0].Upload.Components

 LET ProfileName &amp;lt;= get(item=ProfileType,
 field=BaseType || "Windows")
 LET _ &amp;lt;= import(artifact= ProfileName)

 // Build the Sigma rules into a downloadable rule set.
 LET Rules = SELECT read_file(
 accessor='fs',
 filename=vfs_path) AS Data FROM uploads()
 WHERE vfs_path =~ '.yaml'

 LET TestSigmaRules &amp;lt;= join(array=Rules.Data, sep='\n---\n')

 LET Upload &amp;lt;= upload(name='sigma_rules.yaml', accessor='data',
 file=TestSigmaRules)
 LET Link &amp;lt;= link_to(upload=Upload, text='sigma ruleset')

 SELECT * FROM scope()
 {{ end }}

 {{ $rows := Query "Setup" | Expand }}

 {{ SigmaEditor "upload" ( Scope "ProfileComponents" ) "selected_profile" ( Scope "ProfileName" ) }}

 ### Download {{ Scope "Link" }}

 # Sample Events For testing.

 You can test the sigma rules on test events in JSONL
 format. Upload samples into this notebook by using the
 `Notebook Uploads` dialog.

 {{ define "Testing" }}
 // Feed all the json rows to the log sources.
 LET AllRows = SELECT * FROM foreach(row={
 SELECT vfs_path FROM uploads()
 WHERE vfs_path =~ 'attach.+json$'
 }, query={
 SELECT * FROM parse_jsonl(accessor='fs', filename=vfs_path)
 })

 LET TestingLogSourceDict &amp;lt;= to_dict(item={
 SELECT _key, AllRows AS _value
 FROM items(item=LogSources)
 })

 // Build the log sources automatically.
 LET TestingLogSources &amp;lt;= sigma_log_sources(`**`=TestingLogSourceDict)

 // Apply the Sigma Rules on the samples.
 SELECT _Rule.Title AS Rule ,
 Details,
 dict(System=System,
 EventData=X.EventData || X.UserData,
 Message=X.Message) AS Event,
 _Match AS Match
 FROM sigma(
 rules=split(string=TestSigmaRules, sep_string="\n---\n"),
 log_sources= TestingLogSources, debug=Debug,
 default_details=DefaultDetailsLambda,
 field_mapping= FieldMapping)

 {{ end }}

 ## Match rules on test set

 {{ if ( Scope "Debug" ) }}
 Debug mode is enabled, so all events will be shown. Inspect
 the Match object to see which detections matched.
 {{ else }}
 Debug mode is disabled, so only matching events will be shown. Enable Debug mode by editing the notebook.
 {{ end }}

 {{ Query "Testing" | Table}}

 ## View the test set

 {{ Query "SELECT * FROM AllRows " | Table}}

&lt;/code>&lt;/pre></description></item><item><title>Notebooks.Timelines</title><link>https://docs.velociraptor.app/artifact_references/pages/notebooks.timelines/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/notebooks.timelines/</guid><description>&lt;p>The notebook creates a default Super-Timeline.&lt;/p>
&lt;p>Timelines are used to visualize time series data from other
collections in the same place. This notebook template creates an
initial timeline.&lt;/p>
&lt;p>Once this timeline is created, you can add any time series table in
other notebooks (e.g. Collection or Hunt notebooks) to this super
timeline.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Notebooks.Timelines
description: |
 The notebook creates a default Super-Timeline.

 Timelines are used to visualize time series data from other
 collections in the same place. This notebook template creates an
 initial timeline.

 Once this timeline is created, you can add any time series table in
 other notebooks (e.g. Collection or Hunt notebooks) to this super
 timeline.

type: NOTEBOOK

parameters:
 - name: TimelineName
 description: The name of the super timeline to create.
 default: Supertimeline

sources:
 - notebook:
 - type: markdown
 name: Timeline Description
 template: |
 # {{ Scope "TimelineName" }}

 Add to this timeline any time-series data from any other
 notebooks:

 1. Click the `Add Timeline` button at the top of any table.
 2. Switch to global notebook timelines and select this timeline.
 3. Select the timestamp and message columns to add a timeline.

 {{ Scope "TimelineName" | Timeline }}

 - type: vql
 name: Timeline Interactive Cell
 template: |
 /*
 # Timeline Annotations

 Refresh this to list all timeline annotations as a table.
 */
 SELECT *
 FROM timeline(notebook_id=NotebookId,
 components="Annotation",
 timeline=TimelineName)
 ORDER BY Timestamp

&lt;/code>&lt;/pre></description></item><item><title>Notebooks.VQLx2</title><link>https://docs.velociraptor.app/artifact_references/pages/notebooks.vqlx2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/notebooks.vqlx2/</guid><description>&lt;p>A notebook initialized with 2 VQL cells&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Notebooks.VQLx2
description: |
 A notebook initialized with 2 VQL cells

type: NOTEBOOK

sources:
 - notebook:
 - type: vql
 name: First Cell
 output: |
 &amp;lt;&amp;lt; 1st cell: Click here to edit &amp;gt;&amp;gt;
 template: |
 SELECT * FROM orgs()
 - type: vql
 name: Second Cell
 output: |
 &amp;lt;&amp;lt; 2nd cell: Click here to edit &amp;gt;&amp;gt;
 template: |
 SELECT * FROM gui_users() WHERE name = whoami()

&lt;/code>&lt;/pre></description></item><item><title>Reporting.Default</title><link>https://docs.velociraptor.app/artifact_references/pages/reporting.default/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/reporting.default/</guid><description>&lt;p>A default template for HTML export. This template will be used to
host HTML exports such as the notebook and the reporting
templates. Velociraptor will evaluate this template on the following
dict:&lt;/p>
&lt;ul>
&lt;li>key main: contains a string with all the results of rendering
the notebook inside.&lt;/li>
&lt;/ul>
&lt;h2 id="notes">Notes&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>All HTML elements are allowed in a HTML template.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It is possible to run arbitrary VQL (and therefore arbitrary
code) inside HTML templates. Therefore to modify this you will
need the SERVER_ARTIFACT_WRITER permission.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-yaml">
name: Reporting.Default

type: SERVER

description: |
 A default template for HTML export. This template will be used to
 host HTML exports such as the notebook and the reporting
 templates. Velociraptor will evaluate this template on the following
 dict:

 - key main: contains a string with all the results of rendering
 the notebook inside.

 ## Notes

 1. All HTML elements are allowed in a HTML template.

 2. It is possible to run arbitrary VQL (and therefore arbitrary
 code) inside HTML templates. Therefore to modify this you will
 need the SERVER_ARTIFACT_WRITER permission.

reports:
 - name: Templates
 type: TEMPLATES
 template: |
 {{ define "fold_start" }}
 &amp;lt;div role="button" class="btn btn-primary btn-block row collapsible"&amp;gt;View Details&amp;lt;/div&amp;gt;
 &amp;lt;div class="collapse row"&amp;gt;&amp;lt;div class="card card-body overflow-auto"&amp;gt;
 {{end}}
 {{ define "fold_end" }}
 &amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;
 {{ end }}

 {{ define "hidden_paragraph_start" }}
 {{- if .description -}}
 &amp;lt;div&amp;gt;&amp;lt;a href="#" class="collapsible"&amp;gt;{{ .description }} ...&amp;lt;/a&amp;gt;
 {{- else -}}
 &amp;lt;div&amp;gt;&amp;lt;a href="#" class="collapsible"&amp;gt;More ...&amp;lt;/a&amp;gt;
 {{- end -}}
 &amp;lt;div class="collapse"&amp;gt;
 {{end}}

 {{ define "hidden_paragraph_end" }}
 &amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;
 {{ end }}


 - type: HTML
 template: |
 {{ import "Reporting.Default" "Templates" }}

 &amp;lt;!doctype html&amp;gt;
 &amp;lt;html lang="en-US"&amp;gt;
 &amp;lt;head&amp;gt;
 {{ $hostinfo := Query "SELECT timestamp(epoch=now()).UTC.String AS Time, \
 OS, Fqdn FROM info()" | Expand }}

 &amp;lt;meta charset="utf-8"&amp;gt;
 &amp;lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&amp;gt;
 &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1"&amp;gt;

 &amp;lt;!-- Name of the scan --&amp;gt;
 &amp;lt;title&amp;gt;{{ Get $hostinfo "0.Fqdn" }} Artifact Collection&amp;lt;/title&amp;gt;
 &amp;lt;style&amp;gt;
 @charset "UTF-8";
 body {
 padding-top: 57px;
 }
 .btn-primary.btn {
 color: #00aa00;
 background-color: #fff;
 border-color: #fff;
 }
 .btn-primary.btn:hover {
 color: #fff;
 background-color: #00911e;
 border-color: #00911e;
 }
 .btn.btn-primary:not(:disabled):not(.disabled):active, .btn.btn-primary:not(:disabled):not(.disabled).active {
 color: #fff;
 background-color: #008773;
 border-color: #008773;
 }
 .btn.btn-primary:focus, .btn.btn-primary.focus {
 color: #fff;
 background-color: #00911e;
 border-color: #00911e;
 box-shadow: 0 0 0 0.2rem rgba(38, 143, 255, 0.5);
 }
 .header {
 background-color: black;
 border-bottom: 1px solid #00aa00;
 }
 .collapse {
 display: none;
 }
 .anchor {
 display: block;
 position: relative;
 top: -57px;
 visibility: hidden;
 }
 .logo {
 margin-top: -17px;
 margin-bottom: -10px;
 margin-left: 20px;
 height: 40px;
 }

 .section {
 color: #FFFFFF;
 font-size: 24px;
 background-color: #00aa00;
 font-family: Gotham, "Helvetica Neue", Helvetica, Arial, sans-serif;
 font-variant: normal;
 padding-top: 15px;
 padding-bottom: 15px;
 text-align: center;
 }
 .top-section {
 border-bottom-left-radius: 40px;
 border-bottom-right-radius: 40px;
 }

 /* Error */ .chromaerr { color: #a61717; background-color: #e3d2d2 }
 /* LineTableTD */ .chromalntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
 /* LineTable */ .chromalntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }
 /* LineHighlight */ .chromahl { display: block; width: 100%; }
 /* LineNumbersTable */ .chromalnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
 /* LineNumbers */ .chromaln { display: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
 /* Keyword */ .chromak { color: #000000; font-weight: bold }
 /* KeywordConstant */ .chromakc { color: #000000; font-weight: bold }
 /* KeywordDeclaration */ .chromakd { color: #000000; font-weight: bold }
 /* KeywordNamespace */ .chromakn { color: #000000; font-weight: bold }
 /* KeywordPseudo */ .chromakp { color: #000000; font-weight: bold }
 /* KeywordReserved */ .chromakr { color: #000000; font-weight: bold }
 /* KeywordType */ .chromakt { color: #445588; font-weight: bold }
 /* NameAttribute */ .chromana { color: #008080 }
 /* NameBuiltin */ .chromanb { color: #0086b3 }
 /* NameBuiltinPseudo */ .chromabp { color: #999999 }
 /* NameClass */ .chromanc { color: #445588; font-weight: bold }
 /* NameConstant */ .chromano { color: #008080 }
 /* NameDecorator */ .chromand { color: #3c5d5d; font-weight: bold }
 /* NameEntity */ .chromani { color: #800080 }
 /* NameException */ .chromane { color: #990000; font-weight: bold }
 /* NameFunction */ .chromanf { color: #990000; font-weight: bold }
 /* NameLabel */ .chromanl { color: #990000; font-weight: bold }
 /* NameNamespace */ .chromann { color: #555555 }
 /* NameTag */ .chromant { color: #000080 }
 /* NameVariable */ .chromanv { color: #008080 }
 /* NameVariableClass */ .chromavc { color: #008080 }
 /* NameVariableGlobal */ .chromavg { color: #008080 }
 /* NameVariableInstance */ .chromavi { color: #008080 }
 /* LiteralString */ .chromas { color: #dd1144 }
 /* LiteralStringAffix */ .chromasa { color: #dd1144 }
 /* LiteralStringBacktick */ .chromasb { color: #dd1144 }
 /* LiteralStringChar */ .chromasc { color: #dd1144 }
 /* LiteralStringDelimiter */ .chromadl { color: #dd1144 }
 /* LiteralStringDoc */ .chromasd { color: #dd1144 }
 /* LiteralStringDouble */ .chromas2 { color: #dd1144 }
 /* LiteralStringEscape */ .chromase { color: #dd1144 }
 /* LiteralStringHeredoc */ .chromash { color: #dd1144 }
 /* LiteralStringInterpol */ .chromasi { color: #dd1144 }
 /* LiteralStringOther */ .chromasx { color: #dd1144 }
 /* LiteralStringRegex */ .chromasr { color: #009926 }
 /* LiteralStringSingle */ .chromas1 { color: #dd1144 }
 /* LiteralStringSymbol */ .chromass { color: #990073 }
 /* LiteralNumber */ .chromam { color: #009999 }
 /* LiteralNumberBin */ .chromamb { color: #009999 }
 /* LiteralNumberFloat */ .chromamf { color: #009999 }
 /* LiteralNumberHex */ .chromamh { color: #009999 }
 /* LiteralNumberInteger */ .chromami { color: #009999 }
 /* LiteralNumberIntegerLong */ .chromail { color: #009999 }
 /* LiteralNumberOct */ .chromamo { color: #009999 }
 /* Operator */ .chromao { color: #000000; font-weight: bold }
 /* OperatorWord */ .chromaow { color: #000000; font-weight: bold }
 /* Comment */ .chromac { color: #999988; font-style: italic }
 /* CommentHashbang */ .chromach { color: #999988; font-style: italic }
 /* CommentMultiline */ .chromacm { color: #999988; font-style: italic }
 /* CommentSingle */ .chromac1 { color: #999988; font-style: italic }
 /* CommentSpecial */ .chromacs { color: #999999; font-weight: bold; font-style: italic }
 /* CommentPreproc */ .chromacp { color: #999999; font-weight: bold; font-style: italic }
 /* CommentPreprocFile */ .chromacpf { color: #999999; font-weight: bold; font-style: italic }
 /* GenericDeleted */ .chromagd { color: #000000; background-color: #ffdddd }
 /* GenericEmph */ .chromage { color: #000000; font-style: italic }
 /* GenericError */ .chromagr { color: #aa0000 }
 /* GenericHeading */ .chromagh { color: #999999 }
 /* GenericInserted */ .chromagi { color: #000000; background-color: #ddffdd }
 /* GenericOutput */ .chromago { color: #888888 }
 /* GenericPrompt */ .chromagp { color: #555555 }
 /* GenericStrong */ .chromags { font-weight: bold }
 /* GenericSubheading */ .chromagu { color: #aaaaaa }
 /* GenericTraceback */ .chromagt { color: #aa0000 }
 /* TextWhitespace */ .chromaw { color: #bbbbbb }

 &amp;lt;/style&amp;gt;
 &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"&amp;gt;

 &amp;lt;!-- Bootstrap core CSS --&amp;gt;
 &amp;lt;link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous"&amp;gt;
 &amp;lt;link rel="stylesheet" href="https://cdn.datatables.net/1.10.21/css/jquery.dataTables.min.css" &amp;gt;

 &amp;lt;script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"&amp;gt;&amp;lt;/script&amp;gt;
 &amp;lt;script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"&amp;gt;&amp;lt;/script&amp;gt;
 &amp;lt;script src="https://cdn.datatables.net/1.10.21/js/jquery.dataTables.min.js"&amp;gt;&amp;lt;/script&amp;gt;
 &amp;lt;/head&amp;gt;
 &amp;lt;body&amp;gt;
 &amp;lt;nav class="header navbar navbar-expand-lg navbar-dark fixed-top"&amp;gt;
 &amp;lt;a class="navbar-brand" href="#" aria-label="CyberCX"&amp;gt;
 &amp;lt;img src="https://docs.velociraptor.app/artifact_references/pages/reporting.default/https://www.velocidex.com/images/logos/velo_word_on_side.svg" class="logo"/&amp;gt;
 &amp;lt;/a&amp;gt;
 &amp;lt;button class="navbar-toggler" type="button"
 data-toggle="collapse"
 data-target="#navbarSupportedContent"
 aria-controls="navbarSupportedContent"
 aria-expanded="false" aria-label="Toggle navigation"&amp;gt;
 &amp;lt;span class="navbar-toggler-icon"&amp;gt;&amp;lt;/span&amp;gt;
 &amp;lt;/button&amp;gt;
 &amp;lt;div class="collapse navbar-collapse" id="navbarSupportedContent"&amp;gt;
 &amp;lt;ul class="navbar-nav mr-auto"&amp;gt;
 &amp;lt;li class="nav-item active"&amp;gt;
 &amp;lt;a class="nav-link" href="#"&amp;gt;Top &amp;lt;span class="sr-only"&amp;gt;(top)&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;
 &amp;lt;/li&amp;gt;
 &amp;lt;li class="nav-item"&amp;gt;
 &amp;lt;a class="nav-link" href="https://github.com/Velocidex/velociraptor"&amp;gt;GitHub&amp;lt;/a&amp;gt;
 &amp;lt;/li&amp;gt;
 &amp;lt;li class="nav-item"&amp;gt;
 &amp;lt;a class="nav-link" href="#" id="print-button"&amp;gt;Print&amp;lt;/a&amp;gt;
 &amp;lt;/li&amp;gt;

 &amp;lt;li class="nav-item dropdown"&amp;gt;
 &amp;lt;a class="nav-link dropdown-toggle" href="#"
 id="navbarDropdown" role="button"
 data-toggle="dropdown"
 aria-haspopup="true" aria-expanded="false"&amp;gt;
 Artifacts Collected
 &amp;lt;/a&amp;gt;
 &amp;lt;div class="dropdown-menu" aria-labelledby="navbarDropdown"&amp;gt;
 {{ range .parts }}
 &amp;lt;a class="dropdown-item" href="#{{- .Artifact.Name -}}"&amp;gt;
 {{ .Artifact.Name }}
 &amp;lt;/a&amp;gt;
 {{ end }}
 &amp;lt;/div&amp;gt;
 &amp;lt;/li&amp;gt;
 &amp;lt;/ul&amp;gt;
 &amp;lt;/div&amp;gt;
 &amp;lt;/nav&amp;gt;

 &amp;lt;main role="main" class="container"&amp;gt;
 &amp;lt;div class="row section top-section"&amp;gt;
 &amp;lt;div class="col"&amp;gt;
 {{ $data := Query "SELECT timestamp(epoch=now()).UTC.String AS Time, OS, Fqdn FROM info()" | Expand }}
 {{ Get $hostinfo "0.Fqdn" }} Artifact Collection
 &amp;lt;/div&amp;gt;
 &amp;lt;div class="col"&amp;gt;{{- Get $data "0" -}}&amp;lt;/div&amp;gt;
 &amp;lt;/div&amp;gt;

 {{ range .parts }}

 &amp;lt;div class=""&amp;gt;
 &amp;lt;a class="anchor" name="{{- .Artifact.Name -}}"&amp;gt;&amp;lt;/a&amp;gt;
 &amp;lt;!-- If the artifact has its own report, just include it as is --&amp;gt;
 {{ if .HTML }}
 {{ .HTML }}
 {{ else }}
 &amp;lt;!-- Default report in case the artifact does not have one --&amp;gt;
 &amp;lt;h1&amp;gt;{{ .Artifact.Name }}
 &amp;lt;div class="btn btn-primary-outline float-right"&amp;gt;{{ .Artifact.Author }}
 &amp;lt;/div&amp;gt;
 &amp;lt;/h1&amp;gt;

 {{ $name := .Artifact.Name }}

 {{ template "hidden_paragraph_start" dict "description" "View Artifact Description" }}
 {{ Markdown .Artifact.Description }}

 {{ if .Artifact.Reference }}
 &amp;lt;h3&amp;gt;References&amp;lt;/h3&amp;gt;
 &amp;lt;ul&amp;gt;
 {{ range .Artifact.Reference }}
 &amp;lt;li&amp;gt;&amp;lt;a href="{{ . }}"&amp;gt;{{ . }}&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;
 {{ end }}
 &amp;lt;/ul&amp;gt;
 {{ end }}
 {{ template "hidden_paragraph_end" }}

 {{ range .Artifact.Sources }}
 {{ $source := print "source(\n source='" .Name "', artifact='" $name "')" }}
 {{ $query := print "SELECT * FROM " $source " \nLIMIT 100" }}

 &amp;lt;!-- There could be a huge number of rows just to get the count, so we cap at 10000 --&amp;gt;
 {{ $count := Get ( Query (print "LET X = SELECT * FROM " $source \
 " LIMIT 10000 SELECT 1 AS ALL, count() AS Count FROM X Group BY ALL") | Expand ) \
 "0.Count" }}

 {{ if $count }}
 {{ if .Name }}
 &amp;lt;h3&amp;gt;Source {{ $name }}/{{ .Name }}&amp;lt;/h3&amp;gt;
 {{ Markdown .Description }}
 {{ end }}

 &amp;lt;!-- Show the artifact source if required. --&amp;gt;
 {{ template "hidden_paragraph_start" dict "description" "Source" }}
 &amp;lt;div class="row card card-body noprint"&amp;gt;
 {{ if .Query }}
 {{ Markdown ( print "```vql\n" .Query "```\n") }}
 {{ else }}
 {{ range .Queries }}
 {{ Markdown ( print "```vql\n" . "```\n") }}
 {{ end }}
 {{ end }}
 &amp;lt;/div&amp;gt;
 {{ template "hidden_paragraph_end" }}

 &amp;lt;!-- If this is a flow show the parameters. --&amp;gt;
 {{ $flow := Query "LET X = SELECT Request.Parameters.env AS Env FROM flows(client_id=ClientId, flow_id=FlowId)" \
 "SELECT * FROM foreach(row=X[0].Env, query={ SELECT Key, Value FROM scope()})" | Expand }}
 {{ if $flow }}
 {{ template "hidden_paragraph_start" dict "description" "Parameters" }}
 &amp;lt;div class="row card card-body noprint"&amp;gt;
 &amp;lt;h3&amp;gt; Parameters &amp;lt;/h3&amp;gt;

 &amp;lt;table class="table"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;th&amp;gt;Key&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;Value&amp;lt;/th&amp;gt;&amp;lt;/thead&amp;gt;
 &amp;lt;tbody&amp;gt;
 {{ range $flow }}
 &amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;{{ Get . "Key" }}&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;{{ Get . "Value" }}&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;
 {{ end }}
 &amp;lt;/tbody&amp;gt;
 &amp;lt;/table&amp;gt;
 &amp;lt;/div&amp;gt;
 {{ template "hidden_paragraph_end" }}
 {{ end }}

 {{ if gt $count 9999 }}
 &amp;lt;p&amp;gt;The source produced more than {{ $count }} rows.&amp;lt;/p&amp;gt;
 {{ else }}
 &amp;lt;p&amp;gt;The source retrieved a total of {{ $count }} rows.&amp;lt;/p&amp;gt;
 {{ end }}

 {{ template "fold_start" }}
 &amp;lt;div class="noprint"&amp;gt;
 &amp;lt;p&amp;gt; Below you will find a table of the first 100 rows, obtained by the VQL query:
 &amp;lt;/p&amp;gt;
 {{ Markdown (print "```vql\n" $query "\n```\n" ) }}
 &amp;lt;/div&amp;gt;
 {{ Query $query | Table }}
 {{ template "fold_end" }}

 {{ else }}
 &amp;lt;p&amp;gt;No rows returned&amp;lt;/p&amp;gt;
 {{ end }}
 {{ end }}
 {{ end }}
 &amp;lt;/div&amp;gt;

 {{ end }}
 &amp;lt;/main&amp;gt;
 &amp;lt;script&amp;gt;
 $(".collapsible").click(function() {
 $(this).next().toggle("slow");
 try {
 $("table.table-striped").DataTable().columns.adjust();
 } catch(e) {

 };
 });

 $("#print-button").click(function() {
 $(".collapse").removeClass("collapse");
 $('table.table-striped').DataTable().destroy();
 $(".collapsible").hide();
 $(".noprint").hide();
 setTimeout(function() {
 window.print();
 location.reload();
 }, 1000);
 });

 $(document).ready( function () {
 try {
 $('table.table-striped').DataTable({
 "scrollY": 400,
 "scrollX": true,
 "autoWidth": false,
 });
 } catch(e) {};
 });
 &amp;lt;/script&amp;gt;
 &amp;lt;/body&amp;gt;
 &amp;lt;/html&amp;gt;

&lt;/code>&lt;/pre></description></item><item><title>Reporting.Hunts.Details</title><link>https://docs.velociraptor.app/artifact_references/pages/reporting.hunts.details/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/reporting.hunts.details/</guid><description>&lt;p>Report details about which client ran each hunt, how long it took
and if it has completed.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Reporting.Hunts.Details
description: |
 Report details about which client ran each hunt, how long it took
 and if it has completed.

type: SERVER

parameters:
 - name: ArtifactRegex
 type: regex
 default: .
 description: Filter hunts by this

 - name: DescriptionRegex
 type: regex
 default: .
 description: Filter hunts by this description

sources:
 - query: |
 LET hunts = SELECT hunt_id,
 create_time,
 hunt_description
 FROM hunts()
 WHERE artifacts =~ ArtifactRegex AND hunt_description =~ DescriptionRegex
 ORDER BY create_time DESC

 LET flows = SELECT hunt_id,
 hunt_description,
 client_info(client_id=ClientId).os_info.fqdn AS FQDN,
 ClientId,
 client_info(client_id=ClientId).os_info.system AS OS,
 timestamp(epoch=Flow.create_time) AS create_time,
 timestamp(epoch=Flow.start_time) AS start_time,
 timestamp(epoch=Flow.active_time) AS active_time,
 FlowId AS flow_id,
 Flow.execution_duration / 1000000000 AS Duration,
 Flow.state AS State
 FROM hunt_flows(hunt_id=hunt_id)
 ORDER BY create_time DESC

 SELECT * FROM foreach(row=hunts, query=flows)

&lt;/code>&lt;/pre></description></item><item><title>Server.Alerts.Notification</title><link>https://docs.velociraptor.app/artifact_references/pages/server.alerts.notification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.alerts.notification/</guid><description>&lt;p>This artifact forwards alerts from Server.Internal.Alerts to a Slack/Teams/Discord via a Webhook.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Alerts.Notification
description: |
 This artifact forwards alerts from Server.Internal.Alerts to a Slack/Teams/Discord via a Webhook.

author: Jos Clephas - @DfirJos

type: SERVER_EVENT

parameters:
 - name: SlackToken
 description: The token URL obtained from Slack/Teams/Discord (or basicly any communication-service that supports webhooks). Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
 - query: |
 LET token_url = if(
 condition=SlackToken,
 then=SlackToken,
 else=server_metadata().SlackToken)

 LET hits = SELECT * from watch_monitoring(artifact='Server.Internal.Alerts')

 SELECT * FROM foreach(row=hits,
 query={
 SELECT * FROM http_client(
 data=serialize(item=dict(
 text=format(format="Alert: %v | Details: %v | Artifact: %v | ClientId: %v | Timestamp: %v)",
 args=[name, event_data, artifact, client_id, timestamp])),
 format="json"),
 headers=dict(`Content-Type`="application/json"),
 method="POST",
 url=token_url)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Alerts.ProcessCreation</title><link>https://docs.velociraptor.app/artifact_references/pages/server.alerts.processcreation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.alerts.processcreation/</guid><description>&lt;p>This artifact alerts when a process was detected with the artifact &amp;lsquo;Windows.Detection.ProcessCreation&amp;rsquo; (which is a client_event artifact that needs to be enabled first).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Alerts.ProcessCreation
description: |
 This artifact alerts when a process was detected with the artifact 'Windows.Detection.ProcessCreation' (which is a client_event artifact that needs to be enabled first).

author: Jos Clephas - @DfirJos

type: SERVER_EVENT

parameters:
 - name: SlackToken
 description: The token URL obtained from Slack/Teams/Discord (or basicly any communication-service that supports webhooks). Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
 - query: |
 LET token_url = if(
 condition=SlackToken,
 then=SlackToken,
 else=server_metadata().SlackToken)

 LET hits = SELECT * from watch_monitoring(artifact='Windows.Detection.ProcessCreation')

 SELECT * FROM foreach(row=hits,
 query={
 SELECT EventData.CommandLine, EventData, Hostname, ClientId, Url, Content, Response FROM http_client(
 data=serialize(item=dict(
 text=format(format="Alert - Command detected '%v' on system %v with client Id %v. Syslog timestamp: %v ",
 args=[EventData.CommandLine, Hostname, ClientId, Timestamp])),
 format="json"),
 headers=dict(`Content-Type`="application/json"),
 method="POST",
 url=token_url)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Alerts.PsExec</title><link>https://docs.velociraptor.app/artifact_references/pages/server.alerts.psexec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.alerts.psexec/</guid><description>&lt;p>Send an email if execution of the PsExec service was detected on
any client. This is a server side artifact.&lt;/p>
&lt;p>Note this requires that the Windows.Event.ProcessCreation
monitoring artifact be collected from clients.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Alerts.PsExec
description: |
 Send an email if execution of the PsExec service was detected on
 any client. This is a server side artifact.

 Note this requires that the Windows.Event.ProcessCreation
 monitoring artifact be collected from clients.

type: SERVER_EVENT

parameters:
 - name: EmailAddress
 default: admin@example.com
 - name: SkipVerify
 type: bool
 description: If set we skip TLS verification.
 - name: MessageTemplate
 default: |
 PsExec execution detected at %v: %v for client %v

sources:
 - query: |
 SELECT * FROM foreach(
 row={
 SELECT * from watch_monitoring(
 artifact='Windows.Events.ProcessCreation')
 WHERE Name =~ 'psexesvc'
 },
 query={
 SELECT * FROM mail(
 to=EmailAddress,
 subject='PsExec launched on host',
 period=60,
 skip_verify=SkipVerify,
 body=format(
 format=MessageTemplate,
 args=[Timestamp, CommandLine, ClientId])
 )
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Alerts.TheHive.Alert</title><link>https://docs.velociraptor.app/artifact_references/pages/server.alerts.thehive.alert/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.alerts.thehive.alert/</guid><description>&lt;p>Creates a TheHive alert when monitored artifacts complete with results.&lt;/p>
&lt;p>The artifact uses Server Metadata to store credentials, instead of storing
these directly in the artifact.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Alerts.TheHive.Alert
description: |
 Creates a TheHive alert when monitored artifacts complete with results.

 The artifact uses Server Metadata to store credentials, instead of storing
 these directly in the artifact.

type: SERVER_EVENT

author: Wes Lambert - @therealwlambert

reference:
 - https://gist.github.com/scudette/3a32abd19350c8fe3368661c4278869d

parameters:
 - name: TheHiveURL
 default: https://mythehive
 - name: TheHiveKey
 default: ''
 - name: VeloServerURL
 default: https://myvelo
 - name: ArtifactsToAlertOn
 default: .
 - name: DisableSSLVerify
 type: bool
 default: True

sources:
 - query: |
 LET thehive_key = if(
 condition=TheHiveKey,
 then=TheHiveKey,
 else=server_metadata().TheHiveKey)
 LET flow_info = SELECT timestamp(epoch=Timestamp) AS Timestamp,
 client_info(client_id=ClientId).os_info.fqdn AS FQDN,
 ClientId, FlowId, Flow.artifacts_with_results[0] AS FlowResults
 FROM watch_monitoring(artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactsToAlertOn

 LET hits = SELECT * FROM foreach(row=flow_info,
 query={
 SELECT *, Timestamp, FQDN, ClientId
 FROM source(artifact=FlowResults,
 client_id=ClientId, flow_id=FlowId)
 })

 SELECT * FROM foreach(row=flow_info,
 query={
 SELECT * FROM http_client(
 data=serialize(item=dict(
 title=format(format="Hit on %v for %v", args=[FlowResults, FQDN]), description=format(format="ClientId: %v\n\nFlowID: %v\n\nURL: %v//app/index.html?#/collected/%v/%v", args=[ClientId, FlowId, VeloServerURL, ClientId, FlowId]), type="artifact-alert", source="velociraptor", sourceRef=format(format="%v", args=[rand(range=1000000000)])), format="json"),
 headers=dict(`Content-Type`="application/json", `Authorization`=format(format="Bearer %v", args=[thehive_key])),
 disable_ssl_security=DisableSSLVerify,
 method="POST",
 url=format(format="%v/api/alert", args=[TheHiveURL]))
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Alerts.TheHive.Case</title><link>https://docs.velociraptor.app/artifact_references/pages/server.alerts.thehive.case/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.alerts.thehive.case/</guid><description>&lt;p>Creates a TheHive case when monitored artifacts complete with results.&lt;/p>
&lt;p>Adds the ClientId, FlowId, and FQDN as tags to the case. Adds FQDN as an
observable.&lt;/p>
&lt;p>The artifact uses Server Metadata to store credentials, instead of storing
these directly in the artifact.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Alerts.TheHive.Case
description: |
 Creates a TheHive case when monitored artifacts complete with results.

 Adds the ClientId, FlowId, and FQDN as tags to the case. Adds FQDN as an
 observable.

 The artifact uses Server Metadata to store credentials, instead of storing
 these directly in the artifact.

type: SERVER_EVENT

author: Wes Lambert - @therealwlambert

reference:
 - https://gist.github.com/scudette/3a32abd19350c8fe3368661c4278869d

parameters:
 - name: TheHiveURL
 default: https://mythehive
 - name: VeloServerURL
 default: https://myvelo
 - name: ArtifactsToAlertOn
 default: .
 type: regex
 - name: DisableSSLVerify
 type: bool
 default: true

sources:
 - query: |
 LET thehive_key = if(
 condition=TheHiveKey,
 then=TheHiveKey,
 else=server_metadata().TheHiveKey)
 LET flow_info = SELECT timestamp(epoch=Timestamp) AS Timestamp,
 client_info(client_id=ClientId).os_info.fqdn AS FQDN,
 ClientId, FlowId, Flow.artifacts_with_results[0] AS FlowResults
 FROM watch_monitoring(artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactsToAlertOn

 LET cases = SELECT * FROM foreach(row=flow_info,
 query={
 SELECT FQDN, parse_json(data=Content)._id AS CaseID FROM http_client(
 data=serialize(item=dict(
 title=format(format="Hit on %v for %v", args=[FlowResults, FQDN]), description=format(format="ClientId: %v\n\nFlowID: %v\n\nURL: %v//app/index.html?#/collected/%v/%v", args=[ClientId, FlowId, VeloServerURL, ClientId, FlowId,]), tags=[ClientId,FlowId, FQDN]), format="json"),
 headers=dict(`Content-Type`="application/json", `Authorization`=format(format="Bearer %v", args=[thehive_key])),
 disable_ssl_security=DisableSSLVerify,
 method="POST",
 url=format(format="%v/api/case", args=[TheHiveURL]))
 })

 SELECT * from foreach(row=cases,
 query={
 SELECT * FROM http_client(
 data=serialize(item=dict(data=FQDN, dataType="fqdn", message=FQDN)),
 headers=dict(`Content-Type`="application/json", `Authorization`=format(format="Bearer %v", args=[thehive_key])),
 disable_ssl_security=DisableSSLVerify,
 method="POST",
 url=format(format="%v/api/case/%v/artifact", args=[TheHiveURL, CaseID]))
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Alerts.Trackaccount</title><link>https://docs.velociraptor.app/artifact_references/pages/server.alerts.trackaccount/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.alerts.trackaccount/</guid><description>&lt;p>This artifact alerts when account usage of a monitored account is detected. This is a server-side artifact, please note that it requires the client_event artifact &amp;lsquo;Windows.Events.Trackaccount&amp;rsquo; to be enabled.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Alerts.Trackaccount
description: |
 This artifact alerts when account usage of a monitored account is detected. This is a server-side artifact, please note that it requires the client_event artifact 'Windows.Events.Trackaccount' to be enabled.

author: Jos Clephas - @DfirJos

type: SERVER_EVENT

parameters:
 - name: SlackToken
 description: The token URL obtained from Slack/Teams/Discord (or basicly any communication-service that supports webhooks). Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
 - query: |
 LET token_url = if(
 condition=SlackToken,
 then=SlackToken,
 else=server_metadata().SlackToken)

 LET hits = SELECT * from watch_monitoring(artifact='Windows.Events.Trackaccount')

 SELECT * FROM foreach(row=hits,
 query={
 SELECT EventRecordID, EventID, TargetUserName, TargetWorkstationName, SourceComputer, LogonType, EventTime, ClientId, Url, Content, Response FROM http_client(
 data=serialize(item=dict(
 text=format(format="EventID: %v - Account '%v' authenticated from system '%v' to '%v' with LogonType %v at %v on client %v (EventRecordID: %v)",
 args=[EventID, TargetUserName, TargetWorkstationName, SourceComputer, LogonType, EventTime, ClientId, EventRecordID])),
 format="json"),
 headers=dict(`Content-Type`="application/json"),
 method="POST",
 url=token_url)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Alerts.WinPmem</title><link>https://docs.velociraptor.app/artifact_references/pages/server.alerts.winpmem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.alerts.winpmem/</guid><description>&lt;p>Send an email if the pmem service has been installed on any of the
endpoints.&lt;/p>
&lt;p>Note this requires that the Windows.Event.ServiceCreation
monitoring artifact be collected from clients.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Alerts.WinPmem
description: |
 Send an email if the pmem service has been installed on any of the
 endpoints.

 Note this requires that the Windows.Event.ServiceCreation
 monitoring artifact be collected from clients.

type: SERVER_EVENT

parameters:
 - name: EmailAddress
 default: admin@example.com
 - name: SkipVerify
 type: bool
 description: If set we skip TLS verification.

sources:
 - query: |
 SELECT * FROM foreach(
 row={
 SELECT * from watch_monitoring(
 artifact='Windows.Events.ServiceCreation')
 WHERE ServiceName =~ 'pmem'
 },
 query={
 SELECT * FROM mail(
 to=EmailAddress,
 subject='Pmem launched on host',
 period=60,
 skip_verify=SkipVerify,
 body=format(
 format="WinPmem execution detected at %s for client %v",
 args=[Timestamp, ClientId]
 )
 )
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Audit.Logs</title><link>https://docs.velociraptor.app/artifact_references/pages/server.audit.logs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.audit.logs/</guid><description>&lt;p>This internal event artifact collects relevant audit events from the
server. Audit events are significant auditable actions that a user
takes, for example, starting a new collection, creating a new hunt,
updating an artifact definition etc.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Audit.Logs
description: |
 This internal event artifact collects relevant audit events from the
 server. Audit events are significant auditable actions that a user
 takes, for example, starting a new collection, creating a new hunt,
 updating an artifact definition etc.

type: SERVER_EVENT

&lt;/code>&lt;/pre></description></item><item><title>Server.Enrichment.CortexAnalyzer</title><link>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.cortexanalyzer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.cortexanalyzer/</guid><description>&lt;p>Run Cortex analyzer jobs across all enabled and applicable analyzers (based on supported analyzer data types), then retrieve the results.&lt;/p>
&lt;p>This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.&lt;/p>
&lt;p>Ex.&lt;/p>
&lt;p>&lt;code>SELECT * from Artifact.Server.Enrichment.CortexAnalyzer(Observable=$YOURHASH, ObservableType='hash')&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Enrichment.CortexAnalyzer
description: |
 Run Cortex analyzer jobs across all enabled and applicable analyzers (based on supported analyzer data types), then retrieve the results.

 This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

 Ex.

 `SELECT * from Artifact.Server.Enrichment.CortexAnalyzer(Observable=$YOURHASH, ObservableType='hash')`

reference:
 - https://github.com/TheHive-Project/Cortex

author: Wes Lambert - @therealwlambert

type: SERVER

parameters:
 - name: Observable
 description: Data to be analyzed by Cortex
 default:
 - name: ObservableType
 description: Type of observable to be submitted to Cortex. Ex. `hash`, `domain`, `ip`
 default:
 - name: TLP
 description: TLP for the job submitted to Cortex
 default: 0
 - name: CortexURL
 description: URL used for Cortex job submission. We recommend using the &amp;lt;a href="#/host/server"&amp;gt;server metadata store&amp;lt;/a&amp;gt; for this.
 default: ''
 - name: CortexKey
 description: API key used for authentication to Cortex. We recommend using the &amp;lt;a href="#/host/server"&amp;gt;server metadata store&amp;lt;/a&amp;gt; for this.
 default: ''
 - name: DisableSSLVerify
 type: bool
 description: Disable SSL Verification
 default: True
 - name: JobMessage
 description: Message to be used when running analyzer job
 default: Job submmitted by Velociraptor
 - name: JobWaitTime
 description: Amount of time to wait for a report from Cortex.
 default: 10minute

sources:
 - query: |
 LET OBSERVABLE &amp;lt;= Observable
 LET OBSERVABLE_DATATYPE &amp;lt;= ObservableType
 LET URL &amp;lt;= if(
 condition=CortexURL,
 then=CortexURL,
 else=server_metadata().CortexURL)
 LET cortex_key =
 if(
 condition=CortexKey,
 then=CortexKey,
 else=server_metadata().CortexKey)
 LET ENABLED_ANALYZERS = SELECT Content FROM
 http_client(
 url=URL + '/analyzer',
 method='GET',
 disable_ssl_security=DisableSSLVerify,
 headers=dict(
 `Authorization`=format(format="Bearer %v", args=[cortex_key])))
 LET ANALYZERS_SUPPORTED = SELECT name AS AnalyzerName, id AS ID, dataTypeList AS DList FROM parse_json_array(data=ENABLED_ANALYZERS.Content)
 LET ANALYZERS_MATCH_TYPE = SELECT ID FROM foreach(row=ANALYZERS_SUPPORTED, query={ SELECT AnalyzerName, ID, _value AS Match FROM
 if(
 condition= filter(list=DList, regex=OBSERVABLE_DATATYPE),
 then="yes",
 else="no")}) WHERE Match = "yes"
 LET ANALYZER_RUN = SELECT parse_json(data=Content) AS Resp FROM
 http_client(
 url=URL + '/analyzer/'+ ID + '/run' ,
 method='POST',
 disable_ssl_security=DisableSSLVerify,
 headers=dict(
 `Content-Type`="application/json",
 `Authorization`=format(format="Bearer %v",
 args=[cortex_key])),
 data=serialize(item=dict(
 data=OBSERVABLE, dataType=OBSERVABLE_DATATYPE, tlp=TLP, message=JobMessage
 ))
 )
 LET JOBID = SELECT Resp.id AS JobID from foreach(row=ANALYZER_RUN)
 LET GETREPORT = SELECT Content AS Resp FROM
 http_client(
 url=format(format="%v/job/%v/waitreport?atMost=%v", args=[URL,JOBID.JobID[0], JobWaitTime]),
 method='GET',
 disable_ssl_security=DisableSSLVerify,
 headers=dict(
 `Content-Type`="application/json",
 `Authorization`=format(format="Bearer %v",
 args=[cortex_key])
 )
 )
 LET REPORT = SELECT parse_json(data=Resp) AS Details FROM GETREPORT
 SELECT Observable, Details.workerName as AnalyzerName, Details as _Details, Details.report AS Report FROM foreach(row=ANALYZERS_MATCH_TYPE, query={SELECT * FROM REPORT})

&lt;/code>&lt;/pre></description></item><item><title>Server.Enrichment.GeoIP</title><link>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.geoip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.geoip/</guid><description>&lt;p>This artifact can use the MaxMind database to Geo resolve an IP
address. You will need to provide a valid GeoIP database.&lt;/p>
&lt;p>You can obtain a free to use (gratis but not libre) database from
&lt;a href="https://www.maxmind.com/" target="_blank" >https://www.maxmind.com/&lt;/a>
 or you can pay for a more accurate option.&lt;/p>
&lt;p>After storing the database somewhere on your server, you should the
location in the server metadata screen to it under the key &amp;ldquo;GeoIPDB&amp;rdquo;
(for example &lt;code>/usr/shared/GeoLite2-City_20210803/GeoLite2-City.mmdb&lt;/code>)&lt;/p>
&lt;p>Alternatively you can import this artifact to gain access to the
utility functions (or just copy them into your own artifact).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Enrichment.GeoIP
description: |
 This artifact can use the MaxMind database to Geo resolve an IP
 address. You will need to provide a valid GeoIP database.

 You can obtain a free to use (gratis but not libre) database from
 https://www.maxmind.com/ or you can pay for a more accurate option.

 After storing the database somewhere on your server, you should the
 location in the server metadata screen to it under the key "GeoIPDB"
 (for example `/usr/shared/GeoLite2-City_20210803/GeoLite2-City.mmdb`)

 Alternatively you can import this artifact to gain access to the
 utility functions (or just copy them into your own artifact).

export: |
 LET DB = server_metadata().GeoIPDB
 LET Country(IP) = geoip(db=DB, ip=IP).country.names.en
 LET State(IP) = geoip(db=DB, ip=IP).subdivisions[0].names.en
 LET City(IP) = geoip(db=DB, ip=IP).city.names.en

parameters:
 - name: IP
 description: An IP to lookup

type: SERVER

sources:
 - query: |
 SELECT Country(IP=_value) AS Country,
 State(IP=_value) AS State,
 City(IP=_value) AS City
 FROM foreach(row=IP)

&lt;/code>&lt;/pre></description></item><item><title>Server.Enrichment.GeoIPISP</title><link>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.geoipisp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.geoipisp/</guid><description>&lt;p>Look up geo-information for an IP address using the MaxMind &amp;ldquo;GeoIP ISP&amp;rdquo;
database.&lt;/p>
&lt;p>You can obtain a free-to-use (gratis but not libre) database from
&lt;a href="https://www.maxmind.com/" target="_blank" >https://www.maxmind.com/&lt;/a>
 or you can pay for a more accurate option.&lt;/p>
&lt;p>You will need to provide the path to a valid GeoIP ISP database located on
your server. The artifact expects you to store the database location in the
server metadata, under the metadata key &amp;ldquo;GeoIPISPDB&amp;rdquo; (for example
&lt;code>/usr/shared/GeoIP2-City_20210910/GeoIP2-ISP.mmdb&lt;/code>).&lt;/p>
&lt;p>Although you can collect this artifact directly, it is more likely that you
would import this artifact from your own artifact to gain access to the
utility lookup functions.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Enrichment.GeoIPISP
description: |
 Look up geo-information for an IP address using the MaxMind "GeoIP ISP"
 database.

 You can obtain a free-to-use (gratis but not libre) database from
 https://www.maxmind.com/ or you can pay for a more accurate option.

 You will need to provide the path to a valid GeoIP ISP database located on
 your server. The artifact expects you to store the database location in the
 server metadata, under the metadata key "GeoIPISPDB" (for example
 `/usr/shared/GeoIP2-City_20210910/GeoIP2-ISP.mmdb`).

 Although you can collect this artifact directly, it is more likely that you
 would import this artifact from your own artifact to gain access to the
 utility lookup functions.

export: |
 LET ISPDB = server_metadata().GeoIPISPDB
 LET ISP(IP) = geoip(db=ISPDB, ip=IP).isp
 LET ORG(IP) = geoip(db=ISPDB, ip=IP).organization
 LET ASN(IP) = geoip(db=ISPDB, ip=IP).autonomous_system_number
 LET ASO(IP) = geoip(db=ISPDB, ip=IP).autonomous_system_organization

parameters:
 - name: IP
 description: An IP to lookup

type: SERVER

sources:
 - query: |
 SELECT ISP(IP=_value) AS ISP,
 ORG(IP=_value) AS Organization,
 ASN(IP=_value) AS ASN,
 ASO(IP=_value) AS ASO
 FROM foreach(row=IP)

&lt;/code>&lt;/pre></description></item><item><title>Server.Enrichment.GreyNoise</title><link>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.greynoise/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.greynoise/</guid><description>&lt;p>Submit an IP to the GreyNoise API.&lt;/p>
&lt;p>&lt;a href="https://developer.greynoise.io/reference/community-api" target="_blank" >https://developer.greynoise.io/reference/community-api&lt;/a>
&lt;/p>
&lt;p>This is a rather simple artifact that can be called from within another artifact (such as one looking for network connections) to enrich the data made available by that artifact.&lt;/p>
&lt;p>Ex.&lt;/p>
&lt;p>&lt;code>SELECT * from Artifact.Server.Enrichment.GreyNoise(IP=$YOURIP)&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Enrichment.GreyNoise
author: Wes Lambert -- @therealwlambert
description: |
 Submit an IP to the GreyNoise API.

 https://developer.greynoise.io/reference/community-api

 This is a rather simple artifact that can be called from within another artifact (such as one looking for network connections) to enrich the data made available by that artifact.

 Ex.

 `SELECT * from Artifact.Server.Enrichment.GreyNoise(IP=$YOURIP)`


type: SERVER

parameters:
 - name: IP
 type: string
 description: The IP to submit to GreyNoise.
 default:
 - name: ApiKey
 type: string
 description: The API key to submit to GreyNoise.
 default: ''
 - name: AccountType
 type: choices
 description: The GreyNoise account type - enterprise or community.
 default: community
 choices:
 - community
 - enterprise
 - name: CommunityURL
 type: string
 description: The GreyNoise community API URL.
 default: https://api.greynoise.io/v3/community/
 - name: EnterpriseURL
 type: string
 description: The GreyNoise enterprise API URL.
 default: https://api.greynoise.io/v2/noise/quick/

sources:
 - query: |
 LET URL &amp;lt;= if(condition= AccountType='community', then=CommunityURL, else=EnterpriseURL)

 LET Data = if(condition= ApiKey!='', 
 then={
 SELECT parse_json(data=Content) AS GreyNoiseLookup
 FROM http_client(url=URL + IP, headers=dict(`Accept`="application/json",`key`=ApiKey), method='GET')
 }, else={
 SELECT parse_json(data=Content) AS GreyNoiseLookup
 FROM http_client(url=URL + IP, headers=dict(`Accept`="application/json"), method='GET')
 })

 SELECT
 GreyNoiseLookup.ip AS IP,
 GreyNoiseLookup.classification AS Classification,
 GreyNoiseLookup.name AS Name,
 GreyNoiseLookup.riot AS Riot,
 GreyNoiseLookup.noise AS Noise,
 GreyNoiseLookup.last_seen AS LastSeen,
 GreyNoiseLookup.link AS Link,
 GreyNoiseLookup AS _GreyNoiseLookup
 FROM Data

&lt;/code>&lt;/pre></description></item><item><title>Server.Enrichment.HybridAnalysis</title><link>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.hybridanalysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.hybridanalysis/</guid><description>&lt;p>Submit a file hash to Hybrid Analysis for a verdict. Default free API restriction is 200 requests/min or 2000 requests/hour.&lt;/p>
&lt;p>This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.&lt;/p>
&lt;p>Ex.&lt;/p>
&lt;p>&lt;code>SELECT * from Artifact.Server.Enrichment.HybridAnalysis(Hash=$YOURHASH)&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Enrichment.HybridAnalysis
author: Wes Lambert -- @therealwlambert
description: |
 Submit a file hash to Hybrid Analysis for a verdict. Default free API restriction is 200 requests/min or 2000 requests/hour.

 This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

 Ex.

 `SELECT * from Artifact.Server.Enrichment.HybridAnalysis(Hash=$YOURHASH)`

type: SERVER

parameters:
 - name: Hash
 type: string
 description: The file hash to submit to Hybrid Analysis (MD5, SHA1, SHA256).
 default:

 - name: HybridAnalysisKey
 type: string
 description: API key for Hybrid Analysis. Leave blank here if using server metadata store.
 default:

 - name: UserAgent
 type: string
 description: Name of the user agent used for submitting hashes.
 default: Velociraptor

sources:
 - query: |
 LET Creds = if(
 condition=HybridAnalysisKey,
 then=HybridAnalysisKey,
 else=server_metadata().HybridAnalysisKey)

 LET URL &amp;lt;= 'https://hybrid-analysis.com/api/v2/search/hash'

 LET Data = SELECT parse_json_array(data=Content) as Content
 FROM http_client(
 url=URL,
 headers=dict(`api-key`=Creds,
 `user-agent`=UserAgent,
 `Content-Type`="application/x-www-form-urlencoded"),
 params=dict(hash=Hash),
 method='POST')

 SELECT * from foreach (
 row=Data,
 query={
 SELECT Content as _Content,
 Content.verdict[0] as Verdict
 FROM scope()
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Enrichment.Virustotal</title><link>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.virustotal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.enrichment.virustotal/</guid><description>&lt;p>Submit a file hash or IP to VirusTotal for details.&lt;/p>
&lt;p>Note that the default public API rate limit is 4 requests/min.&lt;/p>
&lt;p>This artifact can be called from within another artifact (such as one looking
for files) to enrich the data made available by that artifact.&lt;/p>
&lt;p>Example:&lt;/p>
&lt;p>&lt;code>SELECT * from Artifact.Server.Enrichment.Virustotal(Hash=$YOURHASH)&lt;/code>
&lt;code>SELECT * from Artifact.Server.Enrichment.Virustotal(IP=$YOURIP,QueryType='ip')&lt;/code>&lt;/p>
&lt;p>TODO: Implement a timer to spread out requests&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Enrichment.Virustotal
author: Wes Lambert -- @therealwlambert, Whitney Champion -- @shortxstack
description: |
 Submit a file hash or IP to VirusTotal for details.

 Note that the default public API rate limit is 4 requests/min.

 This artifact can be called from within another artifact (such as one looking
 for files) to enrich the data made available by that artifact.

 Example:

 `SELECT * from Artifact.Server.Enrichment.Virustotal(Hash=$YOURHASH)`
 `SELECT * from Artifact.Server.Enrichment.Virustotal(IP=$YOURIP,QueryType='ip')`

 TODO: Implement a timer to spread out requests

type: SERVER

parameters:
 - name: QueryType
 type: choices
 description: The type of query--hash or IP
 default: hash
 choices:
 - hash
 - ip

 - name: Hash
 type: string
 description: The file hash to submit to Hybrid Analysis (MD5, SHA1, SHA256).
 default:

 - name: IP
 type: string
 description: The IP address to submit to Hybrid Analysis.
 default:

 - name: VirustotalKey
 type: string
 description: API key for Virustotal. Leave blank here if using server metadata store.
 default:

sources:
 - query: |
 LET Creds = if(
 condition=VirustotalKey,
 then=VirustotalKey,
 else=server_metadata().VirustotalKey)

 LET URL = if(
 condition= QueryType='hash',
 then= 'https://www.virustotal.com/api/v3/files/' + Hash,
 else= 'https://www.virustotal.com/api/v3/ip_addresses/' + IP)

 LET Data = SELECT parse_json(data=Content) AS VTData
 FROM http_client(url=URL, headers=dict(`x-apikey`=Creds))

 SELECT format(format='%v/%v',
 args=[VTData.data.attributes.last_analysis_stats.malicious,
 VTData.data.attributes.last_analysis_stats.malicious +
 VTData.data.attributes.last_analysis_stats.undetected]) As VTRating,
 timestamp(epoch=VTData.data.attributes.first_seen_itw_date) AS FirstSeen,
 timestamp(epoch=VTData.data.attributes.first_submission_date) AS FirstSubmitted,
 timestamp(epoch=VTData.data.attributes.last_analysis_date) AS LastAnalysis,
 VTData.data.attributes.as_owner AS Owner,
 VTData.data.attributes.whois AS WhoIs,
 VTData.data.attributes.crowdsourced_yara_results AS YARAResults,
 VTData AS _Data
 FROM Data

&lt;/code>&lt;/pre></description></item><item><title>Server.Hunts.AddFlow</title><link>https://docs.velociraptor.app/artifact_references/pages/server.hunts.addflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.hunts.addflow/</guid><description>&lt;p>This artifact adds an existing flow to a running hunt.&lt;/p>
&lt;p>This helps in the case where the original flow in the hunt timed
out. The user then can re-run the hunt manually possibly increasing
timeout. Then they can simply click the add flow to hunt button in
the UI to add the flow to an existing time.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Hunts.AddFlow
description: |
 This artifact adds an existing flow to a running hunt.

 This helps in the case where the original flow in the hunt timed
 out. The user then can re-run the hunt manually possibly increasing
 timeout. Then they can simply click the add flow to hunt button in
 the UI to add the flow to an existing time.

type: SERVER

parameters:
 - name: HuntId
 - name: ClientId
 - name: FlowId

sources:
 - query: |
 SELECT * FROM if(condition=HuntId AND ClientId AND FlowId,
 then={
 SELECT hunt_add(hunt_id=HuntId,
 client_id=ClientId,
 flow_id=FlowId)
 FROM scope()
 }, else={
 SELECT * FROM scope() WHERE
 log(message="&amp;lt;red&amp;gt;ERROR&amp;lt;/&amp;gt;: You must set HuntId, ClientId and FlowId.") AND FALSE
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Hunts.CancelAndDelete</title><link>https://docs.velociraptor.app/artifact_references/pages/server.hunts.cancelanddelete/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.hunts.cancelanddelete/</guid><description>&lt;p>Velociraptor Hunts are a way of running the same flow on
many endpoints at once. Hunts issue very quickly and wait
until each endpoint returns results.&lt;/p>
&lt;p>Sometimes, the artifacts collected might take a long time and
have unacceptable performance impact on the endpoint.
In some cases the artifacts end up retrieving too much data
that is not needed.&lt;/p>
&lt;p>For those cases you might want to run the following server
artifact. It cancels all currently in-flight collections.&lt;/p>
&lt;p>Optionally you can also remove any files already collected if you
do not need them.&lt;/p>
&lt;p>This artifact is implicitly collected by the GUI when pressing the
&amp;ldquo;Delete Hunt&amp;rdquo; Button.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Hunts.CancelAndDelete
description: |
 Velociraptor Hunts are a way of running the same flow on
 many endpoints at once. Hunts issue very quickly and wait
 until each endpoint returns results.

 Sometimes, the artifacts collected might take a long time and
 have unacceptable performance impact on the endpoint.
 In some cases the artifacts end up retrieving too much data
 that is not needed.

 For those cases you might want to run the following server
 artifact. It cancels all currently in-flight collections.

 Optionally you can also remove any files already collected if you
 do not need them.

 This artifact is implicitly collected by the GUI when pressing the
 "Delete Hunt" Button.

type: SERVER

parameters:
 - name: HuntId
 description: hunt_id you would like to kill all associated flows.

 - name: Hunts
 type: json_array
 description: A list of hunt ids to delete
 default: '[]'

 - name: DeleteAllFiles
 description: Also delete all collected files
 type: bool

sources:
 - name: CancelFlows
 query: |
 SELECT * FROM Artifact.Server.Utils.CancelHunt(Hunts=Hunts)

 - name: HuntFiles
 query: |
 LET AllHunts &amp;lt;= if(condition=HuntId, then=Hunts + HuntId, else=Hunts)

 SELECT * FROM foreach(row={
 SELECT _value as HuntId FROM items(item=AllHunts)
 }, query={
 SELECT *
 FROM hunt_delete(hunt_id=HuntId, really_do_it=DeleteAllFiles)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Hunts.List</title><link>https://docs.velociraptor.app/artifact_references/pages/server.hunts.list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.hunts.list/</guid><description>&lt;p>List Hunts currently scheduled on the server.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Hunts.List
description: |
 List Hunts currently scheduled on the server.

type: SERVER

sources:
 - query: |
 SELECT hunt_id,
 timestamp(epoch=create_time) as Created,
 join(array=start_request.artifacts, sep=",") as Artifact,
 state
 FROM hunts()

&lt;/code>&lt;/pre></description></item><item><title>Server.Hunts.Results</title><link>https://docs.velociraptor.app/artifact_references/pages/server.hunts.results/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.hunts.results/</guid><description>&lt;p>Show the results from each artifact collection hunt.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Hunts.Results
description: |
 Show the results from each artifact collection hunt.
parameters:
 - name: huntId
 default: H.d05b2482
 - name: ArtifactName
 default: Linux.Mounts

type: SERVER

sources:
 - query: |
 SELECT * FROM hunt_results(hunt_id=huntId, artifact=ArtifactName)

&lt;/code>&lt;/pre></description></item><item><title>Server.Import.ArtifactExchange</title><link>https://docs.velociraptor.app/artifact_references/pages/server.import.artifactexchange/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.import.artifactexchange/</guid><description>&lt;p>This artifact will automatically import the latest artifact
exchange bundle into the current server.&lt;/p>
&lt;h2 id="security-note">Security note&lt;/h2>
&lt;p>The artifact exchange is not officially supported by the
Velociraptor team and contains contributions from the
community. The quality, security and stability of artifacts from
the exchange is not guaranteed. Some artifacts from the exchange
will fetch external binaries and run them on your endpoints! These
binaries are not reviewed or endorsed by the Velociraptor team or
Rapid7!&lt;/p>
&lt;p>Contributions to the exchange must meet a lower quality bar than
built-in artifacts (for example lacking tests), which means that
they may break at any time or not work as described!&lt;/p>
&lt;p>Collecting any of the artifacts in the exchange is purely at your
own risk!.&lt;/p>
&lt;p>We strongly suggest users review exchange artifacts carefully
before deploying them on their network!&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Import.ArtifactExchange
description: |
 This artifact will automatically import the latest artifact
 exchange bundle into the current server.

 ## Security note

 The artifact exchange is not officially supported by the
 Velociraptor team and contains contributions from the
 community. The quality, security and stability of artifacts from
 the exchange is not guaranteed. Some artifacts from the exchange
 will fetch external binaries and run them on your endpoints! These
 binaries are not reviewed or endorsed by the Velociraptor team or
 Rapid7!

 Contributions to the exchange must meet a lower quality bar than
 built-in artifacts (for example lacking tests), which means that
 they may break at any time or not work as described!

 Collecting any of the artifacts in the exchange is purely at your
 own risk!.

 We strongly suggest users review exchange artifacts carefully
 before deploying them on their network!

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
 - name: ExchangeURL
 default: https://github.com/Velocidex/velociraptor-docs/raw/gh-pages/exchange/artifact_exchange_v2.zip
 - name: ArchiveGlob
 default: "/**/*.{yaml,yml}"
 - name: Tag
 description: |
 Tag artifacts with this tag.

 This applied in addition to any tags contained in the artifact
 description.
 default: "Exchange"

export: |
 LET _Tags(Data) = SELECT * FROM foreach(row={
 SELECT * FROM parse_lines(accessor="data", filename=Data, buffer_size=10000000)
 WHERE Line =~ '''^\s*tags:'''
 }, query={
 SELECT * FROM parse_records_with_regex(
 accessor="data", file=Line, regex="#(?P&amp;lt;Tag&amp;gt;[^ ]+)")
 })

 LET Tags(Data) = _Tags(Data=Data).Tag

sources:
 - query: |
 LET X = SELECT artifact_set(
 definition=Definition,
 tags=(Tag,) + Tags(Data=Definition) ) AS Definition
 FROM foreach(row={
 SELECT Content FROM http_client(
 remove_last=TRUE,
 tempfile_extension=".zip", url=ExchangeURL)
 }, query={
 SELECT read_file(accessor="zip", filename=OSPath) AS Definition
 FROM glob(
 globs=ArchiveGlob,
 root=pathspec(
 DelegateAccessor="auto",
 DelegatePath=Content),
 accessor="zip")
 })

 SELECT Definition.name AS Name,
 Definition.description AS Description,
 Definition.author AS Author
 FROM X

&lt;/code>&lt;/pre></description></item><item><title>Server.Import.Extras</title><link>https://docs.velociraptor.app/artifact_references/pages/server.import.extras/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.import.extras/</guid><description>&lt;p>This artifact imports additional artifacts maintained outside the
Velociraptor tree.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://sigma.velocidex.com/" target="_blank" >The Velociraptor Sigma Project&lt;/a>
&lt;/li>
&lt;li>&lt;a href="https://docs.velociraptor.app/exchange/" target="_blank" >The Artifact Exchange&lt;/a>
&lt;/li>
&lt;li>&lt;a href="https://github.com/rapid7/Rapid7-Labs" target="_blank" >Rapid7 Labs&lt;/a>
&lt;/li>
&lt;li>&lt;a href="https://registry-hunter.velocidex.com/" target="_blank" >The Registry Hunter&lt;/a>
&lt;/li>
&lt;li>&lt;a href="https://sqlitehunter.velocidex.com/" target="_blank" >The SQLite Hunter&lt;/a>
&lt;/li>
&lt;li>&lt;a href="https://triage.velocidex.com/" target="_blank" >The Triage Artifacts&lt;/a>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Server.Import.Extras
description: |
 This artifact imports additional artifacts maintained outside the
 Velociraptor tree.

 * [The Velociraptor Sigma Project](https://sigma.velocidex.com/)
 * [The Artifact Exchange](https://docs.velociraptor.app/exchange/)
 * [Rapid7 Labs](https://github.com/rapid7/Rapid7-Labs)
 * [The Registry Hunter](https://registry-hunter.velocidex.com/)
 * [The SQLite Hunter](https://sqlitehunter.velocidex.com/)
 * [The Triage Artifacts](https://triage.velocidex.com/)

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
 - name: Details
 type: csv
 default: |
 Name,Tag,URL
 The Velociraptor Sigma Project,Extras,https://sigma.velocidex.com/Velociraptor.Sigma.Artifacts.zip
 Artifact Exchange,Exchange,https://github.com/Velocidex/velociraptor-docs/raw/gh-pages/exchange/artifact_exchange_v2.zip
 Rapid7Labs,Exchange,https://github.com/rapid7/Rapid7-Labs/raw/main/Vql/release/Rapid7LabsVQL.zip
 The Registry Hunter,Extras,https://registry-hunter.velocidex.com/Windows.Registry.Hunter.zip
 The SQLiteHunter,Extras,https://sqlitehunter.velocidex.com/SQLiteHunter.zip
 The Triage Artifacts,Extras,https://triage.velocidex.com/artifacts/Velociraptor_Triage_v0.1.zip

sources:
 - query: |
 SELECT * FROM foreach(row=Details,
 query={
 SELECT * FROM Artifact.Server.Import.ArtifactExchange(ExchangeURL=URL, Tag=Tag)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Import.PreviousReleases</title><link>https://docs.velociraptor.app/artifact_references/pages/server.import.previousreleases/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.import.previousreleases/</guid><description>&lt;p>When upgrading the Velociraptor server, the built-in artifacts may change and
use newer VQL features that are not present in older clients.&lt;/p>
&lt;p>If you have some older clients that cannot be upgraded, sometimes collection
of updated built-in artifacts will fail due to incompatibility. In such
situations it is necessary to import older VQL artifacts that will work with
these older clients.&lt;/p>
&lt;p>This server artifact allows you to automatically import all artifacts that
came bundled with previous versions. These should be compatible with older
clients, but may lack newer features and improvements that the latest
artifacts have.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Import.PreviousReleases
description: |
 When upgrading the Velociraptor server, the built-in artifacts may change and
 use newer VQL features that are not present in older clients.

 If you have some older clients that cannot be upgraded, sometimes collection
 of updated built-in artifacts will fail due to incompatibility. In such
 situations it is necessary to import older VQL artifacts that will work with
 these older clients.

 This server artifact allows you to automatically import all artifacts that
 came bundled with previous versions. These should be compatible with older
 clients, but may lack newer features and improvements that the latest
 artifacts have.

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
 - name: VelociraptorRelease
 description: |
 The Velociraptor Release to import.
 type: choices
 default: v0.74
 choices:
 - v0.72
 - v0.73
 - v0.74

sources:
 - query: |
 LET Prefix &amp;lt;= regex_replace(source=VelociraptorRelease, re='\\.', replace="") + "."
 LET ExchangeURL = "https://docs.velociraptor.app/release_artifacts/release_artifacts_" + VelociraptorRelease + ".zip"

 LET X = SELECT artifact_set(
 prefix=Prefix, tags=VelociraptorRelease,
 definition=Definition) AS Definition
 FROM foreach(row={
 SELECT Content FROM http_client(
 remove_last=TRUE,
 tempfile_extension=".zip", url=ExchangeURL)
 }, query={
 -- Replace internal references to use the same version so
 -- artifacts are still internally consistent.
 SELECT regex_replace(source=read_file(accessor="zip", filename=OSPath),
 re='''(?sm) Artifact\.([a-z0-9._]+?[(])''',
 replace=" Artifact." + Prefix + "$1") AS Definition
 FROM glob(
 globs='/**/*.yaml',
 root=pathspec(
 DelegateAccessor="auto",
 DelegatePath=Content),
 accessor="zip")
 WHERE NOT Definition =~ "(?ms)type: +INTERNAL"
 })

 SELECT Definition.name AS Name,
 Definition.description AS Description,
 Definition.author AS Author
 FROM X

&lt;/code>&lt;/pre></description></item><item><title>Server.Information.Clients</title><link>https://docs.velociraptor.app/artifact_references/pages/server.information.clients/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.information.clients/</guid><description>&lt;p>This artifact returns the total list of clients, their hostnames and
the last times they were seen.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Information.Clients
description: |
 This artifact returns the total list of clients, their hostnames and
 the last times they were seen.

type: SERVER

sources:
 - query: |
 SELECT client_id,
 os_info.fqdn as HostName,
 os_info.system as OS,
 os_info.release as Release,
 timestamp(epoch=last_seen_at/ 1000000).String as LastSeenAt,
 last_ip AS LastIP,
 last_seen_at AS _LastSeenAt
 FROM clients()
 ORDER BY _LastSeenAt DESC

&lt;/code>&lt;/pre></description></item><item><title>Server.Information.Users</title><link>https://docs.velociraptor.app/artifact_references/pages/server.information.users/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.information.users/</guid><description>&lt;p>List the user names and SIDs on each machine. We get this
information from the last time we collected Windows.Sys.Users. If we
never collected it for this machine, there will be no results.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Information.Users
description: |
 List the user names and SIDs on each machine. We get this
 information from the last time we collected Windows.Sys.Users. If we
 never collected it for this machine, there will be no results.

type: SERVER

parameters:
 - name: StandardUserAccounts
 description: Well known SIDs to hide from the output.
 default: "(-5..$|S-1-5-18|S-1-5-19|S-1-5-20)"
 type: regex

sources:
 - query: |
 LET clients = SELECT client_id, os_info.fqdn AS Fqdn FROM clients()

 // Get the most recent collection of our user listing.
 LET last_user_listing = SELECT
 session_id AS flow_id,
 active_time, client_id, Fqdn
 FROM flows(client_id=client_id)
 WHERE artifacts_with_results =~'Windows.Sys.Users'
 ORDER BY active_time
 DESC LIMIT 1

 /* For each Windows.Sys.Users collection, extract the user
 names, but hide standard SIDs.
 */
 LET users = SELECT * FROM foreach(
 row=last_user_listing,
 query={
 SELECT Name, UUID, client_id, Fqdn from source(
 flow_id=flow_id,
 artifact='Windows.Sys.Users',
 client_id=client_id)
 WHERE NOT UUID =~ StandardUserAccounts
 })

 SELECT * FROM foreach(row=clients, query=users)

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Alerts</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.alerts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.alerts/</guid><description>&lt;p>An internal event queue for alerts. All alerts sent from clients are
collected in this event queue.&lt;/p>
&lt;p>Alerts are expected to be low frequency and high value and may be
generated client or server side.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Alerts
description: |
 An internal event queue for alerts. All alerts sent from clients are
 collected in this event queue.

 Alerts are expected to be low frequency and high value and may be
 generated client or server side.

type: SERVER_EVENT

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ArtifactDescription</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.artifactdescription/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.artifactdescription/</guid><description>&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ArtifactDescription

type: INTERNAL

reports:
 - type: INTERNAL
 template: |
 {{ $artifact := Scope "artifact" }}

 ## {{ $artifact.Name }}

 #### Type: {{ $artifact.Type }}

 {{ if $artifact.BuiltIn }}
 {{ else }}
 ##### Custom Artifact
 {{ end }}

 {{ if and $artifact.Metadata $artifact.Metadata.Tags }}
 ##### Tags

 {{ range $i, $t := $artifact.Metadata.Tags }}
 * {{ $t }}
 {{ end }}

 {{ end }}

 {{ if $artifact.Author }}
 ##### Author: {{ $artifact.Author }}
 {{end}}

 {{ if $artifact.Description }}

 &amp;lt;div class="description-content"&amp;gt;

 {{ $artifact.Description }}

 {{ if $artifact.Reference }}
 ---
 References:
 &amp;lt;ul&amp;gt;
 {{- range $item := $artifact.Reference -}}
 &amp;lt;li&amp;gt;{{ $item }}&amp;lt;/li&amp;gt;
 {{- end -}}
 &amp;lt;/ul&amp;gt;
 {{ end }}
 &amp;lt;/div&amp;gt;

 {{ end }}

 {{ if $artifact.Tools }}
 ### Tools

 {{ range $artifact.Tools -}}
 * &amp;lt;velo-tool-viewer name="{{.Name}}" version="{{.Version}}"&amp;gt;&amp;lt;/velo-tool-viewer&amp;gt;
 {{ end }}

 {{ end }}

 {{ if $artifact.Parameters }}

 ### Parameters

 &amp;lt;table class="table table-striped"&amp;gt;
 &amp;lt;thead&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;th&amp;gt;Name&amp;lt;/th&amp;gt;
 &amp;lt;th&amp;gt;Type&amp;lt;/th&amp;gt;
 &amp;lt;th&amp;gt;Default&amp;lt;/th&amp;gt;
 &amp;lt;th&amp;gt;Description&amp;lt;/th&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;/thead&amp;gt;
 &amp;lt;tbody&amp;gt;
 {{- range $item := $artifact.Parameters -}}
 {{- if not (eq $item.Type "hidden") -}}
 &amp;lt;tr&amp;gt;
 &amp;lt;td&amp;gt;{{ $item.Name }}&amp;lt;/td&amp;gt;
 &amp;lt;td&amp;gt;{{ $item.Type }}&amp;lt;/td&amp;gt;
 &amp;lt;td&amp;gt;&amp;lt;pre&amp;gt;{{ $item.Default }}&amp;lt;/pre&amp;gt;&amp;lt;/td&amp;gt;
 &amp;lt;td&amp;gt;{{ $item.Description }}&amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 {{- end -}}
 {{- end -}}
 &amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;

 {{ end }}

 {{ if $artifact.Imports }}

 &amp;lt;table class="table table-striped"&amp;gt;
 &amp;lt;thead&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;th&amp;gt;Imports&amp;lt;/th&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;/thead&amp;gt;
 &amp;lt;tbody&amp;gt;
 {{- range $item := $artifact.Imports -}}
 &amp;lt;tr&amp;gt;
 &amp;lt;td&amp;gt;{{ $item }}&amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 {{- end -}}
 &amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;

 {{ end }}

 {{ if $artifact.Export }}
 ### Exports

 ```vql
 {{ $artifact.Export }}
 ```
 {{ end }}

 {{ range $source := $artifact.Sources }}

 {{ if or $source.Queries $source.Query $source.Notebook }}

 ### Source {{ $source.Name }}

 {{ if $source.Query }}

 ```vql
 {{ $source.Query }}
 ```

 {{- else if $source.Queries -}}

 ```vql
 {{ range $query := $source.Queries -}}
 {{- $query -}}
 {{ end }}
 ```

 {{ end }}

 {{ if len $source.Notebook }}

 #### Notebook cells

 {{ range $notebook := $source.Notebook }}

 {{ if $notebook.Name }}
 * `{{ $notebook.Type }}`: {{ $notebook.Name }}
 {{ else }}
 * `{{ $notebook.Type }}`
 {{ end }}
 {{ end }}

 {{ end }}

 {{ end }}

 {{ end }}

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ArtifactModification</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.artifactmodification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.artifactmodification/</guid><description>&lt;p>This event artifact is an internal event stream over which
notifications of artifact modifications are sent. Interested parties
can watch for new artifact modification events and rebuild caches
etc.&lt;/p>
&lt;p>Note: This is an automated system artifact. You do not need to start it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ArtifactModification
description: |
 This event artifact is an internal event stream over which
 notifications of artifact modifications are sent. Interested parties
 can watch for new artifact modification events and rebuild caches
 etc.

 Note: This is an automated system artifact. You do not need to start it.

type: SERVER_EVENT

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ClientConflict</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientconflict/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientconflict/</guid><description>&lt;p>This event artifact is an internal event stream receiving events
about client conflict.&lt;/p>
&lt;p>When two clients attempt to connect to the server with the same
client id, the server rejects one of these with a 409 Conflict HTTP
message. The client id will be forwarded on this artifact as well so
the server may take action.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ClientConflict
description: |
 This event artifact is an internal event stream receiving events
 about client conflict.

 When two clients attempt to connect to the server with the same
 client id, the server rejects one of these with a 409 Conflict HTTP
 message. The client id will be forwarded on this artifact as well so
 the server may take action.

type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ClientDelete</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientdelete/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientdelete/</guid><description>&lt;p>An internal queue that receives events when a client is deleted.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ClientDelete
description: |
 An internal queue that receives events when a client is deleted.

type: SERVER_EVENT

column_types:
 - name: ClientId
 description: The client that was deleted.
 - name: Principal
 description: The principal who initiated the deletion.

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ClientInfo</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientinfo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientinfo/</guid><description>&lt;p>An internal artifact collecting client information. This is used to
update the client info indexes. Client send this automatically at
startup and then every day.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ClientInfo
type: INTERNAL
description: |
 An internal artifact collecting client information. This is used to
 update the client info indexes. Client send this automatically at
 startup and then every day.

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ClientInfoSnapshot</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientinfosnapshot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientinfosnapshot/</guid><description>&lt;p>An internal artifact that fires when the master node writes a new
snapshot. Minion use this to trigger a refresh of their client info
snapshots.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ClientInfoSnapshot
type: INTERNAL
description: |
 An internal artifact that fires when the master node writes a new
 snapshot. Minion use this to trigger a refresh of their client info
 snapshots.

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ClientPing</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientping/</guid><description>&lt;p>An internal event channel for notifying about client pings.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ClientPing
type: INTERNAL
description: |
 An internal event channel for notifying about client pings.

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ClientScheduled</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientscheduled/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.clientscheduled/</guid><description>&lt;p>This event will be fired when a client was sent flows to process.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ClientScheduled
description: |
 This event will be fired when a client was sent flows to process.

type: INTERNAL
column_types:
 - name: ClientId
 - name: InFlightFlows
 description: New flows scheduled for the client
 - name: ClearFlows
 description: If this is set we clear all in flight flows.

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ClientTasks</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.clienttasks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.clienttasks/</guid><description>&lt;p>This event will be fired when a client has new tasks scheduled.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ClientTasks
description: |
 This event will be fired when a client has new tasks scheduled.

type: INTERNAL
column_types:
 - name: ClientId

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Enrollment</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.enrollment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.enrollment/</guid><description>&lt;p>This event artifact is an internal event stream over which client
enrollments are sent. You can watch this event queue to be notified
on any new clients enrolling for the first time.&lt;/p>
&lt;p>Note: This is an automated system artifact. You do not need to start it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Enrollment
description: |
 This event artifact is an internal event stream over which client
 enrollments are sent. You can watch this event queue to be notified
 on any new clients enrolling for the first time.

 Note: This is an automated system artifact. You do not need to start it.

type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.FrontendMetrics</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.frontendmetrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.frontendmetrics/</guid><description>&lt;p>An internal queue that receives metrics from all frontends. The
master Frontend manager service will aggregate these into a combined
metric stream.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.FrontendMetrics
description: |
 An internal queue that receives metrics from all frontends. The
 master Frontend manager service will aggregate these into a combined
 metric stream.

type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.HuntModification</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.huntmodification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.huntmodification/</guid><description>&lt;p>An internal queue to watch modifications of hunts. The hunt
dispatcher from all nodes sends this mutation to the hunt manager
which applies it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.HuntModification
description: |
 An internal queue to watch modifications of hunts. The hunt
 dispatcher from all nodes sends this mutation to the hunt manager
 which applies it.

type: INTERNAL

column_types:
 - name: HuntId
 - name: Mutation
 type: json

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.HuntUpdate</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.huntupdate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.huntupdate/</guid><description>&lt;p>An internal queue to notify hunt dispatchers on all minions that a
certain hunt has changed and should be updated from the internal
cache.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.HuntUpdate
description: |
 An internal queue to notify hunt dispatchers on all minions that a
 certain hunt has changed and should be updated from the internal
 cache.

type: INTERNAL

column_types:
 - name: HuntId
 - name: Hunt
 type: json

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Interrogate</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.interrogate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.interrogate/</guid><description>&lt;p>An internal artifact used track new client interrogations by the
Interrogation service.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Interrogate
description: |
 An internal artifact used track new client interrogations by the
 Interrogation service.

type: SERVER_EVENT

sources:
 - query: |
 SELECT * FROM foreach(
 row={
 SELECT ClientId, Flow, FlowId
 FROM watch_monitoring(artifact='System.Flow.Completion')
 WHERE Flow.artifacts_with_results =~ 'Generic.Client.Info'
 },
 query={
 SELECT * FROM switch(
 a={
 SELECT ClientId,
 FlowId,
 Architecture,
 BuildTime,
 Fqdn,
 Hostname,
 KernelVersion,
 Labels,
 Name,
 OS,
 Platform,
 PlatformVersion
 FROM source(
 client_id=ClientId,
 flow_id=FlowId,
 source="BasicInformation",
 artifact="Custom.Generic.Client.Info")
 },
 b={
 SELECT ClientId,
 FlowId,
 Architecture,
 BuildTime,
 Fqdn,
 Hostname,
 KernelVersion,
 Labels,
 Name,
 OS,
 Platform,
 PlatformVersion
 FROM source(
 client_id=ClientId,
 flow_id=FlowId,
 source="BasicInformation",
 artifact="Generic.Client.Info")
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Interrogation</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.interrogation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.interrogation/</guid><description>&lt;p>This event artifact is an internal event stream over which client
interrogations are sent. When the interrogation service finishes
updating a client record, it will send an event on this artifact.&lt;/p>
&lt;p>Note: This is an automated system artifact. You do not need to start it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Interrogation
description: |
 This event artifact is an internal event stream over which client
 interrogations are sent. When the interrogation service finishes
 updating a client record, it will send an event on this artifact.

 Note: This is an automated system artifact. You do not need to start it.

type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Inventory</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.inventory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.inventory/</guid><description>&lt;p>An internal artifact to listen to inventory (tools) changes.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Inventory
description: |
 An internal artifact to listen to inventory (tools) changes.

type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Label</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.label/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.label/</guid><description>&lt;p>An internal artifact used to track new labeling events.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Label
description: |
 An internal artifact used to track new labeling events.

type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.MasterRegistrations</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.masterregistrations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.masterregistrations/</guid><description>&lt;p>The master will advertise to the minions the events it is interested
in.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.MasterRegistrations
description: |
 The master will advertise to the minions the events it is interested
 in.

type: INTERNAL
column_types:
 - name: Events
 type: json_array

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.MetadataModifications</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.metadatamodifications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.metadatamodifications/</guid><description>&lt;p>This event artifact is an internal event stream over which
notifications of server metadata modifications are sent.&lt;/p>
&lt;p>Note: This is an automated system artifact. You do not need to start it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.MetadataModifications
description: |
 This event artifact is an internal event stream over which
 notifications of server metadata modifications are sent.

 Note: This is an automated system artifact. You do not need to start it.

type: SERVER_EVENT

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Notifications</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.notifications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.notifications/</guid><description>&lt;p>This event artifact is an internal event stream over which client
notifications are sent. A frontend will watch for events over this
stream and if a client is actively connected to this frontend, the
client will be notified that new work is available to it.&lt;/p>
&lt;p>Note: This is an automated system artifact. You do not need to start it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Notifications
description: |
 This event artifact is an internal event stream over which client
 notifications are sent. A frontend will watch for events over this
 stream and if a client is actively connected to this frontend, the
 client will be notified that new work is available to it.

 Note: This is an automated system artifact. You do not need to start it.

type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Ping</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.ping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.ping/</guid><description>&lt;p>An internal queue for Ping requests. The queue is watched by the
replication service on the slave nodes which will notify the target
specified.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Ping
description: |
 An internal queue for Ping requests. The queue is watched by the
 replication service on the slave nodes which will notify the target
 specified.

type: INTERNAL

column_types:
 - name: ClientId
 - name: NotifyTarget

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Pong</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.pong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.pong/</guid><description>&lt;p>An internal queue for Ping replies&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Pong
description: |
 An internal queue for Ping replies

type: INTERNAL

column_types:
 - name: ClientId
 - name: Connected

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ResumedUploads</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.resumeduploads/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.resumeduploads/</guid><description>&lt;p>An internal artifact that display all resumed uploads&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ResumedUploads
description: |
 An internal artifact that display all resumed uploads

column_types:
- name: mtime
 type: timestamp
- name: atime
 type: timestamp
- name: ctime
 type: timestamp
- name: btime
 type: timestamp
- name: expected_size
 type: mb
- name: response
 type: hidden

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.TimelineAdd</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.timelineadd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.timelineadd/</guid><description>&lt;p>This artifact will fire whenever a timeline is added to a super
timeline. You can use this to monitor for users adding timelines and
forward them to an external timeline system (e.g. TimeSketch)&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.TimelineAdd
type: SERVER_EVENT
description: |
 This artifact will fire whenever a timeline is added to a super
 timeline. You can use this to monitor for users adding timelines and
 forward them to an external timeline system (e.g. TimeSketch)

column_types:
 - name: NotebookId
 - name: SuperTimelineName
 - name: Timeline

 # What type of event this is: can be Delete, AddTimeline
 - name: Action

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.ToolDependencies</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.tooldependencies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.tooldependencies/</guid><description>&lt;p>An internal artifact that defines some tool
dependencies. Velociraptor releases for offline collector&lt;/p>
&lt;p>NOTE: Do not modify - this artifact is generated during build in magefile.go&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.ToolDependencies
description: |
 An internal artifact that defines some tool
 dependencies. Velociraptor releases for offline collector

 NOTE: Do not modify - this artifact is generated during build in magefile.go

tools:
 - name: VelociraptorWindows
 url: https://github.com/Velocidex/velociraptor/releases/download/v0.75/velociraptor-v0.75.2-windows-amd64.exe
 serve_locally: true
 version: 0.75.2

 - name: VelociraptorWindows_x86
 url: https://github.com/Velocidex/velociraptor/releases/download/v0.75/velociraptor-v0.75.2-windows-386.exe
 serve_locally: true
 version: 0.75.2

 - name: VelociraptorLinux
 url: https://github.com/Velocidex/velociraptor/releases/download/v0.75/velociraptor-v0.75.2-linux-amd64-musl
 serve_locally: true
 version: 0.75.2

 # On MacOS we cannot embed the config in the binary so we use a
 # shell script stub instead. See
 # https://github.com/Velocidex/velociraptor/issues/2898

 # A Generic collector to be used with the --embedded_config flag.
 - name: VelociraptorCollector
 url: https://github.com/Velocidex/velociraptor/releases/download/v0.75/velociraptor-collector
 serve_locally: true

 - name: VelociraptorWindowsMSI
 url: https://github.com/Velocidex/velociraptor/releases/download/v0.75/velociraptor-v0.75.2-windows-amd64.msi
 serve_locally: true
 version: 0.75.2

 - name: VelociraptorWindows_x86MSI
 url: https://github.com/Velocidex/velociraptor/releases/download/v0.75/velociraptor-v0.75.2-windows-386.msi
 serve_locally: true
 version: 0.75.2

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.UserManager</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.usermanager/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.usermanager/</guid><description>&lt;p>An internal artifact notifying when user accounts are modified.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.UserManager
type: INTERNAL
description: |
 An internal artifact notifying when user accounts are modified.

&lt;/code>&lt;/pre></description></item><item><title>Server.Internal.Welcome</title><link>https://docs.velociraptor.app/artifact_references/pages/server.internal.welcome/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.internal.welcome/</guid><description>&lt;p>This is the welcome screen in the Velociraptor GUI. You can
customize this screen by editing this artifact.&lt;/p>
&lt;p>When editing the artifact in the main &lt;code>View Artifacts&lt;/code> screen you
will see some markdown in the reports section of the YAML
file. Simply edit this markdown and your server will display your
customized report.&lt;/p>
&lt;p>You can use this to add important information to your specific
deployment.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Internal.Welcome
description: |
 This is the welcome screen in the Velociraptor GUI. You can
 customize this screen by editing this artifact.

 When editing the artifact in the main `View Artifacts` screen you
 will see some markdown in the reports section of the YAML
 file. Simply edit this markdown and your server will display your
 customized report.

 You can use this to add important information to your specific
 deployment.

type: SERVER

sources:
- query: SELET * FROM info()

reports:
 - type: CLIENT
 template: |
 &amp;lt;div class="row dashboard "&amp;gt;
 &amp;lt;div class="card col-10"&amp;gt;
 &amp;lt;img src="https://docs.velociraptor.app/artifact_references/pages/server.internal.welcome/./velo.svg" height="150"&amp;gt;
 &amp;lt;div class="card-body"&amp;gt;
 {{ $X := Query "LET DebugLink &amp;lt;= link_to(type='debug', org='root')" | Expand }}

 # Welcome to Velociraptor!

 &amp;lt;table&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;

 * &amp;lt;a href="#/dashboard"&amp;gt;View server dashboard&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/collected/server/new/Server.Import.Extras"&amp;gt;Import Extra artifacts&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/collected/server/new/Server.Utils.CreateLinuxPackages"&amp;gt;Build Linux client packages&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/collected/server/new/Server.Utils.CreateMSI"&amp;gt;Build Windows client MSI&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/collected/server/new/Server.Utils.CreateCollector"&amp;gt;Build an Offline Collector&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/collected/server/new/Server.Orgs.NewOrg"&amp;gt;Create a new Org&amp;lt;/a&amp;gt;

 &amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;

 * &amp;lt;a href="#/host/server"&amp;gt;View Server Configuration&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/events/server/Server.Audit.Logs"&amp;gt;Inspect Server Audit Log&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/secrets"&amp;gt;Manage Server Secrets&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/users"&amp;gt;Manage Velociraptor Users&amp;lt;/a&amp;gt;
 * &amp;lt;a href="#/artifacts/Server.Internal.Welcome/edit"&amp;gt;Customize this welcome screen&amp;lt;/a&amp;gt;
 * &amp;lt;a href="{{ Scope "DebugLink" }}"&amp;gt;Debug the server&amp;lt;/a&amp;gt;

 &amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;

 Or search for a client in the search bar above.

 You can always get back to this welcome screen by clicking the
 little green reptile above!

 ## Tips

 1. Press `Ctrl-/` to view keyboard hotkeys.

 &amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitor.ClientConflict</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitor.clientconflict/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitor.clientconflict/</guid><description>&lt;p>Forces conflicting clients to rekey themselves.&lt;/p>
&lt;p>Sometimes the Velociraptor client is installed into a VM template image with
an existing writeback file. In this case each cloned instance will start the
client with the same client id. When multiple clients attempt to
simultaneously connect to the server with the same client id, the server will
reject them with the HTTP &amp;ldquo;409 Rejected&amp;rdquo; response.&lt;/p>
&lt;p>This artifact detects such conflicts and instructs the affected clients to
generate a new client id (saving their new keys into their writeback files)
and then reconnect with the server.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitor.ClientConflict
type: SERVER_EVENT
description: |
 Forces conflicting clients to rekey themselves.

 Sometimes the Velociraptor client is installed into a VM template image with
 an existing writeback file. In this case each cloned instance will start the
 client with the same client id. When multiple clients attempt to
 simultaneously connect to the server with the same client id, the server will
 reject them with the HTTP "409 Rejected" response.

 This artifact detects such conflicts and instructs the affected clients to
 generate a new client id (saving their new keys into their writeback files)
 and then reconnect with the server.

sources:
 - query: |
 SELECT
 collect_client(client_id=ClientId,
 artifacts="Generic.Client.Rekey", env=dict())
 AS NewCollection
 FROM watch_monitoring(artifact="Server.Internal.ClientConflict")

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitor.Health</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitor.health/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitor.health/</guid><description>&lt;p>This is the main server health dashboard. It is shown on the
homescreen and enabled by default on all new installs.&lt;/p>
&lt;p>You may edit this artifact to customize your server dashboard.&lt;/p>
&lt;p>Alternatively, edit the Welcome screen at the
&lt;code>Server.Internal.Welcome&lt;/code> artifact.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitor.Health
description: |
 This is the main server health dashboard. It is shown on the
 homescreen and enabled by default on all new installs.

 You may edit this artifact to customize your server dashboard.

 Alternatively, edit the Welcome screen at the
 `Server.Internal.Welcome` artifact.

type: SERVER_EVENT

sources:
 - name: Prometheus
 query: SELECT sleep(time=10000000) FROM scope()

reports:
 - type: SERVER_EVENT
 # Only allow the report to run for 10 seconds - this is plenty for
 # the GUI.
 timeout: 10
 parameters:
 - name: Sample
 default: "6"

 template: |
 {{ define "CPU" }}
 LET SampledData &amp;lt;= SELECT * FROM sample(
 n=atoi(string=Sample),
 query={
 SELECT _ts as Timestamp,
 CPUPercent,
 int(int=MemoryUse / 1048576) AS MemoryUse_Mb,
 TotalFrontends
 FROM source(source="Prometheus",
 start_time=StartTime, end_time=EndTime,
 artifact="Server.Monitor.Health")
 })

 LET Stats &amp;lt;= SELECT count() AS Count,
 timestamp(epoch=min(item=Timestamp)) AS MinTime,
 timestamp(epoch=max(item=Timestamp)) AS MaxTime,
 timestamp(epoch=StartTime) AS StartTime
 FROM SampledData
 GROUP BY 1

 // Include a log for verification. Last data should always be
 // very recent and sample should be passed properly.
 LET _ &amp;lt;= log(message="Graphs cover times from %v (%v). Actual data available from %v (%v) to %v (%v) with %v rows. Data is sampled every %v samples.", args=[
 Stats[0].StartTime.String, humanize(time=Stats[0].StartTime),
 Stats[0].MinTime.String, humanize(time=Stats[0].MinTime),
 Stats[0].MaxTime.String, humanize(time=Stats[0].MaxTime),
 Stats[0].Count, Sample])

 SELECT * FROM SampledData
 {{ end }}

 {{ define "CurrentConnections" }}
 SELECT * FROM sample(
 n=atoi(string=Sample),
 query={
 SELECT _ts as Timestamp,
 client_comms_current_connections
 FROM source(source="Prometheus",
 start_time=StartTime, end_time=EndTime,
 artifact="Server.Monitor.Health")
 })
 {{ end }}

 {{ $time_rows := Query "SELECT timestamp(epoch=now()) AS Now FROM scope()" | Expand }}
 ## Server status @ {{ Render ( Get $time_rows "0.Now" ) }}

 &amp;lt;p&amp;gt;The following are total across all frontends.&amp;lt;/p&amp;gt;
 &amp;lt;span class="container"&amp;gt;
 &amp;lt;span class="row"&amp;gt;
 &amp;lt;span class="col-sm panel"&amp;gt;
 CPU and Memory Utilization
 {{- Query "CPU" | TimeChart "RSS.yaxis" 2 -}}
 &amp;lt;/span&amp;gt;
 &amp;lt;span class="col-sm panel"&amp;gt;
 Currently Connected Clients
 {{- Query "CurrentConnections" | TimeChart "RSS.yaxis" 2 -}}
 &amp;lt;/span&amp;gt;
 &amp;lt;/span&amp;gt;
 &amp;lt;/span&amp;gt;

 ## Current Orgs
 {{ define "OrgsTable" }}
 LET ColumnTypes &amp;lt;= dict(ClientConfig='url')
 LET OrgsTable = SELECT Name, OrgId,
 upload(accessor='data', file=_client_config,
 name='client.'+OrgId+'.config.yaml') AS _Upload
 FROM orgs()

 SELECT Name, OrgId, link_to(upload=_Upload) AS ClientConfig
 FROM OrgsTable
 {{ end }}

 {{ Query "OrgsTable" | Table }}

 ## Disk Space

 {{ Query "SELECT * FROM Artifact.Generic.Client.DiskSpace()" | Table }}

 ## Users

 {{ define "UserPermissions" }}
 SELECT name, effective_policy AS _EffectivePolicy,
 join(array=roles, sep=", ") AS Roles
 FROM gui_users()
 {{ end }}

 {{ Query "UserPermissions" | Table }}

 ## Server version

 {{ Query "SELECT server_version FROM config" | Table }}

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitor.Profile</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitor.profile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitor.profile/</guid><description>&lt;p>This artifact collects profiling information from the running
server. This is useful when you notice a high CPU load in the server
and want to know why.&lt;/p>
&lt;p>The following options are most useful:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Goroutines: This shows the backtraces of all currently running
goroutines. It will generally show most of the code working in the
current running set of queries.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Heap: This shows all allocations currently in use and where they
are allocated from. This is useful if the server is taking too
much memory.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Profile: This takes a CPU profile of the running process for the
number of seconds specified in the Duration parameter. You can
read profiles by using:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>go tool pprof -callgrind -output=profile.grind profile.bin
kcachegrind profile.grind
&lt;/code>&lt;/pre>
&lt;p>NOTE: As of 0.7.0 release, this artifact will also collect
goroutines and heap profiles as distinct sources in a more readable
way.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitor.Profile
description: |
 This artifact collects profiling information from the running
 server. This is useful when you notice a high CPU load in the server
 and want to know why.

 The following options are most useful:

 1. Goroutines: This shows the backtraces of all currently running
 goroutines. It will generally show most of the code working in the
 current running set of queries.

 2. Heap: This shows all allocations currently in use and where they
 are allocated from. This is useful if the server is taking too
 much memory.

 3. Profile: This takes a CPU profile of the running process for the
 number of seconds specified in the Duration parameter. You can
 read profiles by using:

 ```
 go tool pprof -callgrind -output=profile.grind profile.bin
 kcachegrind profile.grind
 ```

 NOTE: As of 0.7.0 release, this artifact will also collect
 goroutines and heap profiles as distinct sources in a more readable
 way.

type: SERVER

parameters:
 - name: Allocs
 description: A sampling of all past memory allocations
 type: bool
 default: Y
 - name: Block
 description: Stack traces that led to blocking on synchronization primitives
 type: bool
 - name: Goroutine
 description: Stack traces of all current goroutines
 type: bool
 default: Y
 - name: Heap
 description: A sampling of memory allocations of live objects
 type: bool
 - name: Mutex
 description: Stack traces of holders of contended mutexes
 type: bool
 - name: Profile
 description: CPU profile
 type: bool
 - name: Trace
 description: CPU trace
 type: bool
 - name: Logs
 description: Get logs
 type: bool
 - name: QueryLogs
 description: Get recent queries logs
 type: bool
 - name: Metrics
 description: Get server metrics
 type: bool
 - name: Verbose
 description: Print more detail
 type: bool
 - name: Duration
 description: Duration of sampling for Profile and Trace.
 default: "30"

export: |
 LET CleanUp(Name) = regex_replace(
 re="www.velocidex.com/golang/velociraptor/",
 replace="", source=Name)

sources:
 - query: |
 SELECT Type,
 if(condition=get(field="OSPath"),
 then=upload(name=Type + ".bin", file=OSPath)) AS File,
 get(member="Line") AS Line
 FROM profile(allocs=Allocs, block=Block, goroutine=Goroutine,
 heap=Heap, mutex=Mutex, profile=Profile, trace=Trace,
 debug=if(condition=Verbose, then=2, else=1),
 duration=atoi(string=Duration))

 - name: Goroutines
 query: |
 SELECT *, {
 SELECT format(format="%v (%v:%v)",
 args=[CleanUp(Name=Name), basename(path=File), Line])
 FROM CallStack
 WHERE File =~ 'velociraptor|vfilter|go-ntfs'
 LIMIT 10
 } AS CallStack
 FROM profile_goroutines()
 WHERE CallStack

 - name: Memory
 query: |
 SELECT InUseBytes, InUseObjects, {
 SELECT format(format="%v (%v:%v)",
 args=[CleanUp(Name=Name), basename(path=File), Line])
 FROM CallStack
 WHERE File =~ 'velociraptor|vfilter|go-ntfs'
 LIMIT 10
 } AS CallStack
 FROM profile_memory()
 ORDER BY InUseBytes DESC

 - name: Logs
 query: |
 SELECT * FROM profile(logs=TRUE)

 - name: RunningQueries
 query: |
 SELECT Line.Start AS Timestamp, Line.Query AS Query
 FROM profile(queries=TRUE)
 WHERE NOT Line.Duration

 - name: AllQueries
 query: |
 SELECT Line.Start AS Timestamp, int(int = Line.Duration / 1000000) AS DurationSec, Line.Query AS Query
 FROM profile(queries=TRUE)

 - name: Metrics
 query: |
 SELECT *
 FROM profile(metrics=TRUE)

 - name: Everything
 query: SELECT * FROM profile(type='.+')

column_types:
 - name: InUseBytes
 type: mb

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitor.Shell</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitor.shell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitor.shell/</guid><description>&lt;p>Velociraptor can get an interactive shell on the endpoint by using
the shell command. To use it, the user must be directly
logged on the server.&lt;/p>
&lt;p>Obviously being able to run arbitrary commands on the end point is
a powerful feature and should be used sparingly. There is an audit
trail for shell commands executed and their output available by
streaming all shell commands to the &amp;ldquo;Shell&amp;rdquo; client event monitoring
artifact.&lt;/p>
&lt;p>This server event artifact centralizes all shell access from all
clients into the same log file.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitor.Shell
description: |
 Velociraptor can get an interactive shell on the endpoint by using
 the shell command. To use it, the user must be directly
 logged on the server.

 Obviously being able to run arbitrary commands on the end point is
 a powerful feature and should be used sparingly. There is an audit
 trail for shell commands executed and their output available by
 streaming all shell commands to the "Shell" client event monitoring
 artifact.

 This server event artifact centralizes all shell access from all
 clients into the same log file.

# Can be CLIENT, EVENT, SERVER, SERVER_EVENT
type: SERVER_EVENT

sources:
 - query: |
 -- Watch for shell flow completions.
 LET collections = SELECT Flow
 FROM watch_monitoring(artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ "Windows.System.PowerShell|Windows.System.CmdShell"

 -- Dump the command and the results.
 SELECT * FROM foreach(row=collections,
 query={
 SELECT Flow.session_id AS FlowId,
 Flow.client_id AS ClientId,
 client_info(client_id=Flow.client_id).os_info.fqdn AS Hostname,
 timestamp(epoch=Flow.create_time / 1000000) AS Created,
 timestamp(epoch=Flow.active_time / 1000000) AS LastActive,
 get_flow(flow_id=FlowId,
 client_id=ClientId).request.parameters.env[0].value AS Command,
 Stdout, Stderr FROM source(
 client_id=Flow.client_id,
 flow_id=Flow.session_id,
 artifact=Flow.artifacts_with_results[0])
 })


# Reports can be MONITORING_DAILY, CLIENT
reports:
 - type: SERVER_EVENT
 template: |
 {{ .Description }}

 {{ $rows := Query "SELECT ClientId, Hostname, \
 timestamp(epoch=LastActive) AS Timestamp, Command, Stdout FROM source()" }}

 {{ range $row := $rows }}

 * On {{ Get $row "Timestamp" }} we ran {{ Get $row "Command" }} on {{ Get $row "Hostname" }}

 ```text
 {{ Get $row "Stdout" }}
 ```

 {{end}}

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitor.VeloMetrics</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitor.velometrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitor.velometrics/</guid><description>&lt;p>Get Velociraptor server metrics.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitor.VeloMetrics
description: |
 Get Velociraptor server metrics.

type: SERVER

parameters:
 - name: MetricsURL
 default: http://localhost:8003/metrics

sources:
 - query: |
 LET stats = SELECT parse_string_with_regex(string=Content,
 regex=[
 'client_comms_concurrency (?P&amp;lt;client_comms_concurrency&amp;gt;[^\\s]+)',
 'client_comms_current_connections (?P&amp;lt;client_comms_current_connections&amp;gt;[^\\s]+)',
 'flow_completion (?P&amp;lt;flow_completion&amp;gt;[^\\s]+)',
 'process_open_fds (?P&amp;lt;process_open_fds&amp;gt;[^\\s]+)',
 'uploaded_bytes (?P&amp;lt;uploaded_bytes&amp;gt;[^\\s]+)',
 'uploaded_files (?P&amp;lt;uploaded_files&amp;gt;[^\\s]+)',
 'stats_client_one_day_actives{version="[^"]+"} (?P&amp;lt;one_day_active&amp;gt;[^\\s]+)',
 'stats_client_seven_day_actives{version="[^"]+"} (?P&amp;lt;seven_day_active&amp;gt;[^\\s]+)'
 ]) AS Stat, {
 // On Windows Prometheus does not provide these so we get our own.
 SELECT Times.user + Times.system as CPU,
 MemoryInfo.RSS as RSS
 FROM pslist(pid=getpid())
 } AS PslistStats
 FROM http_client(url=MetricsURL, chunk_size=50000)

 SELECT now() AS Timestamp,
 PslistStats.RSS AS process_resident_memory_bytes,
 parse_float(string=Stat.client_comms_concurrency)
 AS client_comms_concurrency,
 parse_float(string=Stat.client_comms_current_connections)
 AS client_comms_current_connections,
 parse_float(string=Stat.flow_completion) AS flow_completion,
 parse_float(string=Stat.uploaded_bytes) AS uploaded_bytes,
 parse_float(string=Stat.uploaded_files) AS uploaded_files,
 parse_float(string=Stat.process_open_fds)
 AS process_open_fds,
 PslistStats.CPU AS process_cpu_seconds_total,
 parse_float(string=Stat.one_day_active)
 AS one_day_active,
 parse_float(string=Stat.seven_day_active)
 AS seven_day_active
 FROM stats

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitoring.ClientCount</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitoring.clientcount/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitoring.clientcount/</guid><description>&lt;p>An artifact that sends an email every hour of the current state of
the deployment.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitoring.ClientCount

description: |
 An artifact that sends an email every hour of the current state of
 the deployment.

type: SERVER_EVENT

parameters:
 - name: EmailAddress
 default: admin@example.com
 - name: SkipVerify
 type: bool
 description: If set we skip TLS verification.
 - name: CCAddress
 default:
 - name: Subject
 default: "Deployment statistics for Velociraptor"
 - name: Period
 default: "3600"

sources:
 - query: |
 LET metrics = SELECT * FROM Artifact.Server.Monitor.VeloMetrics()

 SELECT * FROM foreach(
 row={
 SELECT * FROM clock(period=atoi(string=Period))
 },
 query={
 SELECT * FROM mail(
 to=EmailAddress,
 cc=CCAddress,
 subject=Subject,
 period=60,
 skip_verify=SkipVerify,
 body=format(format='Total clients currently connected %v',
 args=[metrics.client_comms_current_connections])
 )
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitoring.ScheduleHunt</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitoring.schedulehunt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitoring.schedulehunt/</guid><description>&lt;p>Run client interrogation periodically. This is a sample event
artifact to schedule a hunt periodically. You can change it to
launch other artifacts.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitoring.ScheduleHunt
description: |
 Run client interrogation periodically. This is a sample event
 artifact to schedule a hunt periodically. You can change it to
 launch other artifacts.

type: SERVER_EVENT

parameters:
 - name: ScheduleDayRegex
 default: Tuesday
 type: regex
 - name: ScheduleTimeRegex
 default: "01:28"
 type: regex
 - name: HuntDescription
 default: "Periodic info hunt"

sources:
 - query: |
 LET schedule = SELECT
 UTC.String AS Now,
 Weekday.String AS Today
 FROM clock(period=60)
 WHERE Now =~ ScheduleTimeRegex + ":[0-9][0-9]"
 AND Today =~ ScheduleDayRegex
 AND log(message="Launching at time " + Now)

 SELECT hunt(artifacts=["Generic.Client.Info"],
 spec=dict(`Generic.Client.Info`=dict()),
 description=HuntDescription)
 FROM schedule

&lt;/code>&lt;/pre></description></item><item><title>Server.Monitoring.TimesketchUpload</title><link>https://docs.velociraptor.app/artifact_references/pages/server.monitoring.timesketchupload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.monitoring.timesketchupload/</guid><description>&lt;p>This artifact will automatically upload any Velociraptor timelines to Timesketch.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Monitoring.TimesketchUpload
description: |
 This artifact will automatically upload any Velociraptor timelines to Timesketch.


type: SERVER_EVENT

parameters:
 - name: SketchRegex
 description: |
 Only upload Super timelines matching this regex to their
 corresponding Sketches.
 default: .

 - name: TimelineRegex
 default: .
 description: |
 Only upload Timelines with a name matching this regex to
 Timesketch.

 - name: TimesketchCLICommand
 default: "timesketch"
 description: |
 The path to the Timesketch CLI binary. If you installed in a
 virtual environment this will be inside that environment.

required_permissions:
 - EXECVE

imports:
 - Server.Utils.TimesketchUpload

sources:
 - query: |
 SELECT * FROM foreach(row={
 SELECT NotebookId, SuperTimelineName, Timeline
 FROM watch_monitoring(artifact="Server.Internal.TimelineAdd")
 WHERE Action = "AddTimeline"
 AND SuperTimelineName =~ SketchRegex
 AND Timeline =~ TimelineRegex
 }, query={
 SELECT * FROM ImportToTS(
 SuperTimelineName=SuperTimelineName,
 NotebookId=NotebookId,
 TimelineName=Timeline,
 SketchName=SuperTimelineName)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Orgs.ListOrgs</title><link>https://docs.velociraptor.app/artifact_references/pages/server.orgs.listorgs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.orgs.listorgs/</guid><description>&lt;p>This server artifact will list all currently configured orgs on the server.&lt;/p>
&lt;p>NOTE: This artifact is only available to users with the &lt;code>ORG_ADMIN&lt;/code>
permission, which is normally only granted to users with the administrator
role within the root org (that means you might need to switch to the root org
in the GUI before collecting this artifact).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Orgs.ListOrgs
description: |
 This server artifact will list all currently configured orgs on the server.

 NOTE: This artifact is only available to users with the `ORG_ADMIN`
 permission, which is normally only granted to users with the administrator
 role within the root org (that means you might need to switch to the root org
 in the GUI before collecting this artifact).

type: SERVER

parameters:
- name: AlsoDownloadClientConfigs
 type: bool
 description: When set also downloads client configs from each org

sources:
- query: |
 SELECT * FROM if(condition=AlsoDownloadClientConfigs,
 then={
 SELECT *, upload(file=_client_config,
 accessor="data",
 name=format(format="client.%s.config.yaml", args=OrgId || "RootOrg")) AS ClientConfig
 FROM orgs()
 }, else={
 SELECT * FROM orgs()
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Orgs.NewOrg</title><link>https://docs.velociraptor.app/artifact_references/pages/server.orgs.neworg/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.orgs.neworg/</guid><description>&lt;p>This server artifact will create a new org and assign the current user as an
admin to it.&lt;/p>
&lt;p>NOTE: This artifact is only available to users with the &lt;code>ORG_ADMIN&lt;/code>
permission, which is normally only granted to users with the administrator
role within the root org (that means you might need to switch to the root org
in the GUI before collecting this artifact).&lt;/p>
&lt;p>This artifact will also run a set of server artifacts in the new org. If you
need to run any other initialization steps in the new org, you can package
those into one or more server artifacts and include those in the
&lt;code>InitialArtifacts&lt;/code> parameter.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Orgs.NewOrg
description: |
 This server artifact will create a new org and assign the current user as an
 admin to it.

 NOTE: This artifact is only available to users with the `ORG_ADMIN`
 permission, which is normally only granted to users with the administrator
 role within the root org (that means you might need to switch to the root org
 in the GUI before collecting this artifact).

 This artifact will also run a set of server artifacts in the new org. If you
 need to run any other initialization steps in the new org, you can package
 those into one or more server artifacts and include those in the
 `InitialArtifacts` parameter.

type: SERVER

parameters:
- name: OrgName
 default: "New Org"
 description: |
 The name of the new org. A new Org ID will be assigned.

- name: InitialArtifacts
 type: artifactset
 artifact_type: SERVER
 default: |
 Artifact
 Server.Utils.CreateMSI
 Server.Utils.CreateLinuxPackages
 description: |
 Start the following server artifacts in the new org.

sources:
- query: |
 LET org_record &amp;lt;= org_create(name=OrgName)
 LET _ &amp;lt;= log(message="Created New Org with ID %v", args=org_record.id)

 -- Give the current user permissions to operate in the org.
 LET _ &amp;lt;= user_create(orgs=org_record.id,
 roles=["administrator", "org_admin"],
 user=whoami())

 -- Launch this as a separate collection within the Org.
 SELECT * FROM query(
 query={
 SELECT collect_client(artifacts=InitialArtifacts.Artifact, client_id="server")
 FROM scope()
 }, org_id=org_record.id, env=dict(InitialArtifacts=InitialArtifacts))

&lt;/code>&lt;/pre></description></item><item><title>Server.Powershell.EncodedCommand</title><link>https://docs.velociraptor.app/artifact_references/pages/server.powershell.encodedcommand/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.powershell.encodedcommand/</guid><description>&lt;p>It is possible to pass PowerShell an encoded script. This artifact
decodes such scripts.&lt;/p>
&lt;p>NOTE: The client must be running the Windows.Events.ProcessCreation
event artifact to retrieve process execution logs.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Powershell.EncodedCommand
description: |
 It is possible to pass PowerShell an encoded script. This artifact
 decodes such scripts.

 NOTE: The client must be running the Windows.Events.ProcessCreation
 event artifact to retrieve process execution logs.

type: SERVER_EVENT

sources:
 - query: |
 SELECT ClientId, ParentInfo, CommandLine, Timestamp, utf16(
 string=base64decode(
 string=parse_string_with_regex(
 string=CommandLine,
 regex='-((?i)(en|enc|encode|encodedCommand)) (?P&amp;lt;Encoded&amp;gt;[^ ]+)'
 ).Encoded)) AS Script
 FROM watch_monitoring(artifact='Windows.Events.ProcessCreation')
 WHERE CommandLine =~ '-(en|enc|encode|encodedCommand)'

reports:
 - type: SERVER_EVENT
 template: |

 Encoded Powershell
 ==================

 {{ .Description }}

 ## Decoded Powershell commands.

 {{ Query "SELECT ClientId, { SELECT os_info.fqdn from clients(client_id=ClientId) } AS FQDN, Script FROM source()" | Table }}

&lt;/code>&lt;/pre></description></item><item><title>Server.Slack.Clients.Online</title><link>https://docs.velociraptor.app/artifact_references/pages/server.slack.clients.online/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.slack.clients.online/</guid><description>&lt;p>Send a message to slack when clients come online.&lt;/p>
&lt;p>This artifact searches for all clients that carry the label &amp;ldquo;Slack&amp;rdquo;
by default, and if they have appeared online in the last 5 minutes,
sends a message to Slack and removed the label from the client.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Slack.Clients.Online
description: |
 Send a message to slack when clients come online.

 This artifact searches for all clients that carry the label "Slack"
 by default, and if they have appeared online in the last 5 minutes,
 sends a message to Slack and removed the label from the client.

type: SERVER_EVENT

parameters:
 - name: LabelGroup
 default: Slack
 - name: SlackToken
 description: The token URL obtained from Slack. Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
 - query: |
 LET token_url = if(
 condition=SlackToken,
 then=SlackToken,
 else=server_metadata().SlackToken)

 LET hits = SELECT client_id,
 os_info.fqdn as Hostname ,
 now() - last_seen_at / 1000000 AS LastSeen,
 label(client_id=client_id, labels=LabelGroup, op="remove")
 FROM clients(search="label:" + LabelGroup)
 WHERE LastSeen &amp;lt; 300

 LET send_message = SELECT * FROM foreach(row=hits,
 query={
 SELECT client_id, Hostname, LastSeen, Content, Response
 FROM http_client(
 data=serialize(item=dict(
 text=format(format="Client %v (%v) has appeared online %v seconds ago",
 args=[Hostname, client_id, LastSeen])),
 format="json"),
 headers=dict(`Content-Type`="application/json"),
 method="POST",
 url=token_url)
 })

 // Check every minute
 SELECT * FROM foreach(
 row={SELECT * FROM clock(period=60)},
 query=send_message)

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.AddTimeline</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.addtimeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.addtimeline/</guid><description>&lt;p>Adds a new timeline to a super timeline.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.AddTimeline
description: |
 Adds a new timeline to a super timeline.

type: SERVER

parameters:
 - name: NotebookId
 - name: Timeline
 description: SuperTimeline name
 - name: ChildName
 description: Name of child timeline
 - name: Query
 description: A query that will be parsed and run.
 - name: Key
 description: Sort column for time
 - name: MessageColumn
 description: The name of the column to appear as the message
 - name: RemoveLimit
 description: If specified, we remove the limit clause before adding to the timeline.
 type: bool
 - name: Env
 type: json

sources:
 - query: |
 SELECT timeline_add(
 notebook_id=NotebookId,
 timeline=Timeline,
 name=ChildName,
 message_column=MessageColumn,
 query={
 SELECT * FROM query(query=if(condition=RemoveLimit,
 then=regex_replace(re="(?i)LIMIT [0-9]+", replace="", source=Query),
 else=Query), env=Env)
 },
 key=Key), RemoveLimit
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.AddUser</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.adduser/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.adduser/</guid><description>&lt;p>This server artifact is used to add new user to the Velociraptor
GUI.&lt;/p>
&lt;p>A new random password is generated for the user and stored in the
server metadata object (to ensure it cannot be seen in the output
of the artifact itself). The Administrator can share this password
with the user later.&lt;/p>
&lt;p>When using SSO (e.g. oauth) this password is not used and can be
ignored (Becuase the SSO provider will do the authentication).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.AddUser
description: |
 This server artifact is used to add new user to the Velociraptor
 GUI.

 A new random password is generated for the user and stored in the
 server metadata object (to ensure it cannot be seen in the output
 of the artifact itself). The Administrator can share this password
 with the user later.

 When using SSO (e.g. oauth) this password is not used and can be
 ignored (Becuase the SSO provider will do the authentication).

type: SERVER

parameters:
 - name: UserName
 description: The new username to add

 - name: ResetPassword
 type: bool
 default: "Y"
 description: |
 Reset the user's password. This must be set when
 creating the user in the first place.

 - name: Role
 description: The role to grant the new user.
 type: choices
 default: reader
 choices:
 - reader
 - analyst
 - investigator
 - administrator

sources:
 - query: |
 LET Password &amp;lt;= format(format="%02x", args=rand(range=0xffffffffffff))
 LET ServerMetadataKey &amp;lt;= "User Password " + UserName

 LET DoIt = SELECT * FROM if(condition=ResetPassword,
 then={
 SELECT
 server_set_metadata(metadata=set(
 item=server_metadata(),
 field=ServerMetadataKey, value=Password)),
 user_create(roles=Role, user=UserName, password=Password)
 FROM scope()
 WHERE log(message="New password for user is stored in server metadata under key " + ServerMetadataKey)
 }, else={
 -- Just grant the user the specified role
 SELECT user_create(roles=Role, user=UserName)
 FROM scope()
 })

 SELECT * FROM if(condition=UserName,
 then={
 SELECT * FROM foreach(row=DoIt,
 query={
 SELECT * FROM gui_users()
 WHERE name =~ UserName
 })
 }, else={
 SELECT * FROM scope()
 WHERE log(message="A Username must be set") AND FALSE
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.BackupDirectory</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.backupdirectory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.backupdirectory/</guid><description>&lt;p>This server monitoring artifact will automatically export and
backup selected collected artifacts to a directory on the server.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.BackupDirectory
description: |
 This server monitoring artifact will automatically export and
 backup selected collected artifacts to a directory on the server.

type: SERVER_EVENT

parameters:
 - name: ArtifactNameRegex
 default: "."
 description: A regular expression to select which artifacts to upload
 type: regex

 - name: BackupDirectoryPath
 description: A directory on the server to receive the uploaded files.

 - name: RemoveDownloads
 type: bool
 description: If set, remove the flow export files after upload

required_permissions:
 - SERVER_ADMIN

sources:
 - query: |
 LET completions = SELECT *,
 client_info(client_id=ClientId).os_info.fqdn AS Fqdn,
 create_flow_download(client_id=ClientId,
 flow_id=FlowId, wait=TRUE) AS FlowDownload
 FROM watch_monitoring(artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

 SELECT upload_directory(
 output=BackupDirectoryPath,
 name=format(format="Host %v %v %v.zip",
 args=[Fqdn, FlowId, timestamp(epoch=now())]),
 accessor="fs",
 file=FlowDownload) AS Upload
 FROM completions
 WHERE Upload OR
 if(condition=RemoveDownloads,
 then=rm(filename=file_store(path=FlowDownload)))

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.BackupGCS</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.backupgcs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.backupgcs/</guid><description>&lt;p>This server monitoring artifact will automatically zip and backup
any collected artifacts to GCS.&lt;/p>
&lt;p>You will need to provide credentials to upload to the bucket. The
credentials can be given as parameters or they will be taken from
the server metadata (as DefaultBucket, DefaultGCSProject,
DefaultGCSKey)&lt;/p>
&lt;p>Thanks to @shortxstack and @Recon_InfoSec&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.BackupGCS
description: |
 This server monitoring artifact will automatically zip and backup
 any collected artifacts to GCS.

 You will need to provide credentials to upload to the bucket. The
 credentials can be given as parameters or they will be taken from
 the server metadata (as DefaultBucket, DefaultGCSProject,
 DefaultGCSKey)

 Thanks to @shortxstack and @Recon_InfoSec

type: SERVER_EVENT

parameters:
 - name: ArtifactNameRegex
 default: "."
 description: A regular expression to select which artifacts to upload
 type: regex

 - name: Bucket
 description: The bucket to upload to (blank to use server metadata)
 - name: Project
 - name: GCSKey

 - name: RemoveDownloads
 type: bool
 description: If set, remove the flow export files after upload

sources:
 - query: |
 -- Allow these settings to be set by the artifact parameter or the server metadata.
 LET bucket &amp;lt;= if(condition=Bucket, then=Bucket,
 else=server_metadata().DefaultBucket)
 LET project &amp;lt;= if(condition=Project, then=Project,
 else=server_metadata().DefaultGCSProject)
 LET gcskey &amp;lt;= if(condition=GCSKey, then=GCSKey,
 else=server_metadata().DefaultGCSKey)

 LET completions = SELECT *,
 client_info(client_id=ClientId).os_info.fqdn AS Fqdn,
 create_flow_download(client_id=ClientId,
 flow_id=FlowId, wait=TRUE) AS FlowDownload
 FROM watch_monitoring(artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

 SELECT upload_gcs(
 bucket=bucket,
 project=project,
 credentials=gcskey,
 file=FlowDownload,
 accessor="fs",
 name=format(format="Host %v %v %v.zip",
 args=[Fqdn, FlowId, timestamp(epoch=now())])) AS Upload
 FROM completions
 WHERE Upload OR
 if(condition=RemoveDownloads,
 then=rm(filename=file_store(path=FlowDownload)))

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.BackupS3</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.backups3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.backups3/</guid><description>&lt;p>This server monitoring artifact will automatically zip and backup
any collected artifacts to s3.&lt;/p>
&lt;p>You will need to provide credentials to upload to the bucket. The
credentials can be given as parameters or they will be taken from
the server metadata (as DefaultBucket, DefaultRegion,
S3AccessKeyId, S3AccessSecret, S3AccessToken)&lt;/p>
&lt;p>Thanks to @shortxstack and @Recon_InfoSec&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.BackupS3
description: |
 This server monitoring artifact will automatically zip and backup
 any collected artifacts to s3.

 You will need to provide credentials to upload to the bucket. The
 credentials can be given as parameters or they will be taken from
 the server metadata (as DefaultBucket, DefaultRegion,
 S3AccessKeyId, S3AccessSecret, S3AccessToken)

 Thanks to @shortxstack and @Recon_InfoSec

type: SERVER_EVENT

parameters:
 - name: ArtifactNameRegex
 default: "."
 description: A regular expression to select which artifacts to upload
 type: regex
 
 - name: Bucket
 description: The bucket to upload to (blank to use server metadata)

 - name: Endpoint
 
 - name: Region
 
 - name: CredentialsKey
 
 - name: CredentialsSecret
 
 - name: CredentialsToken
 
 - name: Secret
 description: A Secret name to use for uploading.
 
 - name: RemoveDownloads
 type: bool
 description: If set, remove the flow export files after upload

sources:
 - query: |
 -- Allow these settings to be set by the artifact parameter or
 -- the server metadata.
 LET completions = SELECT *,
 client_info(client_id=ClientId).os_info.fqdn AS Fqdn,
 create_flow_download(client_id=ClientId,
 flow_id=FlowId, wait=TRUE) AS FlowDownload
 FROM watch_monitoring(artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

 SELECT upload_s3(
 bucket=Bucket,
 credentials_key=CredentialsKey,
 credentials_secret=CredentialsSecret,
 endpoint=Endpoint,
 credentials_token=CredentialsToken,
 secret=Secret,
 region=Region,
 file=FlowDownload,
 accessor="fs",
 name=format(format="Host %v %v %v.zip",
 args=[Fqdn, FlowId, timestamp(epoch=now())])) AS Upload
 FROM completions
 WHERE Upload OR
 if(condition=RemoveDownloads,
 then=rm(filename=file_store(path=FlowDownload)))

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.CancelHunt</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.cancelhunt/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.cancelhunt/</guid><description>&lt;p>Sometimes a hunt is issued which is no longer useful. While stopping
the hunt from the GUI prevents new clients from receiving the hunt,
it does not actively cancel collections currently in flight.&lt;/p>
&lt;p>This artifact enumerates all flows in the hunt and actively cancels
them.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.CancelHunt
description: |
 Sometimes a hunt is issued which is no longer useful. While stopping
 the hunt from the GUI prevents new clients from receiving the hunt,
 it does not actively cancel collections currently in flight.

 This artifact enumerates all flows in the hunt and actively cancels
 them.

type: SERVER

parameters:
 - name: HuntId
 - name: Hunts
 type: json_array
 description: A list of hunts to cancel
 default: '[]'

sources:
 - query: |
 LET all_flows(HuntId) = SELECT Flow.client_id AS client_id, Flow.session_id AS flow_id
 FROM hunt_flows(hunt_id=HuntId)
 WHERE NOT Flow.state =~ "ERROR|FINISHED"

 LET cancellations(HuntId) = SELECT HuntId, client_id, flow_id,
 cancel_flow(client_id=client_id, flow_id=flow_id) AS Cancellation
 FROM all_flows(HuntId=HuntId)

 LET AllHunts &amp;lt;= if(condition=HuntId, then=Hunts + HuntId, else=Hunts)

 SELECT * FROM foreach(row={
 SELECT _value as HuntId FROM items(item=AllHunts)
 }, query={
 SELECT * FROM cancellations(HuntId=HuntId)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.CollectClient</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.collectclient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.collectclient/</guid><description>&lt;p>This artifact simplifies collecting from a specific client by
performing all steps automatically:&lt;/p>
&lt;ol>
&lt;li>The collection will be scheduled.&lt;/li>
&lt;li>The artifact will wait for the collection to complete&lt;/li>
&lt;li>The results from the collection will be displayed.&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.CollectClient
description: |
 This artifact simplifies collecting from a specific client by
 performing all steps automatically:

 1. The collection will be scheduled.
 2. The artifact will wait for the collection to complete
 3. The results from the collection will be displayed.

type: SERVER

parameters:
 - name: ArtifactName
 default: Generic.Client.Info
 - name: Client
 description: A client ID or a Hostname
 default: C.1234
 - name: Parameters
 default: "{}"
 description: A key/value JSON object specifying parameters for the artifact
 type: json

sources:
 - query: |
 -- Find a client to collect from by applying the search
 -- critertia and picking the first hit
 LET clients = SELECT client_id FROM clients(search=Client) LIMIT 1
 LET client_id &amp;lt;= clients[0].client_id

 -- If we found something then schedule the collection.
 LET collection &amp;lt;= if(condition=client_id,
 then=collect_client(client_id=client_id,
 artifacts=ArtifactName, env=Parameters),
 else=log(message="No clients found to match search " + Client) AND FALSE)

 -- Wait for the collection to finish - if the client is
 -- currently connected this wont take long
 LET flow_results &amp;lt;= SELECT * FROM if(condition=collection,
 then={
 SELECT * FROM watch_monitoring(artifact='System.Flow.Completion')
 WHERE FlowId = collection.flow_id
 LIMIT 1
 })

 -- Collect the results
 SELECT * FROM foreach(row=flow_results[0].Flow.artifacts_with_results,
 query={
 SELECT *, _value AS Source, client_id
 FROM source(client_id=client_id, flow_id=collection.flow_id, artifact=_value)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.CreateCollector</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.createcollector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.createcollector/</guid><description>&lt;p>A utility artifact to create a stand alone collector.&lt;/p>
&lt;p>This artifact is actually invoked by the Offline collector GUI and
that is the recommended way to launch it. You can find the Offline
collector builder in the &lt;code>Server Artifacts&lt;/code> section of the GUI.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.CreateCollector
description: |
 A utility artifact to create a stand alone collector.

 This artifact is actually invoked by the Offline collector GUI and
 that is the recommended way to launch it. You can find the Offline
 collector builder in the `Server Artifacts` section of the GUI.

type: SERVER

parameters:
 - name: OS
 default: Windows
 type: choices
 choices:
 - Windows
 - Windows_x86
 - Linux
 - MacOS
 - MacOSArm
 - Generic

 - name: artifacts
 description: A list of artifacts to collect
 type: json_array
 default: |
 ["Generic.Client.Info"]

 - name: encryption_scheme
 description: |
 Encryption scheme to use. Currently supported are Password, X509 or PGP

 - name: encryption_args
 description: |
 Encryption arguments
 type: json
 default: |
 {}

 - name: parameters
 description: A dict containing the parameters to set.
 type: json
 default: |
 {}

 - name: target
 description: Output type
 type: choices
 default: ZIP
 choices:
 - ZIP
 - GCS
 - S3
 - SFTP
 - Azure
 - SMBShare

 - name: target_args
 description: Type Dependent args
 type: json
 default: "{}"

 - name: opt_verbose
 default: Y
 type: bool
 description: Show verbose progress.

 - name: opt_banner
 default: Y
 type: bool
 description: Show Velociraptor banner.

 - name: opt_prompt
 default: N
 type: bool
 description: Wait for a prompt before closing.

 - name: opt_admin
 default: Y
 type: bool
 description: Require administrator privilege when running.

 - name: opt_tempdir
 default:
 description: A directory to write tempfiles in

 - name: opt_level
 default: "5"
 type: int
 description: Compression level (0=no compression).

 - name: opt_concurrency
 default: "2"
 type: int
 description: Number of concurrency queries

 - name: opt_format
 default: "jsonl"
 description: Output format (jsonl or csv)

 - name: opt_output_directory
 default: ""
 description: Where we actually write the collection to. You can specify this as a mapped drive to write over the network.

 - name: opt_filename_template
 default: "Collection-%FQDN%-%TIMESTAMP%"
 description: |
 The filename to use. You can expand environment variables as
 well as the following %FQDN% and %TIMESTAMP%.

 - name: opt_collector_filename
 type: string
 description: |
 If used, this option overrides the default filename of the collector being built.

 - name: opt_cpu_limit
 default: "0"
 type: int
 description: |
 A number between 0 to 100 representing the target maximum CPU
 utilization during running of this artifact.

 - name: opt_progress_timeout
 default: "1800"
 type: int
 description: |
 If specified the collector is terminated if it made no progress
 in this long. Note: Execution time may be a lot longer since
 each time any result is produced this counter is reset.

 - name: opt_timeout
 default: "0"
 type: int
 description: |
 If specified the collection must complete in the given time. It
 will be cancelled if the collection exceeds this time.

 - name: opt_version
 default: ""
 type: string
 description: |
 If specified the collection will be packed with the specified
 version of the binary. NOTE: This is rarely what you want
 because the packed builtin artifacts are only compatible with
 the current release version.

 - name: opt_delete_at_exit
 type: bool
 default: N
 description: |
 If specified the collection will be deleted at exit. This only
 makes sense when uploading to the cloud or a remote
 location. NOTE: There is no way to check that the upload
 actually worked so this flag deletes the collection regardless
 of upload success.

 - name: StandardCollection
 type: hidden
 default: |
 LET _ &amp;lt;= log(message="Will collect package %v", args=zip_filename)

 SELECT * FROM collect(artifacts=Artifacts,
 args=Parameters, output=zip_filename,
 cpu_limit=CpuLimit,
 progress_timeout=ProgressTimeout,
 timeout=Timeout,
 password=pass[0].Pass,
 level=Level,
 concurrency=Concurrency,
 format=Format,
 remapping=Remapping,
 metadata=ContainerMetadata)

 - name: S3Collection
 type: hidden
 default: |
 // A utility function to upload the file.
 LET upload_file(filename, name, accessor) = upload_s3(
 file=filename,
 accessor=accessor,
 bucket=TargetArgs.bucket,
 name=name,
 credentials_key=TargetArgs.credentialsKey,
 credentials_secret=TargetArgs.credentialsSecret,
 credentials_token=TargetArgs.credentialsToken,
 region=TargetArgs.region,
 endpoint=TargetArgs.endpoint,
 serverside_encryption=TargetArgs.serverSideEncryption,
 kms_encryption_key=TargetArgs.kmsEncryptionKey,
 s3upload_root=TargetArgs.s3UploadRoot,
 skip_verify=TargetArgs.noverifycert)

 - name: GCSCollection
 type: hidden
 default: |
 LET GCSBlob &amp;lt;= parse_json(data=target_args.GCSKey)

 // A utility function to upload the file.
 LET upload_file(filename, name, accessor) = upload_gcs(
 file=filename,
 accessor=accessor,
 bucket=target_args.bucket,
 project=GCSBlob.project_id,
 name=name,
 credentials=target_args.GCSKey)

 - name: AzureSASURL
 type: hidden
 default: |
 // A utility function to upload the file.
 LET upload_file(filename, name, accessor) = upload_azure(
 file=filename,
 accessor=accessor,
 sas_url=TargetArgs.sas_url,
 name=name)

 - name: SMBCollection
 type: hidden
 default: |
 // A utility function to upload the file.
 LET upload_file(filename, name, accessor) = upload_smb(
 file=filename,
 accessor=accessor,
 username=TargetArgs.username,
 password=TargetArgs.password,
 server_address=TargetArgs.server_address,
 name=name)

 - name: SFTPCollection
 type: hidden
 default : |
 LET upload_file(filename, name, accessor) = upload_sftp(
 file=filename,
 accessor=accessor,
 name=name,
 user=TargetArgs.user,
 path=TargetArgs.path,
 privatekey=TargetArgs.privatekey,
 endpoint=TargetArgs.endpoint,
 hostkey = TargetArgs.hostkey)

 - name: CommonCollections
 type: hidden
 default: |
 LET S = scope()
 LET Remapping &amp;lt;= if(condition=Remapping,
 then=log(message="Will load remapping rules from %v", args=Remapping) &amp;amp;&amp;amp;
 read_file(filename=Remapping),
 else="")

 // Add all the tools we are going to use to the inventory.
 LET _ &amp;lt;= SELECT inventory_add(tool=ToolName, hash=ExpectedHash, version=S.Version)
 FROM parse_csv(filename="/uploads/inventory.csv", accessor="me")
 WHERE log(message="Adding tool " + ToolName +
 " version " + (S.Version || "Unknown"))

 LET baseline &amp;lt;= SELECT Fqdn, dirname(path=Exe) AS ExePath, Exe,
 scope().CWD AS CWD FROM info()

 LET OutputPrefix &amp;lt;= if(condition= OutputPrefix,
 then=pathspec(parse=OutputPrefix),
 else= if(condition= baseline[0].CWD,
 then=pathspec(parse= baseline[0].CWD),
 else=pathspec(parse= baseline[0].ExePath)))

 LET _ &amp;lt;= log(message="Output Prefix : %v", args= OutputPrefix)

 LET FormatMessage(Message) = regex_transform(
 map=dict(`%FQDN%`=baseline[0].Fqdn,
 `%Timestamp%`=timestamp(epoch=now()).MarshalText),
 source=Message)

 // Format the filename safely according to the filename
 // template. This will be the name uploaded to the bucket.
 LET formatted_zip_name &amp;lt;= regex_replace(
 source=expand(path=FormatMessage(Message=FilenameTemplate)),
 re="[^0-9A-Za-z\\-]", replace="_")

 // This is where we write the files on the endpoint.
 LET zip_filename &amp;lt;= OutputPrefix + ( formatted_zip_name + ".zip" )
 LET LogFile &amp;lt;= OutputPrefix + ( formatted_zip_name + ".log" )

 LET _ &amp;lt;= log(message="Log file is at %v", args=LogFile)

 // Create the log file and start writing into it
 // Just forward output from the logging() plugin
 LET LogPipe &amp;lt;= pipe(query={
 SELECT format(format="[%v] %v %v\n",
 args=(level, time, msg)) AS Line
 FROM logging(prelog=TRUE)
 })

 LET _ &amp;lt;= background(query={
 SELECT copy(accessor="pipe", filename="LogPipe", dest=LogFile) AS C
 FROM scope()
 })

 -- Remove the zip file and log file when done if the user asked for it.
 LET _ &amp;lt;= if(condition=DeleteOnExit, then=atexit(query={
 SELECT rm(filename=zip_filename), rm(filename=log_filename) FROM scope()
 WHERE log(message="Removed Zip file %v", args=zip_filename)
 }, env=dict(zip_filename=zip_filename, log_filename=LogFile)))

 -- Make a random hex string as a random password
 LET RandomPassword &amp;lt;= SELECT format(format="%02x",
 args=rand(range=255)) AS A
 FROM range(end=25)

 LET pass = SELECT * FROM switch(a={

 -- For X509 encryption we use a random session password.
 SELECT join(array=RandomPassword.A) as Pass From scope()
 WHERE encryption_scheme =~ "pgp|x509"
 AND log(message="I will generate a container password using the %v scheme",
 args=encryption_scheme)

 }, b={

 -- Otherwise the user specified the password.
 SELECT encryption_args.password as Pass FROM scope()
 WHERE encryption_scheme =~ "password"

 }, c={

 -- No password specified.
 SELECT Null as Pass FROM scope()
 })

 -- For X509 encryption_scheme, store the encrypted
 -- password in the metadata file for later retrieval.
 LET ContainerMetadata = if(
 condition=encryption_args.public_key,
 then=dict(
 EncryptedPass=pk_encrypt(data=pass[0].Pass,
 public_key=encryption_args.public_key,
 scheme=encryption_scheme),
 Scheme=encryption_scheme,
 PublicKey=encryption_args.public_key))

 - name: CloudCollection
 type: hidden
 default: |
 LET TargetArgs &amp;lt;= target_args

 // When uploading to the cloud it is allowed to use directory //
 // separators and we trust the filename template to be a valid
 // filename.
 LET upload_name &amp;lt;= regex_replace(
 source=expand(path=FormatMessage(Message=FilenameTemplate)),
 re="[^0-9A-Za-z\\-/]", replace="_")

 LET _ &amp;lt;= log(message="Will collect package %v and upload to cloud bucket %v",
 args=[zip_filename, TargetArgs.bucket])

 LET Result &amp;lt;= SELECT
 upload_file(filename=Container,
 name= upload_name + ".zip",
 accessor="file") AS Upload,
 upload_file(filename=LogFile,
 name= upload_name + ".log",
 accessor="file") AS LogUpload

 FROM collect(artifacts=Artifacts,
 args=Parameters,
 format=Format,
 output=zip_filename,
 cpu_limit=CpuLimit,
 progress_timeout=ProgressTimeout,
 timeout=Timeout,
 password=pass[0].Pass,
 level=Level,
 concurrency=Concurrency,
 remapping=Remapping,
 metadata=ContainerMetadata)

 LET _ &amp;lt;= if(condition=NOT Result[0].Upload.Path,
 then=log(message="&amp;lt;red&amp;gt;Failed to upload to cloud bucket!&amp;lt;/&amp;gt; Leaving the collection behind for manual upload!"),
 else=log(message="&amp;lt;green&amp;gt;Collection Complete!&amp;lt;/&amp;gt; Please remove %v when you are sure it was properly transferred", args=zip_filename))

 SELECT * FROM Result


 - name: FetchBinaryOverride
 type: hidden
 description: |
 A replacement for Generic.Utils.FetchBinary which
 grabs files from the local archive.

 default: |
 LET RequiredTool &amp;lt;= ToolName
 LET S = scope()

 LET matching_tools &amp;lt;= SELECT ToolName, Filename
 FROM parse_csv(filename="/uploads/inventory.csv", accessor="me")
 WHERE RequiredTool = ToolName

 LET get_ext(filename) = parse_string_with_regex(
 regex="(\\.[a-z0-9]+)$", string=filename).g1

 LET FullPath &amp;lt;= if(condition=matching_tools,
 then=copy(filename=matching_tools[0].Filename,
 accessor="me", dest=tempfile(
 extension=get_ext(filename=matching_tools[0].Filename),
 remove_last=TRUE,
 permissions=if(condition=IsExecutable, then="x"))))

 SELECT FullPath, FullPath AS OSPath,
 Filename AS Name
 FROM matching_tools

sources:
 - query: |
 LET Binaries &amp;lt;= SELECT * FROM foreach(
 row={
 SELECT tools FROM artifact_definitions(deps=TRUE, names=artifacts)
 }, query={
 SELECT * FROM foreach(row=tools,
 query={
 SELECT name AS Binary FROM scope()
 })
 }) GROUP BY Binary

 // Choose the right target binary depending on the target OS
 LET tool_name = SELECT * FROM switch(
 a={ SELECT "VelociraptorWindows" AS Type FROM scope() WHERE OS = "Windows"},
 b={ SELECT "VelociraptorWindows_x86" AS Type FROM scope() WHERE OS = "Windows_x86"},
 c={ SELECT "VelociraptorLinux" AS Type FROM scope() WHERE OS = "Linux"},
 d={ SELECT "VelociraptorCollector" AS Type FROM scope() WHERE OS = "MacOS"},
 e={ SELECT "VelociraptorCollector" AS Type FROM scope() WHERE OS = "MacOSArm"},
 f={ SELECT "VelociraptorCollector" AS Type FROM scope() WHERE OS = "Generic"},
 g={ SELECT "" AS Type FROM scope()
 WHERE NOT log(message="Unknown target type " + OS) }
 )

 LET Target &amp;lt;= tool_name[0].Type

 // This is what we will call it.
 LET CollectorName &amp;lt;= opt_collector_filename ||
 format(format='Collector_%v', args=inventory_get(tool=Target).Definition.filename)

 LET CollectionArtifact &amp;lt;= SELECT Value FROM switch(
 a = { SELECT CommonCollections + StandardCollection AS Value
 FROM scope()
 WHERE target = "ZIP" },
 b = { SELECT S3Collection + CommonCollections + CloudCollection AS Value
 FROM scope()
 WHERE target = "S3" },
 c = { SELECT GCSCollection + CommonCollections + CloudCollection AS Value
 FROM scope()
 WHERE target = "GCS" },
 d = { SELECT SFTPCollection + CommonCollections + CloudCollection AS Value
 FROM scope()
 WHERE target = "SFTP" },
 e = { SELECT AzureSASURL + CommonCollections + CloudCollection AS Value
 FROM scope()
 WHERE target = "Azure" },
 f = { SELECT SMBCollection + CommonCollections + CloudCollection AS Value
 FROM scope()
 WHERE target = "SMBShare" },
 z = { SELECT "" AS Value FROM scope()
 WHERE log(message="Unknown collection type " + target) }
 )

 LET use_server_cert = encryption_scheme =~ "x509"
 AND NOT encryption_args.public_key =~ "-----BEGIN CERTIFICATE-----"
 AND log(message="Pubkey encryption specified, but no cert/key provided. Defaulting to server frontend cert")

 -- For x509, if no public key cert is specified, we use the
 -- server's own key. This makes it easy for the server to import
 -- the file again.
 LET updated_encryption_args &amp;lt;= if(
 condition=use_server_cert,
 then=dict(public_key=server_frontend_cert(),
 scheme="x509"),
 else=encryption_args
 )

 -- Add custom definition if needed. Built in definitions are not added
 LET definitions &amp;lt;= SELECT * FROM chain(
 a = { SELECT name, description, tools, export, parameters, sources
 FROM artifact_definitions(deps=TRUE, names=artifacts)
 WHERE NOT compiled_in AND
 log(message="Adding artifact_definition for " + name) },

 // Create the definition of the Collector artifact.
 b = { SELECT "Collector" AS name, (
 dict(name="Artifacts",
 default=serialize(format='json', item=artifacts),
 type="json_array"),
 dict(name="Parameters",
 default=serialize(format='json', item=parameters),
 type="json"),
 dict(name="encryption_scheme", default=encryption_scheme),
 dict(name="encryption_args",
 default=serialize(format='json', item=updated_encryption_args),
 type="json"
 ),
 dict(name="Level", default=opt_level, type="int"),
 dict(name="Remapping", default=""),
 dict(name="Concurrency", default=opt_concurrency, type="int"),
 dict(name="Format", default=opt_format),
 dict(name="OutputPrefix", default=opt_output_directory),
 dict(name="FilenameTemplate", default=opt_filename_template),
 dict(name="CpuLimit", type="int",
 default=opt_cpu_limit),
 dict(name="ProgressTimeout", type="int",
 default=opt_progress_timeout),
 dict(name="Timeout", default=opt_timeout, type="int"),
 dict(name="DeleteOnExit", default=opt_delete_at_exit, type="bool"),
 dict(name="target_args",
 default=serialize(format='json', item=target_args),
 type="json"),
 ) AS parameters,
 (
 dict(query=CollectionArtifact[0].Value),
 ) AS sources
 FROM scope() },

 // Override FetchBinary to get files from the executable.
 c = { SELECT "Generic.Utils.FetchBinary" AS name,
 (
 dict(name="SleepDuration", type="int", default="0"),
 dict(name="ToolName"),
 dict(name="ToolInfo"),
 dict(name="TemporaryOnly", type="bool"),
 dict(name="Version"),
 dict(name="IsExecutable", type="bool", default="Y"),
 ) AS parameters,
 (
 dict(query=FetchBinaryOverride),
 ) AS sources FROM scope() }
 )

 LET optional_cmdline = SELECT * FROM chain(
 a={ SELECT "-v" AS Opt FROM scope() WHERE opt_verbose},
 b={ SELECT "--nobanner" AS Opt FROM scope() WHERE NOT opt_banner},
 c={ SELECT "--require_admin" AS Opt FROM scope() WHERE opt_admin},
 d={ SELECT "--prompt" AS Opt FROM scope() WHERE opt_prompt},
 e={ SELECT "--tempdir" AS Opt FROM scope() WHERE opt_tempdir},
 f={ SELECT opt_tempdir AS Opt FROM scope() WHERE opt_tempdir}
 )

 // Build the autoexec config file depending on the user's
 // collection type choices.
 LET autoexec &amp;lt;= dict(autoexec=dict(
 argv=("artifacts", "collect", "Collector") + optional_cmdline.Opt,
 artifact_definitions=definitions)
 )

 // Do the actual repacking.
 SELECT repack(
 upload_name=CollectorName,
 target=tool_name[0].Type,
 binaries=Binaries.Binary,
 version=opt_version,
 config=serialize(format='json', item=autoexec)) AS Repacked
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.CreateLinuxPackages</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.createlinuxpackages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.createlinuxpackages/</guid><description>&lt;p>Build Deb and RPM packages ready for deployment in the current org.&lt;/p>
&lt;p>This artifact depends on the following tool:&lt;/p>
&lt;ul>
&lt;li>
&lt;velo-tool-viewer name="VelociraptorLinux" />
&lt;/li>
&lt;/ul>
&lt;p>You can replace this with suitable Velociraptor Linux build, or the
current release binary will be used by default.&lt;/p>
&lt;p>Use the following to inspect the RPM and Deb:&lt;/p>
&lt;ul>
&lt;li>rpm -qi velociraptor.rpm&lt;/li>
&lt;li>rpm -qp &amp;ndash;scripts velociraptor.rpm&lt;/li>
&lt;li>dpkg-deb -I velociraptor.deb&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.CreateLinuxPackages
description: |
 Build Deb and RPM packages ready for deployment in the current org.

 This artifact depends on the following tool:

 * &amp;lt;velo-tool-viewer name="VelociraptorLinux" /&amp;gt;

 You can replace this with suitable Velociraptor Linux build, or the
 current release binary will be used by default.

 Use the following to inspect the RPM and Deb:
 - rpm -qi velociraptor.rpm
 - rpm -qp --scripts velociraptor.rpm
 - dpkg-deb -I velociraptor.deb


type: SERVER

parameters:
 - name: CustomConfig
 description: Supply a custom client config instead of using the one from the current org
 type: yaml
 - name: ServiceName
 description: Customize the service name
 - name: Maintainer
 description: Customize the maintainer
 - name: MaintainerEmail
 description: Customize the maintainer email
 - name: Homepage
 description: Customize the homepage URL
 - name: Vendor
 description: The vendor
 default: The Velociraptor Team

sources:
- query: |
 LET ValidateConfig(Config) = Config.Client.server_urls
 AND Config.Client.ca_certificate =~ "(?ms)-----BEGIN CERTIFICATE-----.+-----END CERTIFICATE-----"
 AND Config.Client.nonce

 LET client_config &amp;lt;= if(condition=ValidateConfig(Config=CustomConfig),
 then=CustomConfig,
 else=org()._client_config)

 LET TmpDir &amp;lt;= tempdir()

 // This is an example of how to modify the spec to customize the
 // creation of the RPM. The default template does not set the
 // vendor property in the RPM, so we just update the metadata
 // template while preserving all the other fields.
 // See https://github.com/google/rpmpack/blob/2467806670a618497006ff8d8623b0430c7605a9/rpm.go#L56
 LET _RPMSpec &amp;lt;= SELECT Spec FROM rpm_create(show_spec=TRUE)
 LET RPMSpec &amp;lt;= _RPMSpec[0].Spec + dict(Templates=_RPMSpec[0].Spec.Templates +
 dict(Metadata=format(format='''
 {"Name": "{{ .SysvService }}",
 "Vendor": "%v",
 "Version": "{{ .Version }}",
 "Release": "{{ .Release}}",
 "Arch": "{{.Arch}}",
 "BuildTime": "%v"
 }
 ''', args=[Vendor, timestamp(epoch=now())])))

 LET _DebSpec &amp;lt;= SELECT Spec FROM deb_create(show_spec=TRUE)
 LET DebSpec &amp;lt;= _DebSpec[0].Spec

 LET UpdateExpansion(Expansion) = Expansion + dict(
 Name=ServiceName || Expansion.Name,
 SysvService=ServiceName || Expansion.SysvService,
 Maintainer=Maintainer || Expansion.Maintainer,
 MaintainerEmail=MaintainerEmail || Expansion.MaintainerEmail,
 Homepage=Homepage || Expansion.Homepage
 )

 SELECT * FROM chain(a={
 SELECT OSPath.Basename AS Name,
 upload(file=OSPath, name=OSPath.Basename) AS Upload
 FROM deb_create(
 directory_name=TmpDir,
 package_spec=DebSpec +
 dict(Expansion=UpdateExpansion(Expansion=DebSpec.Expansion)),
 config=serialize(item=client_config, format="yaml"))
 }, b={
 SELECT OSPath.Basename AS Name,
 upload(file=OSPath, name=OSPath.Basename) AS Upload
 FROM rpm_create(
 directory_name=TmpDir,
 package_spec=RPMSpec +
 dict(Expansion=UpdateExpansion(Expansion=RPMSpec.Expansion)),
 config=serialize(item=client_config, format="yaml"))
 })

column_types:
 - name: Upload
 type: upload_preview

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.CreateMSI</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.createmsi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.createmsi/</guid><description>&lt;p>Build an MSI ready for deployment in the current org.&lt;/p>
&lt;p>This artifact depends on the following tools:&lt;/p>
&lt;ul>
&lt;li>
&lt;velo-tool-viewer name="VelociraptorWindowsMSI" />
&lt;/li>
&lt;li>
&lt;velo-tool-viewer name="VelociraptorWindows_x86MSI" />
&lt;/li>
&lt;/ul>
&lt;p>You can replace those with suitable MSI builds.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.CreateMSI
description: |
 Build an MSI ready for deployment in the current org.

 This artifact depends on the following tools:

 * &amp;lt;velo-tool-viewer name="VelociraptorWindowsMSI" /&amp;gt;
 * &amp;lt;velo-tool-viewer name="VelociraptorWindows_x86MSI" /&amp;gt;

 You can replace those with suitable MSI builds.

type: SERVER

parameters:
 - name: CustomConfig
 description: Supply a custom client config instead of using the one from the current org
 type: yaml
 - name: AlsoBuild_x86
 description: Also build 32 bit MSI for deployment.
 type: bool

sources:
- query: |
 LET ValidateConfig(Config) = Config.Client.server_urls
 AND Config.Client.ca_certificate =~ "(?ms)-----BEGIN CERTIFICATE-----.+-----END CERTIFICATE-----"
 AND Config.Client.nonce

 LET client_config &amp;lt;= if(condition=ValidateConfig(Config=CustomConfig),
 then=CustomConfig,
 else=org()._client_config)

 LET Build(Target) = repack(
 upload_name=format(
 format='Org_%v_%v',
 args=[org().name, inventory_get(tool=Target).Definition.filename]),
 target=Target,
 config=serialize(format='yaml', item=client_config))

 SELECT * FROM chain(a={
 SELECT Build(Target="VelociraptorWindowsMSI") FROM scope()
 }, b={
 SELECT Build(Target="VelociraptorWindows_x86MSI") FROM scope()
 WHERE AlsoBuild_x86
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeadDiskClient</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deaddiskclient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deaddiskclient/</guid><description>&lt;p>Automates the analysis of dead disk images in Velociraptor&lt;/p>
&lt;p>Velociraptor can analyze dead disk images by using accessor
remapping. The process involves detecting a suitable remapping
configuration to remap various image partitions into the relevant
accessors and emulate a &amp;ldquo;Virtual Host&amp;rdquo;.&lt;/p>
&lt;p>Once the remapping configuration is calculated, a new virtual
client can be launched to appear like it is operating on the dead
disk image. Using this technique is it possible to interact with
this virtual client, collect artifacts, join in hunts etc.&lt;/p>
&lt;p>This artifact automates this process. While the artifact is running,
the virtual client will be up. To kill the virtual client you can
cancel this collection. By default the artifact will remain running
for 1 hour but you can extend the time limit while launching the
artifact using the resources tab.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeadDiskClient
description: |
 Automates the analysis of dead disk images in Velociraptor

 Velociraptor can analyze dead disk images by using accessor
 remapping. The process involves detecting a suitable remapping
 configuration to remap various image partitions into the relevant
 accessors and emulate a "Virtual Host".

 Once the remapping configuration is calculated, a new virtual
 client can be launched to appear like it is operating on the dead
 disk image. Using this technique is it possible to interact with
 this virtual client, collect artifacts, join in hunts etc.

 This artifact automates this process. While the artifact is running,
 the virtual client will be up. To kill the virtual client you can
 cancel this collection. By default the artifact will remain running
 for 1 hour but you can extend the time limit while launching the
 artifact using the resources tab.

type: SERVER

resources:
 timeout: 3600

parameters:
- name: ImagePath
 default: /path/to/image.vmdk
 description: |
 This is the path to the image (.vmdk, .vhdx etc) which must reside on the server.

- name: Hostname
 default: DeadDiskHost
 description: The virtual host to provide to the client

- name: WritebackFile
 default: /tmp/remapping.writeback.yaml
 description: |
 Where to store the writeback file. This contains the client ID and
 should persist between invocations.

sources:
- query: |
 LET RemappingFile &amp;lt;= tempfile(extension=".yaml")

 LET ClientConfig &amp;lt;= tempfile(extension=".yaml")

 LET _Exe &amp;lt;= SELECT Exe
 FROM info()

 // Our own binary we use to run.
 LET Exe &amp;lt;= _Exe[0].Exe

 LET CalculateDeadDisk = SELECT copy(accessor="data",
 filename=Remapping,
 dest=RemappingFile) AS RemappingFile,
 copy(accessor="data",
 filename=serialize(
 format="yaml",
 item=org()._client_config),
 dest=ClientConfig) AS ClientConfig
 FROM Artifact.Generic.Utils.DeadDiskRemapping(
 Upload=FALSE,
 Hostname=Hostname,
 ImagePath=ImagePath)

 SELECT Stdout
 FROM foreach(row=CalculateDeadDisk,
 query={
 SELECT *
 FROM execve(argv=[Exe, "--remap", RemappingFile, "--config",
 ClientConfig, "--config.client-writeback-linux",
 WritebackFile, "--config.client-writeback-windows",
 WritebackFile, "--config.client-writeback-darwin",
 WritebackFile, "-v", "client"],
 sep="\n")
 })

column_types:
- name: Stdout
 type: nobreak

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeleteClient</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deleteclient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deleteclient/</guid><description>&lt;p>This artifact completely removes a client from the data store.&lt;/p>
&lt;p>Be careful with this one: there is no way to recover old
data. However, if the client still exists, it will just
automatically re-enroll when it next connects. You will still be able
to talk to it, it is just that old collected data is deleted.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeleteClient
description: |
 This artifact completely removes a client from the data store.

 Be careful with this one: there is no way to recover old
 data. However, if the client still exists, it will just
 automatically re-enroll when it next connects. You will still be able
 to talk to it, it is just that old collected data is deleted.

type: SERVER

parameters:
 - name: ClientIdList
 description: A list of client ids to delete.
 default:

 - name: ReallyDoIt
 description: If you really want to delete the client, check this.
 type: bool

sources:
 - query: |
 let clients_list = SELECT ClientId
 FROM parse_records_with_regex(
 accessor="data", file=ClientIdList,
 regex="(?P&amp;lt;ClientId&amp;gt;C\\.[0-9a-z-]+)")
 WHERE log(message="Deleting client " + ClientId)

 SELECT * FROM foreach(row=clients_list,
 query={
 SELECT * FROM client_delete(client_id=ClientId,
 really_do_it=ReallyDoIt)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeleteEvents</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deleteevents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deleteevents/</guid><description>&lt;p>This artifact permanently deletes Event files for client or
monitoring events.&lt;/p>
&lt;p>NOTE: This action cannot be undone! The event files are deleted
permanently. Since this is a sensitive operation, typically only
users with the administrator role can run it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeleteEvents
description: |
 This artifact permanently deletes Event files for client or
 monitoring events.

 NOTE: This action cannot be undone! The event files are deleted
 permanently. Since this is a sensitive operation, typically only
 users with the administrator role can run it.

type: SERVER

required_permissions:
 - MACHINE_STATE

parameters:
 - name: Artifact
 description: The artifact name to delete
 default:
 - name: ClientId
 description: The client id that the collection was done on
 default:
 - name: StartTime
 type: timestamp
 description: The begining time range to delete
 - name: EndTime
 type: timestamp
 description: The ending time range to delete
 - name: ReallyDoIt
 description: If you really want to delete the collection, check this.
 type: bool

sources:
 - query: |
 SELECT Type, Data.VFSPath AS VFSPath, Error
 FROM delete_events(
 artifact=Artifact, client_id=ClientId,
 start_time=StartTime, end_time=EndTime,
 really_do_it=ReallyDoIt)

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeleteFavoriteFlow</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletefavoriteflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletefavoriteflow/</guid><description>&lt;p>This artifact allows the user to delete a previously saved
favorite. It will only affect the current user.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeleteFavoriteFlow
description: |
 This artifact allows the user to delete a previously saved
 favorite. It will only affect the current user.

parameters:
 - name: Name
 description: A name for this collection template
 - name: Type
 description: The type of favorites to delete.
 type: choices
 default: CLIENT
 choices:
 - CLIENT
 - SERVER
 - CLIENT_EVENT
 - SERVER_EVENT

sources:
 - query: |
 SELECT favorites_delete(name=Name, type=Type)
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeleteFlow</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deleteflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deleteflow/</guid><description>&lt;p>This artifact permanently deletes a flow including it&amp;rsquo;s metadata and
uploaded files.&lt;/p>
&lt;p>NOTE: This action cannot be undone! The collection is deleted
permanently. Since this is a sensitive operation, typically only
users with the administrator role can run it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeleteFlow
description: |
 This artifact permanently deletes a flow including it's metadata and
 uploaded files.

 NOTE: This action cannot be undone! The collection is deleted
 permanently. Since this is a sensitive operation, typically only
 users with the administrator role can run it.

type: SERVER

required_permissions:
 - MACHINE_STATE

parameters:
 - name: FlowId
 description: The flow ID to delete
 default:
 - name: FlowIds
 description: Delete Multiple Flows
 type: json_array
 default: "[]"
 - name: ClientId
 description: The client id that the collection was done on
 default:
 - name: ReallyDoIt
 description: If you really want to delete the collection, check this.
 type: bool
 - name: Sync
 description: If specified we ensure delete happens immediately
 type: bool

sources:
 - query: |
 LET FlowIds &amp;lt;= if(condition=FlowId, then=FlowIds + FlowId, else=FlowIds)

 SELECT *
 FROM foreach(row={
 SELECT _value AS FlowId FROM foreach(row=FlowIds)
 WHERE log(message="Deleteing Flow " + FlowId, dedup=-1)
 },
 query={
 SELECT Type, Data.VFSPath AS VFSPath, Error
 FROM delete_flow(flow_id=FlowId,
 client_id=ClientId, really_do_it=ReallyDoIt, sync=Sync)
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeleteManyFlows</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletemanyflows/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletemanyflows/</guid><description>&lt;p>Sometimes the Velociraptor server accumulates a lot of data that is
no longer needed.&lt;/p>
&lt;p>This artifact will enumerate all flows from all clients and matches
them against some criteria. Flows that match are then removed.&lt;/p>
&lt;p>&lt;strong>NOTE&lt;/strong> This artifact will destroy all data irrevocably. Take
care! You should always do a dry run first to see which flows
will match before using the &lt;code>ReallyDoIt&lt;/code> option.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeleteManyFlows
description: |
 Sometimes the Velociraptor server accumulates a lot of data that is
 no longer needed.

 This artifact will enumerate all flows from all clients and matches
 them against some criteria. Flows that match are then removed.

 **NOTE** This artifact will destroy all data irrevocably. Take
 care! You should always do a dry run first to see which flows
 will match before using the `ReallyDoIt` option.

type: SERVER

parameters:
 - name: ArtifactRegex
 default: Generic.Client.Info
 type: regex
 - name: HostnameRegex
 description: If specified only target these hosts
 type: regex
 - name: DateBefore
 description: Only select flows created before this date. If not set we choose all flows.
 type: timestamp
 - name: CreatorRegex
 default: "."
 type: regex
 description: |
 Match flows created by this user.
 - name: ReallyDoIt
 type: bool
 description: Does not delete until you press the ReallyDoIt button!

sources:
 - query: |
 LET DateBefore &amp;lt;= DateBefore || timestamp(epoch=now())
 LET hits = SELECT * FROM foreach(row={
 SELECT client_id,
 os_info.hostname AS hostname
 FROM clients()
 WHERE hostname =~ HostnameRegex
 },
 query={
 SELECT client_id, hostname,
 session_id, request.creator AS creator,
 request.artifacts as artifacts,
 timestamp(epoch=create_time) AS created
 FROM flows(client_id=client_id)
 WHERE creator =~ CreatorRegex
 AND artifacts =~ ArtifactRegex
 AND created &amp;lt; DateBefore
 }, workers=10)

 SELECT * FROM if(condition=ReallyDoIt,
 then={
 SELECT * FROM foreach(row=hits,
 query={
 SELECT client_id, hostname, creator,
 session_id, artifacts, created, Type, Data, Error
 FROM delete_flow(client_id=client_id,
 flow_id=session_id, really_do_it=ReallyDoIt)
 WHERE log(message=format(format="Deleting flow %v from %v",
 args=[session_id, hostname]))
 }, workers=10)
 }, else={
 SELECT * FROM hits
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeleteMonitoringData</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletemonitoringdata/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletemonitoringdata/</guid><description>&lt;p>Velociraptor collects monitoring data from endpoints all the time.&lt;/p>
&lt;p>Sometimes this data is no longer needed and we might want to free
up disk space.&lt;/p>
&lt;p>This artifact searches the monitoring data for each client and
optionally removes data older than the specified timestamp.&lt;/p>
&lt;p>&lt;strong>NOTE&lt;/strong> This artifact will destroy all data irrevocably. Take
care! You should always do a dry run first to see which flows
will match before using the &lt;code>ReallyDoIt&lt;/code> option.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeleteMonitoringData
description: |
 Velociraptor collects monitoring data from endpoints all the time.

 Sometimes this data is no longer needed and we might want to free
 up disk space.

 This artifact searches the monitoring data for each client and
 optionally removes data older than the specified timestamp.

 **NOTE** This artifact will destroy all data irrevocably. Take
 care! You should always do a dry run first to see which flows
 will match before using the `ReallyDoIt` option.

type: SERVER

parameters:
 - name: DateBefore
 default: 2022-01-01
 type: timestamp
 - name: ArtifactRegex
 type: regex
 default: Generic.Client.Stats
 - name: HostnameRegex
 description: If specified only target these hosts
 type: regex
 default: .
 - name: OnlyRegisteredClients
 type: bool
 description: |
 If enabled only search registered clients. (Might be needed for
 very large deployments).
 - name: ReallyDoIt
 type: bool
 description: Do not actually delete until this is set!

sources:
 - query: |
 LET SearchDeletedClientsQuery = SELECT Name AS ClientId,
 client_info(client_id=Name).os_info.hostname AS Hostname
 FROM glob(globs="/clients/*", accessor="fs")
 WHERE IsDir
 AND Hostname =~ HostnameRegex

 LET SearchRegisteredClientsQuery = SELECT client_id AS ClientId,
 os_info.hostname AS hostname
 FROM clients()
 WHERE hostname =~ HostnameRegex

 LET SearchClients = SELECT * FROM if(
 condition=OnlyRegisteredClients,
 then=SearchRegisteredClientsQuery,
 else=SearchDeletedClientsQuery)

 SELECT * FROM foreach(row=SearchClients,
 query={
 SELECT OSPath,
 OSPath.Dirname.Basename AS ArtifactName, Size,
 timestamp(epoch=split(string=OSPath.Basename, sep="\\.")[0]) AS Timestamp,
 if(condition=ReallyDoIt, then=file_store_delete(path=OSPath)) AS ReallyDoIt
 FROM glob(
 globs="/**.json*", accessor="fs",
 root="/clients/"+ ClientId + "/monitoring")
 WHERE ArtifactName =~ ArtifactRegex
 AND Timestamp &amp;lt; DateBefore
 }, workers=10)

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.DeleteNotebook</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletenotebook/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.deletenotebook/</guid><description>&lt;p>Completely removes a notebook from the server including all its cells, attachments etc.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.DeleteNotebook
description: |
 Completely removes a notebook from the server including all its cells, attachments etc.

type: SERVER

parameters:
 - name: NotebookId
 description: The ID of the notebook to remove.
 - name: ReallyDoIt
 type: bool
 description: Set to really remove the notebook - otherwise it is a dry run.

sources:
 - query: |
 SELECT * FROM notebook_delete(
 notebook_id=NotebookId, really_do_it=ReallyDoIt)

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.ImportCollection</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.importcollection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.importcollection/</guid><description>&lt;p>The Velociraptor offline collector is an automated, preconfigured
collection tool. Users can use the collector to automatically
collect any artifacts on endpoints that do not have the Velociraptor
client (offline endpoints).&lt;/p>
&lt;p>The collector creates a ZIP archive with the results of the
collection in JSON files (and any uploaded files).&lt;/p>
&lt;p>This artifact allows for these offline collections to be imported
back into the Velociraptor GUI. The collected data can then treated
exactly the same as if it was collected by the regular Velociraptor
client (i.e. post-processed through the notebook interface), except
it was collected via the Sneakernet.&lt;/p>
&lt;p>NOTE: This artifact reads the collection ZIP from the server&amp;rsquo;s
filesystem. It is up to you to arrange for the file to be stored on
the server (e.g. SCP it over).&lt;/p>
&lt;p>NOTE: This artifact is still experimental - please provide feedback
on our issue board.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.ImportCollection
description: |
 The Velociraptor offline collector is an automated, preconfigured
 collection tool. Users can use the collector to automatically
 collect any artifacts on endpoints that do not have the Velociraptor
 client (offline endpoints).

 The collector creates a ZIP archive with the results of the
 collection in JSON files (and any uploaded files).

 This artifact allows for these offline collections to be imported
 back into the Velociraptor GUI. The collected data can then treated
 exactly the same as if it was collected by the regular Velociraptor
 client (i.e. post-processed through the notebook interface), except
 it was collected via the Sneakernet.

 NOTE: This artifact reads the collection ZIP from the server's
 filesystem. It is up to you to arrange for the file to be stored on
 the server (e.g. SCP it over).

 NOTE: This artifact is still experimental - please provide feedback
 on our issue board.

type: SERVER

parameters:
 - name: ClientId
 default: auto
 description: |
 The client id to upload this collection into. The
 default is "auto" which will create a new client id.
 - name: Hostname
 description: If creating a new client, this must contain the hostname.
 - name: Path
 description: A path on the server containing the zip file to upload.

sources:
 - query: |
 LET result &amp;lt;= SELECT import_collection(
 client_id=ClientId, hostname=Hostname,
 filename=Path) AS Import
 FROM scope()

 SELECT * FROM switch(a={
 SELECT Import.client_id AS ClientId, Import.session_id AS FlowId,
 Import.total_collected_rows AS TotalRows,
 Import.total_uploaded_files AS UploadedFiles,
 Import.total_uploaded_bytes AS UploadedBytes,
 Import.artifacts_with_results AS Artifacts
 FROM result
 WHERE FlowId

 -- Hunt import
 }, b={
 SELECT Import.hunt_id AS HuntId,
 timestamp(epoch=Import.create_time) AS CreateTime,
 Import.stats.total_clients_scheduled AS TotalClients,
 Import.artifacts AS Artifacts,
 Import.creator AS Creator,
 Import AS _Hunt
 FROM result
 WHERE HuntId
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.KillClient</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.killclient/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.killclient/</guid><description>&lt;p>This artifact aggressively kills a client.&lt;/p>
&lt;p>If the client runs as a service, it will restart by the service manager.&lt;/p>
&lt;p>NOTE: If the client is not running as a service (i.e. interactively)
it may not restart and further communication will be lost!&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.KillClient
description: |
 This artifact aggressively kills a client.

 If the client runs as a service, it will restart by the service manager.

 NOTE: If the client is not running as a service (i.e. interactively)
 it may not restart and further communication will be lost!

type: SERVER


parameters:
 - name: ClientIdList
 description: A list of client ids to kill.
 default:

sources:
 - query: |
 let clients_list = SELECT ClientId
 FROM parse_records_with_regex(
 accessor="data", file=ClientIdList,
 regex="(?P&amp;lt;ClientId&amp;gt;C\\.[0-9a-z-]+)")
 WHERE log(message="Killing client " + ClientId)

 SELECT * FROM foreach(row=clients_list,
 query={
 SELECT killkillkill(client_id=ClientId) FROM scope()
 })

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.ListUsers</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.listusers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.listusers/</guid><description>&lt;p>This server artifact is used to list all current users and their
permissions and org access.&lt;/p>
&lt;p>NOTE: When collected in an org context only users belonging to the
current org are visible. When collected in the context of the root
org, all users in all orgs are visible.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.ListUsers
description: |
 This server artifact is used to list all current users and their
 permissions and org access.

 NOTE: When collected in an org context only users belonging to the
 current org are visible. When collected in the context of the root
 org, all users in all orgs are visible.

type: SERVER

sources:
 - query: |
 SELECT * FROM gui_users(all_orgs=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.Policy</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.policy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.policy/</guid><description>&lt;p>This artifact defines a set of security policies.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.Policy
description: |
 This artifact defines a set of security policies.

type: SERVER

parameters:
- name: ServerConfigFile
 type: string
 description: The path to the server.config.yaml

- name: OutputFilePath
 type: string
 description: Where to write the modified configuration file.
 default: /tmp/1.yaml

- name: GUIAccessByIP
 type: csv
 description: |
 Only allow access to the GUI from these CIDR networks.

 default: |
 CIDR,Description
 0.0.0.0/0,Allow all (Skip)

- name: LockDown
 type: bool
 description: If enabled, switch to lockdown mode.

- name: DisableServerPlugins_Write
 type: bool
 default: Y
 description: |
 Disable server plugins that allow:
 1. Writing to the filesystem.
 2. Collecting server machine state.

- name: DisableServerPlugins_Network
 type: bool
 description: |
 Disable server plugins which allow connecting to external
 resources over the network. These include for exaxmple:
 1. http_client()
 2. upload_elastic()
 3. upload_s3()

 An alternative to this setting is ForceSecrets to allow these
 plugin to only work with named secrets.

- name: ForceSecrets
 type: bool
 description: |
 Force network plugins to only use named secrets. This allows an
 admin to permit only well controlled network access without
 allowing users to connect to arbitrary URLs.

- name: DisableInventoryServiceExternalAccess
 type: bool
 description: |
 Normally the inventory service attempts to download tools in its
 own but if this is set, we prevent any external access.


export: |
 LET PluginsWithFileWrite &amp;lt;= SELECT name, metadata.permissions as perms
 FROM help()
 WHERE type =~ "Plugin" AND perms =~ "FILESYSTEM_WRITE|MACHINE_STATE"
 ORDER BY name

 LET FunctionsWithFileWrite &amp;lt;= SELECT name, metadata.permissions as perms
 FROM help()
 WHERE type =~ "Function" AND perms =~ "FILESYSTEM_WRITE|MACHINE_STATE"
 ORDER BY name

sources:
- query: |
 LET config &amp;lt;= parse_yaml(filename=ServerConfigFile)
 LET GUIAccessByIP &amp;lt;= SELECT * FROM foreach(row= GUIAccessByIP)
 WHERE NOT Description =~ "Skip"
 AND CIDR =~ '''\d+\.\d+\.\d+\.\d+/\d{1,2}''' OR (
 log(message="GUIAccessByIP: Invalid CIDR %v - rejecting",
 args=CIDR, dedup= -1) AND FALSE )

 LET _ &amp;lt;= GUIAccessByIP.CIDR &amp;amp;&amp;amp; set(item=config.GUI,
 field='allowed_cidr',
 value=GUIAccessByIP.CIDR)

 LET _ &amp;lt;= LockDown &amp;amp;&amp;amp;
 set(item=config, field="lockdown", value=TRUE)

 -- Make sure the security section exists
 LET _ &amp;lt;= NOT config.security &amp;amp;&amp;amp; set(item=config,
 field="security", value=dict())

 LET _ &amp;lt;= DisableServerPlugins_Write &amp;amp;&amp;amp;
 set(item=config.security,
 field="denied_plugins",
 value=PluginsWithFileWrite.name ) AND
 set(item=config.security,
 field="denied_functions",
 value=FunctionsWithFileWrite.name)

 LET _ &amp;lt;= ForceSecrets &amp;amp;&amp;amp;
 set(item=config.security,
 field="vql_must_use_secrets",
 value=TRUE )

 SELECT copy(dest= OutputFilePath, accessor="data",
 filename=serialize(item=config, format='yaml'))
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.RemoveTimeline</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.removetimeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.removetimeline/</guid><description>&lt;p>Remove a child timeline from a super timeline.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.RemoveTimeline
description: |
 Remove a child timeline from a super timeline.

type: SERVER

parameters:
 - name: NotebookId
 - name: Timeline
 description: SuperTimeline name
 - name: ChildName
 description: Name of child timeline

sources:
 - query: |
 SELECT if(condition=ChildName AND Timeline AND NotebookId,
 then=timeline_delete(
 timeline=Timeline,
 notebook_id=NotebookId,
 name=ChildName)) AS Removed
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.SaveFavoriteFlow</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.savefavoriteflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.savefavoriteflow/</guid><description>&lt;p>Users may collect various artifacts from hosts. Sometimes it might
take a bit of effort to setup and configure just the perfect
combination of parameters and artifacts to collect.&lt;/p>
&lt;p>This artifact allows the user to save the collection into a
Favorites section, which may be used in future.&lt;/p>
&lt;p>An example of a Spec is&lt;/p>
&lt;pre>&lt;code class="language-json">[{&amp;quot;artifact&amp;quot;:&amp;quot;Windows.KapeFiles.Targets&amp;quot;, &amp;quot;parameters&amp;quot;:{&amp;quot;env&amp;quot;:[{&amp;quot;key&amp;quot;:&amp;quot;EventLogs&amp;quot;, &amp;quot;value&amp;quot;:&amp;quot;Y&amp;quot;}]}}]
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.SaveFavoriteFlow
description: |
 Users may collect various artifacts from hosts. Sometimes it might
 take a bit of effort to setup and configure just the perfect
 combination of parameters and artifacts to collect.

 This artifact allows the user to save the collection into a
 Favorites section, which may be used in future.

 An example of a Spec is
 ```json
 [{"artifact":"Windows.KapeFiles.Targets", "parameters":{"env":[{"key":"EventLogs", "value":"Y"}]}}]
 ```

type: SERVER

parameters:
 - name: Specs
 type: json_array
 description: The collection request that will be recreated.
 - name: Name
 description: A name for this collection template
 - name: Description
 description: A description for the template.
 - name: Type
 description: The type of favorites to save.
 type: choices
 default: CLIENT
 choices:
 - CLIENT
 - SERVER
 - CLIENT_EVENT
 - SERVER_EVENT
 - name: AllUsers
 type: bool
 description: If set, add the favorite to all users in all orgs.

sources:
 - query: |
 LET AddToAllOrgs = SELECT * FROM foreach(
 row={
 SELECT name, org_id
 FROM gui_users(all_orgs=TRUE)
 }, query={
 SELECT * FROM query(query={
 SELECT favorites_save(type=Type,
 description=Description,
 name=Name,
 specs=Specs)
 FROM scope()
 },
 org_id=org_id,
 runas=name,
 env=dict(
 Specs=Specs,
 Name=Name, Type=Type,
 Description=Description))
 })

 LET AddToOneUser = SELECT favorites_save(
 name=Name,
 description=Description,
 specs=Specs,
 type=Type)
 FROM scope()

 SELECT * FROM if(condition=AllUsers,
 then=AddToAllOrgs, else=AddToOneUser)

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.StartHuntExample</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.starthuntexample/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.starthuntexample/</guid><description>&lt;p>This example artifact shows how to create a utility artifact to
provide low privileged users with a controlled ability to perform
high privileged operations.&lt;/p>
&lt;p>This server artifact launches a new &lt;code>Generic.Client.Info&lt;/code> hunt, but
the parameters for the hunt are not determined by the initiating
user. This makes is safe for unprivileged users to schedule this
hunt whenever they want.&lt;/p>
&lt;p>Usually to start a hunt, the user must have the &lt;code>START_HUNT&lt;/code>
permission - usually granted by the &lt;code>administrator&lt;/code> or
&lt;code>investigator&lt;/code> roles. Additionally, to collect this
artifact, a user must have the &lt;code>COLLECT_SERVER&lt;/code> permission - usually
only granted by the &lt;code>administrator&lt;/code> role.&lt;/p>
&lt;p>So by default this artifact does not give any additional permissions
and usually has to be collected by an &lt;code>administrator&lt;/code> (which would
be able to schedule hunts anyway).&lt;/p>
&lt;p>However, it is possible to mark the artifact as basic by using the VQL&lt;/p>
&lt;pre>&lt;code class="language-vql">SELECT artifact_set_metadata(
 artifact=&amp;quot;Server.Utils.StartHuntExample&amp;quot;, basic=TRUE)
FROM scope()
&lt;/code>&lt;/pre>
&lt;p>This will allow users with the &lt;code>COLLECT_BASIC&lt;/code> permission to also
collect it. Once collected the artifact specifies the impersonate
field to &lt;code>admin&lt;/code> which will cause it to run under the &lt;code>admin&lt;/code> user&amp;rsquo;s
permissions.&lt;/p>
&lt;p>This combination allows us to now grant the &lt;code>COLLECT_BASIC&lt;/code>
permission to any user and they will be able to start the hunt via
this artifact, but have no additional permissions to start arbitrary
hunts or collections.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.StartHuntExample
description: |
 This example artifact shows how to create a utility artifact to
 provide low privileged users with a controlled ability to perform
 high privileged operations.

 This server artifact launches a new `Generic.Client.Info` hunt, but
 the parameters for the hunt are not determined by the initiating
 user. This makes is safe for unprivileged users to schedule this
 hunt whenever they want.

 Usually to start a hunt, the user must have the `START_HUNT`
 permission - usually granted by the `administrator` or
 `investigator` roles. Additionally, to collect this
 artifact, a user must have the `COLLECT_SERVER` permission - usually
 only granted by the `administrator` role.

 So by default this artifact does not give any additional permissions
 and usually has to be collected by an `administrator` (which would
 be able to schedule hunts anyway).

 However, it is possible to mark the artifact as basic by using the VQL

 ```vql
 SELECT artifact_set_metadata(
 artifact="Server.Utils.StartHuntExample", basic=TRUE)
 FROM scope()
 ```

 This will allow users with the `COLLECT_BASIC` permission to also
 collect it. Once collected the artifact specifies the impersonate
 field to `admin` which will cause it to run under the `admin` user's
 permissions.

 This combination allows us to now grant the `COLLECT_BASIC`
 permission to any user and they will be able to start the hunt via
 this artifact, but have no additional permissions to start arbitrary
 hunts or collections.

type: SERVER

# Collect this artifact under the admin user permissions.
impersonate: admin

sources:
 - query: |
 -- This query will run with admin ACLs.
 SELECT hunt(
 description="A general hunt",
 artifacts='Generic.Client.Info')
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.TimesketchUpload</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.timesketchupload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.timesketchupload/</guid><description>&lt;p>Timesketch is an interactive collaborative timeline analysis tool
that can be found at &lt;a href="https://timesketch.org/" target="_blank" >https://timesketch.org/&lt;/a>
&lt;/p>
&lt;p>This artifact uploads Velociraptor&amp;rsquo;s timelines to Timesketch using
the Timesketch client library. The artifact assumes the client
library is installed and configured on the server.&lt;/p>
&lt;p>To install the Timesketch client library:&lt;/p>
&lt;pre>&lt;code>pip install timesketch-import-client timesketch-cli-client
&lt;/code>&lt;/pre>
&lt;p>To configure the client library to access your Timesketch instance
see instructions &lt;a href="https://timesketch.org/guides/user/cli-client/" target="_blank" >https://timesketch.org/guides/user/cli-client/&lt;/a>
 and
&lt;a href="https://timesketch.org/guides/user/upload-data/" target="_blank" >https://timesketch.org/guides/user/upload-data/&lt;/a>
&lt;/p>
&lt;p>This artifact assumes that the Timesketch CLI is preconfigured with
the correct credentials in the &lt;code>.timesketchrc&lt;/code> file.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.TimesketchUpload
description: |
 Timesketch is an interactive collaborative timeline analysis tool
 that can be found at https://timesketch.org/

 This artifact uploads Velociraptor's timelines to Timesketch using
 the Timesketch client library. The artifact assumes the client
 library is installed and configured on the server.

 To install the Timesketch client library:
 ```
 pip install timesketch-import-client timesketch-cli-client
 ```

 To configure the client library to access your Timesketch instance
 see instructions https://timesketch.org/guides/user/cli-client/ and
 https://timesketch.org/guides/user/upload-data/

 This artifact assumes that the Timesketch CLI is preconfigured with
 the correct credentials in the `.timesketchrc` file.

required_permissions:
 - EXECVE

parameters:
 - name: NotebookId
 description: The notebook ID that contains the super timeline
 - name: SuperTimelineName
 description: The name of the super timeline
 - name: TimelineName
 description: The name of the timeline within the super timeline.
 - name: SketchName
 description: The name of the sketch to upload to
 - name: TimesketchCLICommand
 default: "timesketch"
 description: |
 The path to the Timesketch CLI binary. If you installed in a
 virtual environment this will be inside that environment.

type: SERVER

export: |
 LET timesketch_import_command = TimesketchCLICommand + "_importer"

 -- The uploader tool can create a new "Sketch" but if we want to
 -- just add a timeline to an existing sketch we need to specify the
 -- ID. This function finds the ID for the specified Sketch if it
 -- exists. NOTE that you can have multiple Sketches with the same
 -- name! We pick the first.
 LET GetIdToSketch(Sketch) = SELECT * FROM foreach(row={
 SELECT Stdout
 FROM execve(
 argv=[TimesketchCLICommand, "--output-format",
 "json", "sketch", "list"], length=10000)
 }, query={
 SELECT * FROM parse_json_array(data=Stdout)
 })
 WHERE name = Sketch

 -- Enumerate all the timelines in a super timeline
 LET _GetAllTimelines(SuperTimelineName, NotebookId) = SELECT *
 FROM foreach(row={
 SELECT *
 FROM timelines(notebook_id=NotebookId)
 WHERE name = SuperTimelineName
 }, query={ SELECT * FROM timelines })

 LET _GetTimelineMetdata(SuperTimelineName, NotebookId, TimelineName) =
 SELECT * FROM _GetAllTimelines(
 SuperTimelineName=SuperTimelineName, NotebookId=NotebookId)
 WHERE Id = TimelineName

 -- Gets the metadata of a named timeline
 LET GetTimelineMetdata(SuperTimelineName, NotebookId, TimelineName) =
 _GetTimelineMetdata(SuperTimelineName= SuperTimelineName,
 NotebookId = NotebookId,
 TimelineName=TimelineName)[0]

 -- Timesketch insists the file have the .csv extension.
 LET tmp &amp;lt;= tempfile(extension=".csv")

 -- We copy the timeline to a temp csv file then upload that. This
 -- might seem inefficient but Timesketch is written in python so it
 -- is already very slow. The extra tempfile does not make much
 -- difference in practice.
 LET WriteTmpFile(NotebookId, SuperTimelineName, TimelineName) =
 SELECT count() AS Count
 FROM write_csv(filename=tmp, query={
 SELECT Timestamp as timestamp, Message as message, *
 FROM timeline(notebook_id=NotebookId, timeline=SuperTimelineName,
 components=TimelineName)
 })
 GROUP BY 1

 LET ImportToTS(SuperTimelineName, NotebookId, TimelineName, SketchName) =
 SELECT * FROM chain(a={
 SELECT format(format="Exporting %v rows to %v", args=[WriteTmpFile(
 NotebookId=NotebookId, SuperTimelineName=SuperTimelineName,
 TimelineName=TimelineName)[0].Count, tmp]) AS Stdout
 FROM scope()
 }, c={
 SELECT * FROM foreach(row={

 -- This is unfortunately slow and unnecessary but Timesketch
 -- does not have a flag that just says - add timeline to
 -- existing sketch. So we have to type to find the sketch ID
 -- first.
 SELECT GetIdToSketch(Sketch=SketchName)[0].id || 0 AS SketchID
 FROM scope()

 }, query={

 -- Launch the import library and display the output.
 SELECT Stdout, Stderr, SketchID,
 SketchName, TimelineName
 FROM execve(argv=[timesketch_import_command, "--sketch_name",
 SketchName, "--sketch_id", SketchID,
 "--timeline_name", TimelineName,
 tmp], sep="\n")
 })
 })

sources:
 - query: |
 SELECT * FROM ImportToTS(
 SuperTimelineName=SuperTimelineName,
 NotebookId=NotebookId,
 TimelineName=TimelineName,
 SketchName=SketchName)

&lt;/code>&lt;/pre></description></item><item><title>Server.Utils.UploadTools</title><link>https://docs.velociraptor.app/artifact_references/pages/server.utils.uploadtools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/server.utils.uploadtools/</guid><description>&lt;p>Velociraptor can use external tools to deploy binaries on the
endpoint for some artifacts that require it. Usually these binaries
are automatically downloaded by the server when required. However,
sometimes a server is deployed on an air-gapped network, or has
egress filtering implemented such that the server is unable to
download binaries on demand.&lt;/p>
&lt;p>In these cases it is useful to automatically pre-populate tools into
a server manually. This artifact simplifies the process.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The artifact produces a curl based script that helps to download
required binaries on an internet connect system.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>When binaries are placed on a directory in the server&amp;rsquo;s
filesystem, the artifact can then be used to automatically upload
the binaries as tools to the server.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>NOTE that in Velociraptor each org is completely separated, so you
will need to re-upload the binaries when you create each org.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Server.Utils.UploadTools
description: |
 Velociraptor can use external tools to deploy binaries on the
 endpoint for some artifacts that require it. Usually these binaries
 are automatically downloaded by the server when required. However,
 sometimes a server is deployed on an air-gapped network, or has
 egress filtering implemented such that the server is unable to
 download binaries on demand.

 In these cases it is useful to automatically pre-populate tools into
 a server manually. This artifact simplifies the process.

 1. The artifact produces a curl based script that helps to download
 required binaries on an internet connect system.

 2. When binaries are placed on a directory in the server's
 filesystem, the artifact can then be used to automatically upload
 the binaries as tools to the server.

 NOTE that in Velociraptor each org is completely separated, so you
 will need to re-upload the binaries when you create each org.

type: SERVER

parameters:
 - name: BasePath
 description: |
 The directory on the server that contains all the binaries that
 are to be synced.

sources:
 - name: DownloaderScript
 query: |
 LET AllCurlCommands =
 SELECT format(format="curl -O -L -C - %v", args=url) AS Curl
 FROM inventory()
 WHERE url
 AND NOT admin_override

 LET Script &amp;lt;= join(sep="\r\n", array=AllCurlCommands.Curl)

 SELECT upload(accessor="scope", file="Script", name="Script.bat") AS Script
 FROM scope()

 - name:
 query: |
 LET BasePath &amp;lt;= pathspec(parse=BasePath)

 SELECT name,
 filename,
 BasePath + filename AS UploadedFile,
 inventory_add(file=BasePath + filename, tool=name, serve_locally=TRUE).hash AS UpdatedHash
 FROM inventory()
 WHERE url
 AND NOT admin_override
 AND stat(filename=BasePath + filename).Size &amp;gt; 100

column_types:
 - name: Script
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Splunk.Flows.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/splunk.flows.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/splunk.flows.upload/</guid><description>&lt;p>This server side event monitoring artifact waits for new artifacts
to be collected from endpoints and automatically uploads those to a
Splunk server.
To configure the event collector properly a couple steps need to be
completed prior to setting up this event:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Configure an index to ingest the data.&lt;/p>
&lt;ul>
&lt;li>Go to Settings &amp;gt; Index.&lt;/li>
&lt;li>New Index.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Configure the collector.&lt;/p>
&lt;ul>
&lt;li>Go to Settings &amp;gt; Data Inputs &amp;gt; HTTP Event Collector.&lt;/li>
&lt;li>Add New.&lt;/li>
&lt;li>Name does not matter, but ensure indexer acknowledgement is OFF.&lt;/li>
&lt;li>Set &lt;code>Selected Indexes&lt;/code> to the index configured in step 1.&lt;/li>
&lt;li>Save API key for this event.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Set Global settings.&lt;/p>
&lt;ul>
&lt;li>Go to Settings &amp;gt; Data Inputs &amp;gt; HTTP Event Collector &amp;gt; Global Settings&lt;/li>
&lt;li>Ensure &lt;code>All Tokens&lt;/code> is set to ENABLED&lt;/li>
&lt;li>Copy the HTTP Port Number for this event&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Configure your Splunk props.conf and tranforms.conf&lt;/p>
&lt;ul>
&lt;li>Add the following to props.conf
[vql]
INDEXED_EXTRACTIONS = json
DATETIME_CONFIG = CURRENT
TZ = GMT
category = Custom
pulldown_type = 1
TRANSFORMS-vql-sourcetype = vql-sourcetype,vql-timestamp
TRUNCATE = 512000&lt;/li>
&lt;li>Add the following to transforms.conf
[vql-sourcetype]
INGEST_EVAL = sourcetype=lower(src_artifact)
[vql-timestamp]
INGEST_EVAL = _time=case( &lt;br>
src_artifact=&amp;ldquo;artifact_Linux_Search_FileFinder&amp;rdquo;,strptime(CTime,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_System_VFS_ListDirectory&amp;rdquo;,strptime(ctime,&amp;quot;%Y-%m-%dT%H:%M:%S.%NZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Timeline_MFT&amp;rdquo;,strptime(event_time,&amp;quot;%Y-%m-%dT%H:%M:%S.%NZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_NTFS_MFT&amp;rdquo;,strptime(Created0x10,&amp;quot;%Y-%m-%dT%H:%M:%S.%NZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_EventLogs_Evtx&amp;rdquo;,strptime(TimeCreated,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Custom_Windows_EventLogs_System_7045&amp;rdquo;,strptime(TimeCreated,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_EventLogs_RDPAuth&amp;rdquo;,strptime(EventTime,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Analysis_EvidenceOfExecution_UserAssist&amp;rdquo;,strptime(LastExecution,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Analysis_EvidenceOfExecution_Amcache&amp;rdquo;,strptime(KeyMTime,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_System_Amcache_InventoryApplicationFile&amp;rdquo;,strptime(LastModified,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Search_FileFinder&amp;rdquo;,strptime(CTime,&amp;quot;%Y-%m-%dT%H:%M:%S.%NZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Applications_NirsoftBrowserViewer&amp;rdquo;,strptime(Visited,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Registry_RecentDocs&amp;rdquo;,strptime(LastWriteTime,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Forensics_UserAccessLogs_Clients&amp;rdquo;,strptime(InsertDate,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Forensics_UserAccessLogs_DNS&amp;rdquo;,strptime(LastSeen,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Forensics_UserAccessLogs_SystemIdentity&amp;rdquo;,strptime(CreationTime,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Custom_Windows_Application_IIS_IISLogs&amp;rdquo;,strptime(event_time,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_MacOS_Applications_Chrome_History&amp;rdquo;,strptime(last_visit_time,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;), &lt;br>
src_artifact=&amp;ldquo;artifact_Windows_Registry_UserAssist&amp;rdquo;,strptime(LastExecution,&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;) &lt;br>
)&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Note: &lt;code>Enable SSL&lt;/code> only works if SSL is properly configured on your
Splunk server &amp;ndash; meaning you have proper certificates and DNS. If you are
accessing your Splunk instance by IP, &lt;code>Enable SSL&lt;/code> should be set to OFF.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-yaml">
name: Splunk.Flows.Upload

description: |
 This server side event monitoring artifact waits for new artifacts
 to be collected from endpoints and automatically uploads those to a
 Splunk server.
 To configure the event collector properly a couple steps need to be
 completed prior to setting up this event:
 1. Configure an index to ingest the data.
 * Go to Settings &amp;gt; Index.
 * New Index.
 2. Configure the collector.
 * Go to Settings &amp;gt; Data Inputs &amp;gt; HTTP Event Collector.
 * Add New.
 * Name does not matter, but ensure indexer acknowledgement is OFF.
 * Set `Selected Indexes` to the index configured in step 1.
 * Save API key for this event.
 3. Set Global settings.
 * Go to Settings &amp;gt; Data Inputs &amp;gt; HTTP Event Collector &amp;gt; Global Settings
 * Ensure `All Tokens` is set to ENABLED
 * Copy the HTTP Port Number for this event
 4. Configure your Splunk props.conf and tranforms.conf
 * Add the following to props.conf
 [vql]
 INDEXED_EXTRACTIONS = json
 DATETIME_CONFIG = CURRENT
 TZ = GMT
 category = Custom
 pulldown_type = 1
 TRANSFORMS-vql-sourcetype = vql-sourcetype,vql-timestamp
 TRUNCATE = 512000
 * Add the following to transforms.conf
 [vql-sourcetype]
 INGEST_EVAL = sourcetype=lower(src_artifact)
 [vql-timestamp]
 INGEST_EVAL = _time=case( \
 src_artifact="artifact_Linux_Search_FileFinder",strptime(CTime,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_System_VFS_ListDirectory",strptime(ctime,"%Y-%m-%dT%H:%M:%S.%NZ"), \
 src_artifact="artifact_Windows_Timeline_MFT",strptime(event_time,"%Y-%m-%dT%H:%M:%S.%NZ"), \
 src_artifact="artifact_Windows_NTFS_MFT",strptime(Created0x10,"%Y-%m-%dT%H:%M:%S.%NZ"), \
 src_artifact="artifact_Windows_EventLogs_Evtx",strptime(TimeCreated,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Custom_Windows_EventLogs_System_7045",strptime(TimeCreated,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_EventLogs_RDPAuth",strptime(EventTime,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Analysis_EvidenceOfExecution_UserAssist",strptime(LastExecution,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Analysis_EvidenceOfExecution_Amcache",strptime(KeyMTime,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_System_Amcache_InventoryApplicationFile",strptime(LastModified,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Search_FileFinder",strptime(CTime,"%Y-%m-%dT%H:%M:%S.%NZ"), \
 src_artifact="artifact_Windows_Applications_NirsoftBrowserViewer",strptime(Visited,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Registry_RecentDocs",strptime(LastWriteTime,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Forensics_UserAccessLogs_Clients",strptime(InsertDate,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Forensics_UserAccessLogs_DNS",strptime(LastSeen,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Forensics_UserAccessLogs_SystemIdentity",strptime(CreationTime,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Custom_Windows_Application_IIS_IISLogs",strptime(event_time,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_MacOS_Applications_Chrome_History",strptime(last_visit_time,"%Y-%m-%dT%H:%M:%SZ"), \
 src_artifact="artifact_Windows_Registry_UserAssist",strptime(LastExecution,"%Y-%m-%dT%H:%M:%SZ") \
 )


 &amp;gt; Note: `Enable SSL` only works if SSL is properly configured on your
 Splunk server -- meaning you have proper certificates and DNS. If you are
 accessing your Splunk instance by IP, `Enable SSL` should be set to OFF.
type: SERVER_EVENT

parameters:
 - name: ArtifactNameRegex
 default: "."
 type: regex
 description: Names of artifacts to upload to Splunk
 - name: url
 default: http://127.0.0.1:8088/services/collector
 description: |
 The Splunk collector url, this is typically the url of the Splunk
 server followed by :8088/services/collector.
 - name: token
 description: |
 API token given when the event collector is configured on Splunk.
 - name: index
 default: velociraptor
 description: |
 Index to ingest the data. This should be set up when configuring
 the event collector.
 - name: SkipVerify
 default: false
 type: bool
 description: |
 SSL configured with the event collector. This is false by default.
 - name: RootCerts
 description: |
 As a better alternative to skip_verify, allows root ca certs to
 be added here.

 - name: HostnameField
 description: Field to extract hostname from
 default: ClientId

 - name: TimestampField
 description: Field to extract timestamp from
 default: timestamp

sources:
 - query: |
 LET completions = SELECT * FROM watch_monitoring(
 artifact="System.Flow.Completion")
 WHERE Flow.artifacts_with_results =~ ArtifactNameRegex
 AND log(message=Flow.artifacts_with_results)

 LET organization &amp;lt;= org().name

 LET documents = SELECT * FROM foreach(row=completions,
 query={
 SELECT * FROM foreach(
 row=Flow.artifacts_with_results,
 query={
 SELECT *, _value AS Artifact,
 timestamp(epoch=now()) AS timestamp,
 ClientId, Flow.session_id AS FlowId,
 "artifact_" + regex_replace(source=_value,
 re='[/.]', replace='_') as src_artifact,
 organization as org_name
 FROM source(
 client_id=ClientId,
 flow_id=Flow.session_id,
 artifact=_value)
 })
 })

 SELECT * FROM splunk_upload(
 query = documents,
 url = url,
 token = token,
 index = index,
 skip_verify = SkipVerify,
 root_ca = RootCerts,
 hostname_field=HostnameField,
 timestamp_field=TimestampField
 )

&lt;/code>&lt;/pre></description></item><item><title>System.Flow.Archive</title><link>https://docs.velociraptor.app/artifact_references/pages/system.flow.archive/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.flow.archive/</guid><description>&lt;p>An internal artifact that produces events for every flow completion
in the system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.Flow.Archive
description: |
 An internal artifact that produces events for every flow completion
 in the system.

type: CLIENT_EVENT

&lt;/code>&lt;/pre></description></item><item><title>System.Flow.Completion</title><link>https://docs.velociraptor.app/artifact_references/pages/system.flow.completion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.flow.completion/</guid><description>&lt;p>An internal artifact that produces events for every flow completion
in the system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.Flow.Completion
description: |
 An internal artifact that produces events for every flow completion
 in the system.

type: CLIENT_EVENT

&lt;/code>&lt;/pre></description></item><item><title>System.Hunt.Archive</title><link>https://docs.velociraptor.app/artifact_references/pages/system.hunt.archive/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.hunt.archive/</guid><description>&lt;p>An internal artifact that receives events when a hunt is archived.&lt;/p>
&lt;p>You can write a server event artifact to do something about the
hunts (like remove flows, generate zip file etc).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.Hunt.Archive
description: |
 An internal artifact that receives events when a hunt is archived.

 You can write a server event artifact to do something about the
 hunts (like remove flows, generate zip file etc).

type: CLIENT_EVENT

&lt;/code>&lt;/pre></description></item><item><title>System.Hunt.Creation</title><link>https://docs.velociraptor.app/artifact_references/pages/system.hunt.creation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.hunt.creation/</guid><description>&lt;p>An event artifact that fires when a user schedules a new hunt.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.Hunt.Creation
description: |
 An event artifact that fires when a user schedules a new hunt.

type: SERVER_EVENT

&lt;/code>&lt;/pre></description></item><item><title>System.Hunt.Participation</title><link>https://docs.velociraptor.app/artifact_references/pages/system.hunt.participation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.hunt.participation/</guid><description>&lt;p>Endpoints may participate in hunts. This artifact collects which
hunt each system participated in.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.Hunt.Participation
description: |
 Endpoints may participate in hunts. This artifact collects which
 hunt each system participated in.

# Will not be written but will be relayed between minions and server.
type: INTERNAL

&lt;/code>&lt;/pre></description></item><item><title>System.Upload.Completion</title><link>https://docs.velociraptor.app/artifact_references/pages/system.upload.completion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.upload.completion/</guid><description>&lt;p>An internal artifact that produces events for every file that is
uploaded to the system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.Upload.Completion
description: |
 An internal artifact that produces events for every file that is
 uploaded to the system.

type: CLIENT_EVENT

&lt;/code>&lt;/pre></description></item><item><title>System.VFS.DownloadFile</title><link>https://docs.velociraptor.app/artifact_references/pages/system.vfs.downloadfile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.vfs.downloadfile/</guid><description>&lt;p>This is an internal artifact used by the GUI to populate the
VFS. You may run it manually if you like, but typically it is
launched by the GUI when the user clicks the &amp;ldquo;Collect from client&amp;rdquo;
button at the file &amp;ldquo;Stats&amp;rdquo; tab.&lt;/p>
&lt;p>If you run it yourself (or via the API) the results will also be
shown in the VFS view.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.VFS.DownloadFile
description: |
 This is an internal artifact used by the GUI to populate the
 VFS. You may run it manually if you like, but typically it is
 launched by the GUI when the user clicks the "Collect from client"
 button at the file "Stats" tab.

 If you run it yourself (or via the API) the results will also be
 shown in the VFS view.

parameters:
 - name: Path
 description: The path of the file to download.
 default: /
 - name: Components
 type: json_array
 description: Alternatively, this is an explicit list of components.
 - name: Accessor
 default: file
 - name: Recursively
 type: bool
 description: |
 If specified, Path is interpreted as a directory and
 we download all files below it.
 - name: UPLOAD_IS_RESUMABLE
 type: bool
 default: Y
 description: If set the uploads can be resumed if the flow times out or errors.

sources:
 - query: |
 LET download_one_file = if(
 condition=version(plugin="stat") &amp;gt; 1,
 then= {
 SELECT OSPath AS Path, Accessor,
 Size, upload(file=OSPath, accessor=Accessor) AS Upload
 FROM stat(filename=Components, accessor=Accessor)
 },
 else= {
 SELECT OSPath AS Path, Accessor,
 Size, upload(file=OSPath, accessor=Accessor) AS Upload
 FROM stat(filename=Path, accessor=Accessor)
 })

 LET download_recursive = if(
 condition=version(plugin="stat") &amp;gt; 1,
 then= {
 SELECT OSPath AS Path, Accessor,
 Size, upload(file=OSPath, accessor=Accessor) AS Upload
 FROM glob(globs="**", root=Components,
 accessor=Accessor, nosymlink=TRUE)
 WHERE Mode.IsRegular
 },
 else={
 SELECT OSPath AS Path, Accessor,
 Size, upload(file=OSPath, accessor=Accessor) AS Upload
 FROM glob(globs="**", root=Path, accessor=Accessor)
 WHERE Mode.IsRegular
 })

 SELECT Path, Accessor,
 Upload.Size AS Size,
 Upload.StoredSize AS StoredSize,
 Upload.Sha256 AS Sha256,
 Upload.Md5 AS Md5,
 Upload.Error AS Error,
 Path.Components AS _Components
 FROM if(condition=Recursively,
 then={ SELECT * FROM download_recursive},
 else={ SELECT * FROM download_one_file})

&lt;/code>&lt;/pre></description></item><item><title>System.VFS.Export</title><link>https://docs.velociraptor.app/artifact_references/pages/system.vfs.export/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.vfs.export/</guid><description>&lt;p>Exports parts of the VFS in a server side collection.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.VFS.Export
description: |
 Exports parts of the VFS in a server side collection.

type: SERVER

parameters:
 - name: Path
 description: |
 A vfs path under which to search for file (NOTE: VFS paths start
 with the accessor name).
 - name: Components
 type: json_array
 default: '[]'
 description: |
 The top level to recurse from. NOTE: The first element in the
 list must be the accessor name.
 - name: ClientId
 description: The client id to apply the artifact on
 - name: FileGlob
 default: '**'
 description: |
 Only match the following files (default all of them) under the
 Path

sources:
 - query: |
 LET components &amp;lt;= Components || pathspec(parse=Path).Components
 SELECT Name, OSPath, Size, IsDir,
 Data.DownloadInfo.flow_id AS FlowId,
 if(condition=Data.DownloadInfo.flow_id,
 then=upload(accessor="vfs", file=OSPath)) AS Upload
 FROM glob(globs=FileGlob, root=components, accessor="vfs")
 WHERE NOT IsDir

&lt;/code>&lt;/pre></description></item><item><title>System.VFS.ListDirectory</title><link>https://docs.velociraptor.app/artifact_references/pages/system.vfs.listdirectory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/system.vfs.listdirectory/</guid><description>&lt;p>This is an internal artifact used by the GUI to populate the
VFS. You may run it manually if you like, but typically it is
launched by the GUI when a user clicks the &amp;ldquo;Refresh this directory&amp;rdquo;
button.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: System.VFS.ListDirectory
description: |
 This is an internal artifact used by the GUI to populate the
 VFS. You may run it manually if you like, but typically it is
 launched by the GUI when a user clicks the "Refresh this directory"
 button.

parameters:
 - name: Path
 description: The path of the file to download.
 default: "/"

 - name: Components
 type: json_array
 description: Alternatively, this is an explicit list of components.

 - name: Accessor
 default: file

 - name: Depth
 type: int
 default: 0

export: |
 -- Make the generator unique with the session id - so it can
 -- only be shared by the two sources in this collection.
 LET VFSGenerator = generate(name="vfs-" + _SessionId, query={
 SELECT * FROM vfs_ls(
 path="/", components=Components,
 accessor=Accessor, depth=Depth)
 }, delay=500) -- wait a while for both sources to connect.

sources:
 - precondition: SELECT * FROM info() WHERE version(plugin="vfs_ls") = 1
 name: Listing
 description: File listing of multiple directories in a single table.
 query: |
 SELECT OSPath AS _OSPath,
 Components AS _Components,
 Accessor AS _Accessor,
 Data AS _Data,
 Name, Size, Mode,
 Mtime as mtime,
 Atime as atime,
 Ctime as ctime,
 Btime as btime,
 Idx AS _Idx
 FROM VFSGenerator
 WHERE Stats = NULL

 - precondition: SELECT * FROM info() WHERE version(plugin="vfs_ls") = 1
 name: Stats
 description: |
 A list of summary objects dividing the Listing source into
 distinct directories.
 query: |
 SELECT Components,
 Accessor,
 Stats
 FROM VFSGenerator
 WHERE Stats != NULL

 - precondition: SELECT * FROM info() WHERE NOT version(plugin="vfs_ls")
 query: |
 // Glob &amp;gt; v2 accepts a component list for the root parameter.
 LET Path &amp;lt;= if(condition=version(plugin="glob") &amp;gt; 2 AND Components,
 then=Components, else=Path)

 // Old versions do not have the root parameter to glob()
 // Fixes https://github.com/Velocidex/velociraptor/issues/322
 LET LegacyQuery = SELECT OSPath as _OSPath,
 Accessor as _Accessor,
 Data as _Data,
 Name, Size, Mode.String AS Mode,
 Mtime as mtime,
 Atime as atime,
 Ctime as ctime
 FROM glob(globs=Path + if(condition=Depth,
 then=format(format='/**%v', args=Depth), else='/*'),
 accessor=Accessor)

 LET NewQuery = SELECT OSPath as _OSPath,
 Accessor as _Accessor,
 Data as _Data,
 Name, Size, Mode.String AS Mode,
 Mtime as mtime,
 Atime as atime,
 Ctime as ctime,
 Btime AS btime
 FROM glob(
 globs=if(condition=Depth,
 then=format(format='/**%v', args=Depth),
 else='/*'),
 root=Path,
 accessor=Accessor)

 SELECT * FROM if(
 condition=version(plugin="glob") &amp;gt;= 1,
 then=NewQuery,
 else=LegacyQuery)

&lt;/code>&lt;/pre></description></item><item><title>Triage.Collection.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/triage.collection.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/triage.collection.upload/</guid><description>&lt;p>A Generic uploader used by triaging artifacts.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Triage.Collection.Upload
description: |
 A Generic uploader used by triaging artifacts.

parameters:
 - name: path
 description: This is the glob of the files we use.
 - name: type
 description: The type of files these are.
 - name: accessor
 default: file

sources:
 - query: |
 LET results = SELECT OSPath, Size,
 Mtime As Modifed,
 type AS Type,
 upload(file=OSPath,
 accessor=accessor,
 ctime=Ctime,
 mtime=Mtime) AS FileDetails
 FROM glob(globs=path, accessor=accessor)
 WHERE NOT IsDir

 SELECT OSPath, Size, Modifed, Type,
 FileDetails.Path AS ZipPath,
 FileDetails.Md5 as Md5,
 FileDetails.Sha256 as SHA256
 FROM results

&lt;/code>&lt;/pre></description></item><item><title>Triage.Collection.UploadTable</title><link>https://docs.velociraptor.app/artifact_references/pages/triage.collection.uploadtable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/triage.collection.uploadtable/</guid><description>&lt;p>A Generic uploader used by triaging artifacts. This is similar to
&lt;code>Triage.Collection.Upload&lt;/code> but uses a CSV table to drive it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Triage.Collection.UploadTable
description: |
 A Generic uploader used by triaging artifacts. This is similar to
 `Triage.Collection.Upload` but uses a CSV table to drive it.

parameters:
 - name: triageTable
 description: "A CSV table controlling upload. Must have the headers: Type, Accessor, Glob."
 type: csv
 default: |
 Type,Accessor,Glob

sources:
 - query: |
 LET results = SELECT OSPath, Size,
 Mtime As Modifed,
 Type,
 upload(file=OSPath,
 mtime=Mtime,
 ctime=Ctime,
 accessor=Accessor) AS FileDetails
 FROM glob(globs=split(string=Glob, sep=","), accessor=Accessor)
 WHERE NOT IsDir

 SELECT * FROM foreach(
 row=triageTable,
 query={
 SELECT OSPath, Size, Modifed, Type,
 FileDetails.Path AS ZipPath,
 FileDetails.Md5 as Md5,
 FileDetails.Sha256 as SHA256
 FROM results
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.ActiveDirectory.BloodHound</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.activedirectory.bloodhound/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.activedirectory.bloodhound/</guid><description>&lt;p>This artifact allows deployment of the BloodHound collection tool Sharphound.&lt;/p>
&lt;p>BloodHound is a popular Active Directory Assessment tool that uses graph
theory to reveal the hidden and often unintended relationships. It can also
be used to identify and eliminate potentially risky domain configuration.&lt;/p>
&lt;p>The Sharphound collection is in JSON format and upload to the server for
additional processing.&lt;/p>
&lt;p>NOTE: Do not run this artifact as an unrestricted hunt. The general
recommendation is to run this artifact on only a handful of machines in a
domain, and then deduplicate output.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ActiveDirectory.BloodHound
description: |
 This artifact allows deployment of the BloodHound collection tool Sharphound.

 BloodHound is a popular Active Directory Assessment tool that uses graph
 theory to reveal the hidden and often unintended relationships. It can also
 be used to identify and eliminate potentially risky domain configuration.

 The Sharphound collection is in JSON format and upload to the server for
 additional processing.

 NOTE: Do not run this artifact as an unrestricted hunt. The general
 recommendation is to run this artifact on only a handful of machines in a
 domain, and then deduplicate output.


author: Matt Green - @mgreen27

reference:
 - https://github.com/BloodHoundAD/BloodHound
 - https://github.com/chryzsh/awesome-bloodhound

required_permissions:
 - EXECVE

implied_permissions:
 - FILESYSTEM_WRITE

tools:
 - name: SharpHound
 url: https://github.com/BloodHoundAD/BloodHound/raw/master/Collectors/SharpHound.exe

type: CLIENT

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- obtain hostname for output prefix
 LET hostname &amp;lt;= SELECT Fqdn FROM info()

 -- get context on target binary
 LET payload &amp;lt;= SELECT * FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="SharpHound")

 -- build tempfolder for output
 LET tempfolder &amp;lt;= tempdir()

 -- execute payload
 LET deploy = SELECT * FROM execve(argv=[payload.OSPath[0],'--outputdirectory',
 tempfolder,'--nozip','--outputprefix',hostname.Fqdn[0] ])

 -- output rows
 SELECT * FROM if(condition= deploy.ReturnCode[0]= 0,
 then={
 SELECT Name, upload(file=OSPath,name=Name)
 FROM glob(globs="/*.json", root=tempfolder)
 },
 else=deploy)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Analysis.EvidenceOfDownload</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.analysis.evidenceofdownload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.analysis.evidenceofdownload/</guid><description>&lt;p>Simple artifact to find evidence of user download activity.&lt;/p>
&lt;p>Based on the Zone.Identifier alternate data stream that is created
alongside with the file downloaded from the internet or
intranet. Zone.Identifier is generated by applications when user
saves files to the local file system from different security zone.&lt;/p>
&lt;p>This artifact searches the directory provided for any file with
alternate data stream named Zone.Identifier and then lists all
files with zoneId = 3 or 4 and calculate the hash value of the file
and prints the content of Zone.Identifier alternate stream as it
could contain useful info in some cases.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Analysis.EvidenceOfDownload
description: |
 Simple artifact to find evidence of user download activity.

 Based on the Zone.Identifier alternate data stream that is created
 alongside with the file downloaded from the internet or
 intranet. Zone.Identifier is generated by applications when user
 saves files to the local file system from different security zone.

 This artifact searches the directory provided for any file with
 alternate data stream named Zone.Identifier and then lists all
 files with zoneId = 3 or 4 and calculate the hash value of the file
 and prints the content of Zone.Identifier alternate stream as it
 could contain useful info in some cases.


reference:
 - https://cyberforensicator.com/2018/06/26/where-did-it-come-from-forensic-analysis-of-zone-identifier/
 - https://www.sans.org/security-resources/posters/windows-forensic-analysis/170/download
 - https://www.csee.umbc.edu/courses/undergraduate/FYS102D/Recycle.Bin.Forensics.for.Windows7.and.Windows.Vista.pdf

author: M.Soheem @msoheem | Antonio Blescia (TheThMando)

type: CLIENT

parameters:
 - name: DirectoryPathGlob
 type: csv
 default: |
 Path
 C:/Users/*/Downloads/**/*
 C:/$Recycle.Bin/*/**/$R*

 - name: ZoneIdRegex
 description: A Regular expression to match the required zone (default Internet and Restricted Zones).
 default: "ZoneId=[34]"

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET glob_patterns = SELECT Path + ':Zone.Identifier' AS Glob FROM DirectoryPathGlob
 LET X = SELECT
 split(string=OSPath, sep=":Zone.Identifier")[0] AS DownloadedFilePath,
 Mtime,
 read_file(filename=OSPath, accessor="ntfs") AS _ZoneIdentifierContent
 FROM glob(globs=glob_patterns.Glob, accessor="ntfs")
 WHERE NOT IsDir

 SELECT *,
 if(condition=DownloadedFilePath, then=hash(path=DownloadedFilePath)) AS FileHash,
 parse_string_with_regex(regex="ZoneId=([^\\r\\n]+)", string=_ZoneIdentifierContent).g1 AS ZoneId,
 parse_string_with_regex(regex="HostUrl=([^\\r\\n]+)", string=_ZoneIdentifierContent).g1 AS HostUrl,
 parse_string_with_regex(regex="ReferrerUrl=([^\\r\\n]+)", string=_ZoneIdentifierContent).g1 AS ReferrerUrl
 FROM X

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.ChocolateyPackages</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chocolateypackages/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chocolateypackages/</guid><description>&lt;p>Chocolatey packages installed in a system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.ChocolateyPackages
description: Chocolatey packages installed in a system.
parameters:
 - name: ChocolateyInstall
 default: ""

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 LET SearchGlob = if(
 condition=ChocolateyInstall,
 then=ChocolateyInstall,

 -- Otherwise just use the environment.
 else=environ(var='ChocolateyInstall')) + '/lib/*/*.nuspec'

 LET files = SELECT OSPath,
 parse_xml(file=OSPath) AS Metadata
 -- Use the ChocolateyInstall parameter if it is set.

 FROM glob(globs=SearchGlob)

 SELECT * FROM if(
 condition=if(condition=ChocolateyInstall,
 then=ChocolateyInstall,
 else=environ(var="ChocolateyInstall")),
 then={
 SELECT OSPath,
 Metadata.package.metadata.id as Name,
 Metadata.package.metadata.version as Version,
 Metadata.package.metadata.summary as Summary,
 Metadata.package.metadata.authors as Authors,
 Metadata.package.metadata.licenseUrl as License
 FROM files
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.Chrome.Cookies</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chrome.cookies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chrome.cookies/</guid><description>&lt;p>Enumerate the users chrome cookies.&lt;/p>
&lt;p>The cookies are typically encrypted by the DPAPI using the user&amp;rsquo;s
credentials. Since Velociraptor is typically not running in the user
context we cannot decrypt these. It may be possible to decrypt the
cookies off line.&lt;/p>
&lt;p>The pertinent information from a forensic point of view are the
user&amp;rsquo;s Created and LastAccess timestamps, and the fact that the user
has actually visited the site and obtained a cookie.&lt;/p>
&lt;h2 id="notes">NOTES:&lt;/h2>
&lt;p>This artifact is deprecated in favor of
&lt;code>Generic.Forensic.SQLiteHunter&lt;/code> and will be removed in future&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.Chrome.Cookies
description: |
 Enumerate the users chrome cookies.

 The cookies are typically encrypted by the DPAPI using the user's
 credentials. Since Velociraptor is typically not running in the user
 context we cannot decrypt these. It may be possible to decrypt the
 cookies off line.

 The pertinent information from a forensic point of view are the
 user's Created and LastAccess timestamps, and the fact that the user
 has actually visited the site and obtained a cookie.

 ## NOTES:

 This artifact is deprecated in favor of
 `Generic.Forensic.SQLiteHunter` and will be removed in future

parameters:
 - name: cookieGlobs
 default: \AppData\Local\Google\Chrome\User Data\*\Cookies
 - name: cookieSQLQuery
 default: |
 SELECT creation_utc, host_key, name, value, path, expires_utc,
 last_access_utc, encrypted_value
 FROM cookies
 - name: userRegex
 default: .
 type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET cookie_files = SELECT * from foreach(
 row={
 SELECT Uid, Name AS User,
 expand(path=Directory) AS HomeDirectory
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex
 },
 query={
 SELECT User, OSPath, Mtime
 FROM glob(root=HomeDirectory, globs=cookieGlobs)
 })

 SELECT * FROM foreach(row=cookie_files,
 query={
 SELECT timestamp(winfiletime=creation_utc * 10) as Created,
 timestamp(winfiletime=last_access_utc * 10) as LastAccess,
 timestamp(winfiletime=expires_utc * 10) as Expires,
 host_key, name, path, value,
 base64encode(string=encrypted_value) as EncryptedValue
 FROM sqlite(
 file=OSPath,
 query=cookieSQLQuery)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.Chrome.Extensions</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chrome.extensions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chrome.extensions/</guid><description>&lt;p>Fetch Chrome extensions.&lt;/p>
&lt;p>Chrome extensions are installed into the user&amp;rsquo;s home directory. We
search for manifest.json files in a known path within each system
user&amp;rsquo;s home directory. We then parse the manifest file as JSON.&lt;/p>
&lt;p>Many extensions use locale packs to resolve strings like name and
description. In this case we detect the default locale and load
those locale files. We then resolve the extension&amp;rsquo;s name and
description from there.&lt;/p>
&lt;h2 id="notes">NOTES:&lt;/h2>
&lt;p>This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.Chrome.Extensions
description: |
 Fetch Chrome extensions.

 Chrome extensions are installed into the user's home directory. We
 search for manifest.json files in a known path within each system
 user's home directory. We then parse the manifest file as JSON.

 Many extensions use locale packs to resolve strings like name and
 description. In this case we detect the default locale and load
 those locale files. We then resolve the extension's name and
 description from there.

 ## NOTES:

 This artifact is deprecated in favor of
 Generic.Forensic.SQLiteHunter and will be removed in future


parameters:
 - name: extensionGlobs
 default: \AppData\Local\Google\Chrome\User Data\*\Extensions\*\*\manifest.json
 - name: userRegex
 default: .
 type: regex

sources:
 - precondition: |
 SELECT OS From info() where OS = 'windows'
 query: |
 /* For each user on the system, search for extension manifests
 in their home directory. */
 LET extension_manifests = SELECT * from foreach(
 row={
 SELECT Uid, Name AS User,
 expand(path=Directory) as Directory
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex
 },
 query={
 SELECT OSPath, Mtime, Ctime, User, Uid
 FROM glob(root=Directory, globs=extensionGlobs)
 })

 /* If the Manifest declares a default_locale then we
 load and parse the messages file. In this case the
 messages are actually stored in the locale file
 instead of the main manifest.json file.
 */
 LET maybe_read_locale_file =
 SELECT * from if(
 condition={
 select * from scope() where Manifest.default_locale
 },
 then={
 SELECT Manifest,
 Uid, User,
 Filename as LocaleFilename,
 ManifestFilename,
 parse_json(data=Data) AS LocaleManifest
 FROM read_file(
 -- Munge the filename to get the messages.json path.
 filenames=regex_replace(
 source=ManifestFilename,
 replace="\\_locales\\" + Manifest.default_locale +
 "\\messages.json",
 re="\\\\manifest.json$"))
 },
 else={
 -- Just fill in empty Locale results.
 SELECT Manifest,
 Uid, User,
 "" AS LocaleFilename,
 "" AS ManifestFilename,
 "" AS LocaleManifest
 FROM scope()
 })

 LET parse_json_files = SELECT * from foreach(
 row={
 SELECT Filename as ManifestFilename,
 Uid, User,
 parse_json(data=Data) as Manifest
 FROM read_file(filenames=OSPath)
 },
 query=maybe_read_locale_file)

 LET parsed_manifest_files = SELECT * from foreach(
 row=extension_manifests,
 query=parse_json_files)

 SELECT Uid, User,

 /* If the manifest name contains __MSG_ then the real
 name is stored in the locale manifest. This condition
 resolves the Name column either to the main manifest or
 the locale manifest.
 */
 if(condition="__MSG_" in Manifest.name,
 then=get(item=LocaleManifest,
 member=regex_replace(
 source=Manifest.name,
 replace="$1",
 re="(?:__MSG_(.+)__)")).message,
 else=Manifest.name) as Name,

 if(condition="__MSG_" in Manifest.description,
 then=get(item=LocaleManifest,
 member=regex_replace(
 source=Manifest.description,
 replace="$1",
 re="(?:__MSG_(.+)__)")).message,
 else=Manifest.description) as Description,

 /* Get the Identifier and Version from the manifest filename */
 regex_replace(
 source=ManifestFilename,
 replace="$1",
 re="(?:.+Extensions\\\\([^\\\\]+)\\\\([^\\\\]+)\\\\manifest.json)$") AS Identifier,
 regex_replace(
 source=ManifestFilename,
 replace="$2",
 re="(?:.+Extensions\\\\([^\\\\]+)\\\\([^\\\\]+)\\\\manifest.json)$") AS Version,

 Manifest.author as Author,
 Manifest.background.persistent AS Persistent,
 regex_replace(
 source=ManifestFilename,
 replace="$1",
 re="(.+Extensions\\\\.+\\\\)manifest.json$") AS Path,

 Manifest.oauth2.scopes as Scopes,
 Manifest.permissions as Permissions,
 Manifest.key as Key

 FROM parsed_manifest_files

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.Chrome.History</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chrome.history/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.chrome.history/</guid><description>&lt;p>Enumerates a targets chrome history.&lt;/p>
&lt;p>Source based on Hindsight and code review of
&lt;a href="https://source.chromium.org/chromium/chromium/src/&amp;#43;/master:components/history/core/browser/history_types.h" target="_blank" >https://source.chromium.org/chromium/chromium/src/+/master:components/history/core/browser/history_types.h&lt;/a>
.&lt;/p>
&lt;h4 id="notes">NOTES:&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Some research has shown that older browsers may not have this
table. In that case you should treat it as you would in a traditional
investigation. This artifact is aimed at taking advantage of the
newer tables to reduce false positives.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>This artifact is deprecated in favor of &lt;code>Generic.Forensic.SQLiteHunter&lt;/code> and
will be removed in future&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.Chrome.History
description: |
 Enumerates a targets chrome history.

 Source based on Hindsight and code review of
 https://source.chromium.org/chromium/chromium/src/+/master:components/history/core/browser/history_types.h.

 #### NOTES:

 - Some research has shown that older browsers may not have this
 table. In that case you should treat it as you would in a traditional
 investigation. This artifact is aimed at taking advantage of the
 newer tables to reduce false positives.

 - This artifact is deprecated in favor of `Generic.Forensic.SQLiteHunter` and
 will be removed in future


author: Angry-Bender @angry-bender
parameters:
 - name: historyGlobs
 default: \AppData\{Local,Roaming}\{Google\Chrome\User Data,Microsoft\Edge\User Data,BraveSoftware\Brave-Browser\User Data,Vivaldi\User Data,Opera Software\Opera*Stable}\*\History
 - name: urlSQLQuery
 default: |
 SELECT U.id AS id,
 U.url AS url,
 V.visit_time as visit_time,
 U.title AS title,
 U.visit_count,
 U.typed_count,
 U.last_visit_time, U.hidden,
 CASE VS.source
 WHEN 0 THEN 'Synced'
 WHEN 1 THEN 'Local'
 WHEN 2 THEN 'Extension'
 WHEN 3 THEN 'ImportFromFirefox'
 WHEN 4 THEN 'ImportFromSafari'
 WHEN 6 THEN 'ImportFromChrome/Edge'
 WHEN 7 THEN 'ImportFromEdgeHTML'
 ELSE 'Local'
 END Source,
 V.from_visit,
 strftime('%H:%M:%f',V.visit_duration/1000000.0, 'unixepoch') as visit_duration,
 V.transition
 FROM urls AS U
 JOIN visits AS V ON U.id = V.url
 LEFT JOIN visit_source AS VS on V.id = VS.id
 - name: userRegex
 default: .
 type: regex
 - name: URLRegex
 default: .
 type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET history_files = SELECT * from foreach(
 row={
 SELECT Uid, Name AS User,
 expand(path=Directory) AS HomeDirectory
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex
 },
 query={
 SELECT User, OSPath, Mtime
 FROM glob(globs=historyGlobs, root=HomeDirectory)
 })

 SELECT * FROM foreach(row=history_files,
 query={
 SELECT User,
 id AS url_id,
 timestamp(winfiletime=visit_time * 10) AS visit_time,
 url as visited_url,
 title,visit_count,typed_count,
 timestamp(winfiletime=last_visit_time * 10) AS last_visit_time,
 hidden,
 from_visit AS from_url_id,
 Source,
 visit_duration,transition,
 timestamp(winfiletime=last_visit_time * 10) as _SourceLastModificationTimestamp,
 OSPath
 FROM sqlite(
 file=OSPath,
 query=urlSQLQuery)
 })
 WHERE visited_url =~ URLRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.Edge.Favicons</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.edge.favicons/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.edge.favicons/</guid><description>&lt;p>Enumerate the user&amp;rsquo;s Microsoft Edge favicons.&lt;/p>
&lt;p>Also tested against Chrome: replace Microsoft Edge with Google Chrome in
the &lt;code>faviconsGlob&lt;/code> parameter.&lt;/p>
&lt;p>Chrome Favicons are stored in the &amp;lsquo;Favicons&amp;rsquo; SQLite database, within
the &amp;lsquo;favicons&amp;rsquo;, &amp;lsquo;favicon_bitmaps&amp;rsquo; and &amp;lsquo;icon_mapping&amp;rsquo; tables. Older
versions of Chrome stored Favicons in a &amp;lsquo;Thumbnails&amp;rsquo; SQLite
database, within the &amp;lsquo;favicons&amp;rsquo; table.&lt;/p>
&lt;h2 id="notes">NOTES:&lt;/h2>
&lt;ul>
&lt;li>This artifact is deprecated in favor of &lt;code>Generic.Forensic.SQLiteHunter&lt;/code> and
will be removed in future&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.Edge.Favicons
description: |
 Enumerate the user's Microsoft Edge favicons.

 Also tested against Chrome: replace Microsoft Edge with Google Chrome in
 the `faviconsGlob` parameter.

 Chrome Favicons are stored in the 'Favicons' SQLite database, within
 the 'favicons', 'favicon_bitmaps' and 'icon_mapping' tables. Older
 versions of Chrome stored Favicons in a 'Thumbnails' SQLite
 database, within the 'favicons' table.

 ## NOTES:

 - This artifact is deprecated in favor of `Generic.Forensic.SQLiteHunter` and
 will be removed in future

references:
 - https://www.foxtonforensics.com/browser-history-examiner/chrome-history-location

author: Phill Moore, @phillmoore

parameters:
 - name: faviconsGlob
 default: /AppData/Local/Microsoft/Edge/User Data/*/Favicons

 - name: faviconsQuery
 default: |
 SELECT favicons.id AS ID,
 favicon_bitmaps.icon_id AS IconID,
 favicon_bitmaps.image_data as _image,
 HEX(favicon_bitmaps.image_data) as _image_hex,
 datetime( favicon_bitmaps.last_updated / 1000000 + ( strftime( '%s', '1601-01-01' ) ), 'unixepoch', 'localtime' ) AS LastUpdated,
 icon_mapping.page_url AS PageURL,
 favicons.url AS FaviconURL
 FROM favicons
 INNER JOIN icon_mapping
 INNER JOIN favicon_bitmaps
 ON icon_mapping.icon_id = favicon_bitmaps.icon_id
 AND favicons.id = favicon_bitmaps.icon_id
 ORDER BY favicons.id ASC
 - name: userRegex
 default: .
 type: regex

precondition: |
 SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET favicons_files = SELECT * from foreach(
 row={
 SELECT Uid, Name AS User,
 expand(path=Directory) AS HomeDirectory
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex
 },
 query={
 SELECT User, OSPath, Mtime
 FROM glob(globs=faviconsGlob, root=HomeDirectory)
 })

 SELECT * FROM foreach(row=favicons_files,
 query={
 SELECT ID, IconID, LastUpdated, PageURL, FaviconURL,
 upload(accessor="data",
 file=_image,
 name=format(format="Image%v.png", args=ID)) AS Image, _image_hex, OSPath as _OSPath
 FROM sqlite(
 file=OSPath,
 query=faviconsQuery)
 })

column_types:
- name: Image
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.Edge.History</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.edge.history/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.edge.history/</guid><description>&lt;p>Enumerate the users chrome history.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.Edge.History
description: |
 Enumerate the users chrome history.

parameters:
 - name: historyGlobs
 default: \AppData\Local\Microsoft\Edge\User Data\*\History
 - name: urlSQLQuery
 default: |
 SELECT U.id AS id, U.url AS url, V.visit_time as visit_time,
 U.title AS title, U.visit_count, U.typed_count,
 U.last_visit_time, U.hidden, V.from_visit, strftime('%H:%M:%f',
 V.visit_duration/1000000.0, 'unixepoch') as visit_duration,
 V.transition FROM urls AS U JOIN visits AS V ON U.id = V.url
 - name: userRegex
 default: .
 type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 SELECT * FROM Artifact.Windows.Applications.Chrome.History(
 historyGlobs=historyGlobs, urlSQLQuery=urlSQLQuery,
 userRegex=userRegex)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.Firefox.Downloads</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.firefox.downloads/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.firefox.downloads/</guid><description>&lt;p>Enumerate the users Firefox downloads.&lt;/p>
&lt;h4 id="notes">NOTES&lt;/h4>
&lt;p>This artifact is deprecated in favor of &lt;code>Generic.Forensic.SQLiteHunter&lt;/code> and
will be removed in future&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.Firefox.Downloads
description: |
 Enumerate the users Firefox downloads.

 #### NOTES

 This artifact is deprecated in favor of `Generic.Forensic.SQLiteHunter` and
 will be removed in future

author: |
 Angry-Bender @angry-bender, based on
 Custom.Windows.Application.Firefox.History by Zach Stanford @svch0st

parameters:
 - name: placesGlobs
 default: \AppData\Roaming\Mozilla\Firefox\Profiles\*\places.sqlite
 - name: urlSQLQuery
 default: |
 SELECT * FROM moz_annos,moz_anno_attributes,moz_places WHERE moz_annos.place_id=moz_places.id AND moz_annos.anno_attribute_id=moz_anno_attributes.id
 - name: userRegex
 default: .
 type: regex
 - name: URLRegex
 default: .
 type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET places_files = SELECT * from foreach(
 row={
 SELECT Uid, Name AS User,
 expand(path=Directory) AS HomeDirectory
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex
 },
 query={
 SELECT User, OSPath, Mtime
 FROM glob(root=HomeDirectory, globs=placesGlobs)
 })

 LET metadata = SELECT * FROM foreach(row=places_files,
 query={
 SELECT parse_json(data=content)
 FROM sqlite(
 file=OSPath,
 query=urlSQLQuery)
 WHERE name = 'downloads/metaData'
 })

 SELECT * FROM foreach(row=places_files,
 query={
 SELECT User,
 timestamp(epoch=dateAdded) as startTime,
 if(condition=name=~'metaData',
 then=timestamp(epoch=parse_json(data=content).endTime)
 ) AS endTime,
 timestamp(epoch=lastModified) as last_modified,
 id,
 name,
 url,
 place_id,
 if(condition=name=~'metaData',
 then=parse_json(data=content).fileSize
 ) AS fileSize,
 if(condition=name=~'metaData',
 then=parse_json(data=content).state
 ) AS state,
 if(condition=name=~'destinationFileURI',
 then=content
 ) AS localDirectory,
 flags,
 expiration,
 type
 FROM sqlite(
 file=OSPath,
 query=urlSQLQuery)
 ORDER BY last_modified DESC
 })
 WHERE url =~ URLRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.Firefox.History</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.firefox.history/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.firefox.history/</guid><description>&lt;p>Enumerate the users Firefox history.&lt;/p>
&lt;h2 id="notes">NOTES:&lt;/h2>
&lt;p>This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.Firefox.History
description: |
 Enumerate the users Firefox history.

 ## NOTES:

 This artifact is deprecated in favor of
 Generic.Forensic.SQLiteHunter and will be removed in future


author: Zach Stanford @svch0st, Modified by @angry-bender
parameters:
 - name: placesGlobs
 default: \AppData\Roaming\Mozilla\Firefox\Profiles\*\places.sqlite
 - name: urlSQLQuery
 default: |
 SELECT *,url as url_visited FROM moz_historyvisits, moz_places WHERE moz_historyvisits.place_id=moz_places.id
 - name: userRegex
 default: .
 type: regex
 - name: URLRegex
 default: .
 type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET places_files = SELECT * from foreach(
 row={
 SELECT Uid, Name AS User,
 expand(path=Directory) AS HomeDirectory
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex
 },
 query={
 SELECT User, OSPath, Mtime
 FROM glob(root=HomeDirectory, globs=placesGlobs)
 })

 SELECT * FROM foreach(row=places_files,
 query={
 SELECT User, OSPath,
 timestamp(epoch=visit_date/1000000) as visit_time,
 place_id,url_visited,title,rev_host,visit_count,hidden,typed,description
 FROM sqlite(
 file=OSPath,
 query=urlSQLQuery)
 })
 WHERE url_visited =~ URLRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.IISLogs</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.iislogs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.iislogs/</guid><description>&lt;p>This artifact enables grep of IISLogs.&lt;/p>
&lt;p>Parameters include SearchRegex and WhitelistRegex as regex terms and
MoreRecentThan as timestamp.&lt;/p>
&lt;p>&lt;strong>Hint:&lt;/strong> Make sure to get the right location of the log files as
they are often stored at different non-default locations.&lt;/p>
&lt;p>&lt;strong>Hint 2:&lt;/strong> MoreRecentThan filter is only applied to the Last
Modified Time of files returned by the IISLogFiles glob. This
improves the artefact&amp;rsquo;s performance on systems with many log
files. Use the SearchRegex filter for filtering on a per line
basis.&lt;/p>
&lt;p>For example, a regex like &lt;code>2025-07-2[1-5]&lt;/code> will efficiently
recover lines with ISO times between the 21st and 25th July 2025.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.IISLogs
description: |
 This artifact enables grep of IISLogs.

 Parameters include SearchRegex and WhitelistRegex as regex terms and
 MoreRecentThan as timestamp.

 **Hint:** Make sure to get the right location of the log files as
 they are often stored at different non-default locations.

 **Hint 2:** MoreRecentThan filter is only applied to the Last
 Modified Time of files returned by the IISLogFiles glob. This
 improves the artefact's performance on systems with many log
 files. Use the SearchRegex filter for filtering on a per line
 basis.

 For example, a regex like `2025-07-2[1-5]` will efficiently
 recover lines with ISO times between the 21st and 25th July 2025.

author: "Matt Green - @mgreen27, Updated by Stephan Mikiss"

parameters:
 - name: IISLogFiles
 default: '*:/inetpub/logs/**3/*.log'
 - name: MoreRecentThan
 default: ""
 type: timestamp
 - name: SearchRegex
 description: "Regex of strings to search in line."
 default: ' POST '
 type: regex
 - name: WhitelistRegex
 description: "Regex of strings to leave out of output."
 default:
 type: regex

sources:
 - precondition: SELECT OS From info() where OS = 'windows'

 query: |
 LET files = SELECT OSPath,Mtime AS MTime FROM glob(globs=IISLogFiles)

 LET more_recent = SELECT * FROM if(
 condition=MoreRecentThan,
 then={
 SELECT * FROM files
 WHERE MTime &amp;gt; MoreRecentThan
 }, else=files)

 SELECT * FROM foreach(row=more_recent,
 query={
 SELECT Line, OSPath FROM parse_lines(filename=OSPath)
 WHERE
 Line =~ SearchRegex
 AND NOT if(condition= WhitelistRegex,
 then= Line =~ WhitelistRegex,
 else= FALSE)
 })

 notebook:
 - type: vql_suggestion
 name: IIS Groks
 template: |
 /*
 ### IIS grok

 Note: IIS doesn't have a standard logging format so we have added some
 suggestions. Comment in preferred or add / modify your own.
 */

 LET target_grok = "%{TIMESTAMP_ISO8601:LogTimeStamp} %{IPORHOST:Site} %{WORD:Method} %{URIPATH:UriPath} %{NOTSPACE:QueryString} %{NUMBER:Port} %{NOTSPACE:Username} %{IPORHOST:Clienthost} %{NOTSPACE:Useragent} %{NOTSPACE:Referrer} %{NUMBER:Response} %{NUMBER:Subresponse} %{NUMBER:Win32status} %{NUMBER:Timetaken:int}"
 --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:timetaken:int}"
 --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:iisSite} %{NOTSPACE:computername} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:protocol} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{IPORHOST:cshost} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:bytessent:int} %{NUMBER:bytesrecvd:int} %{NUMBER:timetaken:int}"


 LET parsed = SELECT Fqdn, ClientId as _ClientId, Line as _Raw,
 grok(data=Line,grok=target_grok) as GrokParsed
 FROM source()

 SELECT * FROM foreach(row=parsed,
 query={ SELECT *, Fqdn, _Raw FROM GrokParsed })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.MegaSync</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.megasync/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.megasync/</guid><description>&lt;p>Parses MEGASync logs and allows using regular expressions to search for
entries of interest.&lt;/p>
&lt;p>With &lt;code>UploadLogs&lt;/code> selected a copy of the logs are uploaded to the server.&lt;/p>
&lt;p>&lt;code>SearchVSS&lt;/code> enables searching over VSS with automatic deduplication.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.MegaSync
description: |
 Parses MEGASync logs and allows using regular expressions to search for
 entries of interest.

 With `UploadLogs` selected a copy of the logs are uploaded to the server.

 `SearchVSS` enables searching over VSS with automatic deduplication.

author: "Matt Green - @mgreen27"

reference:
 - https://attack.mitre.org/techniques/T1567/002/

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: LogFiles
 default: 'C:\Users\*\AppData\Local\Mega Limited\MEGAsync\logs\*.log'
 - name: SearchRegex
 description: "Regex of strings to search in line."
 default: 'Transfer\s\(UPLOAD\)|upload\squeue|local\sfile\saddition\sdetected|Sync\s-\ssending\sfile|\"user\"'
 type: regex
 - name: WhitelistRegex
 description: "Regex of strings to leave out of output."
 default:
 type: regex

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

 - name: UploadLogs
 description: "Upload MEGASync logs."
 type: bool

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- Find target files
 LET files = SELECT *, OSPath as Source
 FROM glob(globs=LogFiles, accessor=Accessor)

 -- Collect all Lines in scope of regex search
 LET output = SELECT * FROM foreach(row=files,
 query={
 SELECT Line, OSPath,
 Mtime,
 Atime,
 Ctime,
 Size
 FROM parse_lines(filename=OSPath,accessor='file')
 WHERE TRUE
 AND Line =~ SearchRegex
 AND NOT if(condition= WhitelistRegex,
 then= Line=~WhitelistRegex,
 else = false)
 })
 GROUP BY Line

 SELECT
 Line as RawLine,
 OSPath
 FROM output


 - name: LogFiles
 query: |
 SELECT
 OSPath,
 if(condition=UploadLogs,
 then= upload(file=OSPath, accessor=Accessor)
 ) as Upload,
 'MEGAsync logfile' as Description,
 Mtime,
 Atime,
 Ctime,
 Size
 FROM output
 GROUP BY OSPath

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.NirsoftBrowserViewer</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.nirsoftbrowserviewer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.nirsoftbrowserviewer/</guid><description>&lt;p>This artifact wraps the Nirsoft BrowsingHistoryView tool - a tool
for parsing browser history from a variety of browsers.&lt;/p>
&lt;p>More information about the tool can be found here
&lt;a href="https://www.nirsoft.net/utils/browsing_history_view.html" target="_blank" >https://www.nirsoft.net/utils/browsing_history_view.html&lt;/a>
&lt;/p>
&lt;p>NOTE: This binary is treated as malware by many detection engines
since it is capable of dumping user passwords and search history!!!
Running it on the endpoint may (hopefully) trigger endpoint defenses.&lt;/p>
&lt;p>BrowsingHistoryView v2.55 - View browsing history of your Web browsers
Copyright (c) 2012 - 2023 Nir Sofer&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.NirsoftBrowserViewer
description: |
 This artifact wraps the Nirsoft BrowsingHistoryView tool - a tool
 for parsing browser history from a variety of browsers.

 More information about the tool can be found here
 https://www.nirsoft.net/utils/browsing_history_view.html

 NOTE: This binary is treated as malware by many detection engines
 since it is capable of dumping user passwords and search history!!!
 Running it on the endpoint may (hopefully) trigger endpoint defenses.

 BrowsingHistoryView v2.55 - View browsing history of your Web browsers
 Copyright (c) 2012 - 2023 Nir Sofer

tools:
 - name: NirsoftBrowsingHistoryView64
 url: https://github.com/Velocidex/Tools/raw/main/BrowsingHistoryView/BrowsingHistoryView-amd64.exe
 expected_hash: c50d3f139bc7ed05fb0f5e25671ec0268b577d5930f27964291cc8747970f2c3
 serve_locally: true

parameters:
 - name: HistorySource
 default: 1
 description: Source of history data (1=All users).
 - name: URLRegex
 default: .
 description: Filter URLs by this regex
 type: regex
 - name: DateAfter
 type: timestamp
 - name: DateBefore
 type: timestamp
 - name: AlsoUpload
 type: bool
 description: Also upload BrowsingHistoryView produced CSV file.
 - name: PARSE_TZ
 default: LOCAL
 description: Default timezone for parsing timestamps

implied_permissions:
 - EXECVE
 - FILESYSTEM_WRITE

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

 LET CSVFile &amp;lt;= tempfile(extension='.csv')

 -- Download the binary and create a csv file to write on.
 LET tmp_exe = SELECT OSPath AS BinPath
 FROM Artifact.Generic.Utils.FetchBinary(ToolName="NirsoftBrowsingHistoryView64")

 LET results = SELECT CSVFile
 FROM foreach(row=tmp_exe,
 query={
 SELECT CSVFile,
 if(condition=AlsoUpload,
 then=upload(file=CSVFile,
 name="NirsoftBrowsingHistoryView.csv")) AS Upload
 FROM execve(argv=[
 BinPath,
 "/VisitTimeFilterType", "1",
 "/HistorySource", HistorySource, "/LoadIE", "1",
 "/LoadFirefox", "1", "/LoadChrome", "1",
 "/LoadSafari", "1",
 "/scomma", CSVFile, "/SaveDirect"])
 })
 WHERE Upload OR TRUE

 -- Filter the results by the user specs
 SELECT * FROM foreach(row=results,
 query={
 -- This timestamp is in US style time and local time... boo :-(
 SELECT *, timestamp(string=`Visit Time`,
 format="1/2/2006 3:04:05 PM") AS Visited
 FROM parse_csv(filename=CSVFile)
 })
 WHERE URL =~ URLRegex AND
 Visited &amp;gt; DateAfterTime AND
 Visited &amp;lt; DateBeforeTime

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.OfficeMacros</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.officemacros/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.officemacros/</guid><description>&lt;p>Scans through a given directory glob for common office files. Then tries to
extract any embedded macros by parsing the OLE file structure.&lt;/p>
&lt;p>Office macros are a prominent initial infection vector. Many users click
through the warning dialogs, thus leading to infection.&lt;/p>
&lt;p>If a macro calls an external program (e.g. PowerShell) this is very
suspicious!&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.OfficeMacros
description: |
 Scans through a given directory glob for common office files. Then tries to
 extract any embedded macros by parsing the OLE file structure.

 Office macros are a prominent initial infection vector. Many users click
 through the warning dialogs, thus leading to infection.

 If a macro calls an external program (e.g. PowerShell) this is very
 suspicious!

parameters:
 - name: officeExtensions
 default: "*.{xls,xlsm,doc,docx,ppt,pptm}"
 - name: officeFileSearchGlob
 default: C:\Users\**\
 description: The directory to search for office documents.

sources:
 - query: |
 SELECT * FROM foreach(
 row={
 SELECT OSPath FROM glob(globs=officeFileSearchGlob + officeExtensions)
 },
 query={
 SELECT * from olevba(file=OSPath)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.SBECmd</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.sbecmd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.sbecmd/</guid><description>&lt;p>Execute Eric Zimmerman&amp;rsquo;s SBECmd and return output for analysis.&lt;/p>
&lt;p>SBECmd is a CLI for analyzing Shellbags data.&lt;/p>
&lt;p>Objective:&lt;/p>
&lt;ul>
&lt;li>Find which folders were accessed on the local machine, the
network, and/or removable devices. Evidence of previously
existing folders after deletion/overwrite. When certain folders
were accessed.&lt;/li>
&lt;/ul>
&lt;p>Interpretation:&lt;/p>
&lt;ul>
&lt;li>Stores information about which folders were most recently
browsed by the user.&lt;/li>
&lt;/ul>
&lt;p>NOTE: Velociraptor can now parse Shellbags natively with the
&lt;code>Windows.Forensics.Shellbags&lt;/code> artifact.&lt;/p>
&lt;p>MITRE ATT&amp;amp;CK ID: TA0009 - Collection&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.SBECmd
description: |
 Execute Eric Zimmerman's SBECmd and return output for analysis.

 SBECmd is a CLI for analyzing Shellbags data.

 Objective:

 - Find which folders were accessed on the local machine, the
 network, and/or removable devices. Evidence of previously
 existing folders after deletion/overwrite. When certain folders
 were accessed.

 Interpretation:

 - Stores information about which folders were most recently
 browsed by the user.

 NOTE: Velociraptor can now parse Shellbags natively with the
 `Windows.Forensics.Shellbags` artifact.

 MITRE ATT&amp;amp;CK ID: TA0009 - Collection

author: Eduardo Mattos - @eduardfir

reference:
 - https://github.com/EricZimmerman

type: CLIENT

tools:
 - name: SBECmd
 url: https://github.com/Velocidex/Tools/raw/main/SBECmd/ShellBagsExplorer/SBECmd.exe

precondition: SELECT OS From info() where OS = 'windows'

implied_permissions:
 - EXECVE
 - FILESYSTEM_WRITE

parameters:
 - name: userRegex
 default: .
 type: regex

 - name: UploadFiles
 description: "Select to Upload SBECmd Output files."
 type: bool

 - name: RemovePayload
 description: "Select to Remove Payload after execution."
 type: bool


sources:
 - query: |
 -- get context on target binary
 LET payload &amp;lt;= SELECT * FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="SBECmd", IsExecutable=TRUE)

 -- build tempfolder for output
 LET tempfolder &amp;lt;= tempdir(remove_last=TRUE)

 -- get users with profiles
 LET UserProfiles = SELECT
 Uid, Name,
 expand(path=Directory) AS HomeDirectory, UUID, Mtime
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex and HomeDirectory =~ "Users"

 -- execute payload
 LET deploy &amp;lt;= SELECT * FROM foreach(row=UserProfiles,
 query={
 SELECT *, Name
 FROM execve(argv=[
 payload.OSPath[0],
 "-d", HomeDirectory,
 "--csv", tempfolder + "\\" + Name,
 "--dedupe"])
 })

 -- parse csvs
 SELECT * FROM foreach(row=deploy,
 query={
 SELECT *, Name as UserName
 FROM parse_csv(filename=tempfolder + "\\" + Name + "\\Deduplicated.csv")
 })

 - name: Uploads
 query: |
 SELECT * FROM chain(
 a={
 SELECT * FROM if(
 condition=UploadFiles,
 then={
 SELECT Name, upload(file=OSPath,
 name=relpath(base=tempfile, path=OSPath)) as FileDetails
 FROM glob(globs="/**", root=tempfolder)
 })
 },
 b={
 SELECT * FROM if(
 condition=RemovePayload,
 then={
 SELECT * FROM execve(argv=['powershell','Remove-Item',
 payload.OSPath[0],'-Force' ])
 })
 })
 WHERE Stdout =~ "SBECmd"

&lt;/code>&lt;/pre></description></item><item><title>Windows.Applications.TeamViewer.Incoming</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.applications.teamviewer.incoming/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.applications.teamviewer.incoming/</guid><description>&lt;p>Parses the TeamViewer Connections_incoming.txt log file.&lt;/p>
&lt;p>When inbound logging enabled, this file will show all inbound TeamViewer
connections.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Applications.TeamViewer.Incoming
description: |
 Parses the TeamViewer Connections_incoming.txt log file.

 When inbound logging enabled, this file will show all inbound TeamViewer
 connections.

author: Matt Green - @mgreen27

reference:
 - https://attack.mitre.org/techniques/T1219/
 - https://www.systoolsgroup.com/forensics/teamviewer/


type: CLIENT
parameters:
 - name: FileGlob
 default: C:\Program Files (x86)\TeamViewer\Connections_incoming.txt
 - name: DateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: DateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: TeamViewerIDRegex
 description: "Regex of TeamViewer ID"
 default: .
 type: regex
 - name: SourceHostRegex
 description: "Regex of source host"
 default: .
 type: regex
 - name: UserRegex
 description: "Regex of user"
 default: .
 type: regex

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- Build time bounds
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=DateAfter, else="1600-01-01")
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=DateBefore, else="2200-01-01")

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths &amp;lt;= SELECT OSPath FROM glob(
 globs=expand(path=FileGlob), accessor=Accessor)

 LET parse_log(OSPath, Accessor) = SELECT OSPath,
 parse_string_with_regex(
 string=Line,
 regex="^(?P&amp;lt;TeamViewerID&amp;gt;^\\d+)\\s+"+
 "(?P&amp;lt;SourceHost&amp;gt;.+)\\s" +
 "(?P&amp;lt;StartTime&amp;gt;\\d{2}-\\d{2}-\\d{4}\\s\\d{2}:\\d{2}:\\d{2})\\s" +
 "(?P&amp;lt;EndTime&amp;gt;\\d{2}-\\d{2}-\\d{4}\\s\\d{2}:\\d{2}:\\d{2})\\s" +
 "(?P&amp;lt;User&amp;gt;.+)\\s+" +
 "(?P&amp;lt;ConnectionType&amp;gt;[^\\s]+)\\s+" +
 "(?P&amp;lt;ConnectionID&amp;gt;.+)$") as Record
 FROM parse_lines(filename=OSPath, accessor=Accessor)
 WHERE Line
 AND Record.TeamViewerID =~ TeamViewerIDRegex
 AND Record.SourceHost =~ SourceHostRegex
 AND Record.User =~ UserRegex

 -- function returning IOC hits
 LET logsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT *, timestamp(epoch=Record.StartTime,
 format="02-01-2006 15:04:05") AS StartTime,
 timestamp(epoch=Record.EndTime,
 format="02-01-2006 15:04:05") AS EndTime
 FROM parse_log(OSPath=OSPath, Accessor=Accessor)
 WHERE StartTime &amp;lt; DateBeforeTime
 AND StartTime &amp;gt; DateAfterTime
 AND EndTime &amp;lt; DateBeforeTime
 AND EndTime &amp;gt; DateAfterTime
 })

 SELECT
 Record.TeamViewerID as TeamViewerID,
 Record.SourceHost as SourceHost,
 StartTime,
 EndTime,
 Record.User as User,
 Record.ConnectionType as ConnectionType,
 Record.ConnectionID as ConnectionID,
 OSPath
 FROM logsearch(PathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Attack.ParentProcess</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.attack.parentprocess/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.attack.parentprocess/</guid><description>&lt;p>Maps the MITRE Att&amp;amp;ck framework process executions into artifacts.&lt;/p>
&lt;p>NOTE: This artifact uses the process tracker. If you also enable the
Windows.Events.TrackProcesses or Windows.Events.TrackProcessesBasic
artifacts, this will be able to retrieve information about exited
processes.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Attack.ParentProcess
description: |
 Maps the MITRE Att&amp;amp;ck framework process executions into artifacts.

 NOTE: This artifact uses the process tracker. If you also enable the
 Windows.Events.TrackProcesses or Windows.Events.TrackProcessesBasic
 artifacts, this will be able to retrieve information about exited
 processes.

reference:
 - https://www.sans.org/security-resources/posters/hunt-evil/165/download
 - https://github.com/teoseller/osquery-attck/blob/master/windows-incorrect_parent_process.conf

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: lookupTable
 type: csv
 description: |
 A table mapping a process name to its expected parents. Both
 columns are regular expressions. The ProcessName must appear
 only once - you can specify multiple possible parents using
 regular expressions.

 default: |
 ProcessName,ParentRegex
 smss.exe,System
 runtimebroker.exe,svchost.exe
 taskhostw.exe,svchost.exe
 services.exe,wininit.exe
 lsass.exe,wininit.exe
 svchost.exe,services.exe
 cmd.exe,explorer.exe
 powershell.exe,explorer.exe
 iexplore.exe,explorer.exe
 firefox.exe,(firefox|explorer).exe
 chrome.exe,(chrome|explorer).exe

sources:
 - query: |
 SELECT * FROM foreach(row=lookupTable,
 query={
 SELECT Name AS ActualProcessName,
 process_tracker_get(id=Ppid).Data.Name AS ActualParentName,
 Pid, Ppid,
 CommandLine,
 StartTime,
 EndTime,
 Exe,
 ParentRegex as ExpectedParentName,
 Username,
 join(array=process_tracker_callchain(id=Pid).Data.Name,
 sep=" -&amp;gt; ") AS CallChain
 FROM process_tracker_pslist()
 WHERE ActualProcessName =~ ProcessName
 AND ActualParentName
 AND NOT ActualParentName =~ ParentRegex
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Attack.Prefetch</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.attack.prefetch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.attack.prefetch/</guid><description>&lt;p>Maps the MITRE Att&amp;amp;ck framework process executions into artifacts.&lt;/p>
&lt;p>This pack was generated from
&lt;a href="https://github.com/teoseller/osquery-attck" target="_blank" >https://github.com/teoseller/osquery-attck&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Attack.Prefetch
description: |
 Maps the MITRE Att&amp;amp;ck framework process executions into artifacts.

 This pack was generated from
 https://github.com/teoseller/osquery-attck

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 SELECT Name, ModTime, Mtime AS modified
 FROM glob(globs="C:/Windows/Prefetch/*")

# Reports can be MONITORING_DAILY, CLIENT, SERVER_EVENT
reports:
 - type: CLIENT
 parameters:
 - name: lookupTable
 type: csv
 default: |
 signature,description
 attrib,Attrib Execute is usually used to modify file attributes - ATT&amp;amp;CK T1158
 schtasks.exe,Schtasks Execute: usaullay used to create a scheduled task - ATT&amp;amp;CK T1053:S0111
 taskeng.exe,taskeng Execute: usaullay used to create a scheduled task - ATT&amp;amp;CK T1053
 tscon.exe,tscon.exe Execute: usaullay used to Terminal Services Console - ATT&amp;amp;CK T1076
 mstsc.exe,mstsc.exe Execute: usaullay used to perform a RDP Session - ATT&amp;amp;CK T1076
 at.exe,Schtasks Execute: usaullay used to create a scheduled task - ATT&amp;amp;CK T1053:S0110
 tasklist.exe,Tasklist Execute: usaullay used to list task - ATT&amp;amp;CK T1057:T1063:T1007:S0057
 taskkill.exe,Taskkill Execute: usaullay used to kill task
 mshta.exe,Mshta Execute: is a utility that executes Microsoft HTML Applications (HTA) - ATT&amp;amp;CK T1170
 whoami.exe,Whoami Execute: used to prints the effective username of the current user
 xcopy.exe,Xcopy Execute: is used for copying multiple files or entire directory trees from one directory to another and for copying files across a network.
 esentutl.exe,Esentutl Execute: is a legitimate built-in command-line program it could be used to create a exe from dump raw source.
 net.exe,Net Execute: is used in command-line operations for control of users: groups: services: and network connections - ATT&amp;amp;CK T1126:T1087:T1201:T1069:S0039:T1018:T1007:T1124
 vssadmin.exe,Vssadmin Execute: usaullay used to execute activity on Volume Shadow copy
 InstallUtil.exe,InstallUtil Execute: InstallUtil is a command-line utility that allows for installation and uninstallation of resources by executing specific installer components specified in .NET binaries - ATT&amp;amp;CK T1118
 cmstp.exe,CMSTP Execute: The Microsoft Connection Manager Profile Installer (CMSTP.exe) is a command-line program used to install Connection Manager service profiles. - ATT&amp;amp;CK T1191
 cmd.exe,Command-Line Interface Execute: CMD execution - ATT&amp;amp;CK T1059
 cscript.exe,Command-Line Interface Execute: Cscript execution starts a script so that it runs in a command-line environment. - ATT&amp;amp;CK T1216
 powershell.exe,POWERSHELL Execute: is a powerful interactive command-line interface and scripting environment included in the Windows operating system - ATT&amp;amp;CK T1086
 regsvr32.exe,POWERSHELL Execute: is a powerful interactive command-line interface and scripting environment included in the Windows operating system - ATT&amp;amp;CK T1117
 PsExec.exe,PsExec Execute: is a free Microsoft tool that can be used to execute a program on another computer. - ATT&amp;amp;CK T1035:S0029
 runas.exe,Runas Execute: Allows a user to run specific tools and programs with different permissions than the user's current logon provides. - ATT&amp;amp;CK T1134
 bitsadmin.exe,Bitsadmin Execute: Windows Background Intelligent Transfer Service (BITS) is a low-bandwidth: asynchronous file transfer mechanism exposed through Component Object Model (COM) - ATT&amp;amp;CK T1197:S0190
 certutil.exe,Certutil Execute: Certutil.exe is a legitimate built-in command-line program to manage certificates in Windows - ATT&amp;amp;CK T1105:T1140:T1130:S0160
 netsh.exe,Netsh Execute: Netsh.exe (also referred to as Netshell) is a command-line scripting utility used to interact with the network configuration of a system - ATT&amp;amp;CK T1128:T1063:S0108
 netstat.exe,Netstat Execute: is an operating system utility that displays active TCP connections: listening ports: and network statistics. - ATT&amp;amp;CK T1049:S0104
 reg.exe,Reg Execute: Reg is a Windows utility used to interact with the Windows Registry. - ATT&amp;amp;CK T1214:T1012:T1063:S0075
 regedit.exe,Regedit Execute: is a Windows utility used to interact with the Windows Registry. - ATT&amp;amp;CK T1214
 systeminfo.exe,Systeminfo Execute: Systeminfo is a Windows utility that can be used to gather detailed information about a computer. - ATT&amp;amp;CK T1082:S0096
 sc.exe,SC.exe Execute: Service Control - Create: Start: Stop: Query or Delete any Windows SERVICE. . - ATT&amp;amp;CK T1007


 template: |
 {{ .Description }}

 The below shows any prefetch files of interest and what they
 could potentially mean.

 {{ define "query" }}
 LET lookup &amp;lt;= SELECT * FROM lookupTable
 {{ end }}

 {{ define "data"}}
 LET data &amp;lt;= SELECT * FROM source()
 {{ end }}

 {{ range (Query "data" "query" "SELECT * FROM lookup") }}
 {{ $rows := Query (printf "SELECT * FROM source() WHERE Name =~ '%v'" (Get . "signature") ) }}
 {{ if $rows }}

 ## {{ Get $rows "0.Name" }}
 Modified on {{ Get $rows "0.ModTime" }}.

 {{ Get . "description" }}

 {{ end }}
 {{ end }}

 # Timeline

 {{ Query "SELECT modified * 1000, Name FROM foreach(row=lookup, query={ SELECT * FROM data WHERE Name =~ signature})" | Timeline }}

&lt;/code>&lt;/pre></description></item><item><title>Windows.Attack.UnexpectedImagePath</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.attack.unexpectedimagepath/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.attack.unexpectedimagepath/</guid><description>&lt;p>Some malware are hiding in plain text by masquerading a legitimate
executable name.&lt;/p>
&lt;p>This artifact looks for processes with known names that are being
loaded from unexpected locations.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Attack.UnexpectedImagePath

description: |
 Some malware are hiding in plain text by masquerading a legitimate
 executable name.

 This artifact looks for processes with known names that are being
 loaded from unexpected locations.

reference:
 - https://www.sans.org/posters/hunt-evil/
 - https://github.com/teoseller/osquery-attck/blob/master/windows-incorrect_path_process.conf

author: Amged Wageh

parameters:
 - name: expected_paths
 type: csv
 default: |
 ProcName,ExpectedPath
 csrss.exe,c:\windows\system32\csrss.exe
 smss.exe,c:\windows\system32\smss.exe
 services.exe,c:\windows\system32\services.exe
 wininit.exe,c:\windows\system32\wininit.exe
 svchost.exe,c:\windows\system32\svchost.exe
 svchost.exe,c:\windows\syswow64\svchost.exe
 runtimebroker.exe,c:\windows\system32\runtimebroker.exe
 lsaiso.exe,c:\windows\system32\lsaiso.exe
 taskhostw.exe,c:\windows\system32\taskhostw.exe
 lsass.exe,c:\windows\system32\lsass.exe
 winlogon.exe,c:\windows\system32\winlogon.exe
 explorer.exe,c:\windows\explorer.exe
 explorer.exe,c:\windows\syswow64\explorer.exe
 conhost.exe,c:\windows\system32\conhost.exe
 dllhost.exe,c:\windows\system32\dllhost.exe
 dllhost.exe,c:\windows\syswow64\dllhost.exe
 wmiprvse.exe,c:\windows\system32\wbem\wmiprvse.exe
 wmiprvse.exe,c:\windows\syswow64\wbem\wmiprvse.exe

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET expected_paths_lookup &amp;lt;= memoize(key="ProcName", query={
 SELECT ProcName, enumerate(items=ExpectedPath) AS Path
 FROM expected_paths
 GROUP BY ProcName
 })

 LET suspicious_processes = SELECT Pid AS PID, Name AS ProcessName, Ppid AS PPID,
 Exe AS ImagePath, CommandLine, Username, StartTime,
 if(condition=EndTime&amp;lt;StartTime, then="", else=EndTime) AS EndTime,
 get(item=expected_paths_lookup, field=Name).Path AS ExpectedPaths,
 process_tracker_callchain(id=Pid) AS CallChain,
 process_tracker_get(id=Ppid) AS Parent
 FROM process_tracker_pslist()
 WHERE ImagePath != "" AND ExpectedPaths AND
 NOT lowcase(string=ImagePath) IN ExpectedPaths

 SELECT PID, ProcessName, ImagePath, CommandLine, Username, StartTime, EndTime,
 PPID, Parent.Data.Name As ParentProcessName,
 Parent.Data.Exe As ParentImagePath,
 Parent.Data.CommandLine As ParentCommandLine,
 Parent.Data.Username As ParentUsername,
 Parent.StartTime As ParentStartTime,
 if(condition=Parent.EndTime&amp;lt;Parent.StartTime, then=NULL, else=EndTime) AS ParentEndTime,
 CallChain.Data AS _CallChain,
 { SELECT Pid, Name, Ppid, Exe,
 CommandLine, Username, StartTime, EndTime
 FROM
 foreach(row=process_tracker_children(id=PID).Data)
 } AS SubProcesses
 FROM suspicious_processes

&lt;/code>&lt;/pre></description></item><item><title>Windows.Carving.CobaltStrike</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.carving.cobaltstrike/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.carving.cobaltstrike/</guid><description>&lt;p>This artifact extracts Cobalt Strike configuration from a byte stream, process
or file on disk such as a process dump. Best used as a triage step against a
detection of a Cobalt Strike beacon via a YARA process scan.&lt;/p>
&lt;p>The User can define bytes, file glob, process name or pid regex as a target. The
content will search for a configuration pattern, extract a defined byte size,
xor with discovered key, then attempt configuration extraction.&lt;/p>
&lt;ul>
&lt;li>Cobalt Strike beacon configuration is typically XORed with 0x69 or 0x2e
(depending on version) but trivial to change.&lt;/li>
&lt;li>Configuration is built in a typical index / type / length / value structure
with either big endian values or zero terminated strings.&lt;/li>
&lt;li>If no beacon is found, parser will fallback to Cobalt Strike Shellcode analysis.&lt;/li>
&lt;/ul>
&lt;p>This content simply carves the configuration and does not unpack files on
disk. That means pointing this artifact as a packed or obfuscated file may not
obtain the expected results.&lt;/p>
&lt;p>Unpacking later version.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Carving.CobaltStrike
author: Matt Green - @mgreen27
description: |
 This artifact extracts Cobalt Strike configuration from a byte stream, process
 or file on disk such as a process dump. Best used as a triage step against a
 detection of a Cobalt Strike beacon via a YARA process scan.

 The User can define bytes, file glob, process name or pid regex as a target. The
 content will search for a configuration pattern, extract a defined byte size,
 xor with discovered key, then attempt configuration extraction.

 - Cobalt Strike beacon configuration is typically XORed with 0x69 or 0x2e
 (depending on version) but trivial to change.
 - Configuration is built in a typical index / type / length / value structure
 with either big endian values or zero terminated strings.
 - If no beacon is found, parser will fallback to Cobalt Strike Shellcode analysis.

 This content simply carves the configuration and does not unpack files on
 disk. That means pointing this artifact as a packed or obfuscated file may not
 obtain the expected results.

 Unpacking later version.

reference:
 - https://attack.mitre.org/software/S0154/
 - https://blog.didierstevens.com/2020/11/07/1768-k/

parameters:
 - name: TargetBytes
 default:
 - name: TargetFileGlob
 default:
 - name: PidRegex
 default: .
 type: regex
 - name: ProcessRegex
 default: .
 type: regex
 - name: ExtractBytes
 type: int
 default: 10000
 - name: BruteXor
 type: bool
 description: Select to attempt brute forcing Xor byte in config. Default is 0x2e or 0x69.
 - name: IncludeDecodedData
 type: bool
 description: Select to include decoded data in output.
 - name: FindConfigTemplate
 type: hidden
 default: |
 rule cobalt_strike_beacon {
 strings:
 $REPLACEME

 condition:
 any of them
 }
 - name: FindShellcode
 type: hidden
 default: |
 rule cobalt_strike_shellcode {
 strings:
 $header = { FC }
 $s1 = "hwini"
 $s2 = "hws2_"
 $s3 = "wininet"

 condition:
 ( $header at 0 and filesize &amp;lt; 4096 )
 or any of ($s*) // we enact offset limits in VQL ( 0..4096 )
 }
 - name: FindSleepFunction
 type: hidden
 default: |
 rule cobalt_strike_sleepfunction {
 strings:
 $x64 = { 4C 8B 53 08 45 8B 0A 45 8B 5A 04 4D 8D 52 08 45 85 C9 75 05 45 85 DB 74 33 45 3B CB 73 E6 49 8B F9 4C 8B 03 }
 $x86 = { 8B 46 04 8B 08 8B 50 04 83 C0 08 89 55 08 89 45 0C 85 C9 75 04 85 D2 74 23 3B CA 73 E6 8B 06 8D 3C 08 33 D2 }

 condition:
 any of them
 }

export: |
 LET PROFILE = '''[
 [CobaltConfig, 0, [
 # 0x0001:BeaconType, 0x0001:Type, 0x0002:Length
 ["BeaconType", 6, "Enumeration", {
 "type": "uint16b",
 "choices": {
 "0": "windows-beacon_http-reverse_http",
 "1": "windows-beacon_dns-reverse_http",
 "2": "windows-beacon_smb-bind_pipe",
 "8": "windows-beacon_https-reverse_https",
 "16": "windows-beacon_tcp-bind_tcp"
 }
 }],

 # 0x0002:Port, 0x0001:Type, 0x0002:Length
 ["__port_prefix", 0, "String",{"term_hex": "000200010002", length: 10000, max_length: 10000}],
 ["Port", "x=&amp;gt;len(list=x.__port_prefix) + 6", "uint16b"],

 # 0x0003:Sleeptime,0x0002:Type, 0x0004:Length
 ["__sleeptime_prefix", 0, "String", {"term_hex": "000300020004", length: 10000, max_length: 10000}],
 ["Sleeptime", "x=&amp;gt;len(list=x.__sleeptime_prefix) + 6", "uint32b"],

 # 0x0004:Maxgetsize, 0x0002:Type, 0x0004:Length
 ["__maxgetsize_prefix", 0, "String",{"term_hex": "000400020004", length: 10000, max_length: 10000}],
 ["Maxgetsize", "x=&amp;gt;len(list=x.__maxgetsize_prefix) + 6", "uint32b"],

 # 0x0005:Jitter, 0x0001:Type, 0x0002:Length
 ["__jitter_prefix", 0, "String",{"term_hex": "000500010002", length: 10000, max_length: 10000}],
 ["Jitter", "x=&amp;gt;len(list=x.__jitter_prefix) + 6", "uint16b"],

 # 0x0006:MaxDns, 0x0001:Type, 0x0002:Length
 ["__maxdns_prefix", 0, "String",{"term_hex": "000600010002", length: 10000, max_length: 10000}],
 ["MaxDns", "x=&amp;gt;len(list=x.__maxdns_prefix) + 6", "uint16b"],

 # 0x0007:Publickey,0x0003:Type,
 ["__publickey_prefix", 0, "String",{"term_hex": "000700030100", length: 10000, max_length: 10000}],
 ["__publickey_raw", "x=&amp;gt;len(list=x.__publickey_prefix) + 6", "String",{"term_hex":"00000008"}],
 ["PublicKey", "x=&amp;gt;len(list=x.__publickey_prefix) + 6", "Value",{"value":"x=&amp;gt;format(format='% x',args=x.__publickey_raw)"}],

 # 0x0008:server/get-uri,0x0003:Type,
 ["__c2server_prefix", 0, "String",{"term_hex": "00080003", length: 10000, max_length: 10000}],
 ["C2Server", "x=&amp;gt;len(list=x.__c2server_prefix) + 6", "String"],

 # 0x0009:useragent,0x0003:Type,
 ["__useragent_prefix", 0, "String",{"term_hex": "00090003", length: 10000, max_length: 10000}],
 ["UserAgent", "x=&amp;gt;len(list=x.__useragent_prefix) + 6", "String"],

 # 0x000a:PostUri,0x0003:Type,
 ["__PostUri_prefix", 0, "String", {"term_hex": "000a0003", length: 10000, max_length: 10000}],
 ["PostURI", "x=&amp;gt;len(list=x.__PostUri_prefix) + 6", "String"],

 # 0x000b:Malleable_C2_Instructions,0x0003:Type, adding length check as not sure if we can rely on termination
 ["__Malleable_C2_Instructions_prefix", 0, "String",{"term_hex": "000b0003", length: 10000, max_length: 10000}],
 ["__Malleable_C2_Instructions_length","x=&amp;gt;len(list=x.__Malleable_C2_Instructions_prefix) + 4","uint16b"],
 ["__Malleable_C2_Instructions", "x=&amp;gt;len(list=x.__Malleable_C2_Instructions_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__Malleable_C2_Instructions_length"}],
 ["MalleableC2Instructions",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__Malleable_C2_Instructions, re='[^ -~\\r\\n]', replace='')])" }],
 #["Malleable_C2_Instructions",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__Malleable_C2_Instructions)" }], #uncomment to return base64 encoded raw Malleable_C2_Instructions

 # 0x000c:HttpGetHeader,0x0003:Type, adding length check as we can not rely on termination
 ["__HttpGetHeader_prefix", 0, "String",{"term_hex": "000c0003", length: 10000, max_length: 10000}],
 ["__HttpGetHeader_length","x=&amp;gt;len(list=x.__HttpGetHeader_prefix) + 4","uint16b"],
 ["__HttpGetHeader","x=&amp;gt;len(list=x.__HttpGetHeader_prefix) + 6","String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__HttpGetHeader_length"}],
 ["HttpGetHeader",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__HttpGetHeader, re='[^ -~\\r\\n]', replace='')])" }],
 #["HttpGetHeader",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__HttpGetHeader)" }], #uncomment to return base64 encoded raw HttpGetHeader

 # 0x000d:HttpPostHeader,0x0003:Type, adding length check as we can not rely on termination
 ["__http_post_header_prefix", 0, "String",{"term_hex": "000d0003", length: 10000, max_length: 10000}],
 ["__HttpPostHeader_length","x=&amp;gt;len(list=x.__http_post_header_prefix) + 4","uint16b"],
 ["__HttpPostHeader","x=&amp;gt;len(list=x.__http_post_header_prefix) + 6","String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__HttpPostHeader_length"}],
 ["HttpPostHeader",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__HttpPostHeader, re='[^ -~\\r\\n]', replace='')])" }],
 #["HttpPostHeader",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__HttpPostHeader)" }], #uncomment to return base64 encoded raw HttpPostHeader

 # 0x000e:SpawnTo,0x0003:Type # Adding length check as we can not rely on termination
 ["__SpawnTo_header_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
 ["__SpawnTo_header_length","x=&amp;gt;len(list=x.__SpawnTo_header_prefix) + 4","uint16b"],
 ["__SpawnTo", "x=&amp;gt;len(list=x.__SpawnTo_header_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__SpawnTo_header_length"}],
 ["SpawnTo",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__SpawnTo, re='[^ -~\\r\\n]', replace='')])" }],
 #["SpawnTo",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__SpawnTo)" }], #uncomment to return base64 encoded raw SpawnTo

 # 0x000f:PipeName,0x0003:Type
 ["__pipename_prefix", 0, "String",{"term_hex": "000f0003", length: 10000, max_length: 10000}],
 ["Pipename", "x=&amp;gt;len(list=x.__pipename_prefix) + 6", "String",{"term_hex":"0000"}],

 # 0x0010:KillDateYear, 0x0001:Type, 0x0002:Length
 ["__KillDateYear_prefix", 0, "String",{"term_hex": "001000010002", length: 10000, max_length: 10000}],
 ["KillDateYear", "x=&amp;gt;len(list=x.__KillDateYear_prefix) + 6", "uint16b"],

 # 0x0011:KillDateMonth, 0x0001:Type, 0x0002:Length
 ["__KillDateMonth_prefix", 0, "String",{"term_hex": "001200010002", length: 10000, max_length: 10000}],
 ["KillDateMonth", "x=&amp;gt;len(list=x.__KillDateMonth_prefix) + 6", "uint16b"],

 # 0x0012:KillDateDay, 0x0001:Type, 0x0002:Length
 ["__KillDateDay_prefix", 0, "String",{"term_hex": "001200010002", length: 10000, max_length: 10000}],
 ["KillDateDay", "x=&amp;gt;len(list=x.__KillDateDay_prefix) + 6", "uint16b"],

 # 0x0013:DNSIdle, 0x0002:Type, 0x0004:Length
 ["__DNSIdle_prefix", 0, "String",{"term_hex": "001300020004", length: 10000, max_length: 10000}],
 ["__DNSIdle1", "x=&amp;gt;len(list=x.__DNSIdle_prefix) + 6", "uint8"],
 ["__DNSIdle2", "x=&amp;gt;len(list=x.__DNSIdle_prefix) + 7", "uint8"],
 ["__DNSIdle3", "x=&amp;gt;len(list=x.__DNSIdle_prefix) + 8", "uint8"],
 ["__DNSIdle4", "x=&amp;gt;len(list=x.__DNSIdle_prefix) + 9", "uint8"],
 ["DNSIdle", 0, "Value", {
 "value": "x=&amp;gt; str(str=x.__DNSIdle1) + '.' + str(str=x.__DNSIdle2) + '.' + str(str=x.__DNSIdle3) + '.' + str(str=x.__DNSIdle4)"
 }],

 # 0x0014:DNSSleep', 0x0002:Type, 0x0004:Length
 ["__DNSSleep_prefix", 0, "String",{"term_hex": "001400020004", length: 10000, max_length: 10000}],
 ["DNSSleep", "x=&amp;gt;len(list=x.__DNSSleep_prefix) + 6", "uint32b"],

 # 0x0015:SSH_1, to complete - didnt find any examples assuming zero terminated
 ["__SSH_1_prefix", 0, "String",{"term_hex": "00150003", length: 10000, max_length: 10000}],
 ["SSH_1", "x=&amp;gt;len(list=x.__SSH_1_prefix) + 6", "String"],

 # 0x0016:SSH_2, to complete - didnt find any examples assuming zero terminated
 ["__SSH_2_prefix", 0, "String",{"term_hex": "00160003", length: 10000, max_length: 10000}],
 ["SSH_2", "x=&amp;gt;len(list=x.__SSH_2_prefix) + 6", "String"],

 # 0x0017:SSH_3, to complete - didnt find any examples assuming zero terminated
 ["__SSH_3_prefix", 0, "String",{"term_hex": "00170003", length: 10000, max_length: 10000}],
 ["SSH_3", "x=&amp;gt;len(list=x.__SSH_3_prefix) + 6", "String"],

 # 0x0018:SSH_4, to complete - didnt find any examples assuming zero terminated
 ["__SSH_4_prefix", 0, "String",{"term_hex": "00180003", length: 10000, max_length: 10000}],
 ["SSH_4", "x=&amp;gt;len(list=x.__SSH_4_prefix) + 6", "String"],

 # 0x0019:SSH_5, to complete - didnt find any examples assuming zero terminated
 ["__SSH_5_prefix", 0, "String",{"term_hex": "00190003", length: 10000, max_length: 10000}],
 ["SSH_5", "x=&amp;gt;len(list=x.__SSH_5_prefix) + 6", "String"],

 # 0x001a:GetVerb,0x0003:Type
 ["__GetVerb_prefix", 0, "String",{"term_hex": "001a0003"}],
 ["GetVerb", "x=&amp;gt;len(list=x.__GetVerb_prefix) + 6", "String",{"term_hex":"0000"}],

 # 0x001b: PostVerb, 0x0003:Type
 ["__PostVerb_prefix", 0, "String",{"term_hex": "001b0003"}],
 ["PostVerb", "x=&amp;gt;len(list=x.__PostVerb_prefix) + 6", "String",{"term_hex":"0000"}],

 # 0x001c:HttpPostChunk,0x0002:Type, 0x0004:Length
 ["__HttpPostChunk_prefix", 0, "String", {"term_hex": "001c00020004"}],
 ["HttpPostChunk", "x=&amp;gt;len(list=x.__HttpPostChunk_prefix) + 6", "uint32b"],

 # 0x001d:spawnto_x86,0x0003:Type
 ["__spawnx86_prefix", 0, "String",{"term_hex": "001d0003", length: 10000, max_length: 10000}],
 ["SpawnTox86", "x=&amp;gt;len(list=x.__spawnx86_prefix) + 6", "String",{"term_hex":"0000"}],

 # 0x001e:spawn_to_x64,0x0003:Type
 ["__spawnx64_prefix", 0, "String",{"term_hex": "001e0003", length: 10000, max_length: 10000}],
 ["SpawnTox64", "x=&amp;gt;len(list=x.__spawnx64_prefix) + 6", "String",{"term_hex":"0000"}],

 # 0x001f:CryptoScheme, 0x0001:Type, 0x0002:Length
 ["__CryptoScheme_prefix", 0, "String",{"term_hex": "001f00010002", length: 10000, max_length: 10000}],
 ["CryptoScheme", "x=&amp;gt;len(list=x.__CryptoScheme_prefix) + 6", "uint16b"],

 # 0x0020:Proxy, 0x0003:Type
 ["__Proxy_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
 #["__Proxy_length","x=&amp;gt;len(list=x.__Proxy_prefix) + 4","uint16b"],
 ["Proxy", "x=&amp;gt;len(list=x.__Proxy_prefix) + 6", "String"],

 # 0x0021:ProxyUsername, 0x0003:Type
 ["__ProxyUsername_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
 ["__ProxyUsername_length","x=&amp;gt;len(list=x.__ProxyUsername_prefix) + 4","uint16b"],
 ["ProxyUsername", "x=&amp;gt;len(list=x.__ProxyUsername_prefix) + 6", "String"],

 # 0x0022:ProxyPassword, 0x0003:Type
 ["__ProxyPassword_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
 ["__ProxyPassword_length","x=&amp;gt;len(list=x.__ProxyPassword_prefix) + 4","uint16b"],
 ["ProxyPassword", "x=&amp;gt;len(list=x.__ProxyPassword_prefix) + 6", "String"],

 # 0x0023:ProxyType, 0x0001:Type, 0x0002:Length
 ["__ProxyType", 0, "String",{"term_hex": "002300010002", length: 10000, max_length: 10000}],
 ["ProxyType", "x=&amp;gt;len(list=x.__ProxyType) + 6", "Enumeration", {
 "type": "uint16b",
 "choices": {
 "1": "No proxy",
 "2": "IE settings",
 "4": "Hardcoded proxy"}
 }],

 # 0x0024:Deprecated, 0x0001:Type, 0x0002:Length
 ["__Deprecated_prefix", 0, "String",{"term_hex": "002400010002", length: 10000, max_length: 10000}],
 ["Deprecated", "x=&amp;gt;len(list=x.__Deprecated_prefix) + 6", "uint16b"],

 # 0x0025:LicenseId,0x0002:Type, 0x0004:Length
 ["__LicenseId_prefix", 0, "String", {"term_hex": "002500020004", length: 10000, max_length: 10000}],
 ["LicenseId", "x=&amp;gt;len(list=x.__LicenseId_prefix) + 6", "uint32b"],

 # 0x0026:bStageCleanup, 0x0001:Type, 0x0002:Length
 ["__bStageCleanup_prefix", 0, "String",{"term_hex": "002600010002", length: 10000, max_length: 10000}],
 ["bStageCleanup", "x=&amp;gt;len(list=x.__bStageCleanup_prefix) + 6", "uint16b"],

 # 0x0027:bCFGCaution, 0x0001:Type, 0x0002:Length
 ["__bCFGCaution_prefix", 0, "String",{"term_hex": "002700010002", length: 10000, max_length: 10000}],
 ["bCFGCaution", "x=&amp;gt;len(list=x.__bCFGCaution_prefix) + 6", "uint16b"],

 # 0x0028:KillDate,0x0002:Type, 0x0004:Length
 ["__KillDate_prefix", 0, "String", {"term_hex": "002800020004", length: 10000, max_length: 10000}],
 ["KillDate", "x=&amp;gt;len(list=x.__KillDate_prefix) + 6", "uint32b"],

 # 0x0029:TextSectionEnd,0x0002:Type, 0x0004:Length
 ["__TextSectionEnd_prefix", 0, "String", {"term_hex": "002900020004", length: 10000, max_length: 10000}],
 ["TextSectionEnd", "x=&amp;gt;len(list=x.__TextSectionEnd_prefix) + 6", "uint32b"],

 # 0x002a:ObfuscateSectionsInfo,0x0003:Type # Adding length check as we can not rely on termination
 ["__ObfuscateSectionsInfo_prefix", 0, "String",{"term_hex": "002a0003", length: 10000, max_length: 10000}],
 ["__ObfuscateSectionsInfo_length","x=&amp;gt;len(list=x.__ObfuscateSectionsInfo_prefix) + 4","uint16b"],
 ["__ObfuscateSectionsInfo", "x=&amp;gt;len(list=x.__ObfuscateSectionsInfo_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__ObfuscateSectionsInfo_length"}],
 ["ObfuscateSectionsInfo",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__ObfuscateSectionsInfo, re='[^ -~\\r\\n]', replace='')])" }],
 #["ObfuscateSectionsInfo",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__ObfuscateSectionsInfo)" }], #uncomment to return base64 encoded raw ObfuscateSectionsInfo

 #0x002b:ProcessInjectStartRWX, 0x0001:Type, 0x0002:Length
 ["__ProcessInjectStartRWX", 0, "String",{"term_hex": "002b00010002", length: 10000, max_length: 10000}],
 ["ProcessInjectStartRWX", "x=&amp;gt;len(list=x.__ProcessInjectStartRWX) + 6", "Enumeration", {
 "type": "uint16b",
 "choices": {
 "0x1": "PAGE_NOACCESS",
 "0x2": "PAGE_READONLY",
 "0x4": "PAGE_READWRITE",
 "0x8": "PAGE_WRITECOPY",
 "0x10": "PAGE_EXECUTE",
 "0x20": "PAGE_EXECUTE_READ",
 "0x40": "PAGE_EXECUTE_READWRITE",
 "0x80": "PAGE_EXECUTE_WRITECOPY"}
 }],

 #0x002c:ProcessInjectUseRWX, 0x0001:Type, 0x0002:Length
 ["__ProcessInjectUseRWX", 0, "String",{"term_hex": "002c00010002", length: 10000, max_length: 10000}],
 ["ProcessInjectUseRWX", "x=&amp;gt;len(list=x.__ProcessInjectUseRWX) + 6", "Enumeration", {
 "type": "uint16b",
 "choices": {
 "0x1": "PAGE_NOACCESS",
 "0x2": "PAGE_READONLY",
 "0x4": "PAGE_READWRITE",
 "0x8": "PAGE_WRITECOPY",
 "0x10": "PAGE_EXECUTE",
 "0x20": "PAGE_EXECUTE_READ",
 "0x40": "PAGE_EXECUTE_READWRITE",
 "0x80": "PAGE_EXECUTE_WRITECOPY"}
 }],

 # 0x002d:ProcessInjectMinAlloc,0x0002:Type, 0x0004:Length
 ["__ProcessInjectMinAlloc_prefix", 0, "String", {"term_hex": "002d00020004", length: 10000, max_length: 10000}],
 ["ProcessInjectMinAlloc", "x=&amp;gt;len(list=x.__ProcessInjectMinAlloc_prefix) + 6", "uint32b"],

 # 0x002e:ProcessInjectTransformx86, 0x0003:Type, # Adding length check as we can not rely on termination
 ["__ProcessInjectTransformx86_prefix", 0, "String",{"term_hex": "002e0003", length: 10000, max_length: 10000}],
 ["__ProcessInjectTransformx86_length","x=&amp;gt;len(list=x.__ProcessInjectTransformx86_prefix) + 4","uint16b"],
 ["__ProcessInjectTransformx86", "x=&amp;gt;len(list=x.__ProcessInjectTransformx86_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__ProcessInjectTransformx86_length"}],
 ["ProcessInjectTransformx86",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__ProcessInjectTransformx86, re='[^ -~\\r\\n]', replace='')])" }],
 #["ProcessInjectTransformx86",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__ProcessInjectTransformx86)" }],#uncomment to return base64 encoded raw ProcessInjectTransformx86


 # 0x002f:ProcessInjectTransformx64, 0x0003:Type, # Adding length check as we can not rely on termination
 ["__ProcessInjectTransformx64_prefix", 0, "String",{"term_hex": "002f0003", length: 10000, max_length: 10000}],
 ["__ProcessInjectTransformx64_length","x=&amp;gt;len(list=x.__ProcessInjectTransformx64_prefix) + 4","uint16b"],
 ["__ProcessInjectTransformx64", "x=&amp;gt;len(list=x.__ProcessInjectTransformx64_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__ProcessInjectTransformx64_length"}],
 ["ProcessInjectTransformx64",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__ProcessInjectTransformx64, re='[^ -~\\r\\n]', replace='')])" }],
 #["ProcessInjectTransformx64",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__ProcessInjectTransformx64)" }],#uncomment to return base64 encoded raw ProcessInjectTransformx64

 # 0x0032:UsesCookies, 0x0001:Type, 0x0002:Length
 ["__UsesCookies_prefix", 0, "String",{"term_hex": "003200010002", length: 10000, max_length: 10000}],
 ["UsesCookies", "x=&amp;gt;len(list=x.__UsesCookies_prefix) + 6", "uint16b"],

 # 0x0033:ProcessInjectExecute, 0x0003:Type # Adding length check as we can not rely on termination
 ["__ProcessInjectExecute_prefix", 0, "String",{"term_hex": "00330003", length: 10000, max_length: 10000}],
 ["__ProcessInjectExecute_length","x=&amp;gt;len(list=x.__ProcessInjectExecute_prefix) + 4","uint16b"],
 ["__ProcessInjectExecute", "x=&amp;gt;len(list=x.__ProcessInjectExecute_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&amp;gt; x.__ProcessInjectExecute_length"}],
 ["ProcessInjectExecute",0,"Value",{ "value": "x=&amp;gt;format(format='%s', args=[regex_replace(source=x.__ProcessInjectExecute, re='[^ -~\\r\\n]', replace='')])" }],
 #["ProcessInjectExecute",0,"Value",{ "value": "x=&amp;gt;'base64:' + base64encode(string=x.__ProcessInjectExecute)" }], #uncomment to return base64 encoded raw ProcessInjectExecute

 # 0x0034:ProcessInjectAllocationMethod, 0x0001:Type, 0x0002:Length
 ["__ProcessInjectAllocationMethod_prefix", 0, "String",{"term_hex": "003400010002", length: 10000, max_length: 10000}],
 ["ProcessInjectAllocationMethod", "x=&amp;gt;len(list=x.__ProcessInjectAllocationMethod_prefix) + 6", "uint16b"],

 # 0x0035:ProcessInjectStub, 0x0003:Type # Adding length check as we can not rely on termination
 ["__ProcessInjectStub_prefix", 0, "String",{"term_hex": "00350003", length: 10000, max_length: 10000}],
 ["__ProcessInjectStub_length","x=&amp;gt;len(list=x.__ProcessInjectStub_prefix) + 4","uint16b"],
 ["__ProcessInjectStub", "x=&amp;gt;len(list=x.__ProcessInjectStub_prefix) + 6", "String",{"term_hex":"00000000", "length": "x=&amp;gt; x.__ProcessInjectStub_length"}],
 ["ProcessInjectStub",0,"Value",{ "value": "x=&amp;gt;format(format='% x', args=x.__ProcessInjectStub)" }],

 # 0x0036:HostHeader, 0x0003:Type # Adding length check as we can not rely on termination
 ["__HostHeader_prefix", 0, "String",{"term_hex": "00360003", length: 10000, max_length: 10000}],
 ["__HostHeader_length","x=&amp;gt;len(list=x.__HostHeader_prefix) + 4","uint16b"],
 ["HostHeader", "x=&amp;gt;len(list=x.__HostHeader_prefix) + 6", "String",{"term_hex":"00000000", "length": "x=&amp;gt; x.__HostHeader_length"}],

 ]],
 [Shellcode, 0, [
 ["__Position", 0, "Value",{"value":"x=&amp;gt;unhex(string=position(data=_Data))"}],
 ["Server", 0, "Value",{"value":"x=&amp;gt;regex_replace(source=regex_replace(source=x.__Position,re='\\x{00}.{4}[^$]*$',replace=''),re='\u0000',replace='')"}],
 ["TargetUri", 0, "Value",{"value":"x=&amp;gt;find_strings(data=_Data,length=5,filter='^/').Strings[0]"}],
 ["__LicenseBytes", 0, "Value",{"value":"x=&amp;gt;read_file(accessor='data',filename=x.__Position || '', offset=len(list=x.Server) + 1 ,length=4)"}],
 ["License", 0, "Value",{"value":"x=&amp;gt;parse_binary(accessor='data', filename=x.__LicenseBytes,struct='uint32b')"}],
 ["Strings", 0, "Value",{"value":"x=&amp;gt;find_strings(data=_Data,length=5,filter='.').Strings"}],
 ]],

 ["EmbeddedPE", 0, [
 ["__PayloadType", 0, "uint32"],
 ["PayloadType", 0, "Value",{"value":"x=&amp;gt;format(format='0x%08x',args=x.__PayloadType)"}],
 ["__PayloadSize", 4, "uint32"],
 #["PayloadSize", 4, "Value",{"value":"x=&amp;gt;format(format='0x%08x',args=x.__PayloadSize)"}],
 ["__XorKey", 8, "uint32b"],
 ["XorKey", 8, "Value",{"value":"x=&amp;gt;format(format='0x%08x',args=x.__XorKey)"}],
 ["__Id2", 12, "uint32"],
 ["Id2", 12, "Value",{"value":"x=&amp;gt;format(format='0x%08x',args=x.__Id2)"}],
 ["__Payload", 16, "Value",{"value":"x=&amp;gt;read_file(accessor='data',filename=embedded_section(path=TargetBytes || OSPath,
 type=if(condition=TargetBytes,then='data',else='auto'))[0].Data || '', offset=16,length=x.__PayloadSize)"}],
 #["__Payload", 16, "String",{"term_hex":"",length=x.__PayloadSize)"}],
 ["DecodedPayload", 16, "Value",{"value":"x=&amp;gt;xor(string=x.__Payload,key=unhex(string=x.XorKey))"}],
 ["PayloadHash", 16, "Value",{"value":"x=&amp;gt;hash(path=xor(string=x.__Payload,key=unhex(string=x.XorKey)),accessor='data')"}],
 ["OriginalFileHash", 16, "Value",{"value":"x=&amp;gt;hash(path=OSPath)"}],
 ]]]'''


sources:
 - query: |
 -- unique function to groupby value for enumerate
 LET unique(values) = SELECT _value as value FROM foreach(row=values) GROUP BY _value

 -- section to dynamically generate Xor configuration YARA hunt strings
 LET a &amp;lt;= unhex(string='01')
 LET b &amp;lt;= unhex(string='02')
 LET c &amp;lt;= unhex(string='03')

 LET XorChars &amp;lt;=
 SELECT format(format="%#02x", args=_value) AS H,
 unhex(string=format(format="%02x", args=_value)) as X
 FROM range(start=0, end=256, step=1)
 WHERE if(condition=BruteXor,
 then=True,
 else= H=~ '0x2e|0x69')

 Let XorCharsStep2 =
 SELECT H, X,
 xor(string=a, key=X) as aXor,
 xor(string=b, key=X) as bXor,
 xor(string=c, key=X) as cXor,
 len(list=X)
 FROM XorChars

 LET YaraStrings =
 SELECT -- { 00 01 00 01 00 02 ?? ?? 00 02 00 01 00 02 ?? ?? 00 03 }
 X,H,
 H + ' = { ' + format(format='% x', args=X + aXor + X + aXor + X + bXor) +
 ' ?? ?? ' + format(format='% x', args=X + bXor + X + aXor + X + bXor) +
 ' ?? ?? ' + format(format='% x', args=X + cXor) + ' }' as Line
 FROM XorCharsStep2

 LET FindConfig =
 regex_replace(
 source=FindConfigTemplate,
 re='REPLACEME',
 replace=join(array=YaraStrings.Line, sep=" $$"))


 -- function to extract potential additional encoded PE in data section
 LET embedded_section(path,type) = SELECT
 path as OriginalFileName,
 _value.Name as Name,
 _value.Size as Size,
 _value.FileOffset as FileOffset,
 _value.VMA as VMA,
 _value.RVA as RVA,
 _value.Perm as Perm,
 read_file(filename=path,
 accessor=type,
 offset=_value.FileOffset,
 length=_value.Size) as Data
 FROM foreach(row= parse_pe(file=path,accessor=type).Sections)
 WHERE Name = '.data' AND Size &amp;gt; 15


 -- scan DataBytes for Cobalt Strike config
 LET ByteConfiguration = SELECT Rule,
 len(list=TargetBytes) as Size,
 hash(path=TargetBytes,accessor='data') as Hash,
 format(format="%v_%v.bin", args=[Rule,String.Offset]) as _DecodedDataName,
 Xor,_Data,
 Rule as _Group
 FROM switch( -- switchcase will find beacon as priority, then search for shellcode
 beacon = {
 SELECT *,
 substr(start=0, end=1, str=String.Data) as Xor,
 read_file(accessor='data',
 filename=TargetBytes,
 offset= String.Offset,
 length=ExtractBytes) as _Data
 FROM yara(accessor='data',files=TargetBytes || "",
 rules=FindConfig, number=99)
 },
 shellcode = {
 SELECT *, '' as Xor,
 read_file(accessor='data',
 filename=TargetBytes,
 offset=String.Offset,length=4096) as _Data
 FROM yara(accessor='data',
 files=TargetBytes,
 rules=FindShellcode, number=99)
 },
 section_encoded_pe = {
 SELECT *,
 'Embedded data section: ' + Rule as Rule,
 substr(start=0,end=1,str=String.Data) as Xor,
 read_file(accessor='data',
 filename=File.OSPath,
 offset=String.Offset,
 length=ExtractBytes) as _Data
 FROM yara(files=parse_binary(
 accessor='data',
 filename= embedded_section(
 path=TargetBytes, type='data')[0].Data || "",
 profile=PROFILE,
 struct="EmbeddedPE").DecodedPayload,
 accessor='data', rules=FindConfig, number=99)
 },
 section_encoded_stager = {
 SELECT *,
 '' as Xor,
 'Embedded data section: ' + Rule as Rule,
 read_file(accessor='data',
 filename=File.OSPath) as _Data
 FROM yara(files=parse_binary(
 accessor='data',
 filename= embedded_section(
 path=TargetBytes,type='data')[0].Data || "",
 profile=PROFILE,
 struct="EmbeddedPE").DecodedPayload,
 accessor='data', rules=FindShellcode, number=99)
 },
 sleepfunction = {
 SELECT *, '' as Xor,
 if(condition= String.Name= '$x86',
 then= 'Sleep mask 32-bit 4.2 deobfuscation routine found.',
 else= 'Sleep mask 64-bit 4.2 deobfuscation routine found.') as _Data
 FROM yara(accessor='data',files=TargetBytes, rules=FindSleepFunction, number=1)
 })

 -- find target files
 LET TargetFiles = SELECT OSPath AS OSPath,Size
 FROM glob(globs=TargetFileGlob) WHERE NOT IsDir


 -- scan files in scope with our rule
 LET FileConfiguration = SELECT * FROM foreach(row=TargetFiles,
 query={
 SELECT
 Rule,
 OSPath, Size,
 hash(path=OSPath) as Hash,
 Xor,_Data,
 Rule + '|' + OSPath.String as _Group,
 format(format="%v_%v_%v.bin", args=[Rule,OSPath,String.Offset]) as _DecodedDataName
 FROM switch( -- switchcase will find beacon as priority, then search for shellcode
 beacon = {
 SELECT *,
 substr(start=0,end=1,str=String.Data) as Xor,
 read_file(
 filename=OSPath,
 offset= String.Offset,
 length=ExtractBytes) as _Data
 FROM yara(files=OSPath, rules=FindConfig, number=99)
 },

 shellcode = {
 SELECT *, '' as Xor,
 read_file(filename=OSPath,length=4096) as _Data
 FROM yara(files=OSPath, rules=FindShellcode, number=99)
 },

 section_encoded_pe = {
 SELECT *,
 'Embedded data section: ' + Rule as Rule,
 substr(start=0,end=1,str=String.Data) as Xor,
 read_file(accessor='data',filename=File.OSPath,
 offset=String.Offset,length=ExtractBytes) as _Data
 FROM yara(files=parse_binary(
 accessor='data',
 filename= embedded_section(path=OSPath,type='auto')[0].Data || "",
 profile=PROFILE,
 struct="EmbeddedPE").DecodedPayload,
 accessor='data', rules=FindConfig, number=99)
 },
 section_encoded_stager = {
 SELECT *,
 '' as Xor,
 'Embedded data section: ' + Rule as Rule,
 read_file(accessor='data',
 filename=File.OSPath,
 length=ExtractBytes) as _Data
 FROM yara(files=parse_binary(
 accessor='data',
 filename= embedded_section(path=OSPath,type='auto')[0].Data || "",
 profile=PROFILE,
 struct="EmbeddedPE").DecodedPayload,
 accessor='data', rules=FindShellcode, number=99)
 },
 sleepfunction = {
 SELECT *, '' as Xor,
 if(condition= String.Name= '$x86',
 then= 'Sleep mask 32-bit 4.2 deobfuscation routine found.',
 else= 'Sleep mask 64-bit 4.2 deobfuscation routine found.') as _Data
 FROM yara(files=OSPath, rules=FindSleepFunction, number=1)
 })
 })


 -- find velociraptor process
 LET me &amp;lt;= SELECT * FROM if(condition= NOT ( TargetFileGlob OR TargetBytes ),
 then = { SELECT Pid FROM pslist(pid=getpid()) })


 -- find all processes and add filters
 LET processes = SELECT Name as ProcessName, CommandLine, Pid
 FROM pslist()
 WHERE
 Name =~ ProcessRegex
 AND format(format="%d", args=Pid) =~ PidRegex
 AND NOT Pid in me.Pid

 -- scan processes in scope with our rule
 LET ProcessConfiguration = SELECT * FROM foreach(
 row=processes,
 query={
 SELECT Rule,
 Pid, ProcessName, CommandLine,
 format(format="%v_%v_%v_%v.bin", args=[Rule,ProcessName,Pid,String.Offset]) as _DecodedDataName,
 Xor,_Data,_Group
 FROM switch( -- switchcase will find beacon as priority, then search for shellcode
 beacon = {
 SELECT *,
 substr(start=0,end=1,str=String.Data) as Xor,
 read_file(accessor='process',
 filename=str(str=Pid),
 offset= String.Offset,
 length=ExtractBytes) as _Data,
 Rule +'|'+ str(str=Pid) +'|'+ ProcessName +'|'+ CommandLine as _Group
 FROM yara(accessor='process',files=str(str=Pid), rules=FindConfig, number=99)
 },
 shellcode = {
 SELECT *, '' as Xor,
 read_file(accessor='process',
 filename=str(str=Pid),
 offset=String.Offset,length=4096) as _Data,
 Rule +'|'+ str(str=Pid) +'|'+ ProcessName +'|'+ CommandLine as _Group
 FROM yara(accessor='process',files=str(str=Pid), rules=FindShellcode, number=99)
 },
 sleepfunction = {
 SELECT *, '' as Xor,
 if(condition= String.Name= '$x86',
 then= 'Sleep mask 32-bit 4.2 deobfuscation routine found.',
 else= 'Sleep mask 64-bit 4.2 deobfuscation routine found.') as _Data,
 '' as _Group
 FROM yara(accessor='process',files=str(str=Pid), rules=FindSleepFunction, number=1)
 })
 })


 -- Add dynamic functions for shellcode parsing
 LET position(data) = if(condition= len(list=split(string=format(format='%x',args=data),sep='ffff')) &amp;gt; 1,
 then= split(string=format(format='%x',args=data),sep='ffff')[-1],
 else= False )
 LET find_strings(data,length,filter) = SELECT Strings
 FROM parse_records_with_regex(file=data,accessor='data',regex='(?P&amp;lt;Strings&amp;gt;[ -~]+)')
 WHERE len(list=Strings) &amp;gt; length - 1
 AND Strings =~ filter
 AND NOT Strings =~ '^\\s+$'
 LIMIT 150


 -- generate results remove any FPs
 LET results &amp;lt;= SELECT *,
 if(condition= Rule=~'cobalt_strike_beacon$',
 then= format(format='0x%x',args=Xor),else='0x00') as Xor,
 if(condition= Rule=~'cobalt_strike_beacon',
 then= parse_binary(accessor='data',
 filename= xor(string=_Data || "" ,key=Xor),
 profile = PROFILE,struct = "CobaltConfig"),
 else= if(condition= Rule=~'cobalt_strike_shellcode',
 then= parse_binary(accessor='data',
 filename= _Data || "",
 profile = PROFILE,struct="Shellcode"),
 else= _Data )) AS DecodedConfig
 FROM if(condition=TargetBytes,
 then=ByteConfiguration,
 else= if(condition=TargetFileGlob,
 then= FileConfiguration,
 else= ProcessConfiguration))
 WHERE _Data
 AND
 (( DecodedConfig.C2Server =~ '^[ -~]+$' AND DecodedConfig.BeaconType )
 OR ( DecodedConfig.Pipename =~ '^[ -~]+$' AND DecodedConfig.BeaconType )
 OR DecodedConfig.Server =~ '^[ -~]+' -- AND DecodedConfig.TargetUri )
 OR Rule='cobalt_strike_sleepfunction' )

 -- add decoded data separate to keep pretty output
 LET output_decoded_data = SELECT *,
 upload(accessor = 'data',
 file = if(condition = Rule='cobalt_strike_beacon',
 then = xor(string=_Data,key=unhex(string=Xor)),
 else = _Data),
 name = _DecodedDataName) as DecodedData
 FROM results

 LET cleanup(config) = to_dict(item=
 {
 SELECT _key, _value
 FROM items(item=config)
 WHERE NOT _key =~ '^__' AND ( _value OR _key =~ '^license' )
 })

 -- output rows, standard config priority, exclude _Data
 SELECT *,
 if(condition= format(format='%T',args=DecodedConfig)='string',
 then= DecodedConfig,
 else= cleanup(config=DecodedConfig)) as DecodedConfig
 FROM column_filter(
 query={
 SELECT * ,
 -- NOTE: some junk strings for shellcode _Group are removed in GROUP BY
 if(condition= Rule='cobalt_strike_beacon',
 then= _Group +'|'+ str(str=DecodedConfig),
 else= _Group +'|'+ str(str=DecodedConfig.Server) +'|'+ str(str=DecodedConfig.TargetUri) +'|'+ str(str=DecodedConfig.Licence) ) as _Group
 FROM if(condition=IncludeDecodedData,
 then= output_decoded_data,
 else= results)
 GROUP BY _Group
 }, exclude=["_Data","_Group"])

column_types:
 - name: DecodedData
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.Carving.USN</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.carving.usn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.carving.usn/</guid><description>&lt;p>Carve URN Journal records from the disk.&lt;/p>
&lt;p>The USN journal is a very important source of information about when
and how files were manipulated on the filesystem. However, typically
the journal is rotated within a few days.&lt;/p>
&lt;p>This artifact carves out USN journal entries from the raw disk. This
might recover older entries which have since been rotated from the
journal file.&lt;/p>
&lt;h2 id="notes">Notes&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Like all carving, USN carving is not very reliable. You
would tend to use it to corroborate an existing theory or to
discover new leads.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>This artifact takes a long time to complete - you should
probably increase the collection timeout past 10 minutes (usually
more than an hour).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The reassembled OSPath is derived from the MFTId referenced in
the USN record. Bear in mind that this might be out of date and
inaccurate.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you need to carve from a standalone file (e.g. collection from
&lt;code>Windows.KapeFiles.Targets&lt;/code>) you should use the
Windows.Carving.USNFiles artifact instead.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Carving.USN
description: |
 Carve URN Journal records from the disk.

 The USN journal is a very important source of information about when
 and how files were manipulated on the filesystem. However, typically
 the journal is rotated within a few days.

 This artifact carves out USN journal entries from the raw disk. This
 might recover older entries which have since been rotated from the
 journal file.

 ## Notes

 1. Like all carving, USN carving is not very reliable. You
 would tend to use it to corroborate an existing theory or to
 discover new leads.

 2. This artifact takes a long time to complete - you should
 probably increase the collection timeout past 10 minutes (usually
 more than an hour).

 3. The reassembled OSPath is derived from the MFTId referenced in
 the USN record. Bear in mind that this might be out of date and
 inaccurate.

 4. If you need to carve from a standalone file (e.g. collection from
 `Windows.KapeFiles.Targets`) you should use the
 Windows.Carving.USNFiles artifact instead.

parameters:
 - name: Device
 default: "C:"
 description: The NTFS drive to carve
 - name: MFTFile
 description: Alternatively provide an MFTFile to use for resolving paths.
 - name: USNFile
 description: Alternatively provide a previously extracted USN file to carve or an image file.
 - name: Accessor
 description: The accessor to use.
 - name: FileNameRegex
 description: "Regex search over File Name"
 default: "."
 type: regex
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=DateAfter, else="1600-01-01")
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=DateBefore, else="2200-01-01")

 -- If the user specified an MFTFile then ignore the device
 LET Device &amp;lt;= if(condition=MFTFile OR USNFile, then=NULL,
 else=if(condition=Device,
 then=pathspec(parse=Device, path_type="ntfs")))

 LET Parse(MFT, USN, Accessor) = SELECT *
 FROM carve_usn(accessor=Accessor,
 mft_filename=MFT, usn_filename=USN)
 WHERE Filename =~ FileNameRegex
 AND Timestamp &amp;lt; DateBeforeTime
 AND Timestamp &amp;gt; DateAfterTime

 SELECT *
 FROM if(condition=Device, then={
 SELECT Timestamp,
 Filename,
 Device + OSPath AS OSPath,
 _Links,
 Reason,
 _FileMFTID as MFTId,
 _FileMFTSequence as Sequence,
 _ParentMFTID as ParentMFTId,
 _ParentMFTSequence as ParentSequence,
 FileAttributes,
 SourceInfo,
 Usn
 FROM Parse(Accessor="ntfs",
 MFT=Device + "$MFT",
 USN=Device)
 }, else={
 SELECT Timestamp,
 Filename,
 OSPath,
 _Links,
 Reason,
 _FileMFTID as MFTId,
 _FileMFTSequence as Sequence,
 _ParentMFTID as ParentMFTId,
 _ParentMFTSequence as ParentSequence,
 FileAttributes,
 SourceInfo,
 Usn
 FROM Parse(Accessor=Accessor,
 MFT=MFTFile, USN=USNFile)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Collectors.File</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.collectors.file/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.collectors.file/</guid><description>&lt;p>Collects files using a set of globs. All globs must be on the same
device. The globs will be searched in one pass - so you can provide
many globs at the same time.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Collectors.File
description: |
 Collects files using a set of globs. All globs must be on the same
 device. The globs will be searched in one pass - so you can provide
 many globs at the same time.

aliases:
 - Windows.Collectors.File

parameters:
 - name: collectionSpec
 description: |
 A CSV file with a Glob column with all the globs to collect.
 NOTE: Globs must not have a leading device.
 type: csv
 default: |
 Glob
 Users\*\NTUser.dat

 - name: Root
 description: |
 On Windows, this is the device to apply all the glob on
 (e.g. `C:`). On *NIX, this should be a path to a subdirectory or
 /.
 default: "C:"

 - name: Accessor
 default: auto
 description: |
 On Windows, this can be changed to `ntfs`.

 - name: NTFS_CACHE_TIME
 type: int
 description: How often to flush the NTFS cache. (Default is never).
 default: "1000000"

 - name: UPLOAD_IS_RESUMABLE
 type: bool
 default: Y
 description: If set the uploads can be resumed if the flow times out or errors.

 - name: MaxFileSize
 type: int
 default: 18446744073709551615
 description: |
 The max size in bytes of the individual files to collect.
 Set to 0 to disable it.


sources:
 - name: All Matches Metadata
 query: |
 LET RootPath &amp;lt;= pathspec(Path=Root, accessor=Accessor)

 -- Generate the collection globs for each device
 LET specs = SELECT RootPath + Glob AS Glob
 FROM collectionSpec
 WHERE log(message=format(format="Processing Device %v with %v: glob is %v",
 args=[Root, Accessor, Glob]))

 -- Join all the collection rules into a single Glob plugin. This ensure we
 -- only make one pass over the filesystem. We only want LFNs.
 LET hits = SELECT OSPath AS SourceFile,
 Size,
 Btime AS Created,
 Ctime AS Changed,
 Mtime AS Modified,
 Atime AS LastAccessed
 FROM glob(globs=specs.Glob, accessor=Accessor)
 WHERE NOT IsDir
 AND log(message="Found " + SourceFile)
 AND ( Size &amp;lt;= MaxFileSize OR
 ( log(message="Skipping file " + SourceFile + " Due to MaxFileSize")
 AND FALSE ))

 -- Pass all the results to the next query. This will serialize
 -- to disk if there are too many results.
 LET all_results &amp;lt;= SELECT Created,
 Changed,
 LastAccessed,
 Modified,
 Size,
 SourceFile
 FROM hits

 SELECT *
 FROM all_results


 - name: Uploads
 query: |
 -- Upload the files. Split into workers so the files are uploaded in parallel.
 LET uploaded_files = SELECT *
 FROM foreach(row={
 SELECT *
 FROM all_results
 },
 workers=30,
 query={
 SELECT Created,
 Changed,
 LastAccessed,
 Modified,
 SourceFile,
 Size,
 upload(file=SourceFile, accessor=Accessor, mtime=Modified) AS Upload
 FROM scope()
 })

 -- Separate the hashes into their own column.
 SELECT now() AS CopiedOnTimestamp,
 SourceFile,
 Upload.Path AS DestinationFile,
 Size AS FileSize,
 Upload.sha256 AS SourceFileSha256,
 Created,
 Changed,
 Modified,
 LastAccessed
 FROM uploaded_files

&lt;/code>&lt;/pre></description></item><item><title>Windows.Collectors.Remapping</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.collectors.remapping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.collectors.remapping/</guid><description>&lt;p>Calculate a remapping file for a collection zip.&lt;/p>
&lt;p>You can get the colection zip using the offline collector or by
exporting the Windows.Triage.Targets collection from the GUI.&lt;/p>
&lt;p>This artifact calculates a remapping config that allows Velociraptor
to directly analyze the ZIP file itself, without needing to extract
it first. This is useful for serverless analysis and to avoid having
to import the artifact first.&lt;/p>
&lt;p>In a way, this remapping allows Velociraptor to treat the collection
zip as a dead disk image in a similar way to
Generic.Utils.DeadDiskRemapping&lt;/p>
&lt;h2 id="use-instructions">Use instructions&lt;/h2>
&lt;ol>
&lt;li>Collect files using Triage collector - For example
Windows.Registry.AppCompatCache with the _BasicCollection target
is a good option.&lt;/li>
&lt;li>Generate a remapping file:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>velociraptor artifacts collect -v Windows.Collectors.Remapping
 --args ImagePath=/path/to/triage_collection.zip
 --args WriteRemappingPath=/tmp/test.remapping.yaml
&lt;/code>&lt;/pre>
&lt;ol start="3">
&lt;li>Apply the remapping file when collecting further artifacts:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>velociraptor --remap /tmp/test.remapping.yaml
 artifacts collect -v Windows.Registry.Hunter
 --args RemappingStrategy=None
&lt;/code>&lt;/pre>
&lt;p>Note that for Windows.Registry.Hunter we need to disable its own
remapping config so that the remapping we provide takes hold.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Collectors.Remapping
description: |
 Calculate a remapping file for a collection zip.

 You can get the colection zip using the offline collector or by
 exporting the Windows.Triage.Targets collection from the GUI.

 This artifact calculates a remapping config that allows Velociraptor
 to directly analyze the ZIP file itself, without needing to extract
 it first. This is useful for serverless analysis and to avoid having
 to import the artifact first.

 In a way, this remapping allows Velociraptor to treat the collection
 zip as a dead disk image in a similar way to
 Generic.Utils.DeadDiskRemapping

 ## Use instructions

 1. Collect files using Triage collector - For example
 Windows.Registry.AppCompatCache with the _BasicCollection target
 is a good option.
 2. Generate a remapping file:

 ```
 velociraptor artifacts collect -v Windows.Collectors.Remapping
 --args ImagePath=/path/to/triage_collection.zip
 --args WriteRemappingPath=/tmp/test.remapping.yaml
 ```

 3. Apply the remapping file when collecting further artifacts:

 ```
 velociraptor --remap /tmp/test.remapping.yaml
 artifacts collect -v Windows.Registry.Hunter
 --args RemappingStrategy=None
 ```

 Note that for Windows.Registry.Hunter we need to disable its own
 remapping config so that the remapping we provide takes hold.

type: SERVER

parameters:
 - name: ImagePath
 default: /tmp/image.dd
 description: Path to the image file to inspect.

 - name: Accessor
 description: |
 Accessor to read the image with.

 If not provided guess based on image file extension.

 - name: Hostname
 default: Virtual Host

 - name: Upload
 type: bool
 default: "Y"
 description: If specified we upload the generated YAML

 - name: WriteRemappingPath
 description: If specified we write the yaml file to this path

 - name: CommonRemapping
 description: Common clauses for all remapping in YAML
 default: |
 remappings:
 - type: permissions
 permissions:
 - COLLECT_CLIENT
 - FILESYSTEM_READ
 - FILESYSTEM_WRITE
 - READ_RESULTS
 - MACHINE_STATE
 - SERVER_ADMIN
 - COLLECT_SERVER
 - EXECVE
 - type: impersonation
 os: windows
 hostname: {{ .Hostname }}
 env:
 - key: SystemRoot
 value: C:\Windows
 - key: WinDir
 value: C:\Windows
 disabled_functions:
 - amsi
 - lookupSID
 - token
 disabled_plugins:
 - execve
 - http_client
 - users
 - certificates
 - handles
 - pslist
 - interfaces
 - modules
 - netstat
 - partitions
 - proc_dump
 - proc_yara
 - vad
 - winobj
 - wmi
 - type: shadow
 from:
 accessor: zip
 "on":
 accessor: zip
 - type: shadow
 from:
 accessor: raw_reg
 "on":
 accessor: raw_reg
 - type: shadow
 from:
 accessor: data
 "on":
 accessor: data

export: |
 LET Unescape(Path) = regex_transform(source=Path, map=dict(
 `%3A`=":"
 ), key="A")

 -- Searches for a partition with a Windows directory, Unless this
 -- is a partition image.
 LET _GetRootAccessor(ImagePath, Accessor) = SELECT
 pathspec(
 DelegatePath=ImagePath,
 DelegateAccessor=Accessor,
 Path=Unescape(Path=OSPath.Path)) AS OSPath
 FROM glob(accessor="collector", globs="*:", root=pathspec(
 DelegatePath=ImagePath,
 DelegateAccessor=Accessor,
 Path="/uploads/auto/"))
 WHERE log(message="Container Root OSPath at %v", args=OSPath)

 LET _MapHiveToKey(Hive, Key, Name, ImagePath) = log(dedup=-1,
 message="&amp;lt;green&amp;gt;Adding hive %v&amp;lt;/&amp;gt;", args=Hive) &amp;amp;&amp;amp;
 dict(type="mount",
 `description`=Name,
 `from`=dict(accessor="raw_reg",
 path_type="registry",
 prefix=pathspec(
 Path="/",
 DelegateAccessor="collector",
 Delegate=ImagePath + Hive)),
 on=dict(accessor="registry", prefix=Key, path_type="registry"))

 LET _MapDirHiveToKey(Hive, Key, Name) = log(dedup=-1,
 message="&amp;lt;green&amp;gt;Adding hive %v&amp;lt;/&amp;gt;", args=Hive) &amp;amp;&amp;amp;
 dict(type="mount",
 `description`=Name,
 `from`=dict(accessor="raw_reg",
 path_type="registry",
 prefix=pathspec(
 Path="/",
 DelegateAccessor="file",
 DelegatePath=Hive)),
 on=dict(accessor="registry", prefix=Key, path_type="registry"))

 -- Look for user hives and map them in HKEY_USERS
 LET _FindUserHives(ImagePath) = SELECT _MapHiveToKey(
 Name="Map User hive for " + OSPath[-2],
 Hive=OSPath,
 Key="HKEY_USERS\\" + OSPath[-2],
 ImagePath=ImagePath
 ) AS Map
 FROM glob(globs='/Users/*/NTUser.DAT',
 accessor="collector",
 root=ImagePath)
 WHERE log(dedup=-1, message="&amp;lt;green&amp;gt;Found User Hive at %v&amp;lt;/&amp;gt;", args=OSPath.Path)

 LET _FindDirUserHives(ImagePath) = SELECT _MapDirHiveToKey(
 Name="Map User hive for " + OSPath[-2],
 Hive=OSPath,
 Key="HKEY_USERS\\" + OSPath[-2]) AS Map
 FROM glob(globs='/Users/*/NTUser.DAT',
 root=ImagePath)
 WHERE log(dedup=-1, message="&amp;lt;green&amp;gt;Found User Hive at %v&amp;lt;/&amp;gt;", args=OSPath.Path)

 LET CalculateWindowsMappings(ImagePath) = Remappings.remappings + (
 dict(type="mount",
 `from`=dict(accessor="collector", prefix=ImagePath),
 on=dict(accessor="ntfs", prefix="\\\\.\\C:", path_type="ntfs")
 ),
 dict(type="mount",
 `from`=dict(accessor="collector", prefix=ImagePath),
 on=dict(accessor="file", prefix="C:", path_type="windows")
 ),
 dict(type="mount",
 `from`=dict(accessor="collector", prefix=ImagePath),
 on=dict(accessor="auto", prefix="C:", path_type="windows")
 ),
 _MapHiveToKey(Name="Map Software Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/SOFTWARE",
 Key="HKEY_LOCAL_MACHINE/Software"),
 _MapHiveToKey(Name="Map Security Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/Security",
 Key="HKEY_LOCAL_MACHINE/Security"),
 _MapHiveToKey(Name="Map System Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/System",
 Key="HKEY_LOCAL_MACHINE/System"),
 _MapHiveToKey(Name="Map SAM Hive",
 ImagePath=ImagePath,
 Hive="/Windows/System32/Config/SAM",
 Key="SAM"),
 _MapHiveToKey(Name="Map Amcache Hive",
 ImagePath=ImagePath,
 Hive="/Windows/appcompat/Programs/Amcache.hve",
 Key="Amcache")
 ) + _FindUserHives(ImagePath=ImagePath).Map

sources:
- query: |
 LET Remappings = parse_yaml(
 filename=template(template=CommonRemapping,
 expansion=dict(Hostname=Hostname)),
 accessor="data")

 -- Select the type of mapping to calculate depending on what ImagePath is.
 LET CalculateMappings &amp;lt;= SELECT * FROM foreach(row={
 SELECT OSPath
 FROM _GetRootAccessor(ImagePath=ImagePath, Accessor="auto")
 },
 query={
 SELECT * FROM CalculateWindowsMappings(ImagePath=OSPath)
 })

 LET YamlText &amp;lt;= serialize(format="yaml",
 item=dict(remappings=CalculateMappings))

 LET _ &amp;lt;= WriteRemappingPath &amp;amp;&amp;amp;
 copy(dest=WriteRemappingPath, accessor='data', filename=YamlText)

 SELECT Upload &amp;amp;&amp;amp; upload(accessor="data", file=YamlText, name="remapping.yaml") AS Upload,
 WriteRemappingPath &amp;amp;&amp;amp;
 copy(dest=WriteRemappingPath,
 accessor='data',
 filename=YamlText) AS RemappingFile
 FROM scope()

- name: TestRegistry
 query:
 LET _ &amp;lt;= remap(config=YamlText)
 SELECT OSPath
 FROM glob(globs="HKEY_LOCAL_MACHINE/Software/*", accessor='registry')

- name: TestFile
 query:
 SELECT OSPath
 FROM glob(globs="*/*")

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Amcache</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.amcache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.amcache/</guid><description>&lt;p>This artifact collects AMCache entries with a SHA1 hash to enable threat
detection.&lt;/p>
&lt;p>AmCache is an artifact which stores metadata related to PE execution and
program installation on Windows 7 and Server 2008 R2 and above. This artifact
includes EntryName, EntryPath and SHA1 as great data points for IOC collection.
Secondary datapoints include publisher/company, BinaryType and OriginalFileName.&lt;/p>
&lt;p>Available filters include:&lt;/p>
&lt;ul>
&lt;li>SHA1regex - regex entries to filter by SHA1.&lt;/li>
&lt;li>PathRegex - filter on path if available.&lt;/li>
&lt;li>NameRegex - filter on EntryName OR OriginalFileName.&lt;/li>
&lt;/ul>
&lt;p>NOTE:&lt;/p>
&lt;ul>
&lt;li>Secondary fields are not consistent across AMCache types and some legacy
versions do not return these fields.&lt;/li>
&lt;li>Some enrichment has occurred but any secondary fields should be treated as
guidance only.&lt;/li>
&lt;li>This artifact collects only entries with a SHA1, for complete AMCache
analysis please download raw artifact sets.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Amcache
author: Matt Green - @mgreen27
description: |
 This artifact collects AMCache entries with a SHA1 hash to enable threat
 detection.

 AmCache is an artifact which stores metadata related to PE execution and
 program installation on Windows 7 and Server 2008 R2 and above. This artifact
 includes EntryName, EntryPath and SHA1 as great data points for IOC collection.
 Secondary datapoints include publisher/company, BinaryType and OriginalFileName.

 Available filters include:

 - SHA1regex - regex entries to filter by SHA1.
 - PathRegex - filter on path if available.
 - NameRegex - filter on EntryName OR OriginalFileName.

 NOTE:

 - Secondary fields are not consistent across AMCache types and some legacy
 versions do not return these fields.
 - Some enrichment has occurred but any secondary fields should be treated as
 guidance only.
 - This artifact collects only entries with a SHA1, for complete AMCache
 analysis please download raw artifact sets.

reference:
 - https://www.ssi.gouv.fr/uploads/2019/01/anssi-coriin_2019-analysis_amcache.pdf

parameters:
 - name: AMCacheGlob
 default: "%SYSTEMROOT%/appcompat/Programs/Amcache.hve"
 description: AMCache hive path
 - name: KeyPathGlob
 default: /Root/{Inventory, File}*/**
 type: hidden
 description: Registry key path glob
 - name: SHA1Regex
 default: .
 description: Regex of SHA1s to filter
 type: regex
 - name: PathRegex
 description: Regex of recorded path.
 type: regex
 - name: NameRegex
 description: Regex of entry / binary name
 type: regex

sources:
 - query: |
 LET files &amp;lt;= SELECT OSPath
 FROM glob(globs=expand(path=AMCacheGlob))

 SELECT * FROM foreach(row=files,
 query={
 SELECT
 Key.OSPath.DelegatePath As HivePath,
 Key.OSPath.Path as EntryKey,
 Key.ModTime as KeyMTime,

 -- Key is like \Root\InventoryDriverBinary\"c:/windows/system32/drivers/1394ohci.sys"
 Key.OSPath.Components[1] as EntryType,

 if(condition=get(member="FileId"),
 then=strip(string=FileId, prefix='0000'),
 else=if(condition=get(member="101"),
 then=strip(string=`101`, prefix='0000'),
 else=if(condition=get(member="DriverId"),
 then=strip(string=DriverId, prefix='0000')))) as SHA1,

 if(condition=get(member="Name"),
 then=Name,
 else=if(condition=get(member="FriendlyName"),
 then=FriendlyName,
 else=if(condition=get(member="15"),
 then=split(string=str(str=`15`), sep='\\\\')[-1],
 else=if(condition=get(member="DriverName"),
 then=DriverName)))) as EntryName,

 if(condition=get(member="LowerCaseLongPath"),
 then=LowerCaseLongPath,
 else=if(condition=get(member="15"),
 then=`15`,
 else=if(condition=get(member="AddinCLSID"),
 then=AddinCLSID))) as EntryPath,

 if(condition=get(member="Publisher"),
 then=Publisher,
 else=if(condition=get(member="Provider"),
 then=Provider,
 else=if(condition=get(member="DriverCompany"),
 then=DriverCompany))) as Publisher,

 get(member="OriginalFileName") AS OriginalFileName,

 if(condition=get(member="BinaryType"),
 then=BinaryType,
 else=if(condition=get(member="AddInType"),
 then=AddinType + ' ' + OfficeArchitecture,
 else=if(condition=Key.OSPath.Path =~ 'InventoryDevicePnp',
 then='DevicePnp',
 else=if(condition=Key.OSPath.Path =~ 'InventoryDriverBinary',
 then='DriverBinary')))) as BinaryType

 FROM read_reg_key(
 globs=KeyPathGlob,
 root=pathspec(DelegatePath=OSPath),
 accessor='raw_reg')
 WHERE SHA1
 AND SHA1 =~ SHA1Regex
 AND if(condition= NameRegex,
 then= EntryName =~ NameRegex OR OriginalFileName =~ NameRegex,
 else= True)
 AND if(condition= PathRegex,
 then= EntryPath =~ PathRegex,
 else= True)
 })
&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.BinaryHunter</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.binaryhunter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.binaryhunter/</guid><description>&lt;p>This artifact enables hunting for binary attributes.&lt;/p>
&lt;p>The artifact takes a glob targeting input, then checks each file in scope for an MZ header.
The artifact also queries Authenticode details and parses out PE attributes.&lt;/p>
&lt;p>Both PE and Authenticode output can be queried for relevant strings by using a regex filter and whitelist to hunt with.
This enables unique capability to hunt for specific things such as PE imports, exports or other attributes.&lt;/p>
&lt;p>Note: this artifacts filters are cumulative so a hash based hit will return
no results if the file is filtered out by other filters.
For most performant searches use path, size and and date filters. By default
the artifact uses the &amp;lsquo;auto&amp;rsquo; data accessor but can also be changed as desired.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.BinaryHunter
author: "Matt Green - @mgreen27"
description: |
 This artifact enables hunting for binary attributes.

 The artifact takes a glob targeting input, then checks each file in scope for an MZ header.
 The artifact also queries Authenticode details and parses out PE attributes.

 Both PE and Authenticode output can be queried for relevant strings by using a regex filter and whitelist to hunt with.
 This enables unique capability to hunt for specific things such as PE imports, exports or other attributes.

 Note: this artifacts filters are cumulative so a hash based hit will return
 no results if the file is filtered out by other filters.
 For most performant searches use path, size and and date filters. By default
 the artifact uses the 'auto' data accessor but can also be changed as desired.

parameters:
 - name: TargetGlob
 description: Glob to target.
 default: "C:/Users/**/*"
 - name: Accessor
 description: Velociraptor accessor to use. Changing to ntfs will increase scan time.
 default: auto
 - name: UnexpectedExtension
 description: "Exclude binaries with expected extension: com|cpl|dll|drv|exe|mui|scr|sfx|sys|winmd"
 type: bool
 - name: ExcludeTrusted
 description: Exclude binaries with Trusted Authenticode certificates.
 type: bool
 - name: AuthenticodeRegex
 description: Regex to search through all authenrticode data.
 default: .
 type: regex
 - name: AuthenticodeWhitelistRegex
 description: Regex to whitelist in all Authenticode data.
 default:
 type: regex
 - name: PEInformationRegex
 description: Regex to filter for PE information. e.g VersionInformation, exports etc
 default: .
 type: regex
 - name: PEInformationWhitelistRegex
 description: Regex to whitelist for PE information. e.g VersionInformation, exports etc
 default:
 type: regex
 - name: DateAfter
 description: Search for binaries with timestamps after this date. YYYY-MM-DDTmm:hh:ssZ
 type: timestamp
 - name: DateBefore
 description: Search for binaries with timestamps before this date. YYYY-MM-DDTmm:hh:ssZ
 type: timestamp
 - name: SizeMax
 description: Return binaries only under this size in bytes.
 type: int64
 default: 4294967296
 - name: SizeMin
 description: Return binaries only over this size in bytes.
 type: int64
 default: 0
 - name: MD5List
 description: MD5 hash list to hunt for. New MD5 hash on each line
 default:
 - name: SHA1List
 description: SHA1 hash list to hunt for. New SHA1 hash on each line
 default:
 - name: SHA256List
 description: SHA256 hash list to hunt for. New SHA256 hash on each line
 default:
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.
 - name: UploadFiles
 type: bool
 description: |
 Select to upload files.

sources:
 - query: |
 -- setup hash lists if needed
 LET MD5Array &amp;lt;= split(sep='\\s+',string=MD5List)
 LET SHA1Array &amp;lt;= split(sep='\\s+',string=SHA1List)
 LET SHA256Array &amp;lt;= split(sep='\\s+',string=SHA256List)

 -- firstly find files in scope with performance
 LET find_files = SELECT *,
 read_file(filename=OSPath,accessor=Accessor,offset=0,length=2) as _Header
 FROM if(condition=DateBefore AND DateAfter,
 then={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=TargetGlob,accessor=Accessor)
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 AND ( Mtime &amp;lt; DateBefore OR Ctime &amp;lt; DateBefore OR Btime &amp;lt; DateBefore )
 AND ( Mtime &amp;gt; DateAfter OR Ctime &amp;gt; DateAfter OR Btime &amp;gt; DateAfter )
 },
 else={ SELECT * FROM if(condition=DateBefore,
 then={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=OSPath,accessor=Accessor)
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 AND ( Mtime &amp;lt; DateBefore OR Ctime &amp;lt; DateBefore OR Btime &amp;lt; DateBefore )
 },
 else={ SELECT * FROM if(condition=DateAfter,
 then={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=TargetGlob,accessor=Accessor)
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 AND ( Mtime &amp;gt; DateAfter OR Ctime &amp;gt; DateAfter OR Btime &amp;gt; DateAfter )
 },
 else={
 SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
 FROM glob(globs=TargetGlob,accessor=Accessor)
 WHERE NOT IsDir AND NOT IsLink
 AND Size &amp;gt; SizeMin AND Size &amp;lt; SizeMax
 })})})
 WHERE _Header = 'MZ'
 AND if(condition= UnexpectedExtension,
 then= NOT Name =~ '\.(com|cpl|dll|drv|exe|mui|scr|sfx|sys|winmd)$',
 else= True)


 -- parse PE attributes and run final filters
 LET results = SELECT
 dict(OSPath=OSPath,Name=Name,Size=Size,
 Timestamps=dict(Mtime=Mtime,Atime=Atime,Ctime=Ctime,Btime=Btime)
 ) as File,
 authenticode(filename=OSPath) as Authenticode,
 parse_pe(file=OSPath) as PE,
 hash(path=OSPath) as Hash
 FROM find_files
 WHERE
 serialize(item=Authenticode) =~ AuthenticodeRegex
 AND NOT if(condition=WhitelistRegex,
 then= serialize(item=Authenticode) =~ AuthenticodeWhitelistRegex,
 else= False)
 AND serialize(item=PE) =~ PEInformationRegex
 AND NOT if(condition=PEInformationWhitelistRegex,
 then= serialize(item=PE) =~ PEInformationWhitelistRegex,
 else= False)
 AND if(condition= ExcludeTrusted,
 then= NOT Authenticode.Trusted = "trusted",
 else= True)
 AND if(condition= MD5List OR SHA1List OR SHA256List,
 then=(
 if(condition= MD5List,
 then= Hash.MD5 in MD5Array)
 OR if(condition= SHA1List,
 then= Hash.SHA1 in SHA1Array)
 OR if(condition= SHA256List,
 then= Hash.SHA256 in SHA256Array)
 ), else = True )
 
 LET upload_files= SELECT *,
 upload(file=File.OSPath) as UploadFile
 FROM results
 
 SELECT * FROM if(condition= UploadFiles,
 then= upload_files,
 else= results)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.BinaryRename</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.binaryrename/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.binaryrename/</guid><description>&lt;p>This artifact will detect renamed binaries commonly abused by adversaries.&lt;/p>
&lt;p>Binary rename is a defense evasion technique used to bypass brittle process
name and path based detections. Observed in use across
all stages of the attack lifecycle it is a technique used by a large
selection of actors from commodity malware crews through to Nation States.&lt;/p>
&lt;p>Add additional entries to the VersionInfoTable parameter. For straight
detection on an Internal or Original name, the Filename entry can be set to
an unlikely value - e.g ANY or left blank.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.BinaryRename
author: "Matt Green - @mgreen27"
description: |
 This artifact will detect renamed binaries commonly abused by adversaries.

 Binary rename is a defense evasion technique used to bypass brittle process
 name and path based detections. Observed in use across
 all stages of the attack lifecycle it is a technique used by a large
 selection of actors from commodity malware crews through to Nation States.

 Add additional entries to the VersionInfoTable parameter. For straight
 detection on an Internal or Original name, the Filename entry can be set to
 an unlikely value - e.g ANY or left blank.


reference:
 - https://mgreen27.github.io/posts/2019/05/12/BinaryRename.html
 - https://attack.mitre.org/techniques/T1036/003/

type: CLIENT

parameters:
 - name: TargetGlob
 default: /**/*.exe
 - name: VersionInfoTable
 type: csv
 default: |
 Filename,Internal,Original,Description,Note
 cmd.exe,cmd,Cmd.Exe,Windows Command Processor,cmd.exe
 7z.exe,7z,7z.exe,7-Zip Console,7z.exe
 certutil.exe,CertUtil.exe,CertUtil.exe,CertUtil,certutil.exe
 cmstp.exe,CMSTP,CMSTP.EXE,Microsoft Connection Manager Profile Installer,cmstp.exe
 cscript.exe,cscript.exe,cscript.exe,Microsoft ® Console Based Script Host,cscript.exe
 mshta.exe,MSHTA.EXE,MSHTA.EXE,Microsoft ® HTML Application host,mshta.exe
 msiexec.exe,msiexec,msiexec.exe,Windows® installer,msiexec.exe
 powershell.exe,POWERSHELL,PowerShell.EXE,Windows PowerShell,powershell.exe
 psexec.exe,PsExec,psexec.c,Sysinternals PSExec,psexec.exe
 psexec64.exe,PsExec,psexec.exe,Sysinternals PSExec,psexec64.exe
 regsvr32.exe,REGSVR32,REGSVR32.EXE,Microsoft© Register Server,regsvr32.exe
 rundll32.exe,rundll,RUNDLL32.EXE,Windows host process (Rundll32),rundll32.exe
 winrar.exe,WinRAR,WinRAR.exe,WinRAR archiver,winrar.exe
 wmic.exe,wmic.exe,wmic.exe,WMI Commandline Utility,wmic.exe
 wscript.exe,wscript.exe,wscript.exe,Microsoft ® Windows Based Script Host,wscript.exe
 wevtutil.exe,wevtutil.exe,wevtutil.exe,,wevtutil.exe
 net.exe,net.exe,net.exe,,net.exe
 net1.exe,net1.exe,net1.exe,,net1.exe
 netsh.exe,netsh.exe,netsh.exe,,netsh.exe
 powershell_ise.exe,powershell_ise.exe,powershell_ise.exe,,powershell_ise.exe
 dsquery.exe,dsquery.exe,dsquery.exe,Microsoft AD DS/LDS query command line utility,dsquery.exe
 nbtstat.exe,nbtinfo.exe,nbtinfo.exe,Microsoft TCP/IP NetBios Information,nbtstat.exe
 nltest.exe,nltestrk.exe,nltestrk.exe,Microsoft® Logon Server Test Utility,nltest.exe
 qprocess.exe,qprocess,qprocess.exe,Query Process Utility,qprocess.exe
 qwinsta.exe,qwinsta,qwinsta.exe,Query Session Utility,qwinsta.exe
 ANY,nc,nc.exe,NetCat for Windows - https://github.com/diegocr/netcat,nc.exe
 ANY,AdFind.exe,AdFind.exe,Joeware ADFind,AdFind.exe
 ANY,rclone,rclone.exe,Rsync for cloud storage,rclone.exe
 ANY,MEGAsync.exe,MEGAsync.exe,MEGAsync,MEGAsync.exe
 ANY,MEGAcmdShell.exe,MEGAcmdShell,MEGAcmdShell,MEGAcmdShell
 ANY,pCloud.exe,pCloud.exe,pCloud cloud storage,pCloud.exe
 ANY,,pCloud Drive.exe,pCloud setup,pCloud Drive.exe
 ANY,mimikatz,mimikatz.exe,mimikatz for Windows,mimikatz.exe
 ANY,ProcDump,procdump,Sysinternals process dump utility,procdump.exe
 ANY,ProcDump,procdump,Sysinternals process dump utility,procdump64.exe
 ANY,Ammyy Admin,,Ammyy Admin,AA_v3.exe
 ANY,,,AnyDesk,AnyDesk.exe
 ANY,PDQDeploySetup.exe,PDQDeploySetup.exe,PDQ Deploy Install,Deploy_19.3.298.0.exe
 ANY,PDQInventory.exe,PDQInventory.exe,PDQ Inventory Installer,Inventory_19.3.298.0.exe
 ANY,,,UltraVNC Setup,UltraVNC_1_3_81_X64_Setup.exe
 ANY,,,File Shredder by PowTools,file_shredder_setup.exe
 ANY,,pCloud Drive.exe,pCloud Drive,pCloud_Windows_3.11.12_x64.exe
 plink.exe,Plink,Plink,"Command-line SSH, Telnet, and Rlogin client",plink.exe
 pscp.exe,PSCP,PSCP,Command-line SCP/SFTP client,pscp.exe
 psftp.exe,PSFTP,PSFTP,Command-line interactive SFTP client,psftp.exe
 ANY,,,Total Commander Installer,tcmd1000x32.exe
 ANY,BulletsPassView,BulletsPassView.exe,BulletsPassView,BulletsPassView.exe
 ANY,WinLister,WinLister.exe,WinLister,winlister.exe
 ANY,HRSword,HRSword.exe,Huorong Sword GUI Frontend,HRSword v5.0.47.bin
 ANY,,,Email Password-Recovery,mailpv.exe
 ANY,Process Hacker,ProcessHacker.exe,Process Hacker,ProcessHacker.exe
 ANY,peview,peview.exe,PE Viewer,peview.exe
 ANY,ChromePass,ChromePass,Chrome Password Recovery,ChromePass.exe
 ANY,,,Application for scanning networks,netscan.exe
 ANY,WKV,,Extracts wireless keys stored by Windows,WirelessKeyView.exe
 ANY,Remote Desktop PassView,rdpv.exe,Password Recovery for Remote Desktop,rdpv.exe
 ANY,RouterPassView,RouterPassView.exe,Decrypts Router files.,RouterPassView.exe
 ANY,RemCom,RemCom.exe,Remote Command Executor,RemCom.exe
 ANY,,,Remote Utilities,host7.1.2.0.exe
 ANY,,viewer.7.1.2.0.exe,Remote Utilities - Viewer,viewer7.1.2.0.exe
 ANY,Web Browser Pass View,,Web Browser Password Viewer,WebBrowserPassView.exe
 ANY,PowerTool.exe,PowerTool.exe,Anti-virus/rootkit/bootkit Tool,PowerTool64.exe
 ANY,,winscp.com,Console interface for WinSCP,WinSCP.com
 ANY,winscp,winscp.exe,"WinSCP: SFTP, FTP, WebDAV, S3 and SCP client",WinSCP.exe
 ANY,iepv,iepv.exe,IE Passwords Viewer,iepv.exe
 ANY,VNCPassView,VNCPassView.exe,VNCPassView,VNCPassView.exe
 ANY,PCHunter,PCHunter.exe,Epoolsoft Windows Information View Tools,PCHunter32.exe
 ANY,Massscan_GUI.exe,Massscan_GUI.exe,Masscan_GUI,Massscan_GUI.exe
 ANY,ProxyLite.Windows.Console.exe,ProxyLite.Windows.Console.exe,ProxyLite Console Client,ProxyLite
 ANY,action1_agent.exe,action1_agent.exe,Endpoint Agent,Action1 agent
 ANY,action1_remote.exe,action1_remote.exe,Endpoint Agent,Action1 agent
 ANY,Defender Control,Defender Control,Windows Defender Control,Windows Defender Control
 ANY,NirCmd,NirCmd.exe,Nir Sofer,nircmd.exe
 ANY,NSudo,NSudo.exe,NSudo for Windows,Nsudo
 ANY,Python Application,pythonw.exe,Python,Python 3.10.0 packaged with DWAgent - possibly noisy.


sources:
 - query: |
 LET bins &amp;lt;= SELECT
 if(condition=Filename='',then='ANY',
 else=lowcase(string=Filename)) AS Filename,
 if(condition=Internal='',then='ANY',
 else=lowcase(string=Internal)) AS Internal,
 if(condition=Original='',then='ANY',
 else=lowcase(string=Original)) AS Original
 FROM VersionInfoTable

 SELECT
 OSPath, Name, Size,
 parse_pe(file=OSPath).VersionInformation as VersionInformation,
 hash(path=OSPath) as Hash,
 Mtime, Atime, Ctime, Btime
 FROM glob(globs=TargetGlob)
 WHERE
 NOT IsDir AND NOT IsLink
 AND (
 (( lowcase(string=VersionInformation.OriginalFilename) in bins.Original
 OR lowcase(string=VersionInformation.InternalName) in bins.Internal )
 AND NOT lowcase(string=Name) in bins.Filename )
 OR OSPath =~ 'C:\\\\Windows\\\\System32\\\\(osk|Magnify|Narrator|DisplaySwitch).exe$'
 AND NOT VersionInformation.OriginalFilename =~ '^(osk|SR|Narrator|ScreenMagnifier|DisplaySwitch)\.exe$'
 )

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.EnvironmentVariables</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.environmentvariables/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.environmentvariables/</guid><description>&lt;p>Find processes with the specified environment variables.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.EnvironmentVariables
description: |
 Find processes with the specified environment variables.

parameters:
 - name: ProcessNameRegex
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: EnvironmentVariableRegex
 default: COMSPEC|COR_PROFILER
 type: regex
 - name: FilterValueRegex
 default: .
 type: regex
 - name: WhitelistValueRegex
 description: Ignore these values
 default: ^C:\\Windows\\.+cmd.exe$
 type: regex

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 SELECT * FROM foreach(
 row={
 SELECT * FROM Artifact.Windows.Memory.ProcessInfo(
 ProcessNameRegex=ProcessNameRegex, PidRegex=PidRegex)
 },
 query={
 SELECT Pid, Name, ImagePathName, CommandLine,
 _key AS Var, _value AS Value
 FROM items(item=Env)
 })
 WHERE Var =~ EnvironmentVariableRegex
 AND Value =~ FilterValueRegex
 AND NOT Value =~ WhitelistValueRegex

 notebook:
 - type: Markdown
 template: |-
 # Process Environment Variables

 Environment variables control the way subprocesses work. In
 this artifact we look for processes with unusual sets of
 environment variables.

 {{ $unusual := Query "SELECT * FROM source() WHERE \
 Var =~ 'COR_PROFILER|COMPlus_ETWEnabled'" | Expand }}

 {{ if $unusual }}
 ## Some unusual environment variables.

 There have been some unusual environment variables
 detected. These normally indicate malicious activity.

 {{ Table $unusual }}

 {{ end }}

 {{ $unusual = Query "SELECT * FROM source() WHERE \
 Var =~ 'COMSPEC' AND NOT Value =~ 'cmd.exe$'" | Expand }}
 {{ if $unusual }}

 ## Unusual COMSPEC setting.

 The `COMSPEC` environment variable is usually used to launch
 the command prompt (cmd.exe) but Velociraptor found some
 hits where this is not the case. It could indicate malicious
 activity.

 {{ Table $unusual }}

 {{ end }}

 - type: VQL
 template: |

 /* Markdown
 ## All collected results.

 */

 SELECT * FROM source()
 LIMIT 50

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.ForwardedImports</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.forwardedimports/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.forwardedimports/</guid><description>&lt;p>In Windows a common DLL hooking technique is to replace a dll with a
forwarder dll - i.e. one that forwards all imports to the real
dll. If the forwarder DLL is placed earlier in the import order, the
malicious DLL will be seamlessly loaded and injected into another
process.&lt;/p>
&lt;p>This artifact searches for DLLs which are named the same as the DLL
they are forwarding to.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.ForwardedImports
description: |
 In Windows a common DLL hooking technique is to replace a dll with a
 forwarder dll - i.e. one that forwards all imports to the real
 dll. If the forwarder DLL is placed earlier in the import order, the
 malicious DLL will be seamlessly loaded and injected into another
 process.

 This artifact searches for DLLs which are named the same as the DLL
 they are forwarding to.

reference:
 - https://github.com/monoxgas/Koppeling
 - https://silentbreaksecurity.com/adaptive-dll-hijacking/
 - https://www.mdsec.co.uk/2020/10/i-live-to-move-it-windows-lateral-movement-part-3-dll-hijacking/

parameters:
 - name: DLLGlob
 default: C:\windows\**\*.dll
 - name: ExcludeRegex
 default: WinSXS|Servicing
 type: regex
 - name: LogPeriod
 type: int
 description: How often to log progress in seconds (Default every 1 sec)
 default: 1

sources:
 - query: |
 LET DLLs = SELECT OSPath, Name,

 -- Remove the .dll extension if present to get the bare dll filename.
 lowcase(string=parse_string_with_regex(
 regex="^(?P&amp;lt;BareName&amp;gt;[^.]+)", string=Name).BareName) AS DLLBareName,
 count() AS Total
 FROM glob(globs=DLLGlob)
 WHERE NOT OSPath =~ ExcludeRegex

 LET ParsedDLLs = SELECT *,
 log(message="Examining %v after checking %v DLLs",
 args=[OSPath, Total], dedup= LogPeriod ) AS Log
 FROM foreach(
 row=DLLs, workers=20,
 query={
 SELECT OSPath, Name,
 parse_pe(file=OSPath).Forwards AS Forwards,
 DLLBareName, Total
 FROM scope()
 })

 -- Speed up analysis a bit by using more workers.
 SELECT * FROM foreach(row=ParsedDLLs,
 query={
 SELECT OSPath AS DllPath, ForwardedImport,

 -- The Bare DLL Name from the forwarded name
 Parse.DllPath AS DllImportPath,

 -- The export this is forwarding to.
 Parse.Export AS DLLExportFunc,
 DLLBareName,

 -- The bare dll name the export is referring to.
 basename(path=lowcase(string=Parse.DllPath)) AS ExportDLLName
 FROM foreach(row=Forwards,
 query={
 SELECT parse_string_with_regex(
 regex="(?P&amp;lt;DllPath&amp;gt;.+)\\.(?P&amp;lt;Export&amp;gt;[^.]+$)",
 string=_value) AS Parse,
 _value AS ForwardedImport
 FROM scope()
 })

 -- Only flag imports for forwarder dll name the same as its own dll.
 WHERE ExportDLLName = DLLBareName
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Impersonation</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.impersonation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.impersonation/</guid><description>&lt;p>An access token is an object that describes the security context of
a process or thread. The information in a token includes the
identity and privileges of the user account associated with the
process or thread. When a user logs on, the system verifies the
user&amp;rsquo;s password by comparing it with information stored in a
security database.&lt;/p>
&lt;p>Every process has a primary token that describes the security
context of the user account associated with the process. By default,
the system uses the primary token when a thread of the process
interacts with a securable object. Moreover, a thread can
impersonate a client account. Impersonation allows the thread to
interact with securable objects using the client&amp;rsquo;s security
context. A thread that is impersonating a client has both a primary
token and an impersonation token.&lt;/p>
&lt;p>This artifact enumerates all threads on the system which have an
impersonation token. That is, they are operating with a different token
then the token the entire process has. For example Mimikatz has a
command called &lt;code>token::elevate&lt;/code> to do just such a thing:&lt;/p>
&lt;pre>&lt;code>mimikatz # privilege::debug
Privilege '20' OK

mimikatz # token::elevate
Token Id : 0
User name :
SID name : NT AUTHORITY\SYSTEM

688 {0;000003e7} 1 D 42171 NT AUTHORITY\SYSTEM S-1-5-18 (04g,21p) Primary
-&amp;gt; Impersonated !
* Process Token : {0;000195ad} 1 F 757658339 DESKTOP-NHNHT65\mic S-1-5-21-2310288903-2791442386-3035081252-1001 (15g,24p) Primary
* Thread Token : {0;000003e7} 1 D 759094260 NT AUTHORITY\SYSTEM S-1-5-18 (04g,21p) Impersonation (Delegation)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Impersonation
description: |
 An access token is an object that describes the security context of
 a process or thread. The information in a token includes the
 identity and privileges of the user account associated with the
 process or thread. When a user logs on, the system verifies the
 user's password by comparing it with information stored in a
 security database.

 Every process has a primary token that describes the security
 context of the user account associated with the process. By default,
 the system uses the primary token when a thread of the process
 interacts with a securable object. Moreover, a thread can
 impersonate a client account. Impersonation allows the thread to
 interact with securable objects using the client's security
 context. A thread that is impersonating a client has both a primary
 token and an impersonation token.

 This artifact enumerates all threads on the system which have an
 impersonation token. That is, they are operating with a different token
 then the token the entire process has. For example Mimikatz has a
 command called `token::elevate` to do just such a thing:

 ```
 mimikatz # privilege::debug
 Privilege '20' OK

 mimikatz # token::elevate
 Token Id : 0
 User name :
 SID name : NT AUTHORITY\SYSTEM

 688 {0;000003e7} 1 D 42171 NT AUTHORITY\SYSTEM S-1-5-18 (04g,21p) Primary
 -&amp;gt; Impersonated !
 * Process Token : {0;000195ad} 1 F 757658339 DESKTOP-NHNHT65\mic S-1-5-21-2310288903-2791442386-3035081252-1001 (15g,24p) Primary
 * Thread Token : {0;000003e7} 1 D 759094260 NT AUTHORITY\SYSTEM S-1-5-18 (04g,21p) Impersonation (Delegation)
 ```
reference:
 - https://github.com/kslgroup/TokenImp-Token_Impersonation_Detection/blob/master/TokenImp%20documentation.pdf


precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET processes = SELECT Pid AS ProcPid, Name AS ProcName,
 Username, OwnerSid, TokenIsElevated,
 CommandLine, Exe
 FROM pslist()
 WHERE log(message=format(format="Inspecting %s (%v)", args=[ProcName, Pid]))

 SELECT * FROM foreach(row=processes,
 query={
 // List all the threads and check that their tokens are the
 // same as the process token.
 SELECT ProcPid, ProcName, Username, OwnerSid, TokenIsElevated,
 CommandLine, Exe, ThreadInfo.TokenInfo AS ImpersonationToken
 FROM handles(pid=ProcPid, types='Thread')
 WHERE ImpersonationToken.User AND ImpersonationToken.User != OwnerSid
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Mutants</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.mutants/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.mutants/</guid><description>&lt;p>Enumerate the mutants from selected processes.&lt;/p>
&lt;p>Mutants are often used by malware to prevent re-infection.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Mutants
description: |
 Enumerate the mutants from selected processes.

 Mutants are often used by malware to prevent re-infection.

parameters:
 - name: processRegex
 description: A regex applied to process names.
 default: .
 type: regex
 - name: MutantNameRegex
 default: .+
 type: regex
 - name: MutantWhitelistRegex
 default:
 type: regex

sources:
 - name: Handles
 description: Open handles to mutants. This shows processes owning a handle open to the mutant.
 query: |
 LET processes = SELECT Pid AS ProcPid, Name AS ProcName, Exe
 FROM pslist()
 WHERE ProcName =~ processRegex AND ProcPid &amp;gt; 0

 SELECT * FROM foreach(
 row=processes,
 query={
 SELECT ProcPid, ProcName, Exe, Type, Name, Handle
 FROM handles(pid=ProcPid, types="Mutant")
 })
 WHERE Name =~ MutantNameRegex
 AND if(condition= MutantWhitelistRegex,
 then= NOT Name =~ MutantWhitelistRegex,
 else= True )

 - name: ObjectTree
 description: Reveals all Mutant objects in the Windows Object Manager namespace.
 query: |
 SELECT Name, Type FROM winobj()
 WHERE Type = 'Mutant' AND Name =~ MutantNameRegex
 AND if(condition= MutantWhitelistRegex,
 then= NOT Name =~ MutantWhitelistRegex,
 else= True )

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.ProcessCreation</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.processcreation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.processcreation/</guid><description>&lt;p>This artifact logs specific process creation events to
Velociraptor. It auto-installs Sysmon and it watches the Sysmon ETW
provider for new events.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.ProcessCreation
description: |
 This artifact logs specific process creation events to
 Velociraptor. It auto-installs Sysmon and it watches the Sysmon ETW
 provider for new events.

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

tools:
 - name: SysmonBinary
 url: https://live.sysinternals.com/tools/sysmon64.exe
 serve_locally: true

 - name: SysmonConfig
 url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
 serve_locally: true

parameters:
 - name: ImageRegex
 default: .
 - name: CommandLineRegex
 default: .
 - name: ParentImageRegex
 default: .
 - name: OriginalFileNameRegex
 default: .
 - name: ParentUserRegex
 default: .
 - name: UserRegex
 default: .
 - name: HashesRegex
 default: .
 - name: ParentCommandLineRegex
 default: .
 - name: IntegrityLevelRegex
 default: .
 - name: ProductRegex
 default: .
 - name: CompanyRegex
 default: .
 - name: DescriptionRegex
 default: .
 - name: FileVersionRegex
 default: .
 - name: SysmonFileLocation
 description: If set, we check this location first for sysmon installed.
 default: C:/Windows/sysmon64.exe

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 // Ensure that sysmon is installed.
 LET _ &amp;lt;= SELECT * FROM Artifact.Windows.Sysinternals.SysmonInstall(
 SysmonFileLocation=SysmonFileLocation)

 SELECT *, { SELECT Hostname FROM info() } as Hostname FROM Artifact.Windows.Sysinternals.SysmonLogForward()
 WHERE ID = 1 AND
 EventData.Image =~ ImageRegex AND
 EventData.CommandLine =~ CommandLineRegex AND
 EventData.ParentImage =~ ParentImageRegex AND
 EventData.OriginalFileName =~ OriginalFileNameRegex AND
 EventData.ParentUser =~ ParentUserRegex AND
 EventData.User =~ UserRegex AND
 EventData.Hashes =~ HashesRegex AND
 EventData.ParentCommandLine =~ ParentCommandLineRegex AND
 EventData.IntegrityLevel =~ IntegrityLevelRegex AND
 EventData.Product =~ ProductRegex AND
 EventData.Company =~ CompanyRegex AND
 EventData.Description =~ DescriptionRegex AND
 EventData.FileVersion =~ FileVersionRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.PsexecService</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.psexecservice/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.psexecservice/</guid><description>&lt;p>PsExec works by installing a new service in the system. The service
can be renamed by using the &lt;code>-r&lt;/code> flag and therefore it is not enough to
just watch for a new service called &lt;code>psexecsvc.exe&lt;/code>. This artifact
improves on this by scanning the service binary to detect the
original PsExec binary.&lt;/p>
&lt;p>NOTE: If the service is very quick we are unable to examine the service binary
in time then we will miss it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.PsexecService
description: |
 PsExec works by installing a new service in the system. The service
 can be renamed by using the `-r` flag and therefore it is not enough to
 just watch for a new service called `psexecsvc.exe`. This artifact
 improves on this by scanning the service binary to detect the
 original PsExec binary.

 NOTE: If the service is very quick we are unable to examine the service binary
 in time then we will miss it.

type: CLIENT_EVENT

parameters:
 - name: yaraRule
 type: yara
 default: |
 rule Hit {
 strings:
 $a = "psexec" nocase wide ascii
 condition:
 any of them
 }

sources:
 - query: |
 LET file_scan = SELECT Name AS ServiceName,
 PathName, File.ModTime AS Modified,
 File.Size AS FileSize,
 String.Offset AS StringOffset,
 String.HexData AS StringContext,
 now() AS Timestamp,
 ServiceType, PID,
 {
 SELECT Name, Exe, CommandLine
 FROM pslist() WHERE Ppid = PID
 LIMIT 2
 } AS ChildProcess
 FROM yara(rules=yaraRule, files=PathName)
 WHERE Rule

 LET service_creation = SELECT Parse,
 Parse.TargetInstance.Name AS Name,
 Parse.TargetInstance.PathName As PathName,
 Parse.TargetInstance.ServiceType As ServiceType,
 Parse.TargetInstance.ProcessId AS PID
 FROM wmi_events(
 query="SELECT * FROM __InstanceCreationEvent WITHIN 1 WHERE TargetInstance ISA 'Win32_Service'",
 wait=5000000,
 namespace="ROOT/CIMV2")

 SELECT * FROM foreach(
 row=service_creation,
 query=file_scan)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.PsexecService.Kill</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.psexecservice.kill/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.psexecservice.kill/</guid><description>&lt;p>Psexec can launch a service remotely. This artifact implements a
client side response plan whereby all the child processes of the
service are killed.&lt;/p>
&lt;p>NOTE: There is an inherent race between detection and response. If
the PsExec is very quick we will miss it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.PsexecService.Kill
description: |
 Psexec can launch a service remotely. This artifact implements a
 client side response plan whereby all the child processes of the
 service are killed.

 NOTE: There is an inherent race between detection and response. If
 the PsExec is very quick we will miss it.

type: CLIENT_EVENT

parameters:
 - name: yaraRule
 type: yara
 default: |
 rule Hit {
 strings:
 $a = "psexec" nocase wide ascii
 condition:
 any of them
 }

sources:
 - query: |
 SELECT * FROM foreach(
 row={ SELECT * FROM Artifact.Windows.Detection.PsexecService() },
 query={
 SELECT ServiceName, PathName, Modified, FileSize, Timestamp,
 ServiceType, ChildProcess, Stdout, Stderr FROM execve(
 argv=["taskkill", "/PID", PID, "/T", "/F"])
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Registry</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.registry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.registry/</guid><description>&lt;p>This artifact detects registry changes and triggers an alert.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Registry
description: |
 This artifact detects registry changes and triggers an alert.

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

precondition:
 SELECT * FROM info() WHERE OS =~ "windows"

parameters:
 - name: Period
 type: int
 default: 120
 - name: RegistryPath
 default: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\\*
 - name: RegistryData
 type: regex
 default: .
 - name: AlertName
 default: "T1112 - Suspicious registry key modification"
 - name: diff
 default: added
 - name: CertificateInfo
 default: N
 type: bool
 - name: regex_IssuerName
 default: .
 - name: UntrustedAuthenticode
 description: Show only Executables that are not trusted by Authenticode.
 type: bool
 default: N
 - name: Calculate_hashes
 default: N
 type: bool
 - name: regex_sha256
 default: .
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
 - query: |

 LET query_registry = SELECT *, OSPath.String + Data.value AS FullPath,
 expand(path=Data.value) AS Datavalue
 FROM glob(globs=RegistryPath, accessor="registry") WHERE Data.value =~ RegistryData

 LET query_diff = SELECT *, commandline_split(command=Datavalue) as AbsolutePath
 FROM diff(query=query_registry, period=Period, key="FullPath")
 WHERE Diff = diff

 SELECT *,
 alert(name=AlertName, Key=OSPath, Value=Datavalue, RegistryValue=Diff) as AlertSent,
 if(condition=Calculate_hashes,
 then=hash(path=AbsolutePath[0], accessor="auto")) AS Hash,
 if(condition=CertificateInfo,
 then=authenticode(filename=AbsolutePath[0])) AS Certinfo
 FROM query_diff
 WHERE Diff = diff
 AND Hash.SHA256 =~ regex_sha256
 AND Certinfo.IssuerName=~regex_IssuerName
 AND NOT if(condition= UntrustedAuthenticode,
 then= Certinfo.Trusted = 'trusted',
 else= False )

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Service.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.service.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.service.upload/</guid><description>&lt;p>When a new service is installed, upload the service binary to the server&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Service.Upload
description: |
 When a new service is installed, upload the service binary to the server

type: CLIENT_EVENT

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 // Sometimes the image path contains the full command line - we
 // try to extract the first parameter as the binary itself. Deal
 // with two options - either quoted or not.
 SELECT ServiceName, upload(file=regex_replace(
 source=ImagePath,
 replace="$2",
 re='^("([^"]+)" .+|([^ ]+) .+)')) AS Upload,
 Timestamp, _EventData, _System
 FROM Artifact.Windows.Events.ServiceCreation()

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.TemplateInjection</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.templateinjection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.templateinjection/</guid><description>&lt;p>Detects injected templates in Office and RTF documents.&lt;/p>
&lt;p>Template injection is a form of defense evasion.
For office documents a malicious macro is loaded into an OOXML document
via a resource file masquerading as an office template. The OOXML artifact structure
will also detect MSHTML RCE Vulnerability #CVE-2021-40444 which has a similar payload technique.
For RTF documents, a malicious payload can be delivered by modifying document
formatting control via the &lt;code>\\\*\template&lt;/code> structure.&lt;/p>
&lt;p>This artifact can be modified to search for other suspicious &lt;code>rels&lt;/code> files:&lt;/p>
&lt;ul>
&lt;li>document.xml.rels = macros, ole objects, images.&lt;/li>
&lt;li>settings.xml.rels = templates.&lt;/li>
&lt;li>websettings.xml.rels = frames.&lt;/li>
&lt;li>header#.xml.rels and footer#.xml.rels and others has also been observed
hosting image files for canary files or abused for NetNTLM hash collection.&lt;/li>
&lt;/ul>
&lt;p>Change TemplateFileRegex to &lt;code>\\.xml\\.rels$&lt;/code> for looser file selection.
Change TemplateTargetRegex to &lt;code>^(https?|smb|\\\\|//|mhtml|file)&lt;/code> for looser
Target selection.&lt;/p>
&lt;p>This artifact can also be modified to quickly deploy YARA based detections
on other documents. Simply replace RtfYara with YARA rules of interest and
modify the glob for targeting.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.TemplateInjection
author: Matt Green - @mgreen27
description: |
 Detects injected templates in Office and RTF documents.

 Template injection is a form of defense evasion.
 For office documents a malicious macro is loaded into an OOXML document
 via a resource file masquerading as an office template. The OOXML artifact structure
 will also detect MSHTML RCE Vulnerability #CVE-2021-40444 which has a similar payload technique.
 For RTF documents, a malicious payload can be delivered by modifying document
 formatting control via the `\\\*\template` structure.


 This artifact can be modified to search for other suspicious `rels` files:

 - document.xml.rels = macros, ole objects, images.
 - settings.xml.rels = templates.
 - websettings.xml.rels = frames.
 - header#.xml.rels and footer#.xml.rels and others has also been observed
 hosting image files for canary files or abused for NetNTLM hash collection.

 Change TemplateFileRegex to `\\.xml\\.rels$` for looser file selection.
 Change TemplateTargetRegex to `^(https?|smb|\\\\|//|mhtml|file)` for looser
 Target selection.

 This artifact can also be modified to quickly deploy YARA based detections
 on other documents. Simply replace RtfYara with YARA rules of interest and
 modify the glob for targeting.

reference:
 - https://attack.mitre.org/techniques/T1221/
 - https://www.sans.org/reading-room/whitepapers/testing/template-injection-attacks-bypassing-security-controls-living-land-38780

type: CLIENT

parameters:
 - name: SearchGlob
 description: Glob to search
 default: C:\Users\**\*.{rtf,doc,dot,docx,docm,dotx,dotm,docb,xls,xlt,xlm,xlsx,xlsm,xltx,xltm,xlsb,ppt,pptx,pptm,potx,potm}
 - name: TemplateFileRegex
 description: Regex to search inside resource section.
 default: '(document|settings)\.xml\.rels$'
 type: regex
 - name: TemplateTargetRegex
 description: Regex to search inside resource section.
 default: '^(https?|smb|\\\\|//|mhtml)'
 type: regex
 - name: UploadDocument
 type: bool
 description: Select to upload document on detection.
 - name: RtfYara
 type: yara
 default: |
 rule RTF_TemplateInjection {
 meta:
 author = "Matt Green - @mgreen27"
 description = "Yara for RTF template injection. Using regex match to extract template information"

 strings:
 $regex1 = /\{\\\*\\template\s+http[^\}]+\}/ nocase
 $regex2 = /\{\\\*\\templates\s+\\u-[^\}]+\}/ nocase
 $regex3 = /\{\\\*\\template\s+file[^\}]+\}/ nocase

 condition:
 // header is {\rt only to also flag on malformed rtf heders
 uint32be(0) == 0x7B5C7274 and 1 of them
 }

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- Find target docs
 LET office_docs = SELECT OSPath, Mtime, Size
 FROM glob(globs=SearchGlob)
 WHERE NOT IsDir and Size &amp;gt; 0

 LET rtf_injection &amp;lt;= SELECT * FROM foreach(
 row=office_docs,
 query={
 SELECT
 OSPath AS DocumentPath,
 hash(path=OSPath) as DocumentHash,
 Mtime,
 Size,
 'YaraHit: ' + Rule as Section,
 regex_replace(
 source=String.Data,
 re='\{...template\s*|\}',replace='') as TemplateTarget
 FROM yara(files=OSPath, rules=RtfYara)
 WHERE NOT TemplateTarget =~ '^http(s|)://schemas\.microsoft\.com/'

 })

 -- select zip members inside the doc that have some content.
 LET document_parts = SELECT * FROM foreach(
 row={
 SELECT
 OSPath AS OfficePath,
 Mtime as OfficeMtime,
 Size as OfficeSize
 FROM office_docs
 WHERE NOT OSPath in rtf_injection.OSPath
 },
 query= {
 SELECT
 Mtime, Atime, Ctime,
 OSPath,
 OSPath.Path AS ZipMemberPath,
 OfficePath
 FROM glob(
 globs="/**",
 root=pathspec(DelegatePath=OfficePath),
 accessor='zip')
 WHERE not IsDir
 AND Size &amp;gt; 0
 AND ZipMemberPath =~ TemplateFileRegex
 })

 -- parse settings file by line and extract config
 LET template = SELECT * FROM foreach(row=document_parts,
 query={
 SELECT
 OSPath as SectionPath,
 OSPath.DelegatePath as Document,
 OSPath.Path as Section,
 parse_string_with_regex(
 string=Line,
 regex=['\\s+Target="(?P&amp;lt;Target&amp;gt;[^"]+)"\\s+TargetMode='
 ]).Target as TemplateTarget,
 Mtime as SectionMtime,
 Atime as SectionAtime,
 Ctime as SectionCtime
 FROM parse_lines(filename=OSPath, accessor='zip')
 WHERE TemplateTarget
 })

 -- search settings for remote or file templates, format mshtml entries
 LET hits = SELECT * FROM chain(
 rtf = { SELECT * FROM rtf_injection },
 office = {
 SELECT * FROM foreach(row=template,
 query={
 SELECT
 OSPath AS DocumentPath,
 hash(path=OSPath) as DocumentHash,
 Mtime,
 Size,
 Section,
 regex_replace(source=TemplateTarget,
 re='.*Target="(mhtml)',
 replace='mhtml') as TemplateTarget,
 SectionMtime,
 hash(path=SectionPath,accessor='zip') as SectionHash
 FROM stat(filename=Document)
 WHERE
 TemplateTarget =~ TemplateTargetRegex
 AND (( Section=~'/document.xml.rels$' AND TemplateTarget=~'^mhtml:' )
 OR NOT Section=~'/document.xml.rels$' )
 })
 })

 -- upload hits to server
 LET upload_hits = SELECT *, upload(file=DocumentPath) as Upload
 FROM hits

 -- output rows
 SELECT * FROM if(condition= UploadDocument,
 then= { SELECT * FROM upload_hits},
 else= { SELECT * FROM hits})

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Thumbdrives.List</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.thumbdrives.list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.thumbdrives.list/</guid><description>&lt;p>Users inserting Thumb drives or other Removable drive pose a
constant security risk. The external drive may contain malware or
other undesirable content. Additionally thumb drives are an easy way
for users to exfiltrate documents.&lt;/p>
&lt;p>This artifact watches for any removable drives and provides a
complete file listing to the server for any new drive inserted. It
also provides information about any addition to the thumb drive
(e.g. a new file copied onto the drive).&lt;/p>
&lt;p>We exclude very large removable drives since they might have too
many files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Thumbdrives.List
description: |
 Users inserting Thumb drives or other Removable drive pose a
 constant security risk. The external drive may contain malware or
 other undesirable content. Additionally thumb drives are an easy way
 for users to exfiltrate documents.

 This artifact watches for any removable drives and provides a
 complete file listing to the server for any new drive inserted. It
 also provides information about any addition to the thumb drive
 (e.g. a new file copied onto the drive).

 We exclude very large removable drives since they might have too
 many files.

type: CLIENT_EVENT

parameters:
 - name: maxDriveSize
 type: int
 description: We ignore removable drives larger than this size in bytes.
 default: "32000000000"


sources:
 - query: |
 LET removable_disks = SELECT Name AS Drive,
 atoi(string=Data.Size) AS Size
 FROM glob(globs="/*", accessor="file")
 WHERE Data.Description =~ "Removable" AND Size &amp;lt; atoi(string=maxDriveSize)

 LET file_listing = SELECT OSPath,
 Mtime As Modified,
 Size
 FROM glob(globs=Drive+"\\**", accessor="file")
 LIMIT 1000

 SELECT * FROM diff(
 query={
 SELECT * FROM foreach(
 row=removable_disks,
 query=file_listing)
 },
 key="OSPath",
 period=10)
 WHERE Diff = "added"

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Thumbdrives.OfficeKeywords</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.thumbdrives.officekeywords/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.thumbdrives.officekeywords/</guid><description>&lt;p>Users inserting Thumb drives or other Removable drive pose a
constant security risk. The external drive may contain malware or
other undesirable content. Additionally thumb drives are an easy way
for users to exfiltrate documents.&lt;/p>
&lt;p>This artifact automatically scans any office files copied to a
removable drive for keywords. This could be useful to detect
exfiltration attempts of restricted documents.&lt;/p>
&lt;p>We exclude very large removable drives since they might have too
many files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Thumbdrives.OfficeKeywords
description: |
 Users inserting Thumb drives or other Removable drive pose a
 constant security risk. The external drive may contain malware or
 other undesirable content. Additionally thumb drives are an easy way
 for users to exfiltrate documents.

 This artifact automatically scans any office files copied to a
 removable drive for keywords. This could be useful to detect
 exfiltration attempts of restricted documents.

 We exclude very large removable drives since they might have too
 many files.

type: CLIENT_EVENT

parameters:
 - name: officeExtensions
 default: "\\.(xls|xlsm|doc|docx|ppt|pptm)$"
 type: regex

 - name: yaraRule
 description: This yara rule will be run on document contents.
 type: yara
 default: |
 rule Hit {
 strings:
 $a = "this is my secret" wide nocase
 $b = "this is my secret" nocase

 condition:
 any of them
 }

sources:
 - query: |
 SELECT * FROM foreach(
 row = {
 SELECT * FROM Artifact.Windows.Detection.Thumbdrives.List()
 WHERE OSPath =~ officeExtensions
 },
 query = {
 SELECT * FROM Artifact.Generic.Applications.Office.Keywords(
 yaraRule=yaraRule, searchGlob=OSPath, documentGlobs="")
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Thumbdrives.OfficeMacros</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.thumbdrives.officemacros/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.thumbdrives.officemacros/</guid><description>&lt;p>Users inserting Thumb drives or other Removable drive pose a
constant security risk. The external drive may contain malware or
other undesirable content. Additionally thumb drives are an easy way
for users to exfiltrate documents.&lt;/p>
&lt;p>This artifact watches for any removable drives and scans any added
office documents for VBA macros.&lt;/p>
&lt;p>We exclude very large removable drives since they might have too
many files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Thumbdrives.OfficeMacros
description: |
 Users inserting Thumb drives or other Removable drive pose a
 constant security risk. The external drive may contain malware or
 other undesirable content. Additionally thumb drives are an easy way
 for users to exfiltrate documents.

 This artifact watches for any removable drives and scans any added
 office documents for VBA macros.

 We exclude very large removable drives since they might have too
 many files.

type: CLIENT_EVENT

parameters:
 - name: officeExtensions
 default: "\\.(xls|xlsm|doc|docx|ppt|pptm)$"
 type: regex

sources:
 - query: |
 SELECT * FROM foreach(
 row = {
 SELECT * FROM Artifact.Windows.Detection.Thumbdrives.List()
 WHERE OSPath =~ officeExtensions
 },
 query = {
 SELECT * from olevba(file=OSPath)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Usn</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.usn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.usn/</guid><description>&lt;p>NTFS is a journal filesystem. This means that it maintains a journal
file where intended filesystem changes are written first, then the
filesystem is changed. This journal is called the USN journal in NTFS.&lt;/p>
&lt;p>Velociraptor can watch the USN journal for new filesystem
events. This allows Velociraptor to detect when new files are
created or modified.&lt;/p>
&lt;p>A common use case is to determine when a new prefetch file is
modified (this indicates a binary was executed). Note: It seems
prefetch files are not updated immediately - there could be a small
delay between the execution and the prefetch being modified.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Usn
description: |
 NTFS is a journal filesystem. This means that it maintains a journal
 file where intended filesystem changes are written first, then the
 filesystem is changed. This journal is called the USN journal in NTFS.

 Velociraptor can watch the USN journal for new filesystem
 events. This allows Velociraptor to detect when new files are
 created or modified.

 A common use case is to determine when a new prefetch file is
 modified (this indicates a binary was executed). Note: It seems
 prefetch files are not updated immediately - there could be a small
 delay between the execution and the prefetch being modified.

type: CLIENT_EVENT

parameters:
 - name: PathRegex
 description: A regex to match the entire path (you can watch a directory or a file type).
 default: \.pf$
 type: regex
 - name: Device
 description: The NTFS drive to watch
 default: C:\\
 - name: USN_FREQUENCY
 type: int
 description: How many seconds before rechecking the USN journal.
 default: "30"
 - name: NTFS_CACHE_TIME
 type: int
 description: How often to flush the NTFS cache.
 default: "30"

precondition: SELECT OS from info() where OS = "windows"

sources:
 - query: |
 SELECT * FROM watch_usn(device=Device)
 WHERE OSPath =~ PathRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.WMIProcessCreation</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.wmiprocesscreation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.wmiprocesscreation/</guid><description>&lt;p>WMI Process creation is a common lateral movement technique. The
attacker simply uses WMI to call the Create() method on the
Win32_Process WMI object.&lt;/p>
&lt;p>This can be easily done via the &lt;code>wmic.exe&lt;/code> command or via PowerShell:&lt;/p>
&lt;pre>&lt;code class="language-bash">wmic process call create cmd.exe
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.WMIProcessCreation
description: |
 WMI Process creation is a common lateral movement technique. The
 attacker simply uses WMI to call the Create() method on the
 Win32_Process WMI object.

 This can be easily done via the `wmic.exe` command or via PowerShell:

 ```bash
 wmic process call create cmd.exe
 ```

type: CLIENT_EVENT

sources:
 - query: |
 SELECT Parse from wmi_events(
 query="SELECT * FROM MSFT_WmiProvider_ExecMethodAsyncEvent_Pre WHERE ObjectPath=\"Win32_Process\" AND MethodName=\"Create\"",
 namespace="ROOT/CIMV2",
 wait=50000000)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Yara.Device</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.device/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.device/</guid><description>&lt;p>This artifact enables running YARA over a Physical device and offset
specific targeting.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>Url link to a YARA rule.&lt;/li>
&lt;li>or a Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above. The
default is targeting the Master Boot Record (MBR).&lt;/p>
&lt;p>Note: by default the YARA scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.&lt;/p>
&lt;p>Due to scanning raw devices and size being potentially very large I have included
an example on how to upload the MBR as the default YARA rule.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Yara.Device
author: Matt Green - @mgreen27
description: |
 This artifact enables running YARA over a Physical device and offset
 specific targeting.

 There are 2 kinds of YARA rules that can be deployed:

 1. Url link to a YARA rule.
 2. or a Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above. The
 default is targeting the Master Boot Record (MBR).

 Note: by default the YARA scan will stop after one hit. Multi-string rules will also only
 show one string in returned rows.

 Due to scanning raw devices and size being potentially very large I have included
 an example on how to upload the MBR as the default YARA rule.

parameters:
 - name: DevicePath
 default: \\.\PHYSICALDRIVE0
 description: Raw Device for main disk to target.
 - name: StartOffest
 type: int
 default: 0
 - name: ScanLength
 type: int
 default: 512
 - name: YaraUrl
 description: If configured will attempt to download Yara rules from Url
 type: upload
 - name: YaraRule
 type: yara
 default: |
 rule MBR {
 meta:
 author = "Matt Green - @mgreen27"
 description = "Checks MBR header at offset 510 and collects MBR in HitContext"
 strings:
 $mbr = /^.{512}$/ //first entry covering bytes we want to upload.
 $mbrheader = { 55 AA }
 condition:
 $mbr and $mbrheader at 510
 }
 - name: NumberOfHits
 description: THis artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int64

sources:
 - query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- target yara with raw_file pachspec
 SELECT
 DevicePath,
 StartOffest,
 ScanLength,
 Namespace,
 Rule,
 Meta,
 Tags,
 String.Name as YaraString,
 String.Offset AS HitOffset,
 upload(
 accessor='data',
 file=String.Data,
 name=format(format='%s_%s',
 args=[basename(path=DevicePath),str(str=String.Offset)])
 ) AS HitContext
 FROM yara(files=pathspec(
 DelegateAccessor="raw_file",
 DelegatePath=DevicePath,
 Path=StartOffest),
 accessor='offset',
 start=0,
 end=ScanLength,
 rules=yara_rules,
 context=ContextBytes,
 number=NumberOfHits )

column_types:
 - name: HitContext
 type: upload_preview

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Yara.Glob</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.glob/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.glob/</guid><description>&lt;p>This artifact returns a list of target files then runs YARA over the target
list.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>Url link to a YARA rule.&lt;/li>
&lt;li>or a Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above.&lt;/p>
&lt;p>The artifact uses Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with YARA hits.&lt;/p>
&lt;p>Some examples of path glob may include:&lt;/p>
&lt;ul>
&lt;li>Specific binary: &lt;code>/usr/bin/ls&lt;/code>&lt;/li>
&lt;li>Wildcards: &lt;code>/var/www/*.js&lt;/code>&lt;/li>
&lt;li>More wildcards: &lt;code>/var/www/**/*.js&lt;/code>&lt;/li>
&lt;li>Multiple extensions: &lt;code>/var/www/*\.{php,aspx,js,html}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:/Users/**/*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;li>Windows: &lt;code>C:\Users\**\*.{exe,dll,ps1,bat}&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
 This artifact returns a list of target files then runs YARA over the target
 list.

 There are 2 kinds of YARA rules that can be deployed:

 1. Url link to a YARA rule.
 2. or a Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above.

 The artifact uses Glob for search so relevant filters can be applied
 including Glob, Size and date. Date filters will target files with a timestamp
 before LatestTime and after EarliestTime. The artifact also has an option to
 upload any files with YARA hits.

 Some examples of path glob may include:

 * Specific binary: `/usr/bin/ls`
 * Wildcards: `/var/www/*.js`
 * More wildcards: `/var/www/**/*.js`
 * Multiple extensions: `/var/www/*\.{php,aspx,js,html}`
 * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
 * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

 NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
 This will NOT follow any symlinks and may cause unexpected results if
 unknowingly targeting a folder with symlinks.
 If upload is selected NumberOfHits is redundant and not advised as hits are
 grouped by path to ensure files only downloaded once.

aliases:
 - Windows.Detection.Yara.Glob
 - Linux.Detection.Yara.Glob
 - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
 - name: PathGlob
 description: Only file names that match this glob will be scanned.
 default: /usr/bin/ls
 - name: SizeMax
 description: maximum size of target file.
 type: int64
 - name: SizeMin
 description: minimum size of target file.
 type: int64
 - name: UploadHits
 type: bool
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: YaraUrl
 description: If configured will attempt to download Yara rules form Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule IsELF:TestRule {
 meta:
 author = "the internet"
 date = "2021-05-03"
 description = "A simple ELF rule to test yara features"
 condition:
 uint32(0) == 0x464c457f
 }
 - name: NumberOfHits
 description: This artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int

sources:
 - query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- time testing
 LET time_test(stamp) =
 if(condition= DateBefore AND DateAfter,
 then= stamp &amp;lt; DateBefore AND stamp &amp;gt; DateAfter,
 else=
 if(condition=DateBefore,
 then= stamp &amp;lt; DateBefore,
 else=
 if(condition= DateAfter,
 then= stamp &amp;gt; DateAfter,
 else= True
 )))

 -- first find all matching glob
 LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
 FROM glob(globs=PathGlob,nosymlink='True')
 WHERE
 NOT IsDir AND NOT IsLink
 AND if(condition=SizeMin,
 then= SizeMin &amp;lt; Size,
 else= True)
 AND if(condition=SizeMax,
 then=SizeMax &amp;gt; Size,
 else= True)
 AND
 ( time_test(stamp=Mtime)
 OR time_test(stamp=Atime)
 OR time_test(stamp=Ctime)
 OR time_test(stamp=Btime))

 -- scan files and prepare hit metadata
 LET hits = SELECT * FROM foreach(row=files,
 query={
 SELECT
 OSPath,
 File.Size as Size,
 Mtime, Atime, Ctime, Btime,
 Rule, Tags, Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 upload( accessor='scope',
 file='String.Data',
 name=format(format="%v-%v-%v",
 args=[
 OSPath,
 if(condition= String.Offset - ContextBytes &amp;lt; 0,
 then= 0,
 else= String.Offset - ContextBytes),
 if(condition= String.Offset + ContextBytes &amp;gt; Size,
 then= Size,
 else= String.Offset + ContextBytes) ]
 )) as HitContext
 FROM yara(rules=yara_rules,files=OSPath,
 context=ContextBytes,number=NumberOfHits)
 })

 -- upload files if selected
 LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

 -- return rows
 SELECT * FROM if(condition= UploadHits,
 then= upload_hits,
 else= hits )

column_types:
 - name: HitContext
 type: preview_upload
&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Yara.NTFS</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.ntfs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.ntfs/</guid><description>&lt;p>This artifact searches the MFT, returns a list of target files then runs YARA
over the target list.&lt;/p>
&lt;p>There are 3 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>URL link to a YARA rule.&lt;/li>
&lt;li>Shorthand YARA in the format &lt;code>wide nocase ascii:string1,string2,string3&lt;/code>.&lt;/li>
&lt;li>or a Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above.&lt;/p>
&lt;p>The artifact uses Windows.NTFS.MFT so similar regex filters can be applied
including Path, Size and date. The artifact also has an option to search across
all attached drives and upload any files with YARA hits.&lt;/p>
&lt;p>Some examples of path regex may include:&lt;/p>
&lt;ul>
&lt;li>Extension at a path: &lt;code>C:\\Windows\\System32\\.+\.dll$&lt;/code>&lt;/li>
&lt;li>More wildcards: &lt;code>Windows\\.+\\.+\.dll$&lt;/code>&lt;/li>
&lt;li>Specific file: &lt;code>Windows\\System32\\kernel32\.dll$&lt;/code>&lt;/li>
&lt;li>Multiple extensions: &lt;code>\.(php|aspx|resx|asmx)$&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Note: no drive and forward slashes - these expressions are for paths
relative to the root of the filesystem.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Yara.NTFS
author: Matt Green - @mgreen27
description: |
 This artifact searches the MFT, returns a list of target files then runs YARA
 over the target list.

 There are 3 kinds of YARA rules that can be deployed:

 1. URL link to a YARA rule.
 2. Shorthand YARA in the format `wide nocase ascii:string1,string2,string3`.
 3. or a Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above.

 The artifact uses Windows.NTFS.MFT so similar regex filters can be applied
 including Path, Size and date. The artifact also has an option to search across
 all attached drives and upload any files with YARA hits.

 Some examples of path regex may include:

 * Extension at a path: `C:\\Windows\\System32\\.+\.dll$`
 * More wildcards: `Windows\\.+\\.+\.dll$`
 * Specific file: `Windows\\System32\\kernel32\.dll$`
 * Multiple extensions: `\.(php|aspx|resx|asmx)$`

 Note: no drive and forward slashes - these expressions are for paths
 relative to the root of the filesystem.
 If upload is selected NumberOfHits is redundant and not advised as hits are
 grouped by path to ensure files only downloaded once.

type: CLIENT
parameters:
 - name: FileNameRegex
 description: Only file names that match this regular expression will be scanned.
 default: ^kernel32\.dll$
 - name: PathRegex
 description: Only paths that match this regular expression will be scanned.
 default: C:\\Windows\\System32\\
 - name: DriveLetter
 description: "Target drive. Default is a C:"
 default: "C:"
 - name: SizeMax
 type: int
 - name: SizeMin
 type: int
 - name: AllDrives
 type: bool
 - name: UploadHits
 type: bool
 - name: EarliestSILastChanged
 type: timestamp
 - name: LatestSILastChanged
 type: timestamp
 - name: EarliestFNCreation
 type: timestamp
 - name: LatestFNCreation
 type: timestamp
 - name: YaraUrl
 description: If configured will attempt to download Yara rules form Url
 default:
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule IsPE:TestRule {
 meta:
 author = "the internet"
 date = "2021-03-04"
 description = "A simple PE rule to test yara features"
 condition:
 uint16(0) == 0x5A4D and
 uint32(uint32(0x3C)) == 0x00004550
 }
 - name: NumberOfHits
 description: THis artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int64
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int


sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- check which Yara to use
 LET yara_rules = YaraUrl || YaraRule

 -- first find all matching files mft
 LET files = SELECT
 OSPath, IsDir
 FROM Artifact.Windows.NTFS.MFT(
 MFTDrive=DriveLetter, AllDrives=AllDrives,
 FileRegex=FileNameRegex,PathRegex=PathRegex,
 SizeMax=SizeMax, SizeMin=SizeMin)
 WHERE NOT IsDir
 AND NOT OSPath =~ '''\\\\.\\.:\\&amp;lt;Err&amp;gt;\\'''
 AND if(condition=EarliestSILastChanged,
 then= LastRecordChange0x10 &amp;gt; EarliestSILastChanged,
 else= True)
 AND if(condition=LatestSILastChanged,
 then= LastRecordChange0x10 &amp;lt; LatestSILastChanged,
 else= True)
 AND if(condition=EarliestFNCreated,
 then= Created0x30 &amp;gt; EarliestFNCreation,
 else= True)
 AND if(condition=LatestFNCreated,
 then= Created0x30 &amp;lt; LatestFNCreation,
 else= True)

 -- scan files and only report a single hit.
 LET hits = SELECT * FROM foreach(row=files,
 query={
 SELECT
 FileName, OSPath,
 File.Size AS Size,
 File.ModTime AS ModTime,
 Rule, Tags, Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 if(condition=String.Data,
 then=upload(
 accessor='scope',
 file='String.Data',
 name=format(format="%v-%v-%v",
 args=[
 OSPath,
 if(condition= String.Offset - ContextBytes &amp;lt; 0,
 then= 0,
 else= String.Offset - ContextBytes),
 if(condition= String.Offset + ContextBytes &amp;gt; File.Size,
 then= File.Size,
 else= String.Offset + ContextBytes) ]
 ))) as HitContext
 FROM yara(rules=yara_rules,
 files=OSPath, context=ContextBytes, number=NumberOfHits)
 })

 -- upload files that have hit
 LET upload_hits=SELECT *,
 upload(file=OSPath) AS Upload
 FROM hits
 GROUP BY OSPath

 -- return rows
 SELECT * FROM if(condition=UploadHits,
 then={ SELECT * FROM upload_hits},
 else={ SELECT * FROM hits})

column_types:
 - name: HitContext
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Yara.PhysicalMemory</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.physicalmemory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.physicalmemory/</guid><description>&lt;p>This artifact enables running YARA over physical memory.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>URL link to a YARA rule.&lt;/li>
&lt;li>A standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above. The
default is Cobalt Strike opcodes.&lt;/p>
&lt;p>The artifact will load the WinPmem driver, then YARA scan the
physical memory and remove the driver.&lt;/p>
&lt;p>NOTE: This artifact is experimental and can crash the system!&lt;/p>
&lt;h4 id="handling-signatures-with-fixed-strings">Handling signatures with fixed strings.&lt;/h4>
&lt;p>When the signature specifies fixed strings, the YARA engine will
load it into memory, causing the signature to match memory used by
Velociraptor. To avoid this false positive encode the fixed
string as an alternative string.&lt;/p>
&lt;p>For example instead of:&lt;/p>
&lt;pre>&lt;code>$sequence_5 = { 250000ff00 33d0 8b4db0 c1e908 }
&lt;/code>&lt;/pre>
&lt;p>Write as:&lt;/p>
&lt;pre>&lt;code>$sequence_5 = { 250000ff00 33d0 8b4db0 c1e9 ( 08 | 08 ) }
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Yara.PhysicalMemory
description: |
 This artifact enables running YARA over physical memory.

 There are 2 kinds of YARA rules that can be deployed:

 1. URL link to a YARA rule.
 2. A standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above. The
 default is Cobalt Strike opcodes.

 The artifact will load the WinPmem driver, then YARA scan the
 physical memory and remove the driver.

 NOTE: This artifact is experimental and can crash the system!

 #### Handling signatures with fixed strings.

 When the signature specifies fixed strings, the YARA engine will
 load it into memory, causing the signature to match memory used by
 Velociraptor. To avoid this false positive encode the fixed
 string as an alternative string.

 For example instead of:
 ```
 $sequence_5 = { 250000ff00 33d0 8b4db0 c1e908 }
 ```

 Write as:
 ```
 $sequence_5 = { 250000ff00 33d0 8b4db0 c1e9 ( 08 | 08 ) }
 ```

type: CLIENT
parameters:
 - name: ServiceName
 description: Override the name of the driver service to install.
 - name: DriverPath
 description: Where to unpack the driver before loading it.
 default: C:\Windows\Temp\winpmem.sys
 - name: NumberOfHits
 description: THis artifact will stop by default at one hit. This setting allows additional hits
 default: 100
 type: int64
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int
 - name: YaraUrl
 description: If configured will attempt to download Yara rules from Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule win_cobalt_strike_auto {
 meta:
 author = "Felix Bilstein - yara-signator at cocacoding dot com"
 date = "2019-11-26"
 version = "1"
 description = "autogenerated rule brought to you by yara-signator"
 tool = "yara-signator 0.2a"
 malpedia_reference = "https://malpedia.caad.fkie.fraunhofer.de/details/win.cobalt_strike"
 malpedia_license = "CC BY-SA 4.0"
 malpedia_sharing = "TLP:WHITE"

 strings:
 $sequence_0 = { 3bc7 750d ff15???????? 3d33270000 }
 $sequence_1 = { e9???????? eb0a b801000000 e9???????? }
 $sequence_2 = { 8bd0 e8???????? 85c0 7e0e }
 $sequence_3 = { ffb5f8f9ffff ff15???????? 8b4dfc 33cd e8???????? c9 c3 }
 $sequence_4 = { e8???????? e9???????? 833d?????????? 7505 e8???????? }
 $sequence_5 = { 250000ff00 33d0 8b4db0 c1e9 ( 08 | 08 ) }
 $sequence_6 = { ff75f4 ff7610 ff761c ff75 (fc | fc) }
 $sequence_7 = { 8903 6a06 eb39 33ff 85c0 762b 03 ( f1 | f1 ) }
 $sequence_8 = { 894d ( d4 | d4 ) 8b458c d1f8 894580 8b45f8 c1e818 0fb6c8 }
 $sequence_9 = { 890a 8b45 ( 08 | 08 ) 0fb64804 81e1ff000000 c1e118 8b5508 0fb64205 }
 $sequence_10 = { 33d2 e8???????? 48b873797374656d3332 4c8bc7 488903 49ffc0 }
 $sequence_11 = { 488bd1 498d4b ( d8 | d8 ) 498943e0 498943e8 }
 $sequence_12 = { b904000000 486bc9 ( 0e | 0e ) 488b542430 4c8b442430 418b0c08 8b0402 }
 $sequence_13 = { ba80000000 e8???????? 488d4c2438 e8???????? 488d4c2420 8bd0 e8???????? }
 $sequence_14 = { 488b4c2430 8b0401 ( 89 | 89 ) 442428 b804000000 486bc004 }
 $sequence_15 = { 4883c708 4883c304 49ff ( c3 | c3 ) 48ffcd 0f854fffffff 488d4c2420 }

 condition:
 7 of them
 }

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 LET SparsePath = pathspec(
 DelegateAccessor='raw_file',
 DelegatePath='''\\.\pmem''',
 Path={
 SELECT atoi(string=Start) AS Offset,
 atoi(string=Length) AS Length
 FROM Artifact.Windows.Sys.PhysicalMemoryRanges()
 WHERE Type = 3
 })

 -- Load the WinPmem binary
 LET _ &amp;lt;= winpmem(service=ServiceName, driver_path=DriverPath)

 SELECT
 Rule,
 Meta,
 String.Offset as HitOffset,
 String.Name as HitName,
 String.HexData as HitHexData
 FROM yara(files=SparsePath, accessor='winpmem',
 rules=yara_rules, context=ContextBytes, number=NumberOfHits)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Yara.Process</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.process/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.process/</guid><description>&lt;p>This artifact enables running YARA over processes in memory.&lt;/p>
&lt;p>There are 2 kinds of YARA rules that can be deployed:&lt;/p>
&lt;ol>
&lt;li>URL link to a YARA rule.&lt;/li>
&lt;li>or a Standard YARA rule attached as a parameter.&lt;/li>
&lt;/ol>
&lt;p>Only one method of YARA will be applied and search order is as above. The
default is Cobalt Strike opcodes.&lt;/p>
&lt;p>Regex parameters can be applied for process name and pid for targeting. The
artifact also has an option to upload any process with YARA hits.&lt;/p>
&lt;p>Note: by default the YARA scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Yara.Process
author: Matt Green - @mgreen27
description: |
 This artifact enables running YARA over processes in memory.

 There are 2 kinds of YARA rules that can be deployed:

 1. URL link to a YARA rule.
 3. or a Standard YARA rule attached as a parameter.

 Only one method of YARA will be applied and search order is as above. The
 default is Cobalt Strike opcodes.

 Regex parameters can be applied for process name and pid for targeting. The
 artifact also has an option to upload any process with YARA hits.

 Note: by default the YARA scan will stop after one hit. Multi-string rules will also only
 show one string in returned rows.
 If upload is selected NumberOfHits is redundant and not advised as hits are
 grouped by path to ensure files only downloaded once.


type: CLIENT
parameters:
 - name: ProcessRegex
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: UploadHits
 type: bool
 - name: YaraUrl
 description: If configured will attempt to download Yara rules from Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule win_cobalt_strike_auto {
 meta:
 author = "Felix Bilstein - yara-signator at cocacoding dot com"
 date = "2019-11-26"
 version = "1"
 description = "autogenerated rule brought to you by yara-signator"
 tool = "yara-signator 0.2a"
 malpedia_reference = "https://malpedia.caad.fkie.fraunhofer.de/details/win.cobalt_strike"
 malpedia_license = "CC BY-SA 4.0"
 malpedia_sharing = "TLP:WHITE"

 strings:
 $sequence_0 = { 3bc7 750d ff15???????? 3d33270000 }
 $sequence_1 = { e9???????? eb0a b801000000 e9???????? }
 $sequence_2 = { 8bd0 e8???????? 85c0 7e0e }
 $sequence_3 = { ffb5f8f9ffff ff15???????? 8b4dfc 33cd e8???????? c9 c3 }
 $sequence_4 = { e8???????? e9???????? 833d?????????? 7505 e8???????? }
 $sequence_5 = { 250000ff00 33d0 8b4db0 c1e908 }
 $sequence_6 = { ff75f4 ff7610 ff761c ff75fc }
 $sequence_7 = { 8903 6a06 eb39 33ff 85c0 762b 03f1 }
 $sequence_8 = { 894dd4 8b458c d1f8 894580 8b45f8 c1e818 0fb6c8 }
 $sequence_9 = { 890a 8b4508 0fb64804 81e1ff000000 c1e118 8b5508 0fb64205 }
 $sequence_10 = { 33d2 e8???????? 48b873797374656d3332 4c8bc7 488903 49ffc0 }
 $sequence_11 = { 488bd1 498d4bd8 498943e0 498943e8 }
 $sequence_12 = { b904000000 486bc90e 488b542430 4c8b442430 418b0c08 8b0402 }
 $sequence_13 = { ba80000000 e8???????? 488d4c2438 e8???????? 488d4c2420 8bd0 e8???????? }
 $sequence_14 = { 488b4c2430 8b0401 89442428 b804000000 486bc004 }
 $sequence_15 = { 4883c708 4883c304 49ffc3 48ffcd 0f854fffffff 488d4c2420 }

 condition:
 7 of them
 }
 - name: NumberOfHits
 description: THis artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int64
 - name: ExePathWhitelist
 description: Regex of ProcessPaths to exclude
 type: regex


sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- find velociraptor process
 LET me = SELECT Pid FROM pslist(pid=getpid())

 -- find all processes and add filters
 LET processes = SELECT Name as ProcessName, Exe as ExePath, CommandLine, Pid, WorkingSetSize
 FROM pslist()
 WHERE
 Name =~ ProcessRegex
 AND format(format="%d", args=Pid) =~ PidRegex
 AND NOT Pid in me.Pid
 AND NOT if(condition=ExePathWhitelist,
 then= Exe=~ExePathWhitelist)

 -- scan processes in scope with our rule, limit 1 hit
 LET hits = SELECT * FROM foreach(
 row=processes,
 query={
 SELECT
 ProcessName,
 ExePath,
 CommandLine,
 Pid,
 Rule,
 Tags,
 Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 upload( accessor='scope',
 file='String.Data',
 name=format(format="%v-%v_%v",
 args=[
 split(string=ProcessName, sep='\\.')[0], Pid,
 String.Offset ]
 )) as HitContext

 FROM proc_yara(
 pid=int(int=Pid),
 rules=yara_rules,
 context=ContextBytes,
 number=NumberOfHits
 )
 })

 -- upload hits using proc_dump plugin
 LET upload_hits = SELECT * FROM foreach(
 row=hits,
 query={
 SELECT
 ProcessName,
 ExePath,
 CommandLine,
 Pid,
 Rule,
 Tags,
 Meta,
 YaraString,
 HitOffset,
 HitContext,
 upload(
 file=OSPath,
 name=format(format='%v-%v.dmp',
 args= [ split(string=ProcessName, sep='\\.')[0], Pid ])
 ) as ProcessDump
 FROM proc_dump(pid=Pid)
 })

 -- return rows
 SELECT * FROM if(condition=UploadHits,
 then=upload_hits,
 else=hits)

column_types:
 - name: HitContext
 type: preview_upload
&lt;/code>&lt;/pre></description></item><item><title>Windows.Detection.Yara.UEFI</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.uefi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.detection.yara.uefi/</guid><description>&lt;p>This artifact enables running YARA over files in an EFI System Partition (ESP).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Detection.Yara.UEFI
author: Matt Green - @mgreen27
description: |
 This artifact enables running YARA over files in an EFI System Partition (ESP).


parameters:
 - name: ImagePath
 default: \\.\PhysicalDrive0
 description: Raw Device for main disk containing partition table to parse.
 - name: SectorSize
 type: int
 default: 512
 - name: TargetGlob
 default: "**/*.efi"
 - name: SizeMax
 description: maximum size of target file.
 type: int64
 - name: SizeMin
 description: minimum size of target file.
 type: int64
 - name: UploadHits
 type: bool
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: YaraUrl
 description: If configured will attempt to download Yara rules form Url
 type: upload
 - name: YaraRule
 type: yara
 description: Final Yara option and the default if no other options provided.
 default: |
 rule win_blacklotus_auto {
 meta:
 author = "Felix Bilstein - yara-signator at cocacoding dot com"
 date = "2023-07-11"
 description = "Detects win.blacklotus."
 strings:
 $sequence_0 = { 498bcf e8???????? 448bc0 498bd7 4d03c0 488bce }
 $sequence_1 = { 4c897020 55 488d68c8 4881ec30010000 4c8bd1 }
 $sequence_2 = { 488b0d???????? 4c8d054e140100 488bd7 488bd8 e8???????? 488b05???????? 488bcb }
 $sequence_3 = { 8b0c91 498bd2 4903c9 e8???????? }
 $sequence_4 = { 4585d2 743f 8b05???????? 4103c1 }
 $sequence_5 = { 4883ec20 488d7910 8bea 488b1f 33f6 }
 $sequence_6 = { 488bd9 b10e e8???????? 8a4b02 40b70d }
 $sequence_7 = { 410f47f7 8bc6 488b742460 4883c430 415f }
 $sequence_8 = { 4923d3 4803d1 440fb74a0c 440fb7520e }
 $sequence_9 = { 6642837cc11010 0f859d000000 428b54c114 41bbffffff7f 4923d3 }
 condition:
 7 of them and filesize &amp;lt; 181248
 }
 rule MAL_Rootkit_CosmicStrand
 {
 meta:
 	author = "Natalie Zargarov @ Rapid7"
 description = "CosmicStrand UEFI rootkit detection rule. Detects the compromised .efi driver "
 targeting = "process,efi"
 tags ="Rootkit"
 strings:
 $trait_0 = {89 C6 53 89 D8 BB 3F B8 11 03}
 $trait_1 = {8B 3D 18 10 01 00 33 DB 8D 45 F8 50 53 53 6A 0B}
 $trait_2= {83 EC 4C 53 57 68 A0 10 01 00 8D 45 F8}
 $trait_3= {53 81 C7 FF 0F 00 00 68 54 44 55 00 81 E7 00 F0 FF FF 57 6A 01}
 $trait_4= {50 68 08 08 08 08 68 D0 43 DE DE 68 1F 96 00 00 BF E4 10 01 00}
 $string_0 = "winlogon.exe"
 condition:
 1 of ($trait_*) and
 1 of ($string_*)
 }
 - name: NumberOfHits
 description: This artifact will stop by default at one hit. This setting allows additional hits
 default: 1
 type: int
 - name: ContextBytes
 description: Include this amount of bytes around hit as context.
 default: 0
 type: int

sources:
- query: |
 -- check which Yara to use
 LET yara_rules &amp;lt;= YaraUrl || YaraRule

 -- time testing
 LET time_test(stamp) =
 if(condition= DateBefore AND DateAfter,
 then= stamp &amp;lt; DateBefore AND stamp &amp;gt; DateAfter,
 else=
 if(condition=DateBefore,
 then= stamp &amp;lt; DateBefore,
 else=
 if(condition= DateAfter,
 then= stamp &amp;gt; DateAfter,
 else= True
 )))

 LET find_efi = SELECT StartOffset,EndOffset,
 Size AS PartitionSize,
 name AS PartitionName
 FROM Artifact.Windows.Forensics.PartitionTable(
 ImagePath=ImagePath, SectorSize=SectorSize)
 WHERE PartitionName =~ "EFI"

 LET find_files = SELECT * FROM foreach(row=find_efi,
 query={
 SELECT *,
 StartOffset,EndOffset,
 PartitionSize,
 PartitionName
 FROM glob(globs=TargetGlob,
 accessor="fat",
 root=pathspec(
 DelegateAccessor="offset",
 DelegatePath=pathspec(
 DelegateAccessor="raw_file",
 DelegatePath=ImagePath,
 Path=format(format="%d", args=StartOffset))))
 })

 LET target_files = SELECT
 StartOffset as PartitionOffset, PartitionSize,
 OSPath,
 Size, Mtime, Atime, Ctime, Btime,
 Data.first_cluster as FirstCluster,
 Data.attr AS Attr,
 Data.deleted as IsDeleted,
 Data.short_name AS ShortName
 FROM find_files
 WHERE NOT IsDir
 AND if(condition=SizeMin,
 then= SizeMin &amp;lt; Size,
 else= True)
 AND if(condition=SizeMax,
 then= SizeMax &amp;gt; Size,
 else= True)
 AND ( time_test(stamp=Mtime)
 OR time_test(stamp=Atime)
 OR time_test(stamp=Ctime)
 OR time_test(stamp=Btime))

 -- scan files and prepare hit metadata
 LET hits = SELECT * FROM foreach(row=target_files,
 query={
 SELECT
 OSPath as _OSPath,
 OSPath.Path as OSPath,
 File.Size as Size,
 Mtime, Atime, Ctime, Btime,
 Rule, Tags, Meta,
 String.Name as YaraString,
 String.Offset as HitOffset,
 upload( accessor='scope',
 file='String.Data',
 name=format(format="%v-%v-%v",
 args=[
 OSPath.Path,
 if(condition= String.Offset - ContextBytes &amp;lt; 0,
 then= 0,
 else= String.Offset - ContextBytes),
 if(condition= String.Offset + ContextBytes &amp;gt; Size,
 then= Size,
 else= String.Offset + ContextBytes) ]
 )) as HitContext
 FROM yara( accessor='fat', rules=yara_rules,files=OSPath,
 context=ContextBytes,number=NumberOfHits )
 })

 -- upload files if selected
 LET upload_hits = SELECT *,
 upload(accessor='fat',file=_OSPath,name=_OSPath.Path) as Upload
 FROM hits

 -- return rows
 SELECT * FROM if(condition= UploadHits,
 then= upload_hits,
 else= hits )

column_types:
 - name: HitContext
 type: preview_upload
&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.DNS</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.dns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.dns/</guid><description>&lt;p>Monitors DNS queries using ETW.&lt;/p>
&lt;p>There are several filters available to filter out and/or target using regular
expressions. By default duplicate DNSCache requests are filtered out.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.DNS
author: Matt Green - @mgreen27
description: |
 Monitors DNS queries using ETW.

 There are several filters available to filter out and/or target using regular
 expressions. By default duplicate DNSCache requests are filtered out.

type: CLIENT_EVENT

parameters:
 - name: ImageRegex
 description: "ImagePath regex filter for"
 default: .
 type: regex
 - name: CommandLineRegex
 description: "Commandline to filter for."
 default: .
 type: regex
 - name: QueryRegex
 description: "DNS query request (domain) to filter for."
 default: .
 type: regex
 - name: AnswerRegex
 description: "DNS answer to filter for."
 default: .
 type: regex
 - name: CommandLineExclusion
 description: "Commandline to filter out. Typically we do not want Dnscache events."
 default: 'svchost.exe -k NetworkService -p -s Dnscache$'
 type: regex


sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET TypeLookup &amp;lt;= dict(
 `1` = 'A',
 `2` = 'NS',
 `5` = 'CNAME',
 `6` = 'SOA',
 `12` = 'PTR',
 `13` = 'HINFO',
 `15` = 'MX',
 `16` = 'TXT',
 `17` = 'RP',
 `18` = 'AFSDB',
 `24` = 'SIG',
 `25` = 'KEY',
 `28` = 'AAAA',
 `29` = 'LOC',
 `33` = 'SRV',
 `35` = 'NAPTR',
 `36` = 'KX',
 `37` = 'CERT',
 `39` = 'DNAME',
 `42` = 'APL',
 `43` = 'DS',
 `44` = 'SSHFP',
 `45` = 'IPSECKEY',
 `46` = 'RRSIG',
 `47` = 'NSEC',
 `48` = 'DNSKEY',
 `49` = 'DHCID',
 `50` = 'NSEC3',
 `51` = 'NSEC3PARAM',
 `52` = 'TLSA',
 `53` = 'SMIMEA',
 `55` = 'HIP',
 `59` = 'CDS',
 `60` = 'CDNSKEY',
 `61` = 'OPENPGPKEY',
 `62` = 'CSYNC',
 `63` = 'ZONEMD',
 `64` = 'SVCB',
 `65` = 'HTTPS',
 `108` = 'EUI48',
 `109` = 'EUI64',
 `249` = 'TKEY',
 `250` = 'TSIG',
 `256` = 'URI',
 `257` = 'CAA',
 `32768` = 'TA',
 `32769` = 'DLV')

 SELECT System.TimeStamp AS EventTime,
 EventData.QueryName AS Query,
 get(item=TypeLookup,
 member=str(str=EventData.QueryType)) AS Type,
 EventData.QueryResults AS Answer,
 process_tracker_get(id=System.ProcessID).Data as Process
 FROM watch_etw(
 description="Microsoft-Windows-DNS-Client",
 guid="{1C95126E-7EEA-49A9-A3FE-A378B03DDB4D}")
 WHERE System.ID = 3008
 AND Query
 AND NOT Process.CommandLine =~ CommandLineExclusion
 AND Process.Exe =~ ImageRegex
 AND Query =~ QueryRegex
 AND Answer =~ AnswerRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.DNSQueriesServer</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.dnsqueriesserver/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.dnsqueriesserver/</guid><description>&lt;p>Logs DNS queries on DNS servers.&lt;/p>
&lt;p>This is useful for identifying the true source system that is initiating
malicious DNS requests that you may have observed.&lt;/p>
&lt;p>Note that this can be resource intensive for the CPU on busy DNS servers -
from 5% to 70% CPU load of one core, but memory consumption is very low. This
is still a lot less than enabling DNS debug logging.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.DNSQueriesServer
type: CLIENT_EVENT

description: |
 Logs DNS queries on DNS servers.

 This is useful for identifying the true source system that is initiating
 malicious DNS requests that you may have observed.

 Note that this can be resource intensive for the CPU on busy DNS servers -
 from 5% to 70% CPU load of one core, but memory consumption is very low. This
 is still a lot less than enabling DNS debug logging.

author: "Jos Clephas - jos-ir"

parameters:
 - name: QueryNameRegex
 default: .
 type: regex
 - name: SourceIPRegex
 default: .
 type: regex

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 SELECT System.TimeStamp as TimeStamp,
 System.ID as ID,
 EventData.BufferSize as BufferSize,
 EventData.Flags as Flags,
 EventData.InterfaceIP as InterfaceIP,
 EventData.Port as Port,
 EventData.QNAME as QNAME,
 EventData.QTYPE as QTYPE,
 EventData.RD as RD,
 EventData.Source as Source,
 EventData.TCP as TCP,
 EventData.XID as XID
 FROM watch_etw(
 description="EventLog-Microsoft-Windows-DNSServer-Analytical",
 guid="{EB79061A-A566-4698-9119-3ED2807060E7}")
 WHERE EventData AND
 QNAME =~ QueryNameRegex AND
 Source =~ SourceIPRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.DotNetRundown</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.dotnetrundown/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.dotnetrundown/</guid><description>&lt;p>Queries the Microsoft-Windows-DotNETRuntimeRundown provider to
collect a list of DotNet modules loaded into a process. This can be
useful when responding to reflectively loaded DotNet malware.&lt;/p>
&lt;p>NOTE: System.Timestamp represents when the artifact was run, NOT
when the module was loaded.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.DotNetRundown
author: "@bmcder02"
description: |
 Queries the Microsoft-Windows-DotNETRuntimeRundown provider to
 collect a list of DotNet modules loaded into a process. This can be
 useful when responding to reflectively loaded DotNet malware.

 NOTE: System.Timestamp represents when the artifact was run, NOT
 when the module was loaded.


type: CLIENT

parameters:
 - name: ProcessRegex
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: EventIDRegex
 default: .
 type: regex
 - name: Timeout
 default: 20
 type: int

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET EventData = SELECT System.ID AS EventID, System.ProcessID AS ProcessID,
 process_tracker_get(id=System.ProcessID) AS ProcessDetails,
 *
 FROM watch_etw(
 description="CLR Rundown Provider",
 guid="{A669021C-C450-4609-A035-5AF59AF4DF18}",
 any=0x48, timeout=Timeout)

 SELECT EventID, ProcessID, ProcessDetails.Data.Name AS ProcessName,
 ProcessDetails.Data.Exe AS ProcessPath, System, EventData, ProviderGUID,
 ProcessDetails
 FROM EventData
 WHERE EventID =~ EventIDRegex
 AND ProcessID =~ PidRegex
 AND ProcessPath =~ ProcessRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.EdgeURLs</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.edgeurls/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.edgeurls/</guid><description>&lt;p>Collects all URLs accessed by the Edge browser using ETW.&lt;/p>
&lt;p>It also serves as an example of an ETW artifact, in this case using the
provider:&lt;/p>
&lt;p>&lt;code>Microsoft-Windows-URLMon {245F975D-909D-49ED-B8F9-9A75691D6B6B}&lt;/code>&lt;/p>
&lt;p>NOTE: This artifact can generate a lot of data - you probably want
to filter the URLs a bit and/or target collection to a narrow label
group.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.EdgeURLs
description: |
 Collects all URLs accessed by the Edge browser using ETW.

 It also serves as an example of an ETW artifact, in this case using the
 provider:

 `Microsoft-Windows-URLMon {245F975D-909D-49ED-B8F9-9A75691D6B6B}`

 NOTE: This artifact can generate a lot of data - you probably want
 to filter the URLs a bit and/or target collection to a narrow label
 group.

type: CLIENT_EVENT

parameters:
 - name: URLFilter
 default: .
 description: A regex that can be used to filter uninteresting URLs
 type: regex

sources:
 - query: |
 LET m &amp;lt;= memoize(key="Pid", period=30, query={
 SELECT Pid, Exe, Username FROM pslist()
 })

 SELECT System.ID AS ID,
 System.TimeStamp AS Timestamp,
 get(item=m, field=System.ProcessID) AS ProcInfo,
 get(member="EventData.URL") AS URL
 FROM watch_etw(
 description="Microsoft-Windows-URLMon",
 guid="{245F975D-909D-49ED-B8F9-9A75691D6B6B}")
 WHERE ID = 805 AND URL =~ URLFilter

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.ETWSessions</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.etwsessions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.etwsessions/</guid><description>&lt;p>Windows Event Tracing exposes a lot of low level system information
and events. It is normally employed by security tools to gather
telemetry, however may also be used maliciously.&lt;/p>
&lt;p>This artifact monitors for all new ETW sessions and reports the
tracing process as well as the provider that is being traced.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.ETWSessions
description: |
 Windows Event Tracing exposes a lot of low level system information
 and events. It is normally employed by security tools to gather
 telemetry, however may also be used maliciously.

 This artifact monitors for all new ETW sessions and reports the
 tracing process as well as the provider that is being traced.

type: CLIENT_EVENT

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET PublisherGlob = pathspec(
 Path='''HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\WINEVT\Publishers''',
 path_type="registry")

 LET GUIDLookup(GUID) = SELECT Data.value AS Provider
 FROM stat(accessor="registry", filename=PublisherGlob + ("/" + GUID + "/@"))

 SELECT System.TimeStamp AS Timestamp,
 if(condition=System.ID = 14, then="Installed", else="Removed") AS Action, {
 SELECT Name, CommandLine from pslist(pid=System.ProcessID)
 } AS ProcessInfo ,
 GUIDLookup(GUID=EventData.ProviderName)[0].Provider AS Provider,
 EventData.SessionName AS SessionName,
 System AS _System, EventData AS _EventData
 FROM watch_etw(
 description='Microsoft-Windows-Kernel-EventTracing',
 guid="{B675EC37-BDB6-4648-BC92-F3FDC74D3CA2}", all=0x400)
 WHERE System.ID IN (14, 15)

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.FileCreation</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.filecreation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.filecreation/</guid><description>&lt;p>This artifact follows the Microsoft-Windows-Kernel-File provider.&lt;/p>
&lt;p>NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.KernelFile
description: |
 This artifact follows the Microsoft-Windows-Kernel-File provider.

 NOTE: We can only attach to this provider when running as
 NT_USER/SYSTEM.

aliases:
 - Windows.ETW.FileCreation

type: CLIENT_EVENT

references:
 - https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-File.xml

parameters:
 - name: ProcessRegex
 type: regex
 description: View Processes with Executables matching this regex
 default: .

 - name: IgnoreProcessRegex
 type: regex
 description: Ignore Processes with Executables matching this regex

 - name: Events
 type: multichoice
 description: Events to view
 default: '["NameCreate", "NameDelete", "FileOpen", "Rename", "RenamePath", "CreateNewFile"]'
 choices:
 - NameCreate
 - NameDelete
 - FileOpen
 - Rename
 - RenamePath
 - CreateNewFile

sources:
 - query: |
 -- KERNEL_FILE_KEYWORD_FILENAME | KERNEL_FILE_KEYWORD_CREATE | KERNEL_FILE_KEYWORD_DELETE_PATH
 LET Keyword &amp;lt;= 0x1490
 LET EIDLookup &amp;lt;= dict(
 `10`="NameCreate", `11`="NameDelete", `12`="FileOpen",
 `19`="Rename", `27`="RenamePath",`30`="CreateNewFile")

 LET ETW = SELECT *
 FROM watch_etw(guid='{edd08927-9cc4-4e65-b970-c2560fb5c289}',
 description="Microsoft-Windows-Kernel-File", any=Keyword)

 SELECT System.ID AS EID,
 System AS _System,
 get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
 process_tracker_get(id=System.ProcessID).Data AS ProcInfo,
 process_tracker_callchain(id=System.ProcessID).Data.Exe AS CallChain,
 EventData
 FROM delay(query=ETW, delay=3)
 WHERE EventType IN Events
 AND ProcInfo.Exe =~ ProcessRegex
 AND if(condition=IgnoreProcessRegex,
 then=NOT ProcInfo.Exe =~ IgnoreProcessRegex,
 else=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.KernelFile</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.kernelfile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.kernelfile/</guid><description>&lt;p>This artifact follows the Microsoft-Windows-Kernel-File provider.&lt;/p>
&lt;p>NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.KernelFile
description: |
 This artifact follows the Microsoft-Windows-Kernel-File provider.

 NOTE: We can only attach to this provider when running as
 NT_USER/SYSTEM.

aliases:
 - Windows.ETW.FileCreation

type: CLIENT_EVENT

references:
 - https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-File.xml

parameters:
 - name: ProcessRegex
 type: regex
 description: View Processes with Executables matching this regex
 default: .

 - name: IgnoreProcessRegex
 type: regex
 description: Ignore Processes with Executables matching this regex

 - name: Events
 type: multichoice
 description: Events to view
 default: '["NameCreate", "NameDelete", "FileOpen", "Rename", "RenamePath", "CreateNewFile"]'
 choices:
 - NameCreate
 - NameDelete
 - FileOpen
 - Rename
 - RenamePath
 - CreateNewFile

sources:
 - query: |
 -- KERNEL_FILE_KEYWORD_FILENAME | KERNEL_FILE_KEYWORD_CREATE | KERNEL_FILE_KEYWORD_DELETE_PATH
 LET Keyword &amp;lt;= 0x1490
 LET EIDLookup &amp;lt;= dict(
 `10`="NameCreate", `11`="NameDelete", `12`="FileOpen",
 `19`="Rename", `27`="RenamePath",`30`="CreateNewFile")

 LET ETW = SELECT *
 FROM watch_etw(guid='{edd08927-9cc4-4e65-b970-c2560fb5c289}',
 description="Microsoft-Windows-Kernel-File", any=Keyword)

 SELECT System.ID AS EID,
 System AS _System,
 get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
 process_tracker_get(id=System.ProcessID).Data AS ProcInfo,
 process_tracker_callchain(id=System.ProcessID).Data.Exe AS CallChain,
 EventData
 FROM delay(query=ETW, delay=3)
 WHERE EventType IN Events
 AND ProcInfo.Exe =~ ProcessRegex
 AND if(condition=IgnoreProcessRegex,
 then=NOT ProcInfo.Exe =~ IgnoreProcessRegex,
 else=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.KernelNetwork</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.kernelnetwork/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.kernelnetwork/</guid><description>&lt;p>This artifact follows the Microsoft-Windows-Kernel-Network provider.&lt;/p>
&lt;p>NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.KernelNetwork
description: |
 This artifact follows the Microsoft-Windows-Kernel-Network provider.

 NOTE: We can only attach to this provider when running as
 NT_USER/SYSTEM.

references:
- "https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-Network.xml"

type: CLIENT_EVENT

parameters:
 - name: ProcessRegex
 type: regex
 description: View Processes with Executables matching this regex
 default: .

 - name: IgnoreProcessRegex
 type: regex
 description: Ignore Processes with Executables matching this regex

 - name: Events
 type: multichoice
 description: Events to view
 default: '["ConnectionAttempted", "ConnectionAccepted"]'
 choices:
 - DataSent
 - DataReceived
 - ConnectionAttempted
 - ConnectionAccepted
 - DataSentOverUDPProtocol
 - DataReceivedOverUDPProtocol

sources:
 - query: |
 LET EIDLookup &amp;lt;= dict(
 `10`="DataSent", `11`="DataReceived", `12`="ConnectionAttempted", `15`="ConnectionAccepted",
 `42`="DataSentOverUDPProtocol",`43`="DataReceivedOverUDPProtocol")

 LET ETW = SELECT *
 FROM watch_etw(guid='{7dd42a49-5329-4832-8dfd-43d979153a88}',
 description="Microsoft-Windows-Kernel-Network")

 SELECT System.ID AS EID,
 System AS _System,
 get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
 process_tracker_get(id=EventData.PID).Data AS ProcInfo,
 process_tracker_callchain(id=EventData.PID).Data.Exe AS CallChain,
 EventData
 FROM delay(query=ETW, delay=3)
 WHERE EventType IN Events
 AND EventData.ImageName =~ ProcessRegex
 AND if(condition=IgnoreProcessRegex,
 then=NOT EventData.ImageName =~ IgnoreProcessRegex,
 else=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.KernelProcess</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.kernelprocess/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.kernelprocess/</guid><description>&lt;p>This artifact follows the Microsoft-Windows-Kernel-Process provider.&lt;/p>
&lt;p>NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.KernelProcess
description: |
 This artifact follows the Microsoft-Windows-Kernel-Process provider.

 NOTE: We can only attach to this provider when running as
 NT_USER/SYSTEM.

references:
- "https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-Process.xml"

parameters:
 - name: ProcessRegex
 type: regex
 description: View Processes with Executables matching this regex
 default: .

 - name: IgnoreProcessRegex
 type: regex
 description: Ignore Processes with Executables matching this regex

 - name: Events
 type: multichoice
 description: Events to view
 default: '["ProcessStart", "ImageLoad"]'
 choices:
 - ProcessStart
 - ProcessStop
 - ImageLoad
 - ImageUnload

type: CLIENT_EVENT

sources:
 - query: |
 LET EIDLookup &amp;lt;= dict(
 `1`="ProcessStart", `2`="ProcessStop",
 `5`="ImageLoad", `6`="ImageUnload")

 LET ETW = SELECT *
 FROM watch_etw(guid='{22fb2cd6-0e7b-422b-a0c7-2fad1fd0e716}',
 description="Microsoft-Windows-Kernel-Process", any=0x50)

 SELECT System.ID AS EID,
 get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
 process_tracker_get(id=System.ProcessID).Data AS ParentProcInfo,
 process_tracker_callchain(id=System.ProcessID).Data.Exe AS ParentCallChain,
 EventData
 FROM delay(query=ETW, delay=3)
 WHERE EventType IN Events
 AND EventData.ImageName =~ ProcessRegex
 AND if(condition=IgnoreProcessRegex,
 then=NOT EventData.ImageName =~ IgnoreProcessRegex,
 else=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.Registry</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.registry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.registry/</guid><description>&lt;p>Windows Registry access is a great source of visibility into system
activity.&lt;/p>
&lt;p>There are many ways of gaining visibility into this, the most
reliable being Sysmon. However it is also possible to gain some
visibility using ETW. The Microsoft-Windows-Kernel-Registry provides
ETW events for registry modifications.&lt;/p>
&lt;p>This artifact parses these events and ties them back to the
accessing process. We recommend running this artifact with the
process tracker.&lt;/p>
&lt;p>NOTE: Experience shows this ETW provider is not very reliable and seems to
miss a lot of registry events. This artifact should therefore be considered
experimental.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.Registry
description: |
 Windows Registry access is a great source of visibility into system
 activity.

 There are many ways of gaining visibility into this, the most
 reliable being Sysmon. However it is also possible to gain some
 visibility using ETW. The Microsoft-Windows-Kernel-Registry provides
 ETW events for registry modifications.

 This artifact parses these events and ties them back to the
 accessing process. We recommend running this artifact with the
 process tracker.

 NOTE: Experience shows this ETW provider is not very reliable and seems to
 miss a lot of registry events. This artifact should therefore be considered
 experimental.

type: CLIENT_EVENT

precondition: SELECT * FROM info() WHERE OS = "windows"

parameters:
- name: KeyNameRegex
 type: regex
 default: .
- name: ProcessRegex
 type: regex
 default: .

sources:
- query: |
 LET Cache &amp;lt;= lru(size=1000)
 LET EventLookup &amp;lt;= dict(
 `1`="CreateKey",
 `2`="OpenKey",
 `3`="DeleteKey",
 `4`="QueryKey",
 `5`="SetValueKey",
 `6`="DeleteValueKey",
 `7`="QueryValue",
 `8`="EnumerateKey",
 `9`="EnumerateValueKey"
 )

 LET registry_access = SELECT System, EventData,
 get(item=EventLookup, field=str(str=System.ID)) AS EventType,
 get(item=Cache, field=EventData.KeyObject) || EventData.KeyName AS KeyName
 FROM watch_etw(
 description="Microsoft-Windows-Kernel-Registry",
 guid="{70EB4F03-C1DE-4F73-A051-33D13D5413BD}", any=0x7720)
 WHERE System.ProcessID != getpid() -- exclude ourselves
 AND EventType -- we only care about these events
 AND if(condition=System.ID in (1, 2, 4),
 then=set(item=Cache, field=EventData.KeyObject,
 value=EventData.RelativeName),
 else=TRUE) -- set KeyName in the lru

 LET hits = SELECT System.TimeStamp AS Timestamp,
 process_tracker_get(id=System.ProcessID).Data AS Process,
 EventType, KeyName, EventData
 FROM registry_access
 WHERE KeyName =~ KeyNameRegex

 SELECT Timestamp, EventType,
 System AS _System, EventData AS _EventData,
 Process.Name AS ProcessName, Process.Username AS Owner,
 Process.CommandLine AS CommandLine,
 KeyName, EventData.ValueName AS ValueName
 FROM hits
 WHERE ProcessName =~ ProcessRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.ViewSessions</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.viewsessions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.viewsessions/</guid><description>&lt;p>This artifact enumerates all ETW sessions and optionally kills dangling ones&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.ViewSessions
description: |
 This artifact enumerates all ETW sessions and optionally kills dangling ones

required_permissions:
 - EXECVE

precondition: SELECT OS From info() where OS = 'windows'
parameters:
 - name: SessionRegex
 default: "Velociraptor"
 type: regex
 - name: KillMatching
 type: bool
 description: If set will kill the relevant sessions.


sources:
 - query: |
 SELECT * FROM foreach(row={
 SELECT Stdout, parse_string_with_regex(string=Stdout, regex="(^[^ ]+)").g1 AS SessionName
 from execve(argv=["logman", "query", "-ets"], sep="\n")
 WHERE Stdout =~ "Running" AND SessionName =~ SessionRegex
 }, query={
 SELECT * FROM if(condition=KillMatching,
 then={
 SELECT SessionName, Stdout FROM execve(argv=["logman", "stop", SessionName, "-ets"])
 }, else={
 SELECT SessionName FROM scope()
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.ETW.WMIProcessCreate</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.etw.wmiprocesscreate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.etw.wmiprocesscreate/</guid><description>&lt;p>This artifact the endpoints for process creation through WMI
events. This is a common attacker lateral movement technique.&lt;/p>
&lt;p>The technique works by calling the Create() method on the
win32_process WMI object.&lt;/p>
&lt;p>You can test this with PowerShell:
Invoke-WmiMethod -Path win32_process -Name create -ArgumentList notepad.exe&lt;/p>
&lt;p>This artifact uses the EWT provider:
Microsoft-Windows-WMI-Activity {1418EF04-B0B4-4623-BF7E-D74AB47BBDAA}&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.ETW.WMIProcessCreate
description: |
 This artifact the endpoints for process creation through WMI
 events. This is a common attacker lateral movement technique.

 The technique works by calling the Create() method on the
 win32_process WMI object.

 You can test this with PowerShell:
 Invoke-WmiMethod -Path win32_process -Name create -ArgumentList notepad.exe

 This artifact uses the EWT provider:
 Microsoft-Windows-WMI-Activity {1418EF04-B0B4-4623-BF7E-D74AB47BBDAA}

type: CLIENT_EVENT

sources:
 - query: |
 LET hits = SELECT
 System.ID AS ID,
 System.TimeStamp AS Timestamp,
 get(member="EventData") AS EventData
 FROM watch_etw(
 description="Microsoft-Windows-WMI-Activity",
 guid="{1418EF04-B0B4-4623-BF7E-D74AB47BBDAA}")
 WHERE ID = 23

 SELECT ID, Timestamp, EventData.ClientMachine AS Hostname,
 {
 SELECT Pid, Name, Exe from pslist(pid=int(int=EventData.ClientProcessId))
 } AS ClientProcessInfo,
 {
 SELECT Pid, Name, Exe from pslist(pid=int(int=EventData.CreatedProcessId))
 } AS CreatedProcessInfo,
 timestamp(winfiletime=int(int=EventData.ClientProcessCreationTime)) AS ClientProcessCreationTime,
 timestamp(winfiletime=int(int=EventData.CreatedProcessCreationTime)) AS CreatedProcessCreationTime,
 EventData.Commandline AS Commandline,
 EventData.User AS User
 FROM hits

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.AlternateLogon</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.alternatelogon/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.alternatelogon/</guid><description>&lt;p>Logon specifying alternate credentials - if NLA enabled on
destination Current logged-on User Name Alternate User Name
Destination Host Name/IP Process Name&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.AlternateLogon
description: |
 Logon specifying alternate credentials - if NLA enabled on
 destination Current logged-on User Name Alternate User Name
 Destination Host Name/IP Process Name

reference:
 - https://digital-forensics.sans.org/media/SANS_Poster_2018_Hunt_Evil_FINAL.pdf

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: securityLogFile
 default: C:/Windows/System32/Winevt/Logs/Security.evtx

sources:
 - query: |
 SELECT
 timestamp(epoch=System.TimeCreated.SystemTime) AS EventTime,
 EventData.IpAddress AS IpAddress,
 EventData.IpPort AS Port,
 EventData.ProcessName AS ProcessName,
 EventData.SubjectUserSid AS SubjectUserSid,
 EventData.SubjectUserName AS SubjectUserName,
 EventData.TargetUserName AS TargetUserName,
 EventData.TargetServerName AS TargetServerName,
 System.TimeCreated.SystemTime AS LogonTime
 FROM parse_evtx(filename=securityLogFile)
 WHERE System.EventID.Value = 4648
 AND EventData

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.Cleared</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.cleared/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.cleared/</guid><description>&lt;p>Extract Event Logs related to EventLog clearing&lt;/p>
&lt;ul>
&lt;li>Security Log - EventID 1102&lt;/li>
&lt;li>System Log - EventID 104&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.Cleared
author: Matt Green - @mgreen27

description: |
 Extract Event Logs related to EventLog clearing
 - Security Log - EventID 1102
 - System Log - EventID 104

reference:
 - https://attack.mitre.org/versions/v6/techniques/T1070/

type: CLIENT

parameters:
 - name: TargetGlob
 default: C:\Windows\System32\Winevt\Logs\{System,Security}.evtx
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

sources:
 - query: |
 SELECT
 EventTime,
 UserData.LogFileCleared.Channel || Channel as ClearedLog,
 Message,
 UserData.LogFileCleared.SubjectDomainName + "\\" + UserData.LogFileCleared.SubjectUserName as Username,
 UserData.LogFileCleared.SubjectUserSid || UserSID as UserSID,
 dict(
 EventTime=EventTime,
 Computer=Computer,
 Channel=Channel,
 EventID=EventID,
 EventRecordID=EventRecordID,
 OSPath=OSPath,
 UserData=UserData
 ) as EventData
 FROM Artifact.Windows.EventLogs.EvtxHunter(EvtxGlob=TargetGlob,
 ChannelRegex='^(Security|System)$',
 IdRegex='^(1102|104)',
 IocRegex='clear|cleared',
 DateAfter=DateAfter,
 DateBefore=DateBefore,
 VSSAnalysisAge=VSSAnalysisAge)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.DHCP</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.dhcp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.dhcp/</guid><description>&lt;p>This artifact parses the Windows DHCP event log looking for evidence
of IP address assignments.&lt;/p>
&lt;p>In some investigations it is important to be able to identify the
machine which was assigned a particular IP address at a point in
time. Usually these logs are available from the DHCP server, but in
many cases the server logs are not available (for example, if the
endpoint was visiting a different network or the DHCP server is on a
wireless router with no log retention).&lt;/p>
&lt;p>On windows, there are two types of logs:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The first type is the admin log
(&lt;code>Microsoft-Windows-Dhcp-Client%4Admin.evt&lt;/code>). These only contain
errors such as an endpoint trying to continue its lease, but
the lease is rejected by the server.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The operational log
(&lt;code>Microsoft-Windows-Dhcp-Client%4Operational.evtx&lt;/code>) contains
the full log of each lease. Unfortunately this log is disabled
by default. If it is available we can rely on the information.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.DHCP
description: |

 This artifact parses the Windows DHCP event log looking for evidence
 of IP address assignments.

 In some investigations it is important to be able to identify the
 machine which was assigned a particular IP address at a point in
 time. Usually these logs are available from the DHCP server, but in
 many cases the server logs are not available (for example, if the
 endpoint was visiting a different network or the DHCP server is on a
 wireless router with no log retention).

 On windows, there are two types of logs:

 1. The first type is the admin log
 (`Microsoft-Windows-Dhcp-Client%4Admin.evt`). These only contain
 errors such as an endpoint trying to continue its lease, but
 the lease is rejected by the server.

 2. The operational log
 (`Microsoft-Windows-Dhcp-Client%4Operational.evtx`) contains
 the full log of each lease. Unfortunately this log is disabled
 by default. If it is available we can rely on the information.

parameters:
 - name: eventDirGlob
 default: C:\Windows\system32\winevt\logs\

 - name: adminLog
 default: Microsoft-Windows-Dhcp-Client%4Admin.evtx

 - name: operationalLog
 default: Microsoft-Windows-Dhcp-Client%4Operational.evtx

 - name: accessor
 default: file

sources:
 - name: RejectedDHCP
 query: |
 LET files = SELECT *
 FROM glob(
 root=eventDirGlob,
 globs=adminLog,
 accessor=accessor)

 SELECT Time AS _Time,
 timestamp(epoch=Time) As Timestamp,
 Computer, MAC, ClientIP, DHCPServer, Type FROM foreach(
 row=files,
 query={
 SELECT System.TimeCreated.SystemTime as Time,
 System.Computer AS Computer,
 format(format="%x:%x:%x:%x:%x:%x", args=[EventData.HWAddress]) AS MAC,
 ip(netaddr4_le=EventData.Address1) AS ClientIP,
 ip(netaddr4_le=EventData.Address2) AS DHCPServer,
 "Lease Rejected" AS Type
 FROM parse_evtx(filename=OSPath, accessor=accessor)
 WHERE System.EventID.Value = 1002
 })

 - name: AssignedDHCP
 query: |
 SELECT Time AS _Time,
 timestamp(epoch=Time) As Timestamp,
 Computer, MAC, ClientIP, DHCPServer, Type FROM foreach(
 row=files,
 query={
 SELECT System.TimeCreated.SystemTime as Time,
 System.Computer AS Computer,
 EventData.InterfaceGuid AS MAC,
 ip(netaddr4_le=EventData.Address1) AS ClientIP,
 ip(netaddr4_le=EventData.Address2) AS DHCPServer,
 "Lease Assigned" AS Type
 FROM parse_evtx(filename=OSPath, accessor=accessor)
 WHERE System.EventID.Value = 60000
 })


reports:
 - type: CLIENT
 template: |
 Evidence of DHCP assigned IP addresses
 ======================================

 {{ .Description }}

 {{ define "assigned_dhcp" }}
 SELECT Computer, ClientIP,
 count(items=Timestamp) AS Total,
 enumerate(items=Timestamp) AS Times
 FROM source(source='AssignedDHCP')
 GROUP BY ClientIP
 {{ end }}
 {{ define "rejected_dhcp" }}
 SELECT Computer, ClientIP,
 count(items=Timestamp) AS Total,
 enumerate(items=Timestamp) AS Times
 FROM source(source='RejectedDHCP')
 GROUP BY ClientIP
 {{ end }}

 {{ $assigned := Query "assigned_dhcp"}}
 {{ if $assigned }}
 ## Operational logs

 This machine has DHCP operational logging enabled. We therefore
 can see complete references to all granted leases:
 {{ Table $assigned }}

 ## Timeline

 {{ Query "SELECT _Time * 1000, ClientIP FROM source(source='AssignedDHCP')" | Timeline }}

 {{ end }}

 ## Admin logs

 The admin logs show errors with DHCP lease requests. Typically
 rejected leases indicate that the machine held a least on a IP
 address in the past, but this lease is invalid for its current
 environment. For example, the machine has been moved to a
 different network.

 {{ Query "rejected_dhcp" | Table }}

 {{ Query "SELECT _Time * 1000, ClientIP FROM source(source='RejectedDHCP')" | Timeline }}

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.Evtx</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.evtx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.evtx/</guid><description>&lt;p>Parses and returns events from Windows evtx logs.&lt;/p>
&lt;p>Each event is returned in full, but results can be narrowed by using a glob
pattern for evtx files, a timespan, and regexes to match the evtx path, event
channel, and/or event ID:&lt;/p>
&lt;ul>
&lt;li>EvtxGlob: glob of event log files (evtx) to target&lt;/li>
&lt;li>StartDate: earliest event created timestamp to target&lt;/li>
&lt;li>EndDate: latest event created timestamp to target&lt;/li>
&lt;li>PathRegex: a regex to match against paths returned from EvtxGlob&lt;/li>
&lt;li>ChannelRegex: a regex to match against the event channel&lt;/li>
&lt;li>IDRegex: a regex to match against the event ID&lt;/li>
&lt;/ul>
&lt;p>Gathering these logs enables VQL analysis (&lt;em>e.g.&lt;/em>, via notebooks) and bulk
export (&lt;em>e.g.&lt;/em>, to elasticsearch) for additional processing. It can also be
used as the basis for custom artifacts with more in-depth filtering.&lt;/p>
&lt;p>&lt;strong>Note: This artifact can be resource intensive.&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Parsing and aggregating may use high amounts of CPU on the client. Consider
reducing the ops/second or narrowing the glob/path regex if necessary.&lt;/li>
&lt;li>Parsing may use significant memory and time when searching VSS volumes and
deduplicating events. This is proportional to the evtx file size and number
of VSS copies. Consider whether the extra events are worth the resources.&lt;/li>
&lt;li>Parsing many event logs may take longer than the default timeout. When
parsing all log files and searching VSS, consider doubling the default or
more (especially with reduced ops/second, or if targets have high-volume
3rd-party log sources such as Sysmon).&lt;/li>
&lt;li>The artifact routinely produces hundreds of thousands of rows per host.
Consider filtering results using path, channel, and ID regexes if necessary.&lt;/li>
&lt;/ul>
&lt;p>Inspired by others in &lt;code>Windows.EventLogs.*&lt;/code>, many by Matt Green (@mgreen27).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.Evtx

description: |
 Parses and returns events from Windows evtx logs.

 Each event is returned in full, but results can be narrowed by using a glob
 pattern for evtx files, a timespan, and regexes to match the evtx path, event
 channel, and/or event ID:

 - EvtxGlob: glob of event log files (evtx) to target
 - StartDate: earliest event created timestamp to target
 - EndDate: latest event created timestamp to target
 - PathRegex: a regex to match against paths returned from EvtxGlob
 - ChannelRegex: a regex to match against the event channel
 - IDRegex: a regex to match against the event ID

 Gathering these logs enables VQL analysis (_e.g._, via notebooks) and bulk
 export (_e.g._, to elasticsearch) for additional processing. It can also be
 used as the basis for custom artifacts with more in-depth filtering.

 **Note: This artifact can be resource intensive.**

 - Parsing and aggregating may use high amounts of CPU on the client. Consider
 reducing the ops/second or narrowing the glob/path regex if necessary.
 - Parsing may use significant memory and time when searching VSS volumes and
 deduplicating events. This is proportional to the evtx file size and number
 of VSS copies. Consider whether the extra events are worth the resources.
 - Parsing many event logs may take longer than the default timeout. When
 parsing all log files and searching VSS, consider doubling the default or
 more (especially with reduced ops/second, or if targets have high-volume
 3rd-party log sources such as Sysmon).
 - The artifact routinely produces hundreds of thousands of rows per host.
 Consider filtering results using path, channel, and ID regexes if necessary.

 Inspired by others in `Windows.EventLogs.*`, many by Matt Green (@mgreen27).

author: Chris Hendricks (chris@counteractive.net)

precondition: SELECT OS FROM info() WHERE OS = 'windows'

parameters:
 - name: EvtxGlob
 default: '%SystemRoot%\System32\winevt\Logs\*.evtx'
 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.
 - name: StartDate
 type: timestamp
 description: "Parse events on or after this date (YYYY-MM-DDTmm:hh:ssZ)"
 - name: EndDate
 type: timestamp
 description: "Parse events on or before this date (YYYY-MM-DDTmm:hh:ssZ)"
 - name: PathRegex
 default: "."
 type: regex
 - name: ChannelRegex
 default: "."
 type: regex
 - name: IDRegex
 default: "."
 type: regex

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 // expand provided glob into a list of paths on the file system (fs)
 LET fspaths =
 SELECT OSPath FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)
 WHERE OSPath =~ PathRegex

 // function returning parsed evtx from list of paths
 LET evtxsearch(pathList) = SELECT * FROM foreach(
 row=pathList,
 query={
 SELECT *,
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS TimeCreated,
 System.Channel as Channel,
 System.EventRecordID as EventRecordID,
 System.EventID.Value as EventID,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE
 if(condition=StartDate,
 then=TimeCreated &amp;gt;= timestamp(string=StartDate),
 else=true)
 AND if(condition=EndDate,
 then=TimeCreated &amp;lt;= timestamp(string=EndDate),
 else=true)
 AND Channel =~ ChannelRegex
 AND str(str=EventID) =~ IDRegex
 }
 )

 SELECT * FROM evtxsearch(pathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.EvtxHunter</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.evtxhunter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.evtxhunter/</guid><description>&lt;p>This Artifact will hunt the Event Log message field for a regex value.
For example and IP, username or string.&lt;/p>
&lt;p>Searching EventLog files is helpful for triage and scoping an incident.
The idea is a user can search for any IOC or other string of interest and
return all results across the Event Log ecosystem.&lt;/p>
&lt;p>There are several parameters available for search leveraging regex.&lt;/p>
&lt;ul>
&lt;li>EvtxGlob glob of EventLogs to target. Default to all but can be targeted.&lt;/li>
&lt;li>dateAfter enables search for events after this date.&lt;/li>
&lt;li>dateBefore enables search for events before this date.&lt;/li>
&lt;li>IocRegex enables regex search over the message field.&lt;/li>
&lt;li>WhitelistRegex enables a regex whitelist for the Message field.&lt;/li>
&lt;li>PathRegex enables filtering on evtx path for specific log targeting.&lt;/li>
&lt;li>ChannelRegex allows specific EVTX Channel targets.&lt;/li>
&lt;li>IdRegex enables a regex query to select specific event Ids.&lt;/li>
&lt;li>SearchVSS enables searching over VSS&lt;/li>
&lt;/ul>
&lt;p>Note: this artifact can potentially be heavy on the endpoint.
Please use with caution.
EventIds with an EventData field regex will be applied and requires double
escape for backslash due to serialization of this field.
E.g &lt;code>C:\\\\FOLDER\\\\binary\\.exe&lt;/code>
For EventIds with no EventData the Message field is queried and requires
standard Velociraptor escape. E.g &lt;code>C:\\FOLDER\\binary\\.exe&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.EvtxHunter
description: |
 This Artifact will hunt the Event Log message field for a regex value.
 For example and IP, username or string.

 Searching EventLog files is helpful for triage and scoping an incident.
 The idea is a user can search for any IOC or other string of interest and
 return all results across the Event Log ecosystem.

 There are several parameters available for search leveraging regex.
 - EvtxGlob glob of EventLogs to target. Default to all but can be targeted.
 - dateAfter enables search for events after this date.
 - dateBefore enables search for events before this date.
 - IocRegex enables regex search over the message field.
 - WhitelistRegex enables a regex whitelist for the Message field.
 - PathRegex enables filtering on evtx path for specific log targeting.
 - ChannelRegex allows specific EVTX Channel targets.
 - IdRegex enables a regex query to select specific event Ids.
 - SearchVSS enables searching over VSS

 Note: this artifact can potentially be heavy on the endpoint.
 Please use with caution.
 EventIds with an EventData field regex will be applied and requires double
 escape for backslash due to serialization of this field.
 E.g `C:\\\\FOLDER\\\\binary\\.exe`
 For EventIds with no EventData the Message field is queried and requires
 standard Velociraptor escape. E.g `C:\\FOLDER\\binary\\.exe`

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: EvtxGlob
 default: '%SystemRoot%\System32\Winevt\Logs\*.evtx'
 - name: IocRegex
 type: regex
 description: "IOC Regex"
 default:
 - name: WhitelistRegex
 description: "Regex of string to witelist"
 type: regex
 - name: PathRegex
 description: "Event log Regex to enable filtering on path"
 default: .
 type: regex
 - name: ChannelRegex
 description: "Channel Regex to enable filtering on path"
 default: .
 - name: ProviderRegex
 description: "Provider Regex to enable filtering on provider"
 default: .
 type: regex
 - name: IdRegex
 default: .
 type: regex
 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: MessageDB
 type: hidden
 description: "Add message DB path if desired for offline parsing"

imports:
 - Windows.Sys.AllUsers

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths = SELECT OSPath
 FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)
 WHERE OSPath =~ PathRegex

 -- function returning IOC hits
 LET evtxsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
 System.Computer as Computer,
 System.Channel as Channel,
 System.Provider.Name as Provider,
 System.EventID.Value as EventID,
 System.EventRecordID as EventRecordID,
 System.Security.UserID as UserSID,
 LookupSIDCache(SID=System.Security.UserID || "") AS Username,
 get(field="EventData") as EventData,
 get(field="UserData") as UserData,
 get(field="Message") as Message,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor, messagedb=MessageDB)
 WHERE ( EventData OR UserData OR Message )
 AND EventTime &amp;lt; DateBeforeTime
 AND EventTime &amp;gt; DateAfterTime
 AND Channel =~ ChannelRegex
 AND Provider =~ ProviderRegex
 AND str(str=EventID) =~ IdRegex
 AND format(format='%v %v %v', args=[
 EventData, UserData, Message]) =~ IocRegex
 AND if(condition=WhitelistRegex,
 then= NOT format(format='%v %v %v', args=[
 EventData, UserData, Message]) =~ WhitelistRegex,
 else= True)
 }
 )

 SELECT * FROM evtxsearch(PathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.ExplicitLogon</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.explicitlogon/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.explicitlogon/</guid><description>&lt;p>Searches the Windows Security event log for explicit logon events, that is
Event ID 4648: &amp;ldquo;A logon was attempted using explicit credentials&amp;rdquo;.&lt;/p>
&lt;p>If logging is enabled, these events are generated on the source machine
whenever an authentication attempt occurs under a different user context.
Examples include a user authenticating to another machine using wmic or
mapping a drive using different credentials, or using the RunAs option
locally.&lt;/p>
&lt;p>This artifact by default filters all events with &lt;code>localhost&lt;/code> as the server
and &lt;code>MACHINE$&lt;/code> as target user. A recommended hunt for lateral movement would
be activity to other machines from commonly abused LOLBins or explicit logon
events from unusual processes.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.ExplicitLogon
description: |
 Searches the Windows Security event log for explicit logon events, that is
 Event ID 4648: "A logon was attempted using explicit credentials".

 If logging is enabled, these events are generated on the source machine
 whenever an authentication attempt occurs under a different user context.
 Examples include a user authenticating to another machine using wmic or
 mapping a drive using different credentials, or using the RunAs option
 locally.

 This artifact by default filters all events with `localhost` as the server
 and `MACHINE$` as target user. A recommended hunt for lateral movement would
 be activity to other machines from commonly abused LOLBins or explicit logon
 events from unusual processes.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: EvtxGlob
 default: '%SystemRoot%\System32\Winevt\Logs\Security.evtx'
 - name: UsernameRegex
 description: "Target username Regex"
 default: .
 type: regex
 - name: UsernameWhitelist
 description: "Target username witelist Regex"
 default: '\\$$'
 type: regex
 - name: ServerRegex
 description: "Target server regex"
 default: .
 type: regex
 - name: ServerWhitelist
 description: "Target server whitelist regex"
 default: 'localhost'
 type: regex
 - name: ProcessNameRegex
 description: "Target process Regex"
 default: .
 - name: ProcessNameWhitelist
 description: "Target process whitelist Regex"
 type: regex

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"


sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths = SELECT OSPath
 FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)

 -- function returning IOC hits
 LET evtxsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
 System.Computer as Computer,
 System.EventID.Value as EventID,
 System.EventRecordID as EventRecordID,
 EventData.SubjectUserName as SubjectUserName,
 EventData.SubjectDomainName as SubjectDomainName,
 EventData.TargetUserName as TargetUserName,
 EventData.TargetDomainName as TargetDomainName,
 EventData.TargetServerName as TargetServerName,
 EventData.ProcessName as ProcessName,
 EventData,
 Message,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE
 EventID = 4648
 AND EventTime &amp;lt; DateBeforeTime
 AND EventTime &amp;gt; DateAfterTime
 AND TargetUserName =~ UsernameRegex
 AND NOT if(condition=UsernameWhitelist,
 then= TargetUserName =~ UsernameWhitelist,
 else= FALSE)
 AND TargetServerName =~ ServerRegex
 AND NOT if(condition=ServerWhitelist,
 then= TargetServerName =~ ServerWhitelist,
 else= FALSE)
 AND ProcessName =~ ProcessNameRegex
 AND NOT if(condition=ProcessNameWhitelist,
 then= ProcessName =~ ProcessNameWhitelist,
 else= FALSE)
 }
 )

 SELECT * FROM evtxsearch(PathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.Kerberoasting</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.kerberoasting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.kerberoasting/</guid><description>&lt;p>This Artifact will return all successful Kerberos TGS Ticket events for
Service Accounts (SPN attribute) implemented with weak encryption. These
tickets are vulnerable to brute force attack and this event is an indicator
of a Kerberoasting attack.&lt;/p>
&lt;p>Typical attacker methodology is to firstly request accounts in the domain
with SPN attributes, then request an insecure TGS ticket for brute forcing.
This attack is particularly effective as any domain credentials can be used
to implement the attack and service accounts often have elevated privileges.
Kerberoasting can be used for privilege escalation or persistence by adding a
SPN attribute to an unexpected account.&lt;/p>
&lt;p>Log Source: Windows Security Event Log (Domain Controllers).
Event ID: 4769
Status: 0x0 (Audit Success)
Ticket Encryption: 0x17 (RC4)
Service Name: NOT krbtgt or NOT a system account (account name ends in $)
TargetUserName: NOT a system account (&lt;em>$@&lt;/em>)&lt;/p>
&lt;p>Monitor and alert on unusual events with these conditions from an unexpected
IP.
Note: There are potential false positives so whitelist normal source IPs and
manage risk of insecure ticket generation.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.Kerberoasting
author: Matt Green - @mgreen27

description: |
 This Artifact will return all successful Kerberos TGS Ticket events for
 Service Accounts (SPN attribute) implemented with weak encryption. These
 tickets are vulnerable to brute force attack and this event is an indicator
 of a Kerberoasting attack.

 Typical attacker methodology is to firstly request accounts in the domain
 with SPN attributes, then request an insecure TGS ticket for brute forcing.
 This attack is particularly effective as any domain credentials can be used
 to implement the attack and service accounts often have elevated privileges.
 Kerberoasting can be used for privilege escalation or persistence by adding a
 SPN attribute to an unexpected account.

 Log Source: Windows Security Event Log (Domain Controllers).
 Event ID: 4769
 Status: 0x0 (Audit Success)
 Ticket Encryption: 0x17 (RC4)
 Service Name: NOT krbtgt or NOT a system account (account name ends in $)
 TargetUserName: NOT a system account (*$@*)

 Monitor and alert on unusual events with these conditions from an unexpected
 IP.
 Note: There are potential false positives so whitelist normal source IPs and
 manage risk of insecure ticket generation.

reference:
 - https://attack.mitre.org/techniques/T1208/
 - https://www.trustedsec.com/blog/art_of_kerberoast/

parameters:
 - name: EvtxGlob
 default: '%SystemRoot%\System32\winevt\logs\Security.evtx'
 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths = SELECT OSPath
 FROM glob(globs=expand(path=EvtxGlob))

 -- function returning IOC hits
 LET evtxsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
 System.EventID.Value as EventID,
 System.Computer as Computer,
 EventData.ServiceName as ServiceName,
 EventData.ServiceSid as ServiceSid,
 EventData.TargetUserName as TargetUserName,
 format(format="0x%x", args=EventData.Status) as Status,
 EventData.TargetDomainName as TargetDomainName,
 format(format="0x%x", args=EventData.TicketEncryptionType) as TicketEncryptionType,
 format(format="0x%x", args=EventData.TicketOptions) as TicketOptions,
 EventData.TransmittedServices as TransmittedServices,
 EventData.IpAddress as IpAddress,
 EventData.IpPort as IpPort,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE
 System.EventID.Value = 4769
 AND EventData.TicketEncryptionType = 23
 AND EventData.Status = 0
 AND NOT EventData.ServiceName =~ "krbtgt|\\$$"
 AND NOT EventData.TargetUserName =~ "\\$@"
 })


 SELECT * FROM evtxsearch(PathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.Modifications</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.modifications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.modifications/</guid><description>&lt;p>It is possible to disable windows event logs on a per channel or per
provider basis. Attackers may disable critical log sources to
prevent detections.&lt;/p>
&lt;p>This artifact reads the state of the event log system from the
registry and attempts to detect when event logs were disabled.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.Modifications
description: |
 It is possible to disable windows event logs on a per channel or per
 provider basis. Attackers may disable critical log sources to
 prevent detections.

 This artifact reads the state of the event log system from the
 registry and attempts to detect when event logs were disabled.

precondition:
 SELECT * FROM info() WHERE OS =~ "windows"

parameters:
 - name: ProviderRegex
 default: .
 type: regex
 - name: DateAfter
 description: "search for modifications after this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: DateBefore
 description: "search for modifications before this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp

sources:
 - name: Channels
 description: Detects status of log channels (event log files).
 query: |
 -- Build time bounds
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=DateAfter, else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=DateBefore, else=timestamp(epoch="2200-01-01"))

 LET Key = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Channels\\*"

 SELECT Key.Mtime AS Mtime,
 basename(path=Key.OSPath) AS ChannelName,
 Key.OSPath AS _Key,
 OwningPublisher, Enabled
 FROM read_reg_key(globs=Key)
 WHERE ChannelName =~ ProviderRegex
 AND Mtime &amp;gt; DateAfterTime
 AND Mtime &amp;lt; DateBeforeTime

 - name: Providers
 description: Inspect the state of each provider
 query: |
 LET Key = "HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\WMI\\Autologger\\EventLog-System\\**\\Enabled"
 LET Publishers = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Publishers\\*\\@"

 LET ProviderNames &amp;lt;= memoize(key="GUID", query={
 SELECT OSPath.Components[-2] AS GUID,
 Data.value AS Name
 FROM glob(globs=Publishers, accessor="registry")
 })

 LET X = SELECT Mtime,
 OSPath.Dirname.Basename AS GUID,
 Data.value AS Enabled,
 OSPath.Dirname AS Key,
 to_dict(item={
 SELECT Name AS _key, Data.value AS _value
 FROM glob(root=OSPath.Dirname,
 globs="/*",
 accessor="registry")
 }) AS Content
 FROM glob(globs=Key, accessor="registry")

 SELECT Mtime, GUID, Key AS _RegKey,
 get(item=ProviderNames, member=GUID).Name AS ProviderName,
 Enabled, Content
 FROM X
 WHERE ProviderName =~ ProviderRegex
 AND Mtime &amp;gt; DateAfterTime
 AND Mtime &amp;lt; DateBeforeTime
 ORDER BY ProviderName

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.PowershellModule</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.powershellmodule/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.powershellmodule/</guid><description>&lt;p>This Artifact will search and extract Module events (Event ID 4103) from
Powershell-Operational Event Logs.&lt;/p>
&lt;p>PowerShell is commonly used by attackers across all stages of the attack
lifecycle. Although quite noisy Module logging can provide valuable insight.&lt;/p>
&lt;p>There are several parameters available for search leveraging regex.&lt;/p>
&lt;ul>
&lt;li>DateAfter enables search for events after this date.&lt;/li>
&lt;li>DateBefore enables search for events before this date.&lt;/li>
&lt;li>ContextRegex enables regex search over ContextInfo text field.&lt;/li>
&lt;li>PayloadRegex enables a regex search over Payload text field.&lt;/li>
&lt;li>SearchVSS enables VSS search&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.PowershellModule
description: |
 This Artifact will search and extract Module events (Event ID 4103) from
 Powershell-Operational Event Logs.

 PowerShell is commonly used by attackers across all stages of the attack
 lifecycle. Although quite noisy Module logging can provide valuable insight.

 There are several parameters available for search leveraging regex.
 - DateAfter enables search for events after this date.
 - DateBefore enables search for events before this date.
 - ContextRegex enables regex search over ContextInfo text field.
 - PayloadRegex enables a regex search over Payload text field.
 - SearchVSS enables VSS search


author: Matt Green - @mgreen27

reference:
 - https://attack.mitre.org/techniques/T1059/001/
 - https://www.fireeye.com/blog/threat-research/2016/02/greater_visibilityt.html

parameters:
 - name: EventLog
 default: C:\Windows\system32\winevt\logs\Microsoft-Windows-PowerShell%4Operational.evtx
 - name: DateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: DateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: ContextRegex
 description: "regex search over Payload text field."
 type: regex
 - name: PayloadRegex
 description: "regex search over Payload text field."
 type: regex

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor &amp;lt;= if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- Build time bounds
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

 -- Determine target files
 LET files =
 SELECT *, OSPath as Source
 FROM glob(globs=EventLog, accessor=Accessor)

 -- Main query
 LET hits = SELECT * FROM foreach(
 row=files,
 query={
 SELECT
 timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
 System.EventID.Value as EventID,
 System.Computer as Computer,
 System.Security.UserID as SecurityID,
 EventData.ContextInfo as ContextInfo,
 EventData.Payload as Payload,
 Message,
 System.EventRecordID as EventRecordID,
 System.Level as Level,
 System.Opcode as Opcode,
 System.Task as Task,
 Source
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE EventID = 4103
 AND EventTime &amp;gt; DateAfterTime
 AND EventTime &amp;lt; DateBeforeTime
 AND if(condition=ContextRegex,
 then=ContextInfo=~ContextRegex,else=TRUE)
 AND if(condition=PayloadRegex,
 then=ContextInfo=~PayloadRegex,else=TRUE)
 })
 ORDER BY Source DESC

 -- Output results
 SELECT
 EventTime,
 EventID,
 Computer,
 SecurityID,
 ContextInfo,
 Payload,
 Message,
 EventRecordID,
 Level,
 Opcode,
 Task,
 Source
 FROM hits

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.PowershellScriptblock</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.powershellscriptblock/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.powershellscriptblock/</guid><description>&lt;p>This Artifact will search and extract ScriptBlock events (Event ID 4104) from
Powershell-Operational Event Logs.&lt;/p>
&lt;p>PowerShell is commonly used by attackers across all stages of the attack
lifecycle. A valuable hunt is to search Scriptblock logs for signs of
malicious content.&lt;/p>
&lt;p>There are several parameters available for search leveraging regex.&lt;/p>
&lt;ul>
&lt;li>DateAfter enables search for events after this date.&lt;/li>
&lt;li>DateBefore enables search for events before this date.&lt;/li>
&lt;li>SearchStrings enables regex search over scriptblock text field.&lt;/li>
&lt;li>StringWhiteList enables a regex whitelist for scriptblock text field.&lt;/li>
&lt;li>PathWhitelist enables a regex whitelist for path of scriptblock.&lt;/li>
&lt;li>LogLevel enables searching on type of log. Default is Warning level which
is logged even if ScriptBlock logging is turned off when suspicious keywords
detected in PowerShell interpreter. See second reference for list of keywords.&lt;/li>
&lt;li>SearchVSS enables VSS search.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.PowershellScriptblock
author: Matt Green - @mgreen27

description: |
 This Artifact will search and extract ScriptBlock events (Event ID 4104) from
 Powershell-Operational Event Logs.

 PowerShell is commonly used by attackers across all stages of the attack
 lifecycle. A valuable hunt is to search Scriptblock logs for signs of
 malicious content.

 There are several parameters available for search leveraging regex.
 - DateAfter enables search for events after this date.
 - DateBefore enables search for events before this date.
 - SearchStrings enables regex search over scriptblock text field.
 - StringWhiteList enables a regex whitelist for scriptblock text field.
 - PathWhitelist enables a regex whitelist for path of scriptblock.
 - LogLevel enables searching on type of log. Default is Warning level which
 is logged even if ScriptBlock logging is turned off when suspicious keywords
 detected in PowerShell interpreter. See second reference for list of keywords.
 - SearchVSS enables VSS search.

reference:
 - https://attack.mitre.org/techniques/T1059/001/
 - https://github.com/PowerShell/PowerShell/blob/master/src/System.Management.Automation/engine/runtime/CompiledScriptBlock.cs#L1781-L1943

parameters:
 - name: EvtxGlob
 default: '%SystemRoot%\System32\winevt\logs\Microsoft-Windows-PowerShell%4Operational.evtx'
 - name: DateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: DateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: SearchStrings
 type: regex
 description: "regex search over scriptblock text field."
 - name: StringWhitelist
 description: "Regex of string to whitelist"
 type: regex
 - name: PathWhitelist
 description: "Regex of path to whitelist."
 type: regex
 - name: LogLevel
 description: "Log level. Warning is PowerShell default bad keyword list."
 type: choices
 default: Warning
 choices:
 - All
 - Warning
 - Verbose
 - name: LogLevelMap
 type: hidden
 default: |
 Choice,Regex
 All,"."
 Warning,"3"
 Verbose,"5"

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

 -- Parse Log level dropdown selection
 LET LogLevelRegex &amp;lt;= SELECT format(format="%v", args=Regex) as value
 FROM parse_csv(filename=LogLevelMap, accessor="data")
 WHERE Choice=LogLevel LIMIT 1

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths = SELECT OSPath
 FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)

 -- function returning IOC hits
 LET evtxsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
 System.Computer as Computer,
 System.Channel as Channel,
 System.EventID.Value as EventID,
 System.Security.UserID as SecurityID,
 EventData.Path as Path,
 EventData.ScriptBlockId as ScriptBlockId,
 EventData.ScriptBlockText as ScriptBlockText,
 get(field="Message") as Message,
 System.EventRecordID as EventRecordID,
 System.Level as Level,
 System.Opcode as Opcode,
 System.Task as Task,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE System.EventID.Value = 4104
 AND EventTime &amp;lt; DateBeforeTime
 AND EventTime &amp;gt; DateAfterTime
 AND format(format="%d", args=System.Level) =~ LogLevelRegex.value[0]
 AND if(condition=SearchStrings,
 then=ScriptBlockText =~ SearchStrings,
 else=TRUE)
 AND if(condition=StringWhitelist,
 then= NOT ScriptBlockText =~ StringWhitelist,
 else=TRUE)
 AND if(condition=PathWhitelist,
 then= NOT Path =~ PathWhitelist,
 else=TRUE)
 })

 SELECT * FROM evtxsearch(PathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.RDPAuth</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.rdpauth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.rdpauth/</guid><description>&lt;p>This artifact will extract Event Logs related to Remote Desktop sessions,
logon and logoff.&lt;/p>
&lt;p>Security channel - EventID in 4624,4634 AND LogonType 3, 7, or 10.
Security channel - EventID in 4778,4625,4779, or 4647.
System channel - EventID 9009.
Microsoft-Windows-TerminalServices-RemoteConnectionManager/Operational - EventID 1149.
Microsoft-Windows-TerminalServices-LocalSessionManager/Operational - EventID 23,22,21,24,25,39, or 40.&lt;/p>
&lt;p>Best use of this artifact is to collect RDP and Authentication events around
a timeframe of interest and order by EventTime to scope RDP activity.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.RDPAuth
author: "Matt Green - @mgreen27"
description: |
 This artifact will extract Event Logs related to Remote Desktop sessions,
 logon and logoff.

 Security channel - EventID in 4624,4634 AND LogonType 3, 7, or 10.
 Security channel - EventID in 4778,4625,4779, or 4647.
 System channel - EventID 9009.
 Microsoft-Windows-TerminalServices-RemoteConnectionManager/Operational - EventID 1149.
 Microsoft-Windows-TerminalServices-LocalSessionManager/Operational - EventID 23,22,21,24,25,39, or 40.

 Best use of this artifact is to collect RDP and Authentication events around
 a timeframe of interest and order by EventTime to scope RDP activity.

reference:
 - https://ponderthebits.com/2018/02/windows-rdp-related-event-logs-identification-tracking-and-investigation/

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: Security
 description: path to Security event log.
 default: '%SystemRoot%\System32\Winevt\Logs\Security.evtx'
 - name: System
 description: path to System event log.
 default: '%SystemRoot%\System32\Winevt\Logs\System.evtx'
 - name: LocalSessionManager
 description: path to TerminalServices-LocalSessionManager operational event log.
 default: '%SystemRoot%\System32\Winevt\Logs\Microsoft-Windows-TerminalServices-LocalSessionManager%4Operational.evtx'
 - name: RemoteConnectionManager
 description: path to TerminalServices-RemoteConnectionManager operational event log.
 default: '%SystemRoot%\System32\Winevt\Logs\Microsoft-Windows-TerminalServices-RemoteConnectionManager%4Operational.evtx'
 - name: DateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: DateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: SourceIPRegex
 default: ".+"
 type: regex
 - name: UserNameRegex
 default: ".+"
 type: regex
 - name: UserNameWhitelist
 default: '\$$'
 type: regex
 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")
 LET S = scope()

 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=DateAfter, else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=DateBefore, else=timestamp(epoch="2200-01-01"))

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths &amp;lt;= SELECT OSPath
 FROM glob(globs=[
 expand(path=Security),
 expand(path=System),
 expand(path=LocalSessionManager),
 expand(path=RemoteConnectionManager)], accessor=Accessor)

 -- function returning query hits
 LET evtxsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
 System.Computer as Computer,
 System.Channel as Channel,
 System.EventID.Value as EventID,
 if(condition= System.Channel='Security',
 then= S.EventData.TargetDomainName,
 else= if(condition= S.UserData.EventXML.User,
 then= split(string=S.UserData.EventXML.User,sep='\\\\')[0],
 else= if(condition= S.UserData.EventXML.Param2,
 then= S.UserData.EventXML.Param2,
 else= 'null' ))) as DomainName,
 if(condition= System.Channel='Security',
 then= S.EventData.TargetUserName,
 else= if(condition= S.UserData.EventXML.User,
 then= split(string=S.UserData.EventXML.User,sep='\\\\')[1],
 else= if(condition= S.UserData.EventXML.Param1,
 then= S.UserData.EventXML.Param1,
 else= 'null' ))) as UserName,
 if(condition= System.Channel='Security',
 then= if(condition= S.EventData.LogonType,
 then= S.EventData.LogonType,
 else= 'null' ),
 else= 'null' ) as LogonType,
 if(condition= System.Channel='Security',
 then= if(condition= S.EventData.IpAddress,
 then= S.EventData.IpAddress,
 else= 'null' ),
 else= if(condition= System.Channel=~'TerminalServices',
 then= if(condition= S.UserData.EventXML.Address,
 then= S.UserData.EventXML.Address,
 else= if(condition= S.UserData.EventXML.Param3,
 then= S.UserData.EventXML.Param3,
 else= 'null')),
 else= 'null' )) as SourceIP,
 if(condition= System.Channel=~'TerminalServices|System',
 then=
 get(item=dict(
 `21`='RDP_LOCAL_CONNECTED',
 `22`='RDP_REMOTE_CONNECTED',
 `23`='RDP_SESSION_LOGOFF',
 `24`='RDP_LOCAL_DISCONNECTED',
 `25`='RDP_REMOTE_RECONNECTION',
 `39`='RDP_REMOTE_DISCONNECTED_FORMAL',
 `40`='RDP_REMOTE_DISCONNECTED_REASON',
 `1149`='RDP_INITIATION_SUCCESSFUL',
 `9009`='DESKTOPWINDOWMANAGER_CLOSED'),
 member=str(str=System.EventID.Value)),
 else=if(condition= System.EventID.Value = 4624
 AND S.EventData.LogonType = 10,
 then='RDP_LOGON_SUCCESSFUL_NEW',
 else=if(condition= System.EventID.Value = 4624
 AND S.EventData.LogonType = 3,
 then='LOGON_SUCCESSFUL',
 else=if(condition= System.EventID.Value = 4624
 AND S.EventData.LogonType = 7,
 then='LOGON_SUCCESSFUL_OLD',
 else=if(condition= System.EventID.Value = 4625
 AND S.EventData.LogonType = 3,
 then='LOGON_FAILED',
 else=if(condition= System.EventID.Value = 4625
 AND S.EventData.LogonType = 10,
 then='RDP_LOGON_FAILED',
 else=
 get(item=dict(
 `4778`='LOGON_RECONNECT_EXISTING',
 `4779`='SESSION_DISCONNECT',
 `4647`='USER_INITIATED_LOGOFF',
 `4634`='LOGOFF_DISCONNECT'),
 member=str(str=System.EventID.Value)
 ))))))) as Description,
 get(field="Message") as Message,
 System.EventRecordID as EventRecordID,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE
 ( Channel = 'Security'
 AND ( (EventID in (4624,4634) AND LogonType in (3,10,7))
 OR EventID in (4778,4625,4779,4647)))
 OR ( Channel = 'System' AND EventID = 9009 )
 OR ( Channel = 'Microsoft-Windows-TerminalServices-RemoteConnectionManager/Operational'
 AND EventID = 1149 )
 OR ( Channel = 'Microsoft-Windows-TerminalServices-LocalSessionManager/Operational'
 AND EventID in (23,22,21,24,25,39,40))
 AND EventTime &amp;lt; DateBeforeTime
 AND EventTime &amp;gt; DateAfterTime
 AND if(condition= UserNameWhitelist,
 then= NOT UserName =~ UserNameWhitelist,
 else= True)
 AND UserName =~ UserNameRegex
 AND SourceIP =~ SourceIPRegex
 }
 )

 SELECT * FROM if(condition=VSSAnalysisAge &amp;gt; 0,
 then={
 SELECT * FROM evtxsearch(PathList=fspaths)
 GROUP BY EventRecordID, Channel
 }, else={
 SELECT * FROM evtxsearch(PathList=fspaths)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.ScheduledTasks</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.scheduledtasks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.scheduledtasks/</guid><description>&lt;p>This artifact will extract Event Logs related to ScheduledTasks and provide
a nice format for simplified review.&lt;/p>
&lt;p>Adversaries may abuse tasks for execution, persistence, lateral movement or
privilege escalation. This artifact collates all events from
Microsoft-Windows-TaskScheduler/Operational event log channel and scheduled
task events from the Security log if configured.&lt;/p>
&lt;p>A common hunting use case may be collection all deleted scheduled tasks (EID 141),
all modified scheduled tasks (EID 140) then run frequency analysis and chase
down any abnormalities for the environment. Similarly task execution (EID 129)
and registration (EID 106) can be a good collection hunting for unusual paths.&lt;/p>
&lt;p>Pivoting can be via either: TaskSchedulerEventRegex, TaskName or IOC Regex
(e.g taskname|delete|created|update)&lt;/p>
&lt;p>Note: Audit Other Object Access Events is required to be implemented to record
scheduled tasks being registered, modified or disabled in the Security event
log channel.
See: Computer Configuration\Policies\Windows Settings\Security Settings\Advanced Audit Policy Configuration\Object Access&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.ScheduledTasks
description: |
 This artifact will extract Event Logs related to ScheduledTasks and provide
 a nice format for simplified review.

 Adversaries may abuse tasks for execution, persistence, lateral movement or
 privilege escalation. This artifact collates all events from
 Microsoft-Windows-TaskScheduler/Operational event log channel and scheduled
 task events from the Security log if configured.

 A common hunting use case may be collection all deleted scheduled tasks (EID 141),
 all modified scheduled tasks (EID 140) then run frequency analysis and chase
 down any abnormalities for the environment. Similarly task execution (EID 129)
 and registration (EID 106) can be a good collection hunting for unusual paths.

 Pivoting can be via either: TaskSchedulerEventRegex, TaskName or IOC Regex
 (e.g taskname|delete|created|update)

 Note: Audit Other Object Access Events is required to be implemented to record
 scheduled tasks being registered, modified or disabled in the Security event
 log channel.
 See: Computer Configuration\Policies\Windows Settings\Security Settings\Advanced Audit Policy Configuration\Object Access

author: "@mgreen27 - Matt Green"

precondition: SELECT OS From info() where OS = 'windows'

reference:
 - https://attack.mitre.org/techniques/T1053/005/
 - https://mnaoumov.wordpress.com/2014/05/15/task-scheduler-event-ids/

parameters:
 - name: Security
 description: path to Security event log.
 default: '%SystemRoot%\System32\Winevt\Logs\Security.evtx'
 - name: TaskScheduler
 description: path to the TaskScheduler/Operational event log
 default: '%SystemRoot%\System32\Winevt\Logs\Microsoft-Windows-TaskScheduler%4Operational.evtx'
 - name: DateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: DateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: TaskSchedulerEventRegex
 description: Regex of TaskScheduler log event ids.
 type: regex
 default: .
 - name: SecurityEventRegex
 description: regex of Security log event ids.
 type: regex
 default: '^(4698|4699|4700|4701|4702)$'
 - name: TaskNameRegex
 description: regex of target task name.
 default: .
 type: regex
 - name: TaskNameWhitelist
 description: regex of task names to exclude from results.
 default:
 type: regex
 - name: TaskActionRegex
 description: regex of target task execution process / path.
 default: .
 type: regex
 - name: TaskActionWhitelist
 description: regex of task processes to exclude from results.
 default:
 type: regex
 - name: UserNameRegex
 description: regex of target user name.
 default: .
 type: regex
 - name: IocRegex
 description: IOC regex to search for.
 default: .
 type: regex

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.


sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=DateAfter, else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=DateBefore, else=timestamp(epoch="2200-01-01"))

 -- Lookup what each task ID means (sadly dict keys are always strings).
 LET TaskIDLookup &amp;lt;= dict(
 `4698`="A scheduled task was created.",
 `4699`="A scheduled task was deleted.",
 `4700`="A scheduled task was enabled.",
 `4701`="A scheduled task was disabled.",
 `4702`="A scheduled task was updated.")

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths = SELECT OSPath
 FROM glob(globs=[expand(path=Security), expand(path=TaskScheduler)],
 accessor=Accessor)

 -- function to parse task content and replace xml in EventData
 LET parse_task(data) = dict(
 SubjectUserSid=data.SubjectUserSid,
 SubjectUserName=data.SubjectUserName,
 SubjectDomainName=data.SubjectDomainName,
 SubjectLogonId=data.SubjectLogonId,
 TaskName=data.TaskName,
 TaskContent=parse_xml(
 accessor='data',
 file=regex_replace(
 source= if(condition= data.TaskContentNew,
 then= data.TaskContentNew,
 else= if(condition= data.TaskContent,
 then= data.TaskContent)),
 re='&amp;lt;[?].+?&amp;gt;',
 replace='')).Task,

 ClientProcessStartKey=data.ClientProcessStartKey,
 ClientProcessId=data.ClientProcessId,
 ParentProcessId=data.ParentProcessId,
 RpcCallClientLocality=data.RpcCallClientLocality,
 FQDN=data.FQDN)


 -- function returning query hits
 LET evtxsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
 System.Computer as Computer,
 System.Channel as Channel,
 System.EventID.Value as EventID,
 System.EventRecordID as EventRecordID,
 if(condition=EventData.UserName,
 then= EventData.UserName,
 else= if(condition=EventData.UserContext,
 then=EventData.UserContext,
 else= if(condition=EventData.SubjectUserName,
 then= EventData.SubjectDomainName + '\\' + EventData.SubjectUserName,
 else= 'N/A' ))) as UserName,
 if(condition=EventData.TaskName,
 then= EventData.TaskName) as TaskName,
 if(condition=EventData.ActionName,
 then= EventData.ActionName,
 else= if(condition=EventData.Path,
 then= EventData.Path,
 else= 'N/A' )) as TaskAction,
 if(condition=EventData.TaskContent OR EventData.TaskContentNew,
 then= parse_task(data=EventData),
 else= EventData) as EventData,
 get(field="Message") as Message,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE
 (( Channel = 'Microsoft-Windows-TaskScheduler/Operational'
 AND str(str=EventID) =~ TaskSchedulerEventRegex )
 OR ( Channel = 'Security'
 AND str(str=EventID) =~ SecurityEventRegex ))
 AND TaskName =~ TaskNameRegex
 AND NOT if(condition= TaskNameWhitelist,
 then= TaskName =~ TaskNameWhitelist,
 else= False)
 AND TaskAction =~ TaskActionRegex
 AND NOT if(condition= TaskActionWhitelist,
 then= TaskName =~ TaskActionWhitelist,
 else= False)
 AND UserName =~ UserNameRegex
 AND format(format='%v %v %v %v', args=[
 EventData, UserData, Message, System]) =~ IocRegex
 AND EventTime &amp;gt;= DateAfterTime AND EventTime &amp;lt;= DateBeforeTime
 }
 )

 SELECT
 EventTime,
 Computer,
 Channel,
 EventID,
 EventRecordID,
 UserName,
 TaskName,
 if(condition= Channel = 'Microsoft-Windows-TaskScheduler/Operational',
 then= Message,
 else=get(item=TaskIDLookup, member=str(str=EventID))) as Message,
 if(condition= EventID =~'^(4698|4699|4700|4701|4702)$',
 then= if(condition= EventData.TaskContent.Actions,
 then= if(condition= EventData.TaskContent.Actions.Exec,
 then= if(condition= EventData.TaskContent.Actions.Exec.Arguments,
 then= EventData.TaskContent.Actions.Exec.Command + ' ' + EventData.TaskContent.Actions.Exec.Arguments,
 else= EventData.TaskContent.Actions.Exec.Command),
 else= if(condition=EventData.TaskContent.Actions.ComHandler.ClassId,
 then= 'ClassId: ' + EventData.TaskContent.Actions.ComHandler.ClassId))),
 else= TaskAction) as TaskAction,
 EventData,
 OSPath
 FROM evtxsearch(PathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.ServiceCreationComspec</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.servicecreationcomspec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.servicecreationcomspec/</guid><description>&lt;p>Detects the string &amp;ldquo;COMSPEC&amp;rdquo; (nocase) in Windows Service
Creation (SCM) events. That is: EventID 7045 from the System event log.&lt;/p>
&lt;p>This detects many hack tools that use SCM based lateral movement
including &lt;code>smbexec&lt;/code>.&lt;/p>
&lt;p>If &lt;code>VSSAnalysisAge&lt;/code> is non-zero then this enables querying VSS instances for
the &lt;code>EventLog&lt;/code> path, which includes event deduplication.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.ServiceCreationComspec
description: |
 Detects the string "COMSPEC" (nocase) in Windows Service
 Creation (SCM) events. That is: EventID 7045 from the System event log.

 This detects many hack tools that use SCM based lateral movement
 including `smbexec`.

 If `VSSAnalysisAge` is non-zero then this enables querying VSS instances for
 the `EventLog` path, which includes event deduplication.

author: Matt Green - @mgreen27

parameters:
 - name: EventLog
 default: C:\Windows\system32\winevt\logs\System.evtx
 - name: ComspecRegex
 default: "(COMSPEC|cmd.exe|ADMIN\\$)"
 type: regex

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

sources:
 - name: ServiceCreation
 query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 // Extract all target paths from glob
 LET files = SELECT OSPath
 FROM glob(globs=EventLog, accessor=Accessor)

 // Parse all target files, order by source and add dedupe string
 LET hits = SELECT * FROM foreach(
 row=files,
 query={
 SELECT timestamp(epoch=System.TimeCreated.SystemTime) as EventTime,
 System.EventID.Value as EventID,
 System.Computer as Computer,
 System.Security.UserID as SecurityID,
 EventData.AccountName as ServiceAccount,
 EventData.ServiceName as ServiceName,
 EventData.ImagePath as ImagePath,
 EventData.ServiceType as ServiceType,
 EventData.StartType as StartType,
 System.EventRecordID as EventRecordID,
 System.Level as Level,
 System.Opcode as Opcode,
 System.Task as Task,
 OSPath AS Source
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE System.EventID.Value = 7045 and
 EventData.ImagePath =~ ComspecRegex
 })
 ORDER BY Source DESC

 SELECT
 EventTime,
 EventID,
 Computer,
 SecurityID,
 ServiceAccount,
 ServiceName,
 ImagePath,
 ServiceType,
 StartType,
 EventRecordID,
 Source
 FROM hits

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.Symantec</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.symantec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.symantec/</guid><description>&lt;p>Query the Symantec Endpoint Protection Event Logs. The default artifact will
return EventId 51 and high value strings with goals bubble up some events for
triage.&lt;/p>
&lt;p>Note:
EventID selection is controlled by regex to allow multiple EID selections.
If running a hunt, consider also hunting EventId 45 - Tamper Protection
Detection (this will be noisy so whitelist is required).
IgnoreRegex allows filtering out events relevant to the target environment.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.Symantec
description: |
 Query the Symantec Endpoint Protection Event Logs. The default artifact will
 return EventId 51 and high value strings with goals bubble up some events for
 triage.

 Note:
 EventID selection is controlled by regex to allow multiple EID selections.
 If running a hunt, consider also hunting EventId 45 - Tamper Protection
 Detection (this will be noisy so whitelist is required).
 IgnoreRegex allows filtering out events relevant to the target environment.

reference:
 - https://www.nextron-systems.com/wp-content/uploads/2019/10/Antivirus_Event_Analysis_CheatSheet_1.7.2.pdf

author: Matt Green - @mgreen27

parameters:
 - name: SymantecEventLog
 default: C:\Windows\system32\winevt\logs\Symantec Endpoint Protection Client.evtx
 - name: RegexEventIds
 description: "Regex of Event IDs to hunt for. Consider EID 45 for Tamper Protection Detection"
 type: regex
 default: ^51$
 - name: TargetRegex
 description: "Regex to hunt for - default is high value SEP detections"
 default: "Infostealer|Hacktool|Mimi|SecurityRisk|WinCredEd|NetCat|Backdoor|Pwdump|SuperScan|XScan|PasswordRevealer|Trojan|Malscript|Agent|Malware|Exploit|webshell|cobalt|Mpreter|sploit|Meterpreter|RAR|7z|encrypted|tsclient|PerfLogs"
 type: regex
 - name: IgnoreRegex
 description: "Regex to ignore events with EventData strings matching."
 type: regex
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

sources:
 - query: |
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))
 SELECT timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
 System.EventID.Value as EventId,
 System.Computer as Computer,
 EventData.Data[0] as EventData
 FROM parse_evtx(filename=SymantecEventLog)
 WHERE
 EventTime &amp;lt; DateBeforeTime AND
 EventTime &amp;gt; DateAfterTime AND
 format(format="%v",args=System.EventID.Value) =~ RegexEventIds AND
 EventData =~ TargetRegex AND
 if(condition=IgnoreRegex,
 then= NOT EventData=~IgnoreRegex,
 else= True)

&lt;/code>&lt;/pre></description></item><item><title>Windows.EventLogs.Telerik</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.telerik/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.eventlogs.telerik/</guid><description>&lt;p>This Artifact will hunt for evidence of Telerik exploitation in the Application
Event Log.&lt;/p>
&lt;p>Telerik is a commonly exploited component of IIS web pages that has been
actively targeted by actors via several CVEs. Several tools and attack
capabilities exist making exploitation of vulnerable services trivial. Due to
the nature of the software and typical deployments the patches may require
manual application.&lt;/p>
&lt;p>IocRegex enables searching for regex in the whole EventData field.
Output of this artifact is targeted fields from EventID 1309 to provide
context for the hit.&lt;/p>
&lt;p>This Artifact will hunt for evidence of Telerik exploitation in the Application Event Log.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.EventLogs.Telerik
description: |
 This Artifact will hunt for evidence of Telerik exploitation in the Application
 Event Log.

 Telerik is a commonly exploited component of IIS web pages that has been
 actively targeted by actors via several CVEs. Several tools and attack
 capabilities exist making exploitation of vulnerable services trivial. Due to
 the nature of the software and typical deployments the patches may require
 manual application.

 IocRegex enables searching for regex in the whole EventData field.
 Output of this artifact is targeted fields from EventID 1309 to provide
 context for the hit.

 This Artifact will hunt for evidence of Telerik exploitation in the Application Event Log.

author: Matt Green - @mgreen27

reference:
 - https://www.cyber.gov.au/acsc/view-all-content/advisories/advisory-2020-004-remote-code-execution-vulnerability-being-actively-exploited-vulnerable-versions-telerik-ui-sophisticated-actors
 - https://attack.mitre.org/techniques/T1190/

parameters:
 - name: EvtxGlob
 default: '%SystemRoot%\System32\Winevt\Logs\Application.evtx'
 - name: IocRegex
 description: "IOC Regex"
 default: telerik.*\\?type=rau
 type: regex
 - name: WhitelistRegex
 description: "Regex of string to witelist"
 type: regex
 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

sources:
 - precondition: SELECT OS From info() where OS = 'windows'

 query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then = DateAfter, else = "1600-01-01" )
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then = DateBefore, else = "2200-01-01" )

 -- expand provided glob into a list of paths on the file system (fs)
 LET fspaths = SELECT OSPath
 FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)

 -- function returning IOC hits
 LET evtxsearch(PathList) = SELECT * FROM foreach(
 row=PathList,
 query={
 SELECT
 timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
 System.Computer as Computer,
 System.Channel as Channel,
 System.EventID.Value as EventID,
 System.EventRecordID as EventRecordID,
 EventData.Data[17] as Exception,
 EventData.Data[16] as User,
 EventData.Data[15] as Process,
 EventData.Data[14] as Pid,
 EventData.Data[21] as SourceIP,
 EventData.Data[19] as Uri,
 EventData.Data[11] as SitePath,
 OSPath
 FROM parse_evtx(filename=OSPath, accessor=Accessor)
 WHERE EventID = 1309
 AND format(format='%v',args=EventData.Data) =~ IocRegex
 AND NOT if(condition=WhitelistRegex,
 then= format(format='%v',args=EventData.Data) =~ WhitelistRegex,
 else= FALSE )
 AND EventTime &amp;gt;= DateAfterTime AND EventTime &amp;lt;= DateBeforeTime
 }
 )

 SELECT * FROM evtxsearch(PathList=fspaths)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.EventLogModifications</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.eventlogmodifications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.eventlogmodifications/</guid><description>&lt;p>It is possible to disable windows event logs on a per channel or per
provider basis. Attackers may disable critical log sources to
prevent detections.&lt;/p>
&lt;p>This artifact monitors the state of the event log system from the
registry and attempts to detect when event logs were disabled.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.EventLogModifications
description: |
 It is possible to disable windows event logs on a per channel or per
 provider basis. Attackers may disable critical log sources to
 prevent detections.

 This artifact monitors the state of the event log system from the
 registry and attempts to detect when event logs were disabled.

type: CLIENT_EVENT

precondition:
 SELECT * FROM info() WHERE OS =~ "windows"

parameters:
 - name: Period
 type: int
 default: 60

sources:
 - query: |
 LET Publishers = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Publishers\\*\\@"

 LET ProviderNames &amp;lt;= memoize(key="GUID", query={
 SELECT OSPath.Components[-2] AS GUID,
 Data.value AS Name
 FROM glob(globs=Publishers, accessor="registry")
 })

 LET Key = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Channels\\*"

 LET Query = SELECT Key.Mtime AS Mtime,
 Key.OSPath[-1] AS ChannelName,
 format(format="%s/%v", args=[Key.OSPath[-1], Enabled]) AS QueryKey ,
 Key.OSPath AS _Key,
 get(item=ProviderNames, field=OwningPublisher).Name AS Publisher, Enabled
 FROM read_reg_key(globs=Key)

 SELECT * FROM diff(query=Query, period=Period, key="QueryKey")
 WHERE Diff =~ "added"

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.FailedLogBeforeSuccess</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.failedlogbeforesuccess/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.failedlogbeforesuccess/</guid><description>&lt;p>Sometimes attackers will brute force an local user&amp;rsquo;s account&amp;rsquo;s
password. If the account password is strong, brute force attacks are
not effective and might not represent a high value event in
themselves.&lt;/p>
&lt;p>However, if the brute force attempt succeeds, then it is a very high
value event (since brute forcing a password is typically a
suspicious activity).&lt;/p>
&lt;p>On the endpoint this looks like a bunch of failed logon attempts in
quick succession followed by a successful login.&lt;/p>
&lt;p>NOTE: In order for this artifact to work we need Windows to be
logging failed account login. This is not on by default and should
be enabled via group policy.&lt;/p>
&lt;p>&lt;a href="https://docs.microsoft.com/en-us/windows/security/threat-protection/auditing/basic-audit-logon-events" target="_blank" >https://docs.microsoft.com/en-us/windows/security/threat-protection/auditing/basic-audit-logon-events&lt;/a>
&lt;/p>
&lt;p>You can set the policy in Group Policy Management Console (GPMC):
&lt;code>Computer Configuration\Windows Settings\Security Settings\Local Policies\Audit Policy&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.FailedLogBeforeSuccess
description: |
 Sometimes attackers will brute force an local user's account's
 password. If the account password is strong, brute force attacks are
 not effective and might not represent a high value event in
 themselves.

 However, if the brute force attempt succeeds, then it is a very high
 value event (since brute forcing a password is typically a
 suspicious activity).

 On the endpoint this looks like a bunch of failed logon attempts in
 quick succession followed by a successful login.

 NOTE: In order for this artifact to work we need Windows to be
 logging failed account login. This is not on by default and should
 be enabled via group policy.

 https://docs.microsoft.com/en-us/windows/security/threat-protection/auditing/basic-audit-logon-events

 You can set the policy in Group Policy Management Console (GPMC):
 `Computer Configuration\Windows Settings\Security Settings\Local Policies\Audit Policy`.
type: CLIENT_EVENT

parameters:
 - name: securityLogFile
 default: &amp;gt;-
 C:/Windows/System32/Winevt/Logs/Security.evtx

 - name: failureCount
 description: Alert if there are this many failures before the successful logon.
 default: 3

 - name: failedLogonTimeWindow
 default: 3600

sources:
 - precondition:
 SELECT OS FROM info() where OS = 'windows'
 query: |
 LET failed_logon = SELECT EventData as FailedEventData,
 System as FailedSystem
 FROM watch_evtx(filename=securityLogFile)
 WHERE System.EventID.Value = 4625


 LET last_5_events = SELECT FailedEventData, FailedSystem
 FROM fifo(query=failed_logon,
 max_rows=500,
 max_age=atoi(string=failedLogonTimeWindow))

 // Force the fifo to materialize.
 LET foo &amp;lt;= SELECT * FROM last_5_events

 LET success_logon = SELECT EventData as SuccessEventData,
 System as SuccessSystem
 FROM watch_evtx(filename=securityLogFile)
 WHERE System.EventID.Value = 4624

 SELECT * FROM foreach(
 row=success_logon,
 query={
 SELECT SuccessSystem.TimeCreated.SystemTime AS LogonTime,
 SuccessSystem, SuccessEventData,
 enumerate(items=FailedEventData) as FailedEventData,
 FailedSystem, count(items=SuccessSystem) as Count
 FROM last_5_events
 WHERE FailedEventData.SubjectUserName = SuccessEventData.SubjectUserName
 GROUP BY LogonTime
 }) WHERE Count &amp;gt; atoi(string=failureCount)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.Kerberoasting</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.kerberoasting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.kerberoasting/</guid><description>&lt;p>&lt;strong>Description&lt;/strong>:
This Artifact will monitor all successful Kerberos TGS Ticket events for
Service Accounts (SPN attribute) implemented with weak encryption. These
tickets are vulnerable to brute force attack and this event is an indicator
of a Kerberoasting attack.&lt;/p>
&lt;p>&lt;strong>ATT&amp;amp;CK&lt;/strong>: &lt;a href="https://attack.mitre.org/techniques/T1208/" target="_blank" >T1208 - Kerberoasting&lt;/a>

Typical attacker methodology is to firstly request accounts in the domain
with SPN attributes, then request an insecure TGS ticket for brute forcing.
This attack is particularly effective as any domain credentials can be used
to implement the attack and service accounts often have elevated privileges.
Kerberoasting can be used for privilege escalation or persistence by adding a
SPN attribute to an unexpected account.&lt;/p>
&lt;p>&lt;strong>Reference&lt;/strong>: &lt;a href="https://www.trustedsec.com/2018/05/art_of_kerberoast/" target="_blank" >The Art of Detecting Kerberoast Attacks&lt;/a>

&lt;strong>Log Source&lt;/strong>: Windows Security Event Log (Domain Controllers)
&lt;strong>Event ID&lt;/strong>: 4769
&lt;strong>Status&lt;/strong>: 0x0 (Audit Success)
&lt;strong>Ticket Encryption&lt;/strong>: 0x17 (RC4)
&lt;strong>Service Name&lt;/strong>: NOT krbtgt or NOT a system account (account name ends in $)
&lt;strong>TargetUserName&lt;/strong>: NOT a system account (&lt;em>$@&lt;/em>)&lt;/p>
&lt;p>Monitor and alert on unusual events from an unexpected IP.
Note: There are potential false positives so whitelist normal source IPs and
manage risk of insecure ticket generation.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.Kerberoasting
description: |
 **Description**:
 This Artifact will monitor all successful Kerberos TGS Ticket events for
 Service Accounts (SPN attribute) implemented with weak encryption. These
 tickets are vulnerable to brute force attack and this event is an indicator
 of a Kerberoasting attack.

 **ATT&amp;amp;CK**: [T1208 - Kerberoasting](https://attack.mitre.org/techniques/T1208/)
 Typical attacker methodology is to firstly request accounts in the domain
 with SPN attributes, then request an insecure TGS ticket for brute forcing.
 This attack is particularly effective as any domain credentials can be used
 to implement the attack and service accounts often have elevated privileges.
 Kerberoasting can be used for privilege escalation or persistence by adding a
 SPN attribute to an unexpected account.

 **Reference**: [The Art of Detecting Kerberoast Attacks](https://www.trustedsec.com/2018/05/art_of_kerberoast/)
 **Log Source**: Windows Security Event Log (Domain Controllers)
 **Event ID**: 4769
 **Status**: 0x0 (Audit Success)
 **Ticket Encryption**: 0x17 (RC4)
 **Service Name**: NOT krbtgt or NOT a system account (account name ends in $)
 **TargetUserName**: NOT a system account (*$@*)


 Monitor and alert on unusual events from an unexpected IP.
 Note: There are potential false positives so whitelist normal source IPs and
 manage risk of insecure ticket generation.


author: Matt Green - @mgreen27

type: CLIENT_EVENT

parameters:
 - name: eventLog
 default: C:\Windows\system32\winevt\logs\Security.evtx

sources:
 - name: Kerberoasting
 query: |
 LET files = SELECT * FROM glob(globs=eventLog)

 SELECT timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
 System.EventID.Value as EventID,
 System.Computer as Computer,
 EventData.ServiceName as ServiceName,
 EventData.ServiceSid as ServiceSid,
 EventData.TargetUserName as TargetUserName,
 "0x" + format(format="%x", args=EventData.Status) as Status,
 EventData.TargetDomainName as TargetDomainName,
 "0x" + format(format="%x", args=EventData.TicketEncryptionType) as TicketEncryptionType,
 "0x" + format(format="%x", args=EventData.TicketOptions) as TicketOptions,
 EventData.TransmittedServices as TransmittedServices,
 EventData.IpAddress as IpAddress,
 EventData.IpPort as IpPort
 FROM foreach(
 row=files,
 async=TRUE,
 query={
 SELECT *
 FROM watch_evtx(filename=OSPath)
 WHERE System.EventID.Value = 4769
 AND EventData.TicketEncryptionType = 23
 AND EventData.Status = 0
 AND NOT EventData.ServiceName =~ "krbtgt|\\$$"
 AND NOT EventData.TargetUserName =~ "\\$@"
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.Mutants</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.mutants/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.mutants/</guid><description>&lt;p>This artifact detects creation of Mutants and triggers an alert.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.Mutants
description: |
 This artifact detects creation of Mutants and triggers an alert. 

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

precondition:
 SELECT * FROM info() WHERE OS =~ "windows"

parameters:
 - name: processRegex
 description: A regex applied to process names.
 default: .
 type: regex
 - name: Period
 type: int
 default: 120
 - name: MutantNameRegex
 default: EvilMutant
 type: regex
 - name: AlertName
 default: "Suspicious mutex created"
 - name: diff
 default: added
 - name: enrich
 description: Enrich mutex with process information. Closely monitor the performance impact if you enable this.
 type: bool
 default: N

sources:
 - query: |
 
 LET processes = SELECT Pid AS ProcPid, Name AS ProcName, Exe FROM process_tracker_pslist() WHERE ProcName =~ processRegex AND int(int=ProcPid) &amp;gt; 0

 LET query_mutant = SELECT * FROM winobj() WHERE Type = "Mutant" AND Name =~ MutantNameRegex 

 LET query_enriched = SELECT * FROM foreach(
 row=processes,
 query={
 SELECT ProcPid, ProcName, Exe, Type, Name, Handle
 FROM handles(pid=int(int=ProcPid), types="Mutant")
 })
 WHERE Type = "Mutant" AND Name =~ MutantNameRegex
 
 LET query_diff = if(condition=enrich, then=query_enriched, else=query_mutant) 
 
 SELECT *, alert(name=AlertName, Name=Name, Type=Type, Exe=Exe) as AlertSent FROM diff(query=query_diff, period=Period, key="Name") WHERE Diff = diff

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.ProcessCreation</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.processcreation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.processcreation/</guid><description>&lt;p>Collect all process creation events.&lt;/p>
&lt;p>This artifact relies on WMI to receive process start events. This
method is not as good as kernel mechanism used by Sysmon. It is more
reliable to use Sysmon instead via the
Windows.Sysinternals.SysmonLogForward artifact instead.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.ProcessCreation
description: |
 Collect all process creation events.

 This artifact relies on WMI to receive process start events. This
 method is not as good as kernel mechanism used by Sysmon. It is more
 reliable to use Sysmon instead via the
 Windows.Sysinternals.SysmonLogForward artifact instead.

type: CLIENT_EVENT

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 -- Add a small delay to allow the process tracker to catch up
 -- for enrichments.
 LET Delayed = SELECT * FROM delay(query={
 SELECT * FROM wmi_events(
 query="SELECT * FROM Win32_ProcessStartTrace",
 wait=5000000, // Do not time out.
 namespace="ROOT/CIMV2")
 }, delay=2)

 // Convert the timestamp from WinFileTime to Epoch.
 SELECT timestamp(winfiletime=atoi(string=Parse.TIME_CREATED)) as Timestamp,
 Parse.ParentProcessID as PPID,
 Parse.ProcessID as PID,
 Parse.ProcessName as Name,
 process_tracker_get(id=Parse.ProcessID).Data.CommandLine AS CommandLine,
 process_tracker_get(id=Parse.ParentProcessID).Data.CommandLine AS ParentCommandLine,
 join(array=process_tracker_callchain(id=Parse.ProcessID).Data.Name,
 sep=" &amp;lt;- ") AS CallChain
 FROM Delayed

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.ServiceCreation</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.servicecreation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.servicecreation/</guid><description>&lt;p>Monitor for creation of new services.&lt;/p>
&lt;p>New services are typically created by installing new software or
kernel drivers. Attackers will sometimes install a new service to
either insert a malicious kernel driver or as a persistence
mechanism.&lt;/p>
&lt;p>This event monitor extracts the service creation events from the
event log and records them on the server.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.ServiceCreation
description: |
 Monitor for creation of new services.

 New services are typically created by installing new software or
 kernel drivers. Attackers will sometimes install a new service to
 either insert a malicious kernel driver or as a persistence
 mechanism.

 This event monitor extracts the service creation events from the
 event log and records them on the server.
type: CLIENT_EVENT

parameters:
 - name: systemLogFile
 default: &amp;gt;-
 C:/Windows/System32/Winevt/Logs/System.evtx

sources:
 - precondition:
 SELECT OS from info() where OS = "windows"

 query: |
 SELECT System.TimeCreated.SystemTime as Timestamp,
 System.EventID.Value as EventID,
 EventData.ImagePath as ImagePath,
 EventData.ServiceName as ServiceName,
 EventData.ServiceType as Type,
 System.Security.UserID as UserSID,
 EventData as _EventData,
 System as _System
 FROM watch_evtx(filename=systemLogFile) WHERE EventID = 7045

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.Trackaccount</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackaccount/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackaccount/</guid><description>&lt;p>Artifact to detect account usage by monitoring event id 4624. This is useful for tracking attacker activity. If you want to receive Slack/Teams/Discord/etc alerts you can enable the server_event artifact named &amp;lsquo;Server.Alerts.Trackaccount&amp;rsquo;&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.Trackaccount
description: |
 Artifact to detect account usage by monitoring event id 4624. This is useful for tracking attacker activity. If you want to receive Slack/Teams/Discord/etc alerts you can enable the server_event artifact named 'Server.Alerts.Trackaccount'

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

parameters:
 - name: eventLog
 default: C:\Windows\system32\winevt\logs\Security.evtx
 - name: UserRegex
 default: 'admin|user'
 type: regex
 - name: LogonTypeRegex
 type: json_array
 default: '[2,3,4,5,7,8,9,10,11]'

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 LET files = SELECT * FROM glob(globs=eventLog)

 SELECT timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
 System.EventRecordID as EventRecordID,
 System.EventID.Value as EventID,
 System.Computer as SourceComputer,
 EventData.TargetUserName as TargetUserName,
 EventData.LogonType as LogonType,
 EventData.IpAddress as IpAddress,
 EventData.WorkstationName as TargetWorkstationName,
 System,
 EventData,
 Message

 FROM foreach(
 row=files,
 async=TRUE,
 query={
 SELECT *
 FROM watch_evtx(filename=OSPath)
 WHERE System.EventID.Value = 4624
 AND EventData.TargetUserName =~ UserRegex
 AND EventData.LogonType in LogonTypeRegex
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.TrackProcesses</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackprocesses/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackprocesses/</guid><description>&lt;p>Uses Sysmon and pslist to keep track of running processes by using the
Velociraptor Process Tracker.&lt;/p>
&lt;p>The Process Tracker keeps track of exited processes, and resolves
process call chains from it in memory cache.&lt;/p>
&lt;p>This event artifact enables the global process tracker and makes it
possible to run many other artifacts that depend on the process
tracker.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.TrackProcesses
description: |
 Uses Sysmon and pslist to keep track of running processes by using the
 Velociraptor Process Tracker.

 The Process Tracker keeps track of exited processes, and resolves
 process call chains from it in memory cache.

 This event artifact enables the global process tracker and makes it
 possible to run many other artifacts that depend on the process
 tracker.

type: CLIENT_EVENT

tools:
 - name: SysmonBinary
 url: https://live.sysinternals.com/tools/sysmon64.exe
 serve_locally: true

 - name: SysmonConfig
 url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
 serve_locally: true

parameters:
 - name: AlsoForwardUpdates
 type: bool
 description: |
 If set we also send process tracker state updates to
 the server.
 - name: MaxSize
 type: int64
 description: Maximum size of the in memory process cache (default 10k)

 - name: SysmonFileLocation
 description: If set, we check this location first for sysmon installed.
 default: C:/Windows/sysmon64.exe

 - name: AddEnrichments
 type: bool
 description: Add process information enrichments (can use more resources)

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 // Ensure that sysmon is installed.
 LET _ &amp;lt;= SELECT * FROM Artifact.Windows.Sysinternals.SysmonInstall(
 SysmonFileLocation=SysmonFileLocation)

 LET UpdateQuery =
 SELECT * FROM foreach(row={
 SELECT *,
 get(member='EventData') AS EventData
 FROM watch_etw(
 guid='{5770385f-c22a-43e0-bf4c-06f5698ffbd9}',
 description='Microsoft-Windows-Sysmon/Operational')
 }, query={
 SELECT * FROM switch(
 start={
 SELECT EventData.ProcessId AS id,
 EventData.ParentProcessId AS parent_id,
 "start" AS update_type,

 -- We need to manually build the dict here so
 -- we can maintain column ordering.
 dict(
 Pid=EventData.ProcessId,
 Ppid=EventData.ParentProcessId,
 Name=split(sep_string="\\", string=EventData.Image)[-1],
 StartTime=EventData.UtcTime,
 EndTime=NULL,
 Username=EventData.User,
 Exe=EventData.Image,
 CommandLine= EventData.CommandLine,
 CurrentDirectory= EventData.CurrentDirectory,
 FileVersion=EventData.FileVersion,
 Description= EventData.Description,
 Company= EventData.Company,
 Product= EventData.Product,
 ParentImage= EventData.ParentImage,
 ParentCommandLine= EventData.ParentCommandLine,
 TerminalSessionId= EventData.TerminalSessionId,
 IntegrityLevel= EventData.IntegrityLevel,
 Hashes=parse_string_with_regex(regex=[
 "SHA256=(?P&amp;lt;SHA256&amp;gt;[^,]+)",
 "MD5=(?P&amp;lt;MD5&amp;gt;[^,]+)",
 "IMPHASH=(?P&amp;lt;IMPHASH&amp;gt;[^,]+)"],
 string=EventData.Hashes)
 ) AS data,
 EventData.UtcTime AS start_time,
 NULL AS end_time
 FROM scope()
 WHERE System.ID = 1
 },
 end={
 SELECT EventData.ProcessId AS id,
 NULL AS parent_id,
 "exit" AS update_type,
 dict() AS data,
 NULL AS start_time,
 EventData.UtcTime AS end_time
 FROM scope()
 WHERE System.ID = 5
 })
 })

 LET SyncQuery =
 SELECT Pid AS id,
 Ppid AS parent_id,
 CreateTime AS start_time,
 dict(
 Name=Name,
 Username=Username,
 Exe=Exe,
 CommandLine=CommandLine) AS data
 FROM pslist()

 LET Tracker &amp;lt;= process_tracker(
 max_size=MaxSize,
 enrichments=if(condition=AddEnrichments, then=[
 '''x=&amp;gt;if(
 condition=NOT x.Data.VersionInformation AND x.Data.Image,
 then=dict(VersionInformation=parse_pe(file=x.Data.Image).VersionInformation))
 ''',
 '''x=&amp;gt;if(
 condition=NOT x.Data.OriginalFilename OR x.Data.OriginalFilename = '-',
 then=dict(OriginalFilename=x.Data.VersionInformation.OriginalFilename))
 '''], else=[]),
 sync_query=SyncQuery, update_query=UpdateQuery, sync_period=60000)

 SELECT * FROM process_tracker_updates()
 WHERE update_type = "stats" OR AlsoForwardUpdates

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.TrackProcessesBasic</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackprocessesbasic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackprocessesbasic/</guid><description>&lt;p>A basic process tracker which uses a simple polled pslist().&lt;/p>
&lt;p>The Process Tracker keeps track of exited processes, and resolves process call
chains from it in memory cache.&lt;/p>
&lt;p>This event artifact enables the global process tracker and makes it possible
to run many other artifacts that depend on the process tracker.&lt;/p>
&lt;p>This tracker DOES NOT require Sysmon and is &lt;strong>incompatible&lt;/strong> with
&lt;code>Windows.Events.TrackProcesses&lt;/code> and
&lt;code>Windows.Events.TrackProcessesETW&lt;/code> (only one should be running).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.TrackProcessesBasic
description: |
 A basic process tracker which uses a simple polled pslist().

 The Process Tracker keeps track of exited processes, and resolves process call
 chains from it in memory cache.

 This event artifact enables the global process tracker and makes it possible
 to run many other artifacts that depend on the process tracker.

 This tracker DOES NOT require Sysmon and is **incompatible** with
 `Windows.Events.TrackProcesses` and
 `Windows.Events.TrackProcessesETW` (only one should be running).

type: CLIENT_EVENT

parameters:
 - name: MaxSize
 type: int64
 description: Maximum size of the in memory process cache (default 10k)
 - name: PollPeriod
 type: int64
 description: How often to run pslist to track processes (in Seconds)
 default: 60

sources:
 - query: |
 LET SyncQuery =
 SELECT Pid AS id,
 Ppid AS parent_id,
 CreateTime AS start_time,
 dict(
 Name=Name,
 Username=Username,
 Exe=Exe,
 CommandLine=CommandLine) AS data
 FROM pslist()

 LET Tracker &amp;lt;= process_tracker(
 sync_query=SyncQuery, sync_period=1000 * PollPeriod)

 SELECT * FROM process_tracker_updates()
 WHERE update_type = "stats"

&lt;/code>&lt;/pre></description></item><item><title>Windows.Events.TrackProcessesETW</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackprocessesetw/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.events.trackprocessesetw/</guid><description>&lt;p>This artifact uses ETW to track process execution using the
Velociraptor Process Tracker.&lt;/p>
&lt;p>The Process Tracker keeps track of exited processes, and resolves
process call chains from it in memory cache.&lt;/p>
&lt;p>This event artifact enables the global process tracker and makes it
possible to run many other artifacts that depend on the process
tracker.&lt;/p>
&lt;p>This tracker DOES NOT require Sysmon and is &lt;strong>incompatible&lt;/strong> with
&lt;code>Windows.Events.TrackProcesses&lt;/code> and
&lt;code>Windows.Events.TrackProcessesBasic&lt;/code> (only one should be running).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Events.TrackProcessesETW
description: |
 This artifact uses ETW to track process execution using the
 Velociraptor Process Tracker.

 The Process Tracker keeps track of exited processes, and resolves
 process call chains from it in memory cache.

 This event artifact enables the global process tracker and makes it
 possible to run many other artifacts that depend on the process
 tracker.

 This tracker DOES NOT require Sysmon and is **incompatible** with
 `Windows.Events.TrackProcesses` and
 `Windows.Events.TrackProcessesBasic` (only one should be running).

type: CLIENT_EVENT

parameters:
 - name: MaxSize
 type: int64
 description: Maximum size of the in memory process cache (default 10k)
 - name: PollPeriod
 type: int64
 description: How often to run pslist to track processes (in Seconds)
 default: 60
 - name: AlsoForwardUpdates
 type: bool
 description: |
 If set we also send process tracker state updates to
 the server.

export: |
 LET EventSource = SELECT *
 FROM watch_etw(kernel_tracer_type=["process", "image_load"],
 guid="kernel")

 LET LRU &amp;lt;= lru(size=1000)

 -- only used to see what is goinng on.
 LET BuildDebugEvent(System, EventData) = dict(
 id=str(str=System.ProcessID),
 parent_id="0",
 update_type="debug",
 start_time=NULL,
 end_time=NULL,
 System=System,
 EventData=EventData,
 data=dict(foo=NULL)
 )

 LET BuildTerminateEvent(System, EventData) = dict(
 id=str(str=EventData.ProcessId),
 parent_id=str(str=EventData.ParentId),
 update_type="exit",
 start_time=NULL,
 end_time=System.TimeStamp,
 System=System,
 EventData=EventData,
 data=get(item=LRU, field=str(str=EventData.ProcessId)).data
 )

 LET BuildStartEvent(System, EventData) = dict(
 id=str(str=EventData.ProcessId),
 parent_id=str(str=EventData.ParentId),
 update_type="start",
 start_time=System.TimeStamp,
 end_time=NULL,
 System=System,
 EventData=EventData,
 data=dict(
 ProcessId=EventData.ProcessId,
 Created=System.TimeStamp,
 ParentId=EventData.ParentId,
 Username=EventData.UserSID,
 Name=EventData.ImageFileName,
 CommandLine=EventData.CommandLine,
 Exe=EventData.CommandLine
 ))

 -- Insert the event into the local LRU cache and return it.
 LET Cache(Pid, Event) = set(item=LRU, field=str(str=Pid), value=Event) &amp;amp;&amp;amp; Event

 -- Enrich the event with the new key value and return it.
 LET Enrich(Pid, Key, Value) = set(item=get(item=LRU,
 field=str(str=Pid)).data, field=Key, value=Value) &amp;amp;&amp;amp;
 get(item=LRU, field=str(str=Pid))

 -- Analyze the event and emit the relevant row if needed.
 LET EmitEvent(System, EventData) = if(

 -- Enrich process data with full executable path from
 -- LoadImage. This event usually comes after the CreateProcess
 -- so we have to re-emit the same event with the updated data.
 condition=System.KernelEventType = "LoadImage" &amp;amp;&amp;amp; EventData.FileName =~ ".exe$",
 then=Enrich(Pid=EventData.ProcessId, Key="Exe", Value=EventData.FileName),
 else=if(

 -- Cache the process record so we can re-emit it with extra details later.
 condition=System.KernelEventType = "CreateProcess",
 then=Cache(Pid=EventData.ProcessId, Event=
 BuildStartEvent(System=System, EventData=EventData)),
 else=if(
 condition=System.KernelEventType = "TerminateProcess",
 then=BuildTerminateEvent(System=System, EventData=EventData))))

 LET UpdateQuery = SELECT * FROM foreach(row=EventSource,
 query={
 SELECT id, parent_id, update_type, start_time, end_time, data
 FROM foreach(row=EmitEvent(System=System, EventData=EventData))
 })

 LET SyncQuery = SELECT Pid AS id,
 Ppid AS parent_id,
 CreateTime AS start_time,
 dict(
 Name=Name,
 Username=Username,
 Exe=Exe,
 CommandLine=CommandLine) AS data
 FROM pslist()

precondition: |
 SELECT OS From info() where OS = 'windows'

sources:
- query: |
 LET Tracker &amp;lt;= process_tracker(
 max_size=MaxSize, sync_query=SyncQuery, update_query=UpdateQuery, sync_period=60000)

 SELECT * FROM process_tracker_updates()
 WHERE update_type = "stats" OR AlsoForwardUpdates

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.Bam</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.bam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.bam/</guid><description>&lt;p>The Background Activity Moderator (BAM) is a Windows service that
Controls activity of background applications. This service exists
in Windows 10 only after Fall Creators update – version 1709.&lt;/p>
&lt;p>It provides full path of the executable file that was run on the
system and last execution date/time&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.Bam
description: |
 The Background Activity Moderator (BAM) is a Windows service that
 Controls activity of background applications. This service exists
 in Windows 10 only after Fall Creators update – version 1709.

 It provides full path of the executable file that was run on the
 system and last execution date/time

reference:
 - https://andreafortuna.org/2018/05/23/forensic-artifacts-evidences-of-program-execution-on-windows-systems/

parameters:
 - name: bamKeys
 type: csv
 default: |
 KeyGlob
 HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\bam\UserSettings\*\*
 HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\bam\State\UserSettings\*\*
 - name: userRegex
 default: .
 type: regex

sources:
 - precondition:
 SELECT OS from info() where OS = "windows"
 query: |
 LET users &amp;lt;= SELECT Name, UUID
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex

 SELECT OSPath.Components[-2] as SID, {
 SELECT Name FROM users
 WHERE UUID = OSPath.Components[-2]
 } As UserName,
 Name as Binary,
 timestamp(winfiletime=parse_binary(
 filename=Data.value, accessor="data",
 profile="[]", struct="int64")) AS Bam_time
 FROM glob(globs=bamKeys.KeyGlob, accessor="registry")
 WHERE Data.type =~ "BINARY"

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.BulkExtractor</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.bulkextractor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.bulkextractor/</guid><description>&lt;p>This content will execute bulk_extractor with record carving plugins from
4n6ist. Initially developed to carve EventLogs from physical disk and
unallocated space, this content may also be used for other
bulk extractor capability. Best use case is for remote targeted machine
collection to remove the need for a disk image.&lt;/p>
&lt;p>&lt;strong>Settings&lt;/strong>
Target - Can be &lt;code>\\\\.\\PhysicalDrive[X], \\\\?\\HarddiskVolumeShadowCopy[Y]&lt;/code>
or &lt;code>C:\\Folder\\Path&lt;/code>
TargetAllPhysical - boolean option to include all attached physical disks
TargetVSS - boolean option to target all VSC
CarveEvtx - boolean option to include evtx carving
FindRegex - regex to include for BulkExtractor find plugins&lt;/p>
&lt;p>FreeCommand - supersedes evtx or find options and allows free form switch
generation for ad-hoc use cases.
e.g &lt;code>-E evtx, -e zip -S unzip_carve_mode=2'&lt;/code>
Will add:
command prefix: &lt;code>-q 99999999999 -R'&lt;/code> and
postfix: &lt;code>-o [Outfolder] [Target]&lt;/code>.
To make: &lt;code>bulk_extractor q 99999999999 -R -E evtx, -e zip -S unzip_carve_mode=2 -o [outfolder] [Target]&lt;/code>&lt;/p>
&lt;p>If FindRegex or &lt;code>-f&lt;/code> has been used in FreeCommand the artifact will attempt
to parse &lt;code>find.txt&lt;/code> output.&lt;/p>
&lt;p>&lt;strong>Note&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>Currently only supported for x64 bit machines.&lt;/li>
&lt;li>This artifact usually takes a long time. Ensure default timeout is high
enough for completion.&lt;/li>
&lt;li>This content is NOT recommended for hunting without great consideration as
bulk_extractor is a multithreaded tool and utilizes all CPU available on the
endpoint.&lt;/li>
&lt;li>The artifact copies carved data to the local disk prior to upload which
is not ideal from a forensic viewpoint.&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.BulkExtractor
description: |
 This content will execute bulk_extractor with record carving plugins from
 4n6ist. Initially developed to carve EventLogs from physical disk and
 unallocated space, this content may also be used for other
 bulk extractor capability. Best use case is for remote targeted machine
 collection to remove the need for a disk image.

 **Settings**
 Target - Can be `\\\\.\\PhysicalDrive[X], \\\\?\\HarddiskVolumeShadowCopy[Y]`
 or `C:\\Folder\\Path`
 TargetAllPhysical - boolean option to include all attached physical disks
 TargetVSS - boolean option to target all VSC
 CarveEvtx - boolean option to include evtx carving
 FindRegex - regex to include for BulkExtractor find plugins

 FreeCommand - supersedes evtx or find options and allows free form switch
 generation for ad-hoc use cases.
 e.g `-E evtx, -e zip -S unzip_carve_mode=2'`
 Will add:
 command prefix: `-q 99999999999 -R'` and
 postfix: `-o [Outfolder] [Target]`.
 To make: `bulk_extractor q 99999999999 -R -E evtx, -e zip -S unzip_carve_mode=2 -o [outfolder] [Target]`

 If FindRegex or `-f` has been used in FreeCommand the artifact will attempt
 to parse `find.txt` output.

 **Note**
 1. Currently only supported for x64 bit machines.
 2. This artifact usually takes a long time. Ensure default timeout is high
 enough for completion.
 3. This content is NOT recommended for hunting without great consideration as
 bulk_extractor is a multithreaded tool and utilizes all CPU available on the
 endpoint.
 4. The artifact copies carved data to the local disk prior to upload which
 is not ideal from a forensic viewpoint.

reference:
 - http://www.kazamiya.net/en/bulk_extractor-rec
 - http://downloads.digitalcorpora.org/downloads/bulk_extractor/BEUsersManual.pdf
 - https://simson.net/clips/academic/2013.COSE.bulk_extractor.pdf

author: Matt Green - @mgreen27

required_permissions:
 - EXECVE

implied_permissions:
 - FILESYSTEM_WRITE

tools:
 - name: Bulk_Extractor_Binary
 url: https://github.com/Velocidex/Tools/raw/main/BulkExtractor/bulk_extractor.exe
 serve_locally: true

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: Target
 description: "Target. Can by physical drive, \\\\?\\HarddiskVolumeShadowCopy1 or C:\\Folder\\Path"
 default: \\.\PhysicalDrive0
 - name: TargetAllPhysical
 description: "Target all attached physical drives"
 type: bool
 - name: TargetVSS
 description: "Target all VSC. Note: Not targeted to folder. Velociraptor CAN collect from the Volume Shadow direct targeted to folder with ntfs accessor so there may be a better way."
 type: bool
 - name: CarveEvtx
 description: "Carve EVTX files"
 type: bool
 - name: FindRegex
 description: "Regex for Bulk_extractor find plugin"
 - name: FreeCommand
 description: "Bulk_extractor custom commands. .e.g '-E evtx, -e zip -S unzip_carve_mode=2'"

sources:
 - query: |
 LET bin &amp;lt;= SELECT *
 FROM Artifact.Generic.Utils.FetchBinary(ToolName="Bulk_Extractor_Binary")
 LET tempfolder &amp;lt;= tempdir()
 LET ExePath &amp;lt;= tempfile(extension=".exe")

 LET target = SELECT
 DeviceID,
 if(condition=DeviceID=~"^\\\\\\\\.\\\\",
 then=split(string=split(string=DeviceID,sep='\\\\\\\\.\\\\')[1],
 sep='\\\\')[0],
 else="bulk_out") as base,
 _DeviceID
 FROM chain(
 a={
 SELECT
 DeviceID,
 upcase(string=DeviceID) as _DeviceID
 FROM Artifact.Windows.Sys.DiskInfo()
 WHERE TargetAllPhysical
 },
 b={
 SELECT
 Target as DeviceID,
 upcase(string=Target) as _DeviceID
 FROM scope()
 WHERE Target =~ '.'
 },
 c={
 SELECT
 regex_replace(source=OSPath,
 re="GLOBALROOT\\\\Device\\\\",replace="")AS DeviceID,
 Data.ID AS ShadowCopyID,
 upcase(string=regex_replace(source=OSPath,
 re="GLOBALROOT\\\\Device\\\\",replace="")) as _DeviceID
 FROM glob(globs='/*', accessor='ntfs')
 WHERE ShadowCopyID AND TargetVSS
 ORDER by OSPath
 })
 GROUP BY _DeviceID

 LET cmdline = SELECT (bin[0].OSPath, '-q', '99999999999', '-R') +
 CMD + '-o' as CMD FROM switch(
 a= {
 SELECT commandline_split(command=FreeCommand) AS CMD
 FROM scope()
 WHERE FreeCommand
 },
 b= {
 SELECT
 ('-E','evtx','-e','find','-f',FindRegex) AS CMD
 FROM scope()
 WHERE CarveEvtx AND FindRegex
 },
 c= {
 SELECT ('-E','evtx') AS CMD
 FROM scope()
 WHERE CarveEvtx
 },
 d= {
 SELECT ('-E','find','-f',FindRegex) AS CMD
 FROM scope()
 WHERE FindRegex
 },
 e= {
 SELECT ('-h') AS CMD FROM scope()
 })

 SELECT * FROM foreach(
 row=target,
 query= {
 SELECT *
 FROM execve(
 argv=cmdline[0].CMD + (
 tempfolder + '\\' +
 regex_replace(source=base, re='[^a-zA-Z]', replace='_'),
 DeviceID),
 length=10000000, sep='\n')})

 - name: FindResults
 query: |
 SELECT * FROM foreach(
 row={ SELECT *
 FROM glob(globs='/*/find.txt', root=tempfolder)
 },
 query={
 SELECT *
 FROM split_records(filenames=OSPath,first_row_is_headers=false,
 columns=['Location','Match','Data'],regex='\t')
 WHERE NOT Location =~ '#'
 })
 WHERE FindRegex OR FreeCommand =~ '-f'

 - name: Upload
 query: |
 SELECT upload(file=OSPath,
 name=strip(string=OSPath,prefix=tempfolder)) AS Upload
 FROM glob(globs="/**", root=tempfolder)
 WHERE Upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.CertUtil</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.certutil/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.certutil/</guid><description>&lt;p>The Windows Certutil binary is capable of downloading arbitrary files.
Attackers typically use it to fetch tools undetected when using &amp;ldquo;Living off
the Land&amp;rdquo; (LOL) techniques.&lt;/p>
&lt;p>Certutil maintains a cache of the downloaded files and this contains valuable
metadata. The artifact parses this metadata to establish what was downloaded
and when.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.CertUtil
description: |
 The Windows Certutil binary is capable of downloading arbitrary files.
 Attackers typically use it to fetch tools undetected when using "Living off
 the Land" (LOL) techniques.

 Certutil maintains a cache of the downloaded files and this contains valuable
 metadata. The artifact parses this metadata to establish what was downloaded
 and when.

reference:
 - https://u0041.co/blog/post/3
 - https://thinkdfir.com/2020/07/30/certutil-download-artefacts/
 - https://lolbas-project.github.io/lolbas/Binaries/Certutil/

parameters:
 - name: MinSize
 type: int
 description: Only show contents larger than this size.
 - name: URLWhitelist
 type: csv
 default: |
 URL
 http://sf.symcd.com
 http://oneocsp.microsoft.com
 http://certificates.godaddy.com
 http://ocsp.pki.goog
 http://repository.certum.pl
 http://www.microsoft.com
 http://ocsp.verisign.com
 http://ctldl.windowsupdate.com
 http://ocsp.sectigo.com
 http://ocsp.usertrust.com
 http://ocsp.comodoca.com
 http://cacerts.digicert.com
 http://ocsp.digicert.com
 - name: MetadataGlobUser
 default: C:/Users/*/AppData/LocalLow/Microsoft/CryptnetUrlCache/MetaData/*
 - name: MetadataGlobSystem
 default: C:/Windows/*/config/systemprofile/AppData/LocalLow/Microsoft/CryptnetUrlCache/MetaData/*
 - name: AlsoUpload
 type: bool

 - name: VSSAnalysisAge
 type: int
 default: 0
 description: |
 If larger than zero we analyze VSS within this many days
 ago. (e.g 7 will analyze all VSS within the last week). Note
 that when using VSS analysis we have to use the ntfs accessor
 for everything which will be much slower.

 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.


sources:
 - query: |
 LET VSS_MAX_AGE_DAYS &amp;lt;= VSSAnalysisAge
 LET Accessor = if(condition=VSSAnalysisAge &amp;gt; 0, then="ntfs_vss", else="auto")

 LET Profile = '[
 ["Header", 0, [
 ["UrlSize", 12, "uint32"],
 ["HashSize", 100, "uint32"],
 ["DownloadTime", 16, "uint64"],
 ["FileSize", 112, "uint32"],
 ["URL", 116, "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.UrlSize"
 }],
 ["Hash", "x=&amp;gt;x.UrlSize + 116", "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.HashSize"
 }]
 ]]
 ]'

 -- Build a whitelist regex
 LET URLRegex &amp;lt;= "^" + join(array=URLWhitelist.URL, sep="|")
 LET Files = SELECT OSPath,

 -- Parse each metadata file.
 parse_binary(filename=OSPath, accessor=Accessor,
 profile=Profile,
 struct="Header") AS Header,

 -- The content is kept in the Content directory.
 OSPath.Dirname.Dirname + "Content" + OSPath.Basename AS _ContentPath,
 read_file(length=4, accessor=Accessor,
 filename=OSPath.Dirname.Dirname + "Content" + OSPath.Basename) AS ContentHeader
 FROM glob(globs=[MetadataGlobUser, MetadataGlobSystem], accessor=Accessor)
 WHERE Header.FileSize &amp;gt; MinSize

 SELECT OSPath AS _MetadataFile, _ContentPath,
 if(condition=AlsoUpload, then=upload(file=OSPath, accessor=Accessor)) AS _MetdataUpload,
 if(condition=AlsoUpload, then=upload(file=_ContentPath, accessor=Accessor)) AS _Upload,
 Header.URL AS URL,
 url(parse=Header.URL).Host AS UrlTLD,
 Header.FileSize AS FileSize,
 regex_replace(re='"', replace="", source=Header.Hash) AS Hash,
 timestamp(winfiletime=Header.DownloadTime) AS DownloadTime,
 if(condition= ContentHeader=~ 'MZ',
 then= parse_pe(file= _ContentPath, accessor=Accessor).VersionInformation,
 else= 'N/A' ) as VersionInformation,
 if(condition= ContentHeader=~ 'MZ',
 then= authenticode(filename= _ContentPath, accessor=Accessor),
 else= 'N/A' ) as Authenticode

 FROM Files
 WHERE NOT URL =~ URLRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.FilenameSearch</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.filenamesearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.filenamesearch/</guid><description>&lt;p>Did a specific file exist on this machine in the past or does it
still exist on this machine?&lt;/p>
&lt;p>This common question comes up frequently in cases of IP theft,
discovery and other matters. One way to answer this question is to
search the $MFT file for any references to the specific filename. If
the filename is fairly unique then a positive hit on that name
generally means the file was present.&lt;/p>
&lt;p>Simply determining that a filename existed on an endpoint in the
past is significant for some investigations.&lt;/p>
&lt;p>This artifact applies a YARA search for a set of filenames of
interest on the $MFT file. For any hit, the artifact then identified
the MFT entry where the hit was found and attempts to resolve that
to an actual filename.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.FilenameSearch
description: |
 Did a specific file exist on this machine in the past or does it
 still exist on this machine?

 This common question comes up frequently in cases of IP theft,
 discovery and other matters. One way to answer this question is to
 search the $MFT file for any references to the specific filename. If
 the filename is fairly unique then a positive hit on that name
 generally means the file was present.

 Simply determining that a filename existed on an endpoint in the
 past is significant for some investigations.

 This artifact applies a YARA search for a set of filenames of
 interest on the $MFT file. For any hit, the artifact then identified
 the MFT entry where the hit was found and attempts to resolve that
 to an actual filename.

parameters:
 - name: yaraRule
 default: |
 rule Hit {
 strings:
 $a = "my secret file.txt" nocase wide ascii
 condition:
 any of them
 }
 type: yara
 - name: Device
 default: "C:"

sources:
 - query: |
 SELECT String.Offset AS Offset,
 String.HexData AS HexData,
 parse_ntfs(device=Device,
 mft=String.Offset / 1024) AS MFT
 FROM yara(
 rules=yaraRule, files=Device + "/$MFT",
 end=10000000000,
 number=1000,
 accessor="ntfs")

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.JumpLists</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.jumplists/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.jumplists/</guid><description>&lt;p>The automaticdestinations jumplist is an OLE2 container containing LNK files
as individual streams&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.JumpLists
description: |
 The automaticdestinations jumplist is an OLE2 container containing LNK files
 as individual streams

imports:
 - Windows.Forensics.Lnk

parameters:
 - name: Globs
 default: C:\Users\*\AppData\Roaming\Microsoft\Windows\Recent\AutomaticDestinations\*.automaticDestinations-ms

sources:
 - query: |
 // https://raw.githubusercontent.com/EricZimmerman/JumpList/a72a510b01922f60ce550c307e5f04131272448f/JumpList/Resources/AppIDs.txt
 LET AppIdTable &amp;lt;= '''AppId|Description
 0006f647f9488d7a|AIM 7.5.11.9 (custom AppID + JL support)
 00098b0ef1c84088|fulDC 6.78
 012dc1ea8e34b5a6|Microsoft Paint 6.1
 01b29f0dc90366bb|AIM 5.9.3857
 b08971c77377bde3|Visual Studio Enterprise 2015 Version 14.0 Update 3
 c31b3d36438b5e2c|Visual Studio Enterprise 2017 Version 15.9.10
 03d877ec11607fe4|Thunderbird 6.0.2
 044a50e6c87bc012|Classic FTP Plus 2.15
 a2b95ca27b6c33d9|Windows Live Photo Gallery
 fdbd48d45512dffc|Photoshop 7
 e26f61afb0824f2e|Photoshop CC 2015
 050620fe75ee0093|VMware Player 3.1.4
 a55ed4fbb973aefb|Microsoft Teams version 1.3.0.4461
 05e01ecaf82f7d8e|Scour Exchange 0.0.0.228
 06059df4b02360af|Kadu 0.10.0 / 0.6.5.5
 070b52cf73249257|Sococo 1.5.0.2274
 0a1d19afe5a80f80|FileZilla 2.2.32
 0a79a7ce3c45d781|CuteFTP 7.1 (Build 06.06.2005.1)
 0b17d3d0c9ca7e29|Document ViewerPicasa 3.8.0 (Build 117.43, 0)
 0b3f13480c2785ae|Paint 6.1 (build 7601: SP1)
 0b48ce76eda60b97|Shareaza 8.0.0.112300
 0cfab0ec14b6f953|Express NewsPictures 2.41 (Build 08.05.07.0)
 0ef606b196796ebb|HP MediaSmart Photo
 10f5a20c21466e85|FTP Voyager 15.2.0.17
 1110d9896dceddb3|imgSeek 0.8.5
 12dc1ea8e34b5a6|Microsoft Paint (built-in Win7)
 12dc1ea8e34b5a6|Microsoft Paint 6.1
 134620458666ccb0|TeraCopy 2.3 64-bit
 135df2a440abe9bb|SoulSeek 156c
 13eb0e5d9a49eaef|Binjet 3.0.2
 1434d6d62d64857d|BitLord 1.2.0-66
 14354e216395983a|Remote Desktop Manager 2.1.0.0 FREE
 1461132e553e2e6c|Firefox 6.0
 169b3be0bc43d592|FastPictureViewer Professional 1.6 (Build 211)
 16d71406474462b5|Snagit Editor 12.4.1
 16ec093b8f51508f|Opera 8.54 build 7730 / 9.64 build 10487 / 11.50 build 1074
 174c2c811c286c58|InfraRecorder 0.53.0.0 64-bit
 177aeb41deb606ae|Adobe Photoshop CS6 (64 Bit)
 17d3eb086439f0d7|TrueCrypt 7.0a
 17d3eb086439f0d7|TrueCrypt 7.1a 64-bit
 18434d518c3a61eb|Minitab 17
 186b5ccada1d986b|NewsGrabber 3.0.36
 19ccee0274976da8|mIRC 4.72 / 5.61
 19e6043495a5b4da|Edit Pad Pro
 1a60b1067913516a|Psi 0.14
 1a89d1befe8e90e3|Adobe Acrobat Distiller Pro XI 32-bit 11.0.0779
 1b29f0dc90366bb|AIM 5.9.3857
 1b4dd67f29cb1962|Windows Explorer (Win7)
 1b4dd67f29cb1962|Windows Explorer Pinned and Recent.
 1bc392b8e104a00e|Remote Desktop
 1bc392b8e104a00e|Remote Desktop Connection 6.1.7600 (Win7)
 1bc9bbbe61f14501|OneNote
 1c30573bdfce4155|Zenmap GUI 6.49BETA4
 1cf97c38a5881255|MediaPortal 1.1.3
 1cffbe973a437c74|DSPlayer 0.889 Lite
 1da3c90a72bf5527|Safari 4.0.5 (531.22.7) / 5.1 (7534.50)
 1eb796d87c32eff9|Firefox 5.0
 20ef367747c22564|Bullet Proof FTP 2010.75.0.75
 223bf0f360c6fea5|I2P 0.8.8 (restartable)
 226400522157fe8b|FileZilla Server 0.9.39 beta
 22c4d315e96389e0|FastCopy 3.12
 22cefa022402327d|Meca Messenger 5.3.0.52
 22cefa022402327d|Meca Messenger 5.3.0.52 (CHANGED)
 236461219accfae0|This is new 1(NEW)
 23646679aaccfae0|Adobe Acrobat 9.4.0
 23646679aaccfae0|Adobe Reader 9 x64
 23646679aaccfae0|Adobe Reader 9.
 23646679aaccfae0|Adobe Reader 9.x
 23646679aaccfae0|Adobe Reader 9.x(CHANGED)
 23709f643539f03d|TGHIS IS NEW 2(NEW)
 23709f6439b9f03d|Hex Editor Neo 5.14
 23709f6439b9f03d|Hex Editor Neo 5.14(CHANGED)
 23ef200ca6364eff|Oracle VM VirtualBox 5.0.16
 23f08dab0f6aaf30|SoMud 1.3.3
 2417caa1f2a881d4|ICQ 7.6 (Build 5617)
 2437d4d14b056114|EiskaltDC++ 2.2.3
 2519133d6d830f7e|IMatch 3.6.0.113
 2544ff74641b639d|WiseFTP 6.1.5
 26717493b25aa6e1|Adobe Dreamweaver CS5 (32-bit)
 26753c97ea000ecd|LibreOffice 5.1.0.3 Math
 271e609288e1210a|Microsoft Office Access 2010 x86
 27da120d7e75cf1f|pbFTPClient 6.1
 27ececd8d89b6767|AIM 6.2.14.2 / 6.5.3.12 / 6.9.17.2
 28493d9d08e13aa6|UltraVNC Viewer 1.2.1.0
 28c8b86deab549a1|Internet Explorer 8 / 9
 28c8b86deab549a1|Internet Explorer 8 / 9 / 10 (32-bit)
 28c8b86deab549a1|Internet Explorer 8.0.7600.16385 / 9
 290532160612e071|WinRAR 2.90 / 3.60 / 4.01
 290532160612e071|WinRar x64
 292a746334889a7e|SQLiteSpy 1.9.13
 2a5a615382a84729|X-Chat 2 2.8.6-2
 2aa756186e21b320|RealTimeQuery 3.2
 2b164f512891ae37|NewsWolf NSListGen
 2b53c4ddf69195fc|Zune x64
 2b5841989b3857da|RealVNC Server 5.3.0 64-bit (Chat)
 2ca2a1a69dc5465f|UltraVNC 1.2.1.0 Server Property Page
 2d1658d5dc3cbe2d|MySpaceIM 1.0.823.0 Beta
 2d61cccb4338dfc8|BitTorrent 5.0.0 / 6.0.0 / 7.2.1 (Build 25548)
 2db8e25112ab4453|Deluge 1.3.12 / 1.3.3
 2db8e25112ab4453|Deluge 1.3.3
 2fa14c7753239e4c|Paint.NET 2.72 / 3.5.8.4081.24580
 2ff9dc8fb7e11f39|I2P 0.8.8 (no window)
 3094cdb43bf5e9c2|Microsoft Office OneNote 2010 x86
 30d23723bdd5d908|Digsby (Build 30140) (JL support)
 315e29a36e961336|Roboform 7.8
 3168cc975b354a01|Slypheed 3.1.2 (Build 1120)
 3198e37206f28dc7|CuteFTP 8.3 Professional (Build 8.3.4.0007)
 319f01bf9fe00f2d|Microsoft Access 2013 64-bit
 319f01bf9fe00f2d|Microsoft Access 2016 64-bit
 31e8ac6b0784ed7d|Foxit Reader 9.4.0.16811
 3353b940c074fd0c|Microsoft Built-in Snipping Tool
 337ed59af273c758|Sticky Notes
 337ed59af273c758|Sticky Notes (Windows 10)
 3461e4d1eb393c9c|WTW 0.8.18.2852 / 0.8.19.2940
 353e9052cccbec5d|Kindle for PC 1.21.0
 3594aab44bca414b|Windows Photo Viewer
 36801066f71b73c5|Binbot 2.0
 36c36598b08891bf|Vovox 2.5.3.4250
 36f6bc3efe1d99e0|Alt.Binz 0.25.0 (Build 27.09.2007)
 37392221756de927|RealPlayer SP 12
 3866ff352d7719e1|Paint.NET 4.0.9
 386a2f6aa7967f36|EyeBrowse 2.7
 387d72eb9c9aa960|UltraVNC 1.2.1.0 Launcher
 3917dd550d7df9a8|Konvertor 4.06 (Build 10)
 3a5148bf2288a434|Secure FTP 2.6.1 (Build 20101209.1254)
 3be7b307dfccb58f|NiouzeFire 0.8.7.0
 3c0022d9de573095|QuteCom 2.2
 3c309c17f7e8ffe1|GIMP 2.8.16
 3c93a049a30e25e6|J. River Media Center 16.0.149
 3cf13d83b0bd3867|RevConnect 0.674p (based on DC++)
 3d877ec11607fe4|Thunderbird 6.0.2
 3dc02b55e44d6697|7-Zip 3.13 / 4.20
 3df22b7648cec4c1|TeamViewer 11.0.55321
 3e9850346f375d41|Foxit Phantom PDF 7.2.2.929
 3ed70ef3495535f7|Gravity 3.0.4
 3edf100b207e2199|digiKam 1.7.0 (KDE 4.4.4)
 3f2cd46691bbee90|GOIM 1.1.0
 3f97341a65bac63a|Ozum 6.07 (Build 6070)
 409b67100697bcc0|Revo Uninstaller Pro 3.1.5
 40f2aca05d8a33f2|Minitab 16
 411447f7de177c68|Windows DVD Maker 64-bit (Win7)
 4278d3dc044fc88a|Gaim 1.5.0
 431a5b43435cc60b|Python (.pyc)
 43578521d78096c6|Windows Media Player Classic Home Cinema 1.3 (32-bit)
 435a2f986b404eb7|SmartFTP 4.0.1214.0
 435a2f986b404eb7|SmartFTP 4.0.1214.0 / 7.0.2200.0
 43886ba3395acdcc|Easy Post 3.0
 44a3621b32122d64|Microsoft Office Word 2010 x64
 44a398496acc926d|Adobe Premiere Pro CS5 (64-bit)
 44a50e6c87bc012|Classic FTP Plus 2.15
 454ef7dca3bb16b2|Exodus 0.10.0.0
 469e4a7982cea4d4|? (.job)
 469e4a7982cea4d4|Windows Wordpad
 46f433176bc0b3d2|WinRAR 5.30 beta 64-bit
 4700ff5ae80a6713|PDFCreator 2.2
 490c000889535727|WinMX 4.9.3.0
 4975d6798a8bdf66|7-Zip 4.65 / 9.20
 497b42680f564128|Zoner PhotoStudio 13 (Build 7)
 49b5edbd92d8cd58|FTP Commander 8.02
 49db7ed4f2703c22|LogMeIn Client 1.3.1835
 4a49906d074a3ad3|Media Go 1.8 (Build 121)
 4a7e4f6a181d3d08|broolzShare
 4aa2a5710da3efe0|DCSharpHub 2.0.0
 4acae695c73a28c7|VLC 0.3.0 / 0.4.6
 4b632cf2ceceac35|Robo-FTP Server 3.2.5
 4b6925efc53a3c08|BCWipe 5.02.2 Task Manager 3.02.3
 4b6925efc53a3c08|BCWipe Task Manager 3.02.3 / 3.06.5.5
 4b8a4727aa452343|Firefox 56.0.2
 4c58cf9096ef3efd|Kindle for PC 1.24.3
 4cdf7858c6673f4b|Bullet Proof FTP 1.26
 4d72cfa1d0a67418|Newsgroup Image Collector
 4d7bdaea55ad352|PeaZip 6.0.0
 4d8bdacf5265a04f|The KMPlayer 2.9.4.1434
 4dd48f858b1a6ba7|Free Download Manager 3.0 (Build 852)
 4e0ac37db19cba15|Xfire 1.138 (Build 44507)
 4e538fde985a3c01|Torch Browser 65.0.0.1614 (x86)
 4f24a7b84a7de5a6|Palringo 2.6.3 (r45983)
 4fceec8e021ac978|CoffeeCup Free FTP 3.5.0.0
 4fd44f9938892caa|CDBurnerXP
 500b8c1d5302fc9c|Python (.pyw)
 50620fe75ee0093|VMware Player 12 build-3272444
 50620fe75ee0093|VMware Player 3.1.4
 50c5e019818564e3|Microsoft Excel Viewer 12.0.6219.1000
 521a29e5d22c13b4|Skype 1.4.0.84 / 2.5.0.154 / 3.8.0.139 / 4.2.0.187 / Skype 5.3.0.120 / 5.5.0.115 / 5.5.32.117
 54c803dfc87b52ba|Nettalk 6.7.12
 550abc1cb58eb92c|VeraCrypt 1.16 / 1.19 64-bit
 550abc1cb58eb92c|VeraCrypt 1.16 64-bit
 558c5bd9f906860a|BearShare Lite 5.2.5.1
 560d789a6a42ad5a|DC++ 0.261 / 0.698 / 0.782 (r2402.1)
 56c5204009d2b915|uTorrent 3.5.5
 590aee7bdd69b59b|Powershell Windows 10
 590aee7bdd69b59b|Windows Powershell 5.0 64-bit
 59e86071b87ac1c3|CuteFTP 8.3 (Build 8.3.4.0007)
 59f56184c796cfd4|ACDSee Photo Manager 10 (Build 219)
 5b186fc4a0b40504|Dtella 1.2.5 (Purdue network only)
 5b72f67adcce9045|UltraVNC 1.2.1.0 Settings
 5b7f3287093c1623|Total Commander 8.52a 64-bit
 5bb830f67194431a|7-Zip 18.05 (x64)
 5c450709f7ae4396|Firefox 1.0 / 2.0 / 3.0
 5c450709f7ae4396|Firefox 3.6.13 (32-bit)
 5d696d521de238c3|Chrome 9.0.597.84 / 12.0.742.100 / 13.0.785.215
 5d696d521de238c3|Chrome 9.0.597.84 / 12.0.742.100 / 13.0.785.215 / 26
 5d696d521de238c3|Google Chrome 9.0.597.84 / 12.0.742.100 / 13.0.785.215 / 48.0.2564.116
 5d6f13ed567aa2da|Microsoft Office Outlook 2010 x64
 5d7b4175afdcc260|Shareaza 2.0.0.0
 5da8f997fd5f9428|Internet Explorer x64
 5df4765359170e26|Firefox 4.0.1
 5e01ecaf82f7d8e|Scour Exchange 0.0.0.228
 5ea2a50c7979fbdc|TrustyFiles 3.1.0.22
 5f6e7bc0fb699772|Microsoft Office PowerPoint 2010 x64
 5f7b5f1e01b83767|Quick Access
 5fb817cd5a8cad21|Google Drive
 5fd959f6fe6b8ae7|PuTTY 0.70 (x64)
 6059df4b02360af|Kadu 0.10.0 / 0.6.5.5
 606a33f5a27b57d4|Microsoft Built-in Computer Management 10.0.10011.16384 (Win10)
 6224453d9701a612|BinTube 3.7.1.0 (requires VLC 10.5!)
 62bff50b969c2575|"Quintessential Media Player 5.0 (Build 121) - also usage stats (times used, tracks played, total time used)"
 62bff50b969c2575|Quintessential Media Player 5.0 (Build 121)
 62dba7fb39bb0adc|Yahoo Messenger 7.5.0.647 / 8.1.0.421 / 9.0.0.2162 / 10.0.0.1270
 65009083bfa6a094|(app launched via XPMode)
 65f7dd884b016ab2|LimeChat 2.39
 669967f27afdebec|NirSoft PstPassword 1.20 (x86)
 6728dd69a3088f97|Command Prompt
 6728dd69a3088f97|Windows Command Processor - cmd.exe (64-bit)
 6824f4a902c78fbd|Firefox 64.0
 689319b6547cda85|emesene 2.11.7
 6a316aa67a46820b|Core FTP LE 1.3c (Build 1437) / 2.2 (Build 1689)
 6a8b377d0f5cb666|WinSCP 2.3.0 (Build 146)
 6aa18a60024620ae|GCN 2.9.1
 6b3a5ce7ad4af9e4|IceChat 9 RC2
 6bb54d82fa42128d|WinSCP 4.3.4 (Build 1428)
 6bb98fb8cdc26d69|Calculator (Windows built-in)
 6bc3383cb68a3e37|iTunes 7.6.0.29 / 8.0.0.35
 6d2bac8f1edf6668|Microsoft Office Outlook 365
 6d2bac8f1edf6668|Microsoft Outlook 2013 32-bit
 6d2bac8f1edf6668|Microsoft Outlook 2016 64-bit
 6e855c85de07bc6a|Microsoft Office Excel 2010 x64
 6e9a79992da9ea2|Nokia PC Suite 7.1
 6e9d40a4c63bb562|Real Player Alternative 1.25 (Media Player Classic 6.4.8.2 / 6.4.9.0)
 6f647f9488d7a|AIM 7.5.11.9 (custom AppID + JL support)
 6fee01bd55a634fe|Smuxi 0.8.0.0
 7010c278903c2b0f|Adobe Acrobat XI Pro 32-bit
 70b52cf73249257|Sococo 1.5.0.2274
 70d9ada92108d731|IrfanView 4.51 (x64)
 714b179e552596df|Bullet Proof FTP 2.4.0 (Build 31)
 7192f2de78fd9e96|TIFNY 5.0.3
 728008617bc3e34b|eM Client 3.0.10206.0
 73c6a317412687c2|Google Talk 1.0.0.104
 73ce3745a843c0a4|FrostWire 5.1.4
 7494a606a9eef18e|Crystal Player 1.98
 74d7f43c1561fc1e|Windows Media Player 12 (32-bit)
 74d7f43c1561fc1e|Windows Media Player 12.0.7600.16415 / 12.0.7601.17514
 74d7f43c1561fc1e|Windows Media Player 12.0.7601.17514
 74ea779831912e30|Skype 7.18.0.112
 74ea779831912e30|Skype 7.24.0.104
 7526de4a8b5914d9|Forte Agent 6.00 (Build 32.1186)
 7593af37134fd767|RealPlayer 6.0.6.99 / 7 / 8 / 10.5
 76689ff502a1fd9e|Imagine Image and Animation Viewer 1.0.7
 76f6f1bd18c19698|aMule 2.2.6
 776beb1fcfc6dfa5|Thunderbird 1.0.6 (20050716) / 3.0.2
 777483d3cdac1727|Gajim 0.14.4
 780732558f827a42|AutoPix 5.3.3
 784182360de0c5b6|Kazaa Lite 1.7.1
 78f0afb5bd4bb278|Microsoft Lync 2016 64-bit (Skype for Business)
 7904145af324576e|Total Commander 7.56a (Build 16.12.2010)
 7904145af324576e|Total Commander 7.56a (Build 16.12.2010) / 8.52a 32-bit
 792699a1373f1386|Piolet 3.1.1
 79370f660ab51725|UploadFTP 2.0.1.0
 7937df3c65790919|FTP Explorer 10.5.19 (Build 001)
 7a4ba998575ff2a4|FreeCommander XE 2016 Build 715 32-bit
 7a7c60efd66817a2|Spotnet 1.7.4
 7a8db574299c8568|Windows Movie Maker 2012 (build 16.4.3528.0331)
 7b2b4f995b54387d|News Reactor 20100224.16
 7b4d500e147e4391|Tor Browser 8.0.4 (x64)
 7b7f65aaeca20a8c|Dropbox App 5.4.24
 7c2916afd6f116a6|LibreOffice 5.1.0.3 Base
 7cb0735d45243070|CDisplay 1.8.1.0
 7dca40fd2a5a971f|LibreOffice 5.1.0.3
 7e4dca80246863e3|Control Panel
 7e4dca80246863e3|Control Panel (?)
 7e4dca80246863e3|Control Panel - Settings
 7fd04185af357bd5|UltraLeeacher 1.7.0.2969 / 1.8 Beta (Build 3490)
 8172865a9d5185cb|Binreader 1.0 (Beta 1)
 817bb211c92fd254|GOM Player 2.0.12.3375 / 2.1.28.5039
 817e5ad5be351574|Microsoft Built-in Services 10.0.10011.16384 (Win10)
 8211531a7918b389|Newsbin Pro 6.00 (Build 1019) (JL support)
 83b03b46dcd30a0e|iTunes 10
 83b03b46dcd30a0e|iTunes 9.0.0.70 / 9.2.1.5 / 10.4.1.10 (begin custom 'Tasks' JL capability)
 83b03b46dcd30a0e|iTunes 9.0.0.70 / 9.2.1.5 / 10.4.1.10 (begin custom 'Tasks' JL capability) / 12.3.2.35 64-bit
 83dd64e7fa560bd5|LibreOffice 5.1.0.3 Calc
 84f066768a22cc4f|Adobe Photoshop CS5 (64-bit)
 8628e76fd9020e81|Fling File Transfer Plus 2.24
 86781fe8437db23e|Messenger Pro 2.66.6.3353
 86b804f7a28a3c17|Miranda IM 0.6.8 / 0.7.6 / 0.8.27 / 0.9.9 / 0.9.29
 86b804f7a28a3c17|Miranda IM 0.6.8 / 0.7.6 / 0.8.27 / 0.9.9 / 0.9.29 (ANSI + Unicode)
 884fd37e05659f3a|VZOchat 6.3.5
 888f2fa044591eda|Twitter - Trusted Microsoft Store App (Win10)
 8904a5fd2d98b546|IceChat 7.70 20101031
 89b0d939f117f75c|Adobe Acrobat 9 Pro Extended (32-bit)
 8a1c1c7c389a5320|Safari 3.2.3 (525.29)
 8a461f82e9eb4102|Foxit Reader 7.2.0.722
 8bd5c6433ca967e9|ACDSee Photo Manager 2009 (v11.0 Build 113)
 8c816c711d66a6b5|MSN Messenger 6.2.0137 / 7.0.0820
 8dcca8b24a5e822e|CDBurnerXP 4.5.7.6623
 8deb27dfa31c5c2a|CoffeeCup Free FTP 4.4 (Build 1904)
 8eafbd04ec8631ce|VMware Workstation 11.0.0 build-2305329
 8eafbd04ec8631ce|VMware Workstation 9 x64
 8f3d7202aa5d4c01|ImgBurn 2.5.8.0
 8f852307189803b8|Far Manager 2.0.1807
 8fb5ce5e2b049ce|Windows Defender (Win10 built-in)
 8fd1364019dc2115|Calibre E-Book Manager 2.33
 8fdb062f1e486cac|Microsoft Powerpoint 2013 32-bit
 9027fe24326910d2|Thunderbird 38.6.0
 905c98e216107aa1|Microsoft Lync 2013 15.0.4753.1000
 9077b9c9cf187cc2|KeePass 1.36
 90e5e8b21d7e7924|Winamp 3.0d (Build 488)
 918e0ecb43d17e23|Notepad (32-bit)
 92f1d5db021cd876|NewsLeecher 4.0 / 5.0 Beta 6
 939c10c2c101c1b0|Stickies 9.0d
 93b18adf1d948fa3|qutIM 0.2
 954ea5f70258b502|Windows Script Host - wscript.exe (32-bit)
 9560577fd87cf573|LeechFTP 1.3 (Build 207)
 96252daff039437a|Lphant 7.0.0.112351
 966fa7c312d9b10|Eraser 6.2.0.2970
 969252ce11249fdd|Mozilla Firefox 40.0 / 44.0.2
 9749cea96d411f37|HexChat 2.10.2 64-bit
 977a5d147aa093f4|Lphant 3.51
 9839aec31243a928|Microsoft Office Excel 2010 x86
 989d7545c2b2e7b2|IMVU 465.8.0.0
 98b0ef1c84088|fulDC 6.78
 99c15cf3e6d52b61|mldonkey 3.1.0
 9a3bdae86d5576ee|WinSCP 3.2.1 (Build 174) / 3.8.0 (Build 312)
 9a464053cd82de6d|LINE Messenger
 9ad1ec169bf2da7f|FlylinkDC++ r405 (Build 7358)
 9ad84c52efeae190|1Password 4.6.0.604
 9b9cdc69c1c24e2b|Notepad (64-bit)
 9b9cdc69c1c24e2b|Notepad 64-bit
 9c08ad74ad8708df|Microsoft Publisher 2016 64-bit
 9c32e2313792e6e8|Microsoft Built-in Disk Cleanup (Win10)
 9c7cc110ff56d1bd|Microsoft Office PowerPoint 2010 x86
 9ce6555426f54b46|HxD 1.7.7.0
 9d1f905ce5044aee|Edge Browser
 9d78513a8998829c|Microsoft Built-in Run Dialog (Win7 + Win10)
 9d91276b0be3e46b|Windows Help and Support (Built-in) Win7
 9dacebaa9ac8ca4e|TLNews Newsreader 2.2.0 (Build 2430)
 9e0b3f677a26bbc4|BitKinex 3.2.3
 9edafe4ba4b22ce7|Eclipse IDE Oxygen (4.7.3a)
 9f03ae476ad461fa|GroupsAloud 1.0
 9f5c7755804b850a|Windows Script Host - wscript.exe (64-bit)
 9fda41b86ddcf1db|VLC 0.5.3 / 0.8.6i / 0.9.7 / 1.1.11
 9fda41b86ddcf1db|VLC Media Player 0.5.3 / 0.8.6i / 0.9.7 / 1.1.11 / 2.2.1
 9fdb10e18cdd0101|Cisco AnyConnect Secure Mobility Client 3.1.02040
 a028c9db28aa15a3|Piriform Defraggler 2.20.989 64-bit
 a0d6b1b874c6e9d2|TOR Browser 6.0.2
 a10b45adb36c1d27|PST Walker 5.54
 a18df73203b0340e|Microsoft Word 2016
 a1d19afe5a80f80|FileZilla 2.2.32
 a2c73c383525f1bb|RealVNC Viewer 5.3.0 64-bit
 a31ec95fdd5f350f|BitComet 0.49 / 0.59 / 0.69 / 0.79 / 0.89 / 0.99 / 1.07 / 1.28
 a3e0d98f5653b539|Instantbird 1.0 (20110623121653) (JL support)
 a4a5324453625195|Microsoft Office Word 2013 x86
 a4a5324453625195|Microsoft Word 2013 32-bit
 a4def57ee99d77e9|Nomad News 1.43
 a52b0784bd667468|Photos Microsoft 16.526.11220.0 (Windows 10)
 a581b8002a6eb671|WiseFTP 5.5.9
 a5db18f617e28a51|ICQ 6.5 (Build 2024)
 a6d4dfec09c69409|Microsoft Word Viewer 11.8169.8172
 a746f9625f7695e8|HeXHub 5.07
 a75b276f6e72cf2a|Kazaa Lite Tools K++ 2.7.0
 a75b276f6e72cf2a|Kazaa Lite Tools K++ 2.7.0 / WinMX 3.53
 a75b276f6e72cf2a|WinMX 3.53
 a777ad264b54abab|JetVideo 8.0.2.200 Basic
 a79a7ce3c45d781|CuteFTP 7.1 (Build 06.06.2005.1)
 a7bd71699cd38d1c|Microsoft Office Word 2010 x86
 a8c43ef36da523b1|Microsoft Office Word 2003 Pinned and Recent.
 a8df13a46d66f6b5|Kommute (Calypso) 0.24
 aa11f575087b3bdc|Unzbin 2.6.8
 ac3a63b839ac9d3a|Azureus Vuze Bittorrent Client 4.6.0.4 / 5.7.1.0
 ac3a63b839ac9d3a|Vuze 4.6.0.4
 ac8920ed05001800|@DMDirc 0.6.5 (Profile store: C:\Users\$user\AppData\Roaming\DMDirc\)
 ac8920ed05001800|DMDirc 0.6.5 (Profile store: C:\Users\$user\AppData\Roaming\DMDirc\)
 accca100973ef8dc|Azureus 2.0.8.4
 ace8715529916d31|40tude Dialog 2.0.15.1 (Beta 38)
 adecfb853d77462a|Microsoft Office Word 2007 Pinned and Recent.
 ae069d21df1c57df|mIRC 6.35 / 7.19
 ae3f2acd395b622e|QuickTime Player 6.5.1 / 7.0.3 / 7.5.5 (Build 249.13)
 aedd2de3901a77f4|Pidgin 2.0.0 / 2.10.0 / 2.7.3
 aedd2de3901a77f4|Pidgin 2.10.11
 b0236d03c0627ac4|ICQ 5.1 / ICQLite Build 1068
 b0459de4674aab56|(.vmcx)
 b0459de4674aab56|Windows Virtual PC - vmwindow.exe (32- and 64-bit)
 b06a975b62567622|Windows Live Messenger 8.5.1235.0517 BETA
 b08971c77377bde3|Microsoft Visual Studio Community 2015
 b17d3d0c9ca7e29|"Picasa 3.8.0 (build 117.43, 0) / 3.9.141 (build 259)"
 b17d3d0c9ca7e29|"Picasa 3.8.0 (Build 117.43, 0)"
 b223c3ffbc0a7a42|Bersirc 2.2.14
 b3016b8da2077262|eMule 0.50a
 b3965c840bf28ef4|AIM 4.8.2616
 b39bc6b590f53961|HexChat 2.10.2 32-bit
 b39c5f226977725d|ACDSee Pro 8.1.99
 b3f13480c2785ae|Paint 6.1 (build 7601: SP1)
 b48ce76eda60b97|Shareaza 8.0.0.112300
 b50ee40805bd280f|QuickTime Alternative 1.9.5 (Media Player Classic 6.4.9.1)
 b6267f3fcb700b60|WiseFTP 4.1.0
 b74736c2bd8cc8a5|WinZip
 b74736c2bd8cc8a5|WinZip 15.5 (9468)
 b77ef7f3fc946302|Pale Moon Browser 26.1.1 (32-bit)
 b7cb1d1c1991accf|FlashFXP 4.0.0 (Build 1548)
 b868d9201b866d96|Microsoft Lync 4.0.7577.0
 b8ab77100df80ab2|Microsoft Excel 2016 64-bit
 b8ab77100df80ab2|Microsoft Office Excel x64
 b8c13a5dd8c455a2|Titan FTP Server 8.40 (Build 1338)
 b8c29862d9f95832|Microsoft Office InfoPath 2010 x86
 b91050d8b077a4e8|Windows Media Center (Win7)
 b91050d8b077a4e8|Windows Media Center x64
 ba132e702c0147ef|KCeasy 0.19-rc1
 ba3a45f7fd2583e1|Blubster 3.1.1
 bac8a6b507360131|Remote Desktop Connection Manager 2.2
 baea31eacd87186b|BinaryBoy 1.97 (Build 55)
 bba8a4896f0d26f|Ares Chat Client (3.1.9.4045)
 bc03160ee1a59fc1|Foxit PDF Reader 5.4.5
 bc0c37e84e063727|Windows Command Processor - cmd.exe (32-bit)
 bc2f88eccd3461b4|Microsoft Built-in Event Viewer 1.0 (Win10)
 bcc705f705d8132b|Instan-t 5.2 (Build 2824)
 bcd7ba75303acbcf|BitLord 1.1
 bd249197a6faeff2|Windows Live Messenger 2011
 be4875bb3e0c158f|CrossFTP 1.75a
 be71009ff8bb02a2|Microsoft Office Outlook x86
 bec10d3aaf939ffa|Pale Moon Browser 26.1.1 (64-bit)
 bf483b423ebbd327|Binary Vortex 5.0
 bf9ae1f46bd9c491|Nimbuzz 2.0.0 (rev 6266)
 bfc1d76f16fa778f|Ares (Galaxy) 1.8.4 / 1.9.8 / 2.1.0 / 2.1.7.3041
 bfc1d76f16fa778f|Ares (Galaxy) 1.8.4 / 1.9.8 / 2.1.0 / 2.1.7.3041 / 3.1.9.4045
 bfe841f4d35c92b1|QuadSucker/News 5.0
 c01d68e40226892b|ClicksAndWhistles 2.7.146
 c02baf50d02056fc|FotoVac 1.0
 c04f69101c131440|CuteFTP 5.0 (Build 50.6.10.2)
 c1eece5026414c64|Recuva 1.52.1086 (64-bit)
 c2d349a0e756411b|Adobe Reader 8.1.2
 c312e260e424ae76|Mail.Ru Agent 5.8 (JL support)
 c5236fd5824c9545|PLAYXPERT 1.0.140.2822
 c54b96f328bdc28d|WiseFTP 7.3.0
 c5c24a503b1727df|XnView 1.98.2 Small / 1.98.2 Standard
 c5c24a503b1727df|XnView 1.98.2 Small / 1.98.2 Standard / 2.35
 c5ef839d8d1c76f4|LimeWire 5.2.13
 c634153e7f5fce9c|IrfanView 3.10 / 4.30
 c634153e7f5fce9c|IrfanView 3.10 / 4.30 / 4.41 32-bit
 c6f7b5bf1b9675e4|BitWise IM 1.7.3a
 c71ef2c372d322d7|PGP Desktop 10
 c765823d986857ba|Adobe Illustrator CS5 (32-bit)
 c7a4093872176c74|Paint Shop Pro Pinned and Recent.
 c8112ac53c5ed250|Jetico Log Viewer 1.1
 c845f3a6022d647c|Another File 2.Build 2/7/2004)
 c8aa3eaee3d4343d|Trillian 0.74 / 3.1 / 4.2.0.25 / 5.0.0.35 (JL support)
 c8e4c10e5460b00c|iMesh 6.5.0.16898
 c91d08dcfc39a506|SM Player 0.6.9 r3447
 c9374251edb4c1a8|BitTornado T-0.3.17
 c98ab5ccf25dda79|NewsShark 2.0
 c9950c443027c765|WinZip 9.0 SR-1 (6224) / 10.0 (6667)
 c997d2e1a0f0929|BCWipe 6.08.6
 c99ddde925d26df3|Robo-FTP 3.7.9 CronMaker
 ca1eb46544793057|RetroShare 0.5.2a (Build 4550)
 ca942805559495e9|aMSN 0.98.4
 caea34d2e74f5c8|uTorrent 3.4.7
 cb1d97aca3fb7e6b|Newz Crawler 1.9.0 (Build 4100)
 cb5250eaef7e3213|ApexDC++ 1.4.3.957
 cb984e3bc7faf234|NewsRover 17.0 (Rev.0)
 cb996a858d7f15c|PDF Architect 4.0.09.25450 64-bit
 cbbe886eca4bfc2d|ExoSee 1.0.0
 cbeb786f0132005d|VLC 0.7.2
 cc4b36fbfb69a757|gtk-gnutella 0.97
 cc76755e0f925ce6|AllPicturez 1.2
 cca6383a507bac64|Gadu-Gadu 10.5.2.13164
 ccb36ff8a8c03b4b|Azureus 2.5.0.4 / Vuze 3.0.5.0
 ccc0fa1b9f86f7b3|CCleaner 5.15.5513 64-bit
 cd2acd4089508507|AbsoluteTelnet 9.18 Lite
 cd40ead0b1eb15ab|NNTPGrab 0.6.2
 cd8cafb0fb6afdab|uTorrent 1.7.7 (Build 8179) / 1.8.5 / 2.0 / 2.21 (Build 25113) / 3.0 (Build 25583)
 cdb6f0c373f2da0f|stunnel 5.31
 cdf30b95c55fd785|Microsoft Office Excel 2007
 cf6379a9a987366e|Digibin 1.31
 cfab0ec14b6f953|Express NewsPictures 2.41 (Build 08.05.07.0)
 cfb56c56fa0f0a54|Mozilla 0.9.9
 d00655d2aa12ff6d|Microsoft Office PowerPoint x64
 d00655d2aa12ff6d|Microsoft PowerPoint 2016 64-bit
 d0261ed6e16b200b|News File Grabber 4.6.0.4
 d1fc019238236806|Newsgroup Commander Pro 9.05
 d22ad6d9d20e6857|ALLPlayer 4.7
 d28ee773b2cea9b2|3D-FTP 9.0 build 7
 d2d0fc95675fb2c8|Microsoft Built-in Print Management (Win10)
 d33ecf70f0b74a77|"Picasa 2.2.0 (Build 28.08, 0)"
 d33ecf70f0b74a77|Picasa 2.2.0 (Build 28.08, 0)
 d3530c5294441522|HydraIRC 0.3.165
 d38a3ea7ec79fbed|LibreOffice 5.1.0.3 Writer
 d38adec6953449ba|Microsoft Office OneNote 2010 x64
 d3c5cf21e86b28af|SeaMonkey 2.3.3
 d41746b133d17456|Tkabber 0.11.1
 d460280b17628695|Java Binary
 d4a589cab4f573f7|Microsoft Project 2010 x86
 d53b52fb65bde78c|Android Newsgroup Downloader 6.2
 d5c02fc7afbb3fd4|NNTPGrab 0.6.2 Server
 d5c3931caad5f793|Adobe Soundbooth CS5 (32-bit)
 d64d36b238c843a3|Microsoft Office InfoPath 2010 x86
 d7528034b5bd6f28|Windows Live Mail Pinned and Recent.
 d7666c416cba240c|NewsMan Pro 3.0.5.2
 d78150e0484a4e1d|Evernote 5.9.6.9494
 d7d647c92cd5d1e6|uTalk 2.6.4 r47692
 d7db75db9cdd7c5d|Xnews 5.04.25
 d8081f151f4bd8a5|CuteFTP 8.3 Lite (Build 8.3.4.0007)
 d838aac097abece7|ACDSee Photo Manager 12 (Build 344)
 d8671c1ed93c75c8|Tor Browser 5.5.2
 d93f411851d7c929|Windows Powershell 5.0 32-bit
 d97efdf3888fe7eb|KeePass 2.31
 da7e8de5b8273a0f|Yahoo Messenger 5.0.0.1226 / 6.0.0.1922
 db3b8d985f0668e|FreeFileSync 10.7
 dba909a61476ccec|NewsWolf 1.41
 dc64de6c91c18300|Brosix Communicator 3.1.3 (Build 110719 nid 1)
 dd658a07478b46c2|PIRCH98 1.0.1.1190
 de48a32edcbe79e4|Acrobat Reader 15.x
 de48a32edcbe79e4|Adobe Acrobat Reader DC 2015.010.20056
 de76415e0060ce13|Noworyta News Reader 2.9
 dee18f19c7e3a2ec|PopNote 5.21
 e0246018261a9ccc|qutIM 0.2.80.0
 e0532b20aa26a0c9|QQ International 1.1 (2042)
 e0f7a40340179171|imule 1.4.5 (rev. 749)
 e107946bb682ce47|FileZilla 3.5.1
 e107946bb682ce47|Filezilla 3.5.1 / 3.16
 e1d47cb031dafb9f|BearShare 6.0.0.22717 / 8.1.0.70928 / 10.0.0.112380
 e2a593822e01aed3|Adobe Flash CS5 (32-bit)
 e30bbea3e1642660|Neebly 1.0.4
 e31a6a8a7506f733|Image AXS Pro 4.1
 e36bfc8972e5ab1d|XPS Viewer
 e40cb5a291ad1a5b|Songbird 1.9.3 (Build 1959)
 e42a8e0f4d9b8dcf|Sysax FTP Automation 5.15
 e4bd2558bfab368d|UltraDefrag 7.0.0
 e57cfc995bdc1d98|Snagit 11
 e6ea77a1d4553872|Gnucleus 1.8.6.0
 e6ee34ac9913c0a9|VLC 0.6.2
 e6ef42224b845020|ALFTP 5.20.0.4
 e70d383b15687e37|Notepad++ 5.6.8 (32-bit)
 e70d383b15687e37|Notepad++ 6.6.7
 e73d9f534ed5618a|BitSpirit 1.2.0.228 / 2.0 / 2.6.3.168 / 2.7.2.239 / 2.8.0.072 / 3.1.0.077 / 3.6.0.550
 e76a4ef13fbf2bb1|Manolito 3.1.1
 e93dbdcede8623f2|Pandion 2.6.106
 e9a39dfba105ea23|FastStone Image Viewer 4.6
 e9a39dfba105ea23|Faststone Image Viewer 4.6 / 5.5
 ea83017cdd24374d|IrfanView Thumbnails
 eab25958dbddbaa4|Binary News Reaper 2 (Beta 0.14.7.448)
 eb3300e672136bc7|Stream Reactor 1.0 Beta 9 (uses VLC!)
 eb7e629258d326a1|WindowWasher 6.6.1.18
 ebd8c95d87f25154|Carrier 2.5.5
 ec3e36af0cdcb3e1|Steam build 2/4/2016
 ecd1a5e2c3af9c46|LibreOffice 5.1.0.3 Press
 ecd21b58c2f65a2f|StealthNet 0.8.7.9
 ecdd9154e84d5544|Wickr Top Secret Messenger Desktop 2.3.5
 ed49e1e6ccdba2f5|GNUnet 0.8.1a
 ed7a5cc3cca8d52a|CCleaner 1.32.345 / 1.41.544 / 2.36.1233 / 3.10.1525
 edc786643819316c|HoneyView3 #5834
 ee0c103672a7a2b9|ManyCam 6.7.0
 ee462c3b81abb6f6|Adobe Reader X 10.1.0
 ef473fab8120b354|uTorrent 3.5.5
 ef606b196796ebb|HP MediaSmart Photo
 efb08d4e11e21ece|Paltalk Messenger 10.0 (Build 409)
 efbb2bf3c1d06466|Auslogics Disk Defrag 6.2.1.0
 f001ea668c0aa916|Cabos 0.8.2
 f01b4d95cf55d32a|Windows Explorer (Win10) ??? TEST THIS
 f01b4d95cf55d32a|Windows Explorer Windows 8.1
 f0275e8685d95486|Microsoft Excel 2013 32-bit
 f0275e8685d95486|Microsoft Office Excel 2013 x86
 f0468ce1ae57883d|Adobe Reader 7.1.0
 f09b920bfb781142|Camfrog 4.0.47 / 5.5.0 / 6.1 (build 146) (JL support)
 f0c7bd3e0584a65a|InfraRecorder 0.53.0.0 32-bit
 f1a4c04eebef2906|[i2p] Robert 0.0.29 Preferences
 f214ca2dd40c59c1|FrostWire 4.20.9
 f2cb1c38ab948f58|X-Chat 1.8.10 / 2.6.9 / 2.8.9
 f5ac5390b9115fdb|Microsoft Office PowerPoint 2007
 f5e4e50707bcd215|Microsoft Message Analyzer 1.4
 f61b65550a84027e|iMesh 11.0.0.112351
 f64de962764b9b0f|FTPRush 1.1.3 / 2.15
 f674c3a77cfe39d0|Winamp 2.95 / 5.1 / 5.621
 f674c3a77cfe39d0|Winamp 2.95 / 5.1 / 5.621 / 5.666
 f6fd5d99e2b6e178|LibreOffice 5.1.0.3 Draw
 f784591ff7f60f76|Microsoft Built-in Defragment and Optimize Drives (Win10)
 f82607a219af2999|Cyberduck 4.1.2 (Build 8999)
 f91fd0c57c4fe449|ExpanDrive 2.1.0
 f920768fe275f7f4|Grabit 1.5.3 Beta (Build 909) / 1.6.2 (Build 940) / 1.7.2 Beta 4 (Build 997)
 f92e607f9de02413|RealPlayer 14.0.6.666
 fa02aa2c575837a6|Microsoft Built-in Task Scheduler 1.0 (Win10)
 fa496fe13dd62edf|KVIrc 3.4.2.1 / 4.0.4
 fa7144034d7d083d|Directory Opus 10.0.2.0.4269 (JL tasks supported)
 fac3aa4105c6c466|Microsoft Built-in System Restore (Win7)
 faef7def55a1d4b|VLC 2.2.6
 fb1f39d1f230480a|Bopup Messenger 5.6.2.9178 (all languages: en,du,fr,ger,rus,es)
 fb1f39d1f230480a|Bopup Messenger 5.6.2.9178 (all languages: en;du;fr;ger;rus;es)
 fb230a9fe81e71a8|Yahoo Messenger 11.0.0.2014-us
 fb3b0dbfee58fac8|Microsoft Office Word 365 x86
 fb3b0dbfee58fac8|Microsoft Word 2016 64-bit
 fb7ca8059b8f2123|ooVoo 3.0.7.21
 fc999f29bc5c3560|Robo-FTP 3.7.9
 fd1ad55e472f20e0|Google Earth Pro 7.3.2.5491
 fdbaca0a1fce6055|MozBackup 1.5.1
 fe57f5df17b45fe|Wireshark 2.6.3
 fe5e840511621941|JetAudio 5.1.9.3018 Basic / 6.2.5.8220 Basic / 7.0.0 Basic / 8.0.16.2000 Basic
 fe8bb4692de7b989|Smart Defrag 4.3.0.847
 fe9e0f7260000a12|RealVNC Server 5.3.0 64-bit (Connect+File Transfer)
 ff103e2cc310d0d|Adobe Reader XI
 ff224628f0e8103c|Morpheus 3.0.3.6
 4cb9c5750d51c07f|Microsoft Movies &amp;amp; TV (Build 10.19031.11411.0)
 ae6df75df512bd06|Microsoft Groove Music (Build 10.19031.1141.0)
 959668a81d4f220e|Sublime Text 3.2.1 (Build 3207)
 9eff0b23d51fe003|XMind 201807140020
 70ffd305907c983b|7zip 18.05
 1c7a9be1b15a03ba|Microsoft ScreenSketch
 1ced32d74a95c7bc|Microsoft Visual Studio Code
 3c3871276e149215|PowerShell 7
 573770283dc3d854|Microsoft Window SecHealthUI
 9390ee5b658e96e|PuTTY 0.72 / 0.73
 a55ed4fbb973aefb|Microsoft Teams
 baacb5294867b833|Notepad++ 7.8.6
 d249d9ddd424b688|Google Chrome 81.0.4044.138
 ff99ba2fb2e34b73|Microsoft Windows Calculator
 4ac866364817f10c|Microsoft Edge (Chromium)
 ccba5a5986c77e43|Microsoft Edge (Chromium)
 188f5ec9d11ded56|Microsoft Edge (Chromium)
 69639df789022856|Google Chrome 86.0.4240.111
 352fd027c0e8f0e5|Zoom
 8bce06a9e923e1f9|Slack 4.10.3
 a55ed4fbb973aefb|Microsoft Teams
 1c7a9be1b15a03ba|Microsoft Snip &amp;amp; Sketch
 466d339d8f21cfbf|Microsoft Snip &amp;amp; Sketch
 9a165f62edbfa161|Microsoft Store
 573770283dc3d854|Windows Defender
 f18460fded109990|Windows Connected Devices
 dd7c3b1adb1c168b|Microsoft Game Bar
 447e6aa2bbdfbc8a|Slack 4.11.3
 3b94415067dd2c5d|GOG Galaxy
 58170c92fa4b91a1|MediaMonkey
 5f218922e0901ebf|MusicBee
 75fdacd8330bac18|AnyDesk
 8b87640a40ec9fc|Snagit 2020
 af0fdd562e3f275b|Snagit 2020
 b7173093b23b9a6a|Beyond Compare 4
 d356105fac5527ef|Steam 1/22/2021
 28efb5b6d2e28389|EA Origin
 20513cdf29d09c0e|Hex Editor Neo
 1d12f965b876dc87|Snagit 2021
 16f2f0042ddbe0e8|Windows Terminal
 352fd027c0e8f0e5|Zoom
 7111c0ce965b7246|Battle.net
 a7ba40025dac9a67|Microsoft Office Hub
 8e4e81d9adc545b8|Microsoft Your Phone
 c01827d56ff89056|Microsoft Sticky Notes
 bd050ac447f6cd65|Microsoft Xbox App
 ff99ba2fb2e34b73|Windows Calculator
 fc98c00f85d4ce77|EditPad Pro 8
 46e77b87767b92|Opera Browser 75
 ad57bd0f4825cce|WinRAR 6.01 Russian 64 bit
 '''

 LET AppIdLookup &amp;lt;= memoize(key="AppId", query={
 SELECT *
 FROM parse_csv(accessor='data', separator="|",
 filename=AppIdTable)
 })

 LET X = SELECT * FROM foreach(row={
 SELECT OSPath AS AutomaticDestinationsPath
 FROM glob(globs=Globs)
 }, query={
 SELECT AutomaticDestinationsPath, Name,
 parse_binary(filename=OSPath, accessor="mscfb",
 profile=Profile, struct="ShellLinkHeader") AS Parsed
 FROM glob(globs='*', accessor="mscfb",
 root=pathspec(DelegatePath=AutomaticDestinationsPath))
 WHERE Size &amp;gt; 0 AND NOT IsDir AND Name =~ "^\\d+$"
 })

 LET Y = SELECT AutomaticDestinationsPath, Name AS Stream,
 split(sep_string=".", string=AutomaticDestinationsPath.Basename)[0] AS ApplicationId,
 ShowHeader(Parsed=Parsed) as _ShellLinkHeader,
 Parsed.LinkInfo as _LinkInfo,
 ShowLinkTarget(ShellBag=Parsed.LinkTargetIDList.IDList.ShellBag) as _LinkTarget,
 Parsed.StringData as _StringData,
 ShowExtraData(Parsed=Parsed) as _ExtraData,
 property_store(Parsed=Parsed) as _PropertyStore
 FROM X

 SELECT *, ApplicationId,
 get(item=AppIdLookup, field=ApplicationId).Description AS Application,
 _LinkTarget.LinkTarget || _LinkInfo.Target.Path AS LinkTarget,
 _ShellLinkHeader.FileSize AS FileSize,
 _ShellLinkHeader.CreationTime AS CreationTime,
 _ShellLinkHeader.AccessTime AS AccessTime,
 _ShellLinkHeader.WriteTime AS WriteTime
 FROM Y

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.Lnk</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.lnk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.lnk/</guid><description>&lt;p>This artifact parses LNK shortcut files.&lt;/p>
&lt;p>A LNK file is a type of Shell Item that serves as a shortcut or reference to a
specific file, folder, or application. It contains metadata and information
about the accessed file or location and is a valuable forensic artifact.
LNK files can be automatically created by the Windows operating system when a
user accesses a file from a supported application or manually created by the user.&lt;/p>
&lt;p>This artifact has several configurable options:&lt;/p>
&lt;ul>
&lt;li>TargetGlob: glob targeting. Default targets *.lnk files in Startup and Recent paths.&lt;/li>
&lt;li>IOCRegex: Regex search on key fields: StringData, TrackerData and PropertyStore.&lt;/li>
&lt;li>IgnoreRegex: Ignore regex filter on key fields.&lt;/li>
&lt;li>UploadLnk: uploads lnk hits.&lt;/li>
&lt;li>SuspiciousOnly: only returns LNK files reporting a suspicious attribute.&lt;/li>
&lt;li>SusSize: Any lnk over this size in bytes is suspicious.&lt;/li>
&lt;li>SusArgSize: Any lnk with Argument strings over this size is suspicious.&lt;/li>
&lt;li>SusArgRegex: Regex for suspicious strings in Arguments.&lt;/li>
&lt;li>SusHostnameRegex: Regex for suspicious TrackerData Hostname.&lt;/li>
&lt;li>VmPrefixMAC: Regex to match known Virtual Machine MacAddress prefix in TrackerData.&lt;/li>
&lt;li>RiskyExe: Regex target exe to flag as risky.&lt;/li>
&lt;/ul>
&lt;p>List of fields targeted by filter regex:&lt;/p>
&lt;ul>
&lt;li>StringData.TargetPath&lt;/li>
&lt;li>StringData.Name&lt;/li>
&lt;li>StringData.RelativePath&lt;/li>
&lt;li>StringData.WorkingDir&lt;/li>
&lt;li>StringData.Arguments&lt;/li>
&lt;li>StringData.IconLocation&lt;/li>
&lt;li>LinkTarget.LinkTarget&lt;/li>
&lt;li>PropertyStore&lt;/li>
&lt;li>TrackerData.MachineID&lt;/li>
&lt;li>TrackerData.MacAddress&lt;/li>
&lt;/ul>
&lt;p>NOTE: regex startof (^) and endof ($) line modifiers will not work.&lt;/p>
&lt;p>Windows.Forensics.Lnk also will highlight suspicious lnk attributes in a Suspicious field.&lt;/p>
&lt;ul>
&lt;li>Large Size - Check for large size, default over 20000 bytes&lt;/li>
&lt;li>Startup Path - Path with \Startup\&lt;/li>
&lt;li>Zeroed Headers - Check for ShellHeader items zeroed.&lt;/li>
&lt;li>Hidden window - Check for ShellLinkHeader.ShowCommand as SHOWMINNOACTIVE&lt;/li>
&lt;li>Target Changed path - Check LNK TargetPath different from PropertyStore path.&lt;/li>
&lt;li>Target Changed size - Check LNK ShellLinkHeader.FileSize different from PropertyStore size.&lt;/li>
&lt;li>Risky target - Checks several LNK target paths to the RiskyExe regex.&lt;/li>
&lt;li>WebDAV - Checks for NetworkProviderType = WNNC_NET_DAV&lt;/li>
&lt;li>Line break in StringData.Name&lt;/li>
&lt;li>Suspicious argument size - large sized arguments over 250 characters as default&lt;/li>
&lt;li>Environment variable script - environment variable with a common script configured (bat|cmd|ps1|js|vbs|vbe|py)&lt;/li>
&lt;li>No Target with environment variable - environment variable only execution&lt;/li>
&lt;li>Suspicious hostname - some common malicious hostnames&lt;/li>
&lt;li>Created in VM - Check TrackerData MacAddress for known VM prefix&lt;/li>
&lt;li>Local Admin- check PropertyStore for indications LNK created by local admin UID 500&lt;/li>
&lt;li>Cyrillic Language - check PropertyStore for Cyrillic strings&lt;/li>
&lt;li>Chinese Language - check PropertyStore for Chinese strings&lt;/li>
&lt;li>Korean Language - check PropertyStore for Korean strings&lt;/li>
&lt;li>Persian Language - check PropertyStore for Persian strings&lt;/li>
&lt;li>Vietnamese Language - check PropertyStore for Vietnamese strings&lt;/li>
&lt;li>CodePage - checks for existence of a ExtraData code page setting. Rare enough to report on - 936:Simplified Chinese, 949:Korean, 950:Traditional Chinese&lt;/li>
&lt;li>Has Overlay - check for overlay and extra data attached to LNK&lt;/li>
&lt;li>Long Base64 - check for a long base64 blog over 20 decoded characters&lt;/li>
&lt;li>Arguments have ticks - ticks are common in malicious LNK files&lt;/li>
&lt;li>Arguments have environment variables - environment variables (%|$env:) are common in malicious LNKs&lt;/li>
&lt;li>Arguments have rare characters - looks for specific rare characters that may indicate obfuscation (?|!|~|@)&lt;/li>
&lt;li>Arguments have leading space - malicious LNK files may have a many leading spaces to obfuscate some tools&lt;/li>
&lt;li>Arguments have http strings - LNKs are regularly used as a download cradle - https?://&lt;/li>
&lt;li>Arguments have UNC strings&lt;/li>
&lt;li>Suspicious arguments - some common malicious arguments observed in field (with mind to False positive)&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.Lnk
author: Matt Green - @mgreen27
description: |
 This artifact parses LNK shortcut files.

 A LNK file is a type of Shell Item that serves as a shortcut or reference to a
 specific file, folder, or application. It contains metadata and information
 about the accessed file or location and is a valuable forensic artifact.
 LNK files can be automatically created by the Windows operating system when a
 user accesses a file from a supported application or manually created by the user.

 This artifact has several configurable options:

 - TargetGlob: glob targeting. Default targets *.lnk files in Startup and Recent paths.
 - IOCRegex: Regex search on key fields: StringData, TrackerData and PropertyStore.
 - IgnoreRegex: Ignore regex filter on key fields.
 - UploadLnk: uploads lnk hits.
 - SuspiciousOnly: only returns LNK files reporting a suspicious attribute.
 - SusSize: Any lnk over this size in bytes is suspicious.
 - SusArgSize: Any lnk with Argument strings over this size is suspicious.
 - SusArgRegex: Regex for suspicious strings in Arguments.
 - SusHostnameRegex: Regex for suspicious TrackerData Hostname.
 - VmPrefixMAC: Regex to match known Virtual Machine MacAddress prefix in TrackerData.
 - RiskyExe: Regex target exe to flag as risky.


 List of fields targeted by filter regex:

 - StringData.TargetPath
 - StringData.Name
 - StringData.RelativePath
 - StringData.WorkingDir
 - StringData.Arguments
 - StringData.IconLocation
 - LinkTarget.LinkTarget
 - PropertyStore
 - TrackerData.MachineID
 - TrackerData.MacAddress

 NOTE: regex startof (^) and endof ($) line modifiers will not work.


 Windows.Forensics.Lnk also will highlight suspicious lnk attributes in a Suspicious field.

 * Large Size - Check for large size, default over 20000 bytes
 * Startup Path - Path with \Startup\
 * Zeroed Headers - Check for ShellHeader items zeroed.
 * Hidden window - Check for ShellLinkHeader.ShowCommand as SHOWMINNOACTIVE
 * Target Changed path - Check LNK TargetPath different from PropertyStore path.
 * Target Changed size - Check LNK ShellLinkHeader.FileSize different from PropertyStore size.
 * Risky target - Checks several LNK target paths to the RiskyExe regex.
 * WebDAV - Checks for NetworkProviderType = WNNC_NET_DAV
 * Line break in StringData.Name
 * Suspicious argument size - large sized arguments over 250 characters as default
 * Environment variable script - environment variable with a common script configured (bat|cmd|ps1|js|vbs|vbe|py)
 * No Target with environment variable - environment variable only execution
 * Suspicious hostname - some common malicious hostnames
 * Created in VM - Check TrackerData MacAddress for known VM prefix
 * Local Admin- check PropertyStore for indications LNK created by local admin UID 500
 * Cyrillic Language - check PropertyStore for Cyrillic strings
 * Chinese Language - check PropertyStore for Chinese strings
 * Korean Language - check PropertyStore for Korean strings
 * Persian Language - check PropertyStore for Persian strings
 * Vietnamese Language - check PropertyStore for Vietnamese strings
 * CodePage - checks for existence of a ExtraData code page setting. Rare enough to report on - 936:Simplified Chinese, 949:Korean, 950:Traditional Chinese
 * Has Overlay - check for overlay and extra data attached to LNK
 * Long Base64 - check for a long base64 blog over 20 decoded characters
 * Arguments have ticks - ticks are common in malicious LNK files
 * Arguments have environment variables - environment variables (%|\$env:) are common in malicious LNKs
 * Arguments have rare characters - looks for specific rare characters that may indicate obfuscation (\?|\!|\~|\@)
 * Arguments have leading space - malicious LNK files may have a many leading spaces to obfuscate some tools
 * Arguments have http strings - LNKs are regularly used as a download cradle - https?://
 * Arguments have UNC strings
 * Suspicious arguments - some common malicious arguments observed in field (with mind to False positive)


reference:
 - https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-shllink

parameters:
 - name: TargetGlob
 default: C:\{ProgramData,Users\*\AppData\*}\Microsoft\Windows\{Start Menu\Programs\StartUp,Recent\**}\*.lnk
 - name: IocRegex
 type: regex
 description: A regex to filter on all fields
 - name: IgnoreRegex
 type: regex
 description: A regex to ignore ilter all fields
 - name: UploadLnk
 description: Also upload the link files themselves.
 type: bool
 - name: UploadTarget
 description: Also upload the link file's targets.
 type: bool
 - name: SuspiciousOnly
 description: Only returns LNK files reporting a suspicious attribute
 type: bool
 - name: SusSize
 description: Any lnk over this size in bytes is suspicious.
 default: 20000
 type: int
 - name: SusArgSize
 default: 250
 description: Any lnk with Argument strings over this size is suspicious.
 type: int
 - name: SusArgRegex
 description: Regex for suspicious strings in Argumetns.
 type: regex
 default: \\AppData\\|\\Users\\Public\\|\\Temp\\|comspec|&amp;amp;cd&amp;amp;echo| -NoP | -W Hidden | [-/]decode | -e.* (JAB|SUVYI|SQBFAFgA|aWV4I|aQBlAHgA)|start\s*[\\/]b|\.downloadstring\(|\.downloadfile\(|iex
 - name: SusHostnameRegex
 description: Regex for suspicious TrackerData Hastname.
 type: regex
 default: ^(Win-|Desktop-|Commando$)
 - name: VmPrefixMAC
 description: VM MacAddress prefix regex to compate to LNK TrackerData.
 type: regex
 default: ^(00:50:56|00:0C:29|00:05:69|00:1C:14|08:00:27|52:54:00|00:21:F6|00:14:4F|00:0F:4B|00:15:5D)
 - name: RiskyExe
 description: Regex target exe to flag as risky.
 type: regex
 default: \\(cmd|powershell|cscript|wscript|rundll32|regsvr32|mshta|wmic|conhost)\.exe$


export: |
 LET S = scope()

 LET GetClassName(GUID) = get(item=KnownGUIDLookup, member=GUID) || (
 version(function="reg_set_value") != NULL &amp;amp;&amp;amp; stat(accessor="registry",
 filename="HKEY_CLASSES_ROOT/CLSID/{" + GUID + "}/@").Data.value ) || GUID

 LET GetPropertyValues(Values) = to_dict(item={
 SELECT _value.Value.Value[0] AS _value, _value.Value.Description[0] AS _key
 FROM foreach(row=Values)
 })

 LET KnownGUIDLookup &amp;lt;= dict(
 `20D04FE0-3AEA-1069-A2D8-08002B30309D`="My Computer",
 `F02C1A0D-BE21-4350-88B0-7367FC96EF3C`="Computers and Devices",
 `679F85CB-0220-4080-B29B-5540CC05AAB6`="Quick Access",
 `DE61D971-5EBC-4F02-A3A9-6C82895E5C04`='AddNewPrograms',
 `724EF170-A42D-4FEF-9F26-B60E846FBA4F`='AdminTools',
 `A520A1A4-1780-4FF6-BD18-167343C5AF16`='AppDataLow',
 `A305CE99-F527-492B-8B1A-7E76FA98D6E4`='AppUpdates',
 `9E52AB10-F80D-49DF-ACB8-4330F5687855`='CDBurning',
 `DF7266AC-9274-4867-8D55-3BD661DE872D`='ChangeRemovePrograms',
 `D0384E7D-BAC3-4797-8F14-CBA229B392B5`='CommonAdminTools',
 `C1BAE2D0-10DF-4334-BEDD-7AA20B227A9D`='CommonOEMLinks',
 `0139D44E-6AFE-49F2-8690-3DAFCAE6FFB8`='CommonPrograms',
 `A4115719-D62E-491D-AA7C-E74B8BE3B067`='CommonStartMenu',
 `82A5EA35-D9CD-47C5-9629-E15D2F714E6E`='CommonStartup',
 `B94237E7-57AC-4347-9151-B08C6C32D1F7`='CommonTemplates',
 `0AC0837C-BBF8-452A-850D-79D08E667CA7`='Computer',
 `4BFEFB45-347D-4006-A5BE-AC0CB0567192`='Conflict',
 `6F0CD92B-2E97-45D1-88FF-B0D186B8DEDD`='Connections',
 `56784854-C6CB-462B-8169-88E350ACB882`='Contacts',
 `82A74AEB-AEB4-465C-A014-D097EE346D63`='ControlPanel',
 `2B0F765D-C0E9-4171-908E-08A611B84FF6`='Cookies',
 `B4BFCC3A-DB2C-424C-B029-7FE99A87C641`='Desktop',
 `FDD39AD0-238F-46AF-ADB4-6C85480369C7`='Documents',
 `088E3905-0323-4B02-9826-5D99428E115F`='Downloads',
 `374DE290-123F-4565-9164-39C4925E467B`='Downloads',
 `1777F761-68AD-4D8A-87BD-30B759FA33DD`='Favorites',
 `FD228CB7-AE11-4AE3-864C-16F3910AB8FE`='Fonts',
 `CAC52C1A-B53D-4EDC-92D7-6B2E8AC19434`='Games',
 `054FAE61-4DD8-4787-80B6-090220C4B700`='GameTasks',
 `D9DC8A3B-B784-432E-A781-5A1130A75963`='History',
 `4D9F7874-4E0C-4904-967B-40B0D20C3E4B`='Internet',
 `352481E8-33BE-4251-BA85-6007CAEDCF9D`='InternetCache',
 `BFB9D5E0-C6A9-404C-B2B2-AE6DB6AF4968`='Links',
 `F1B32785-6FBA-4FCF-9D55-7B8E7F157091`='LocalAppData',
 `2A00375E-224C-49DE-B8D1-440DF7EF3DDC`='LocalizedResourcesDir',
 `4BD8D571-6D19-48D3-BE97-422220080E43`='Music',
 `3DFDF296-DBEC-4FB4-81D1-6A3438BCF4DE`="Music",
 `C5ABBF53-E17F-4121-8900-86626FC2C973`='NetHood',
 `D20BEEC4-5CA8-4905-AE3B-BF251EA09B53`='Network',
 `31C0DD25-9439-4F12-BF41-7FF4EDA38722`='Objects3D',
 `2C36C0AA-5812-4B87-BFD0-4CD0DFB19B39`='OriginalImages',
 `69D2CF90-FC33-4FB7-9A0C-EBB0F0FCB43C`='PhotoAlbums',
 `33E28130-4E1E-4676-835A-98395C3BC3BB`='Pictures',
 `24AD3AD4-A569-4530-98E1-AB02F9417AA8`="LocalPictures",
 `DE92C1C7-837F-4F69-A3BB-86E631204A23`='Playlists',
 `76FC4E2D-D6AD-4519-A663-37BD56068185`='Printers',
 `9274BD8D-CFD1-41C3-B35E-B13F55A758F4`='PrintHood',
 `5E6C858F-0E22-4760-9AFE-EA3317B67173`='Profile',
 `62AB5D82-FDC1-4DC3-A9DD-070D1D495D97`='ProgramData',
 `905E63B6-C1BF-494E-B29C-65B732D3D21A`='ProgramFiles',
 `F7F1ED05-9F6D-47A2-AAAE-29D317C6F066`='ProgramFilesCommon',
 `6365D5A7-0F0D-45E5-87F6-0DA56B6A4F7D`='ProgramFilesCommonX64',
 `DE974D24-D9C6-4D3E-BF91-F4455120B917`='ProgramFilesCommonX86',
 `6D809377-6AF0-444B-8957-A3773F02200E`='ProgramFilesX64',
 `7C5A40EF-A0FB-4BFC-874A-C0F2E0B9FA8E`='ProgramFilesX86',
 `A77F5D77-2E2B-44C3-A6A2-ABA601054A51`='Programs',
 `7B81BE6A-CE2B-4676-A29E-EB907A5126C5`='Programs and Features',
 `DFDF76A2-C82A-4D63-906A-5644AC457385`='Public',
 `C4AA340D-F20F-4863-AFEF-F87EF2E6BA25`='PublicDesktop',
 `ED4824AF-DCE4-45A8-81E2-FC7965083634`='PublicDocuments',
 `3D644C9B-1FB8-4F30-9B45-F670235F79C0`='PublicDownloads',
 `DEBF2536-E1A8-4C59-B6A2-414586476AEA`='PublicGameTasks',
 `3214FAB5-9757-4298-BB61-92A9DEAA44FF`='PublicMusic',
 `B6EBFB86-6907-413C-9AF7-4FC2ABF07CC5`='PublicPictures',
 `2400183A-6185-49FB-A2D8-4A392A602BA3`='PublicVideos',
 `52A4F021-7B75-48A9-9F6B-4B87A210BC8F`='QuickLaunch',
 `AE50C081-EBD2-438A-8655-8A092E34987A`='Recent',
 `BD85E001-112E-431E-983B-7B15AC09FFF1`='RecordedTV',
 `B7534046-3ECB-4C18-BE4E-64CD4CB7D6AC`='RecycleBin',
 `8AD10C31-2ADB-4296-A8F7-E4701232C972`='ResourceDir',
 `3EB685DB-65F9-4CF6-A03A-E3EF65729F3D`='RoamingAppData',
 `B250C668-F57D-4EE1-A63C-290EE7D1AA1F`='SampleMusic',
 `C4900540-2379-4C75-844B-64E6FAF8716B`='SamplePictures',
 `15CA69B3-30EE-49C1-ACE1-6B5EC372AFB5`='SamplePlaylists',
 `859EAD94-2E85-48AD-A71A-0969CB56A6CD`='SampleVideos',
 `4C5C32FF-BB9D-43B0-B5B4-2D72E54EAAA4`='SavedGames',
 `7D1D3A04-DEBB-4115-95CF-2F29DA2920DA`='SavedSearches',
 `EE32E446-31CA-4ABA-814F-A5EBD2FD6D5E`='SEARCH_CSC',
 `98EC0E18-2098-4D44-8644-66979315A281`='SEARCH_MAPI',
 `190337D1-B8CA-4121-A639-6D472D16972A`='SearchHome',
 `8983036C-27C0-404B-8F08-102D10DCFD74`='SendTo',
 `7B396E54-9EC5-4300-BE0A-2482EBAE1A26`='SidebarDefaultParts',
 `A75D362E-50FC-4FB7-AC2C-A8BEAA314493`='SidebarParts',
 `625B53C3-AB48-4EC1-BA1F-A1EF4146FC19`='StartMenu',
 `B97D20BB-F46A-4C97-BA10-5E3608430854`='Startup',
 `43668BF8-C14E-49B2-97C9-747784D784B7`='SyncManager',
 `289A9A43-BE44-4057-A41B-587A76D7E7F9`='SyncResults',
 `0F214138-B1D3-4A90-BBA9-27CBC0C5389A`='SyncSetup',
 `1AC14E77-02E7-4E5D-B744-2EB1AE5198B7`='System',
 `D65231B0-B2F1-4857-A4CE-A8E7C6EA7D27`='SystemX86',
 `A63293E8-664E-48DB-A079-DF759E0509F7`='Templates',
 `5B3749AD-B49F-49C1-83EB-15370FBD4882`='TreeProperties',
 `0762D272-C50A-4BB0-A382-697DCD729B80`='UserProfiles',
 `F3CE0F7C-4901-4ACC-8648-D5D44B04EF8F`='UsersFiles',
 `18989B1D-99B5-455B-841C-AB7C74E4DDFC`='Videos',
 `F86FA3AB-70D2-4FC7-9C99-FCBF05467F3A`='Videos',
 `F38BF404-1D43-42F2-9305-67DE0B28FC23`='Windows')

 LET _PropertyValueDispatcher &amp;lt;= dict(
 `20D04FE0-3AEA-1069-A2D8-08002B30309D`="x=&amp;gt;dict(LongName='ComputerName')",
 `D5CDD502-2E9C-101B-9397-08002B2CF9AE`="x=&amp;gt;x.__DocumentSummaryInformation",
 `28636AA6-953D-11D2-B5D6-00C04FD918D0`="x=&amp;gt;x.__SHELL_DETAILS",
 `446D16B1-8DAD-4870-A748-402EA43D788C`="x=&amp;gt;x.__CACHE",
 `46588AE2-4CBC-4338-BBFC-139326986DCE`="x=&amp;gt;x.__User",
 `841E4F90-FF59-4D16-8947-E81BBFFAB36D`="x=&amp;gt;x.__Software",
 `86407DB8-9DF7-48CD-B986-F999ADC19731`="x=&amp;gt;x.__Share",
 `86D40B4D-9069-443C-819A-2A54090DCCEC`="x=&amp;gt;x.__Tile",
 `9F4C2855-9F79-4B39-A8D0-E1D42DE1D5F3`="x=&amp;gt;x.__AppUserModel",
 `B725F130-47EF-101A-A5F1-02608C9EEBAC`="x=&amp;gt;x.__STORAGE",
 `DABD30ED-0043-4789-A7F8-D013A4736622`="x=&amp;gt;x.__FolderDisplay",
 `E3E0584C-B788-4A5A-BB20-7F5A44C9ACDD`="x=&amp;gt;x.__SEARCH",
 `F29F85E0-4FF9-1068-AB91-08002B27B3D9`="x=&amp;gt;x.__Document",
 `DEBDA43A-37B3-4383-91E7-4498DA2995AB`="x=&amp;gt;x.__NetworkInfo",
 `FB8D2D7B-90D1-4E34-BF60-6EAC09922BBF`="x=&amp;gt;x.__Hash")

 LET PropertyValueDispatcher(x) = eval(
 args=[x,],
 func=get(item=_PropertyValueDispatcher,
 member=x.ParentOf.Format,
 default='x=&amp;gt;"GUID not known"'))

 LET Profile = '''
 [
 ["ShellLinkHeader", 0, [
 ["HeaderSize", 0, "uint32"],
 ["__LinkClsID", 4, "String", {
 "length": 16,
 "term": ""
 }],
 ["LinkClsID", 0, "Value", {
 "value": "x=&amp;gt;format(format='%x', args=x.__LinkClsID)"
 }],
 ["LinkFlags", 20, "Flags", {
 "type": "uint32",
 "bitmap": {
 "HasLinkTargetIDList": 0,
 "HasLinkInfo": 1,
 "HasName": 2,
 "HasRelativePath": 3,
 "HasWorkingDir": 4,
 "HasArguments": 5,
 "HasIconLocation": 6,
 "IsUnicode": 7,
 "ForceNoLinkInfo": 8,
 "HasExpString": 9,
 "RunInSeparateProcess": 10,
 "HasDarwinID": 12,
 "RunAsUser": 13,
 "HasExpIcon": 14,
 "NoPidlAlias": 15,
 "RunWithShimLayer": 17,
 "ForceNoLinkTrack": 18,
 "EnableTargetMetadata": 19,
 "DisableLinkPathTracking": 20,
 "DisableKnownFolderTracking": 21,
 "DisableKnownFolderAlias": 22,
 "AllowLinkToLink": 23,
 "UnaliasOnSave": 24,
 "PreferEnvironmentPath": 25,
 "KeepLocalIDListForUNCTarget": 26
 }
 }],
 ["FileAttributes", 24, "Flags", {
 "type": "uint32",
 "bitmap": {
 "FILE_ATTRIBUTE_READONLY": 0,
 "FILE_ATTRIBUTE_HIDDEN": 1,
 "FILE_ATTRIBUTE_SYSTEM": 2,
 "FILE_ATTRIBUTE_DIRECTORY": 4,
 "FILE_ATTRIBUTE_ARCHIVE": 5,
 "FILE_ATTRIBUTE_NORMAL": 7,
 "FILE_ATTRIBUTE_TEMPORARY": 8,
 "FILE_ATTRIBUTE_SPARSE_FILE": 9,
 "FILE_ATTRIBUTE_REPARSE_POINT": 10,
 "FILE_ATTRIBUTE_COMPRESSED": 11,
 "FILE_ATTRIBUTE_OFFLINE": 12,
 "FILE_ATTRIBUTE_NOT_CONTENT_INDEXED": 13,
 "FILE_ATTRIBUTE_ENCRYPTED": 14,
 }
 }],
 ["CreationTime", 28, "WinFileTime", {
 "type": "uint64"
 }],
 ["AccessTime", 36, "WinFileTime", {
 "type": "uint64"
 }],
 ["WriteTime", 44, "WinFileTime", {
 "type": "uint64"
 }],

 ["FileSize", 52, "uint32"],
 ["IconIndex", 56, "uint32"],
 ["ShowCommand", 60, "Enumeration", {
 "type": "uint32",
 "map": {
 "SHOWNORMAL": 0x00000001,
 "SHOWMAXIMIZED": 0x00000003,
 "SHOWMINNOACTIVE": 0x00000007,
 }
 }],
 ["__HotKeyLow", 62, "Enumeration", {
 "type": "uint8",
 "map": {
 "No key assigned." : 0x00,
 "0" : 0x30,
 "1" : 0x31,
 "2" : 0x32,
 "3" : 0x33,
 "4" : 0x34,
 "5" : 0x35,
 "6" : 0x36,
 "7" : 0x37,
 "8" : 0x38,
 "9" : 0x39,
 "A" : 0x41,
 "B" : 0x42,
 "C" : 0x43,
 "D" : 0x44,
 "E" : 0x45,
 "F" : 0x46,
 "G" : 0x47,
 "H" : 0x48,
 "I" : 0x49,
 "J" : 0x4A,
 "K" : 0x4B,
 "L" : 0x4C,
 "M" : 0x4D,
 "N" : 0x4E,
 "O" : 0x4F,
 "P" : 0x50,
 "Q" : 0x51,
 "R" : 0x52,
 "S" : 0x53,
 "T" : 0x54,
 "U" : 0x55,
 "V" : 0x56,
 "W" : 0x57,
 "X" : 0x58,
 "Y" : 0x59,
 "Z" : 0x5A,
 "F1" : 0x70,
 "F2" : 0x71,
 "F3" : 0x72,
 "F4" : 0x73,
 "F5" : 0x74,
 "F6" : 0x75,
 "F7" : 0x76,
 "F8" : 0x77,
 "F9" : 0x78,
 "F10" : 0x79,
 "F11" : 0x7A,
 "F12" : 0x7B,
 "F13" : 0x7C,
 "F14" : 0x7D,
 "F15" : 0x7E,
 "F16" : 0x7F,
 "F17" : 0x80,
 "F18" : 0x81,
 "F19" : 0x82,
 "F20" : 0x83,
 "F21" : 0x84,
 "F22" : 0x85,
 "F23" : 0x86,
 "F24" : 0x87,
 "NumLock" : 0x90,
 "ScrollLock" : 0x91,
 }
 }],
 ["__HotKeyHigh", 63, "Enumeration", {
 "type": "uint8",
 "map": {
 "No modifier key used." : 0x00,
 "SHIFT" : 0x01,
 "CONTROL" : 0x02,
 "ALT" : 0x04,
 }
 }],
 ["HotKey", 0, "Value", {
 "value": "x=&amp;gt;if(condition= x.__HotKeyLow=~'No key assigned',
 then=x.__HotKeyLow,
 else=x.__HotKeyLow + ' + ' + x.__HotKeyHigh)"

 }],

 # The LinkTargetIDList only exists if the Link Flag is set otherwise it is empty.
 ["LinkTargetIDList", "x=&amp;gt;x.HeaderSize", "Union", {
 "selector": "x=&amp;gt;x.LinkFlags =~ 'HasLinkTargetIDList'",
 "choices": {
 "true": "LinkTargetIDList",
 "false": "Empty"
 }
 }],
 ["LinkInfo", "x=&amp;gt;x.LinkTargetIDList.EndOf", "Union", {
 "selector": "x=&amp;gt;x.LinkFlags =~ 'HasLinkInfo'",
 "choices": {
 "true": "LinkInfo",
 "false": "Empty"
 }
 }],

 # StringData flag checks
 ["__Name", "x=&amp;gt;x.LinkInfo.EndOf", "Union", {
 "selector": "x=&amp;gt;x.LinkFlags =~ 'HasName'",
 "choices": {
 "true": "Name",
 "false": "Empty"
 }
 }],
 ["__RelativePath", "x=&amp;gt;x.__Name.EndOf", "Union", {
 "selector": "x=&amp;gt;x.LinkFlags =~ 'HasRelativePath'",
 "choices": {
 "true": "RelativePath",
 "false": "Empty"
 }
 }],
 ["__WorkingDir", "x=&amp;gt;x.__RelativePath.EndOf", "Union", {
 "selector": "x=&amp;gt;x.LinkFlags =~ 'HasWorkingDir'",
 "choices": {
 "true": "WorkingDir",
 "false": "Empty"
 }
 }],
 ["__Arguments", "x=&amp;gt;x.__WorkingDir.EndOf", "Union", {
 "selector": "x=&amp;gt;x.LinkFlags =~ 'HasArguments'",
 "choices": {
 "true": "Arguments",
 "false": "Empty"
 }
 }],
 ["__IconLocation", "x=&amp;gt;x.__Arguments.EndOf", "Union", {
 "selector": "x=&amp;gt;x.LinkFlags =~ 'HasIconLocation'",
 "choices": {
 "true": "IconLocation",
 "false": "Empty"
 }
 }],
 ["StringData",0,"StringData"],
 ["ExtraData", "x=&amp;gt;x.__IconLocation.EndOf", "Array", {
 "type": "ExtraData",
 "count": 1000,
 "sentinel": "x=&amp;gt;x.Size &amp;lt; 0x00000004"
 }],
 ["Overlay", "x=&amp;gt;x.ExtraData.EndOf", "Overlay"],

 ]],

 # Struct size includes the size field
 ["LinkTargetIDList", "x=&amp;gt;x.IDListSize + 2", [
 ["IDListSize", 0, "uint16"],
 ["IDList", 2, "Array", {
 "type": "ItemIDList",
 "count": 1000 # Max count until sentinel
 }]
 ]],

 # Item List contains shell bags
 ["ItemIDList", "x=&amp;gt;x.ItemIDSize", [
 ["ItemIDSize", 0, "uint16"],
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Type", 2, "uint8"],
 ["TypeHex", 0, Value, {
 value: "x=&amp;gt;format(format='%#02x', args=x.Type)",
 }],

 # https://github.com/EricZimmerman/Lnk/blob/a9e6ebcf7e032efd1172ff8a88a4e870b446fa18/Lnk/LnkFile.cs#L131
 ["ShellBag", 0, "Union", {
 "selector": "x=&amp;gt;format(format='%#02x', args=x.Type)",
 "choices": {
 "0x00": "ShellBag0x00",
 "0x01": "ShellBag0x01",
 "0x02": "ShellBag0x20",
 "0x03": "ShellBag0x30",
 "0x04": "ShellBag0x40",

 "0x13": "ShellBagZipContentsWithParent",
 "0x1f": "ShellBag0x1f",
 "0x20": "ShellBag0x20",
 "0x21": "ShellBag0x20",
 "0x22": "ShellBag0x20",
 "0x23": "ShellBag0x20",
 "0x2a": "ShellBag0x20",
 "0x2e": "ShellBag0x20",
 "0x2f": "ShellBag0x20",
 "0x31": "ShellBag0x30",
 "0x32": "ShellBag0x32",
 "0x35": "ShellBag0x30",
 "0x36": "ShellBag0x30",
 "0x3a": "ShellBag0x30",
 "0x3a": "ShellBag0x30",
 "0x3f": "ShellBagZipContentsWithParent",
 "0x41": "ShellBag0x40",
 "0x42": "ShellBag0x40",
 "0x43": "ShellBag0x40",
 "0x46": "ShellBag0x40",
 "0x47": "ShellBag0x40",
 "0x4b": "ShellBagZipContentsWithParent",
 "0x52": "ShellBagZipContentsWithParent",
 "0x61": "ShellBag0x61",
 "0x71": "ShellBag0x71",
 "0x74": "ShellBag0x74",
 "0x77": "ShellBag0x74",
 "0x79": "ShellBagZipContents",
 "0xaa": "ShellBagZipContents",
 "0xae": "ShellBagZipContents",
 "0xb1": "ShellBag0x30",
 "0xc3": "ShellBag0xc3",
 }
 }]
 ]],

 ["ShellBag0x00", 0, [
 ["DataSize", 4, "uint16"],
 ["__Magic", 4, "uint32"],
 ["DataSig", 6, "uint32"],
 ["PropertySheetListSize", 10, "uint16"],
 ["IdentifierSize", 12, "uint16"],
 ["IdentifierData", 14, String, {
 length: "x=&amp;gt;x.IdentifierSize",
 }],
 ["PropertyList", "x=&amp;gt;14 + x.IdentifierSize", Array, {
 type: "PropertyStorage",
 count: 10,
 sentinel: "x=&amp;gt;x.StorageSize = 0",
 }],
 ["Properties", 0, "Value", {
 "value": 'x=&amp;gt;GetPropertyValues(Values=x.PropertyList.PropertyValue)'
 }],
 ["__CDBurnType", 0, Value, {value: "x=&amp;gt;x.__Magic = 0x4d677541"}],
 ["__ZipFileContents", 0, "ShellBagZipContents"],
 ["__CDBurn", 0, "ShellBagCDBurn"],
 ["__ItemNameDisplay", 0, Value, {
 value: "x=&amp;gt;get(item=x.Properties, field='System.ItemNameDisplay')",
 }],

 # Handle some special cases.
 ["Description", 0, "Value", {
 value: "x=&amp;gt; (x.__CDBurnType &amp;amp;&amp;amp; x.__CDBurn.Description) ||
 (x.__ItemNameDisplay &amp;amp;&amp;amp; dict(Type='Variable',
 Properties=x.Properties,
 LongName=x.__ItemNameDisplay) ) ||
 x.__ZipFileContents.Description",
 }]
 ]],

 ["ShellBagCDBurn", 0, [
 ["DataSize", 20, "uint16"],

 # Variable length search for the extension signature from the start of the struct.
 ["__pre", 0, "String", {
 "term_hex": "0400efbe"
 }],

 # The extension tag should be immediately after the search string.
 ["__ExtensionTag", "x=&amp;gt;len(list=x.__pre)", "uint32"],

 # Extension starts 4 bytes before the tag
 ["Extension", "x=&amp;gt;len(list=x.__pre) - 4", "Union", {
 "selector": "x=&amp;gt;format(format='%#x', args=x.__ExtensionTag)",
 "choices": {
 "0xbeef0004": "Beef0004",
 }
 }],

 # Put all the data together in a convenient location
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type="CDBurn",
 LongName=x.Extension.LongName)',
 }],
 ]],

 ["ShellBag0x01", 0, [
 ["ItemSize", 0, "uint16"],
 ["__SpecialDataSig", 4, "uint32"],
 ["__SpecialDataSigString", 14, String, {
 length: "x=&amp;gt;x.ItemSize - 14",
 term: "",
 }],
 ["Category", 8, Enumeration, {
 type: "uint8",
 choices: {
 "0": "All Control Panel Items",
 "1": "Appearance and Personalization",
 "2": "Hardware and Sound",
 "3": "Network and Internet",
 "4": "Sound, Speech and Audio Devices",
 "5": "System and Security",
 "6": "Clock, Language, and Region",
 "7": "Ease of Access",
 "8": "Programs",
 "9": "User Accounts",
 "10": "Security Center",
 "11": "Mobile PC",
 }
 }],
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type="Control Panel",
 LongName="Control Panel\\" + x.Category)',
 }],
 ]],

 ["ShellBag0x71", 0, [
 ["GUID", 14, "GUID"],
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type="GUID: Control Panel",
 LongName="Control Panel\\" + GetClassName(GUID=x.GUID.Value))',
 }],
 ]],

 ["ShellBag0x74", 0, [
 ["Size", 4, "uint16"],

 # Variable length search for the extension signature from the
 # start of the struct.
 ["__pre", 0, "String", {
 "term_hex": "0400efbe"
 }],

 # The extension tag should be immediately after the search string.
 ["__ExtensionTag", "x=&amp;gt;len(list=x.__pre)", "uint32"],

 # Extension starts 4 bytes before the tag
 ["Extension", "x=&amp;gt;len(list=x.__pre) - 4", "Union", {
 "selector": "x=&amp;gt;format(format='%#x', args=x.__ExtensionTag)",
 "choices": {
 "0xbeef0004": "Beef0004",
 }
 }],

 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type="Users Files Folder",
 LongName=x.Extension.LongName)',
 }],
 ]],

 # TODO
 ["ShellBag0x61", 0, [

 ]],

 ["ShellBag0xc3", 0, [

 ]],

 ["ShellBagZipContents", 0, [
 ["DateString", 0x24, String, {
 encoding: "utf16",
 }],
 ["__FolderNameSize1", 84, uint32],
 ["__FolderNameSize2", 88, uint32],
 ["__FolderNameSize", 0, Value, {
 value: "x=&amp;gt;x.__FolderNameSize1 || x.__FolderNameSize2"
 }],
 ["FolderName", 92, String, {
 encoding: "utf16",
 length: "x=&amp;gt;x.__FolderNameSize * 2",
 }],
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type="Zip file contents",
 DateString=x.DateString,
 LongName=x.FolderName
 )'
 }]
 ]],

 ["ShellBagZipContentsWithParent", 0, [
 ["DateString", 0x24, String, {
 encoding: "utf16",
 }],
 ["__FolderNameSize", 84, uint32],
 ["__ParentFolderNameSize", 88, uint32],
 ["FolderName", 92, String, {
 encoding: "utf16",
 length: "x=&amp;gt;x.__FolderNameSize * 2",
 }],
 ["Start", 0, Value, {value: "x=&amp;gt;x.__FolderNameSize *2 + 94"}],
 ["ParentFolderName", "x=&amp;gt;x.__FolderNameSize *2 + 94", String, {
 encoding: "utf16",
 length: "x=&amp;gt;x.__ParentFolderNameSize * 2",
 }],
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type="Zip file contents",
 DateString=x.DateString,
 LongName=x.FolderName,
 FullPath=x.ParentFolderName + x.FolderName
 )'
 }]
 ]],


 ["ShellBag0x40", 0, [
 ["Name", 5, "String", {
 encoding: "utf8",
 }],
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type="NetworkLocation",
 LongName=x.Name
 )'
 }]
 ]],

 # A LinkInfo stores information about the destination of the link.
 ["LinkInfo", "x=&amp;gt;x.__LinkInfoSize", [
 ["__LinkInfoOffset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["__LinkInfoSize", 0, "uint32"],
 ["__LinkInfoHeaderSize", 4, "uint32"],
 ["LinkInfoFlags", 8, "Flags", {
 "type": "uint32",
 "bitmap": {
 "VolumeIDAndLocalBasePath": 0,
 "CommonNetworkRelativeLinkAndPathSuffix": 1
 }
 }],
 ["__VolumeIDOffset", 0xc, "uint32"],
 ["__LocalBasePathOffset", 16, "uint32"],
 ["__CommonNetworkRelativeLinkOffset", 20, "uint32"],
 ["__CommonPathSuffixOffset", 24, "uint32"],
 ["__LocalBasePath", "x=&amp;gt;x.__LocalBasePathOffset", "String", {}],
 ["__CommonNetworkRelativePath", "x=&amp;gt;x.__CommonNetworkRelativeLinkOffset", "String"],
 ["__CommonPathSuffix", "x=&amp;gt;x.__CommonPathSuffixOffset", "String"],
 ["__VolumeID", "x=&amp;gt;x.__VolumeIDOffset", "VolumeID"],
 ["__CommonNetworkRelativeLink", "x=&amp;gt;x.__CommonNetworkRelativeLinkOffset", "CommonNetworkRelativeLink"],
 ["Target", 0, "Value", { # Depending on the LinkInfoFlags this struct needs to be interpreted differently.
 "value": '
 x=&amp;gt;if(condition=x.LinkInfoFlags =~ "VolumeIDAndLocalBasePath",
 then=dict(Path=x.__LocalBasePath,
 VolumeInfo=x.__VolumeID),
 else=dict(Path=format(format="%v\\%v",
 args=[x.__CommonNetworkRelativeLink.NetName, x.__CommonPathSuffix]),
 RelativeLink=x.__CommonNetworkRelativeLink) )'
 }]
 ]],

 ["CommonNetworkRelativeLink", 0, [
 ["__CommonNetworkRelativeLinkSize", 0, "uint32"],
 ["__CommonNetworkRelativeLinkFlags", 4, "Flags", {
 "type": "uint32",
 "bitmap": {
 "ValidDevice": 0,
 "ValidNetType": 1,
 }
 }],
 ["__NetNameOffset", 8, "uint32"],
 ["__DeviceNameOffset", 12, "uint32"],
 ["NetworkProviderType", 16, "Enumeration", {
 "type": "uint32",
 "map": {
 "WNNC_NET_AVID": 0x001A0000,
 "WNNC_NET_DOCUSPACE": 0x001B0000,
 "WNNC_NET_MANGOSOFT": 0x001C0000,
 "WNNC_NET_SERNET": 0x001D0000,
 "WNNC_NET_RIVERFRONT1": 0X001E0000,
 "WNNC_NET_RIVERFRONT2": 0x001F0000,
 "WNNC_NET_DECORB": 0x00200000,
 "WNNC_NET_PROTSTOR": 0x00210000,
 "WNNC_NET_FJ_REDIR": 0x00220000,
 "WNNC_NET_DISTINCT": 0x00230000,
 "WNNC_NET_TWINS": 0x00240000,
 "WNNC_NET_RDR2SAMPLE": 0x00250000,
 "WNNC_NET_CSC": 0x00260000,
 "WNNC_NET_3IN1": 0x00270000,
 "WNNC_NET_EXTENDNET": 0x00290000,
 "WNNC_NET_STAC": 0x002A0000,
 "WNNC_NET_FOXBAT": 0x002B0000,
 "WNNC_NET_YAHOO": 0x002C0000,
 "WNNC_NET_EXIFS": 0x002D0000,
 "WNNC_NET_DAV": 0x002E0000,
 "WNNC_NET_KNOWARE": 0x002F0000,
 "WNNC_NET_OBJECT_DIRE": 0x00300000,
 "WNNC_NET_MASFAX": 0x00310000,
 "WNNC_NET_HOB_NFS": 0x00320000,
 "WNNC_NET_SHIVA": 0x00330000,
 "WNNC_NET_IBMAL": 0x00340000,
 "WNNC_NET_LOCK": 0x00350000,
 "WNNC_NET_TERMSRV": 0x00360000,
 "WNNC_NET_SRT": 0x00370000,
 "WNNC_NET_QUINCY": 0x00380000,
 "WNNC_NET_OPENAFS": 0x00390000,
 "WNNC_NET_AVID1": 0X003A0000,
 "WNNC_NET_DFS": 0x003B0000,
 "WNNC_NET_KWNP": 0x003C0000,
 "WNNC_NET_ZENWORKS": 0x003D0000,
 "WNNC_NET_DRIVEONWEB": 0x003E0000,
 "WNNC_NET_VMWARE": 0x003F0000,
 "WNNC_NET_RSFX": 0x00400000,
 "WNNC_NET_MFILES": 0x00410000,
 "WNNC_NET_MS_NFS": 0x00420000,
 "WNNC_NET_GOOGLE": 0x00430000,
 }
 }],
 ["__NetNameOffsetUnicode", 20, "uint32"],
 ["__DeviceNameOffsetUnicode", 24, "uint32"],
 ["__NetNameAscii", "x=&amp;gt;x.__NetNameOffset", "String"],
 ["__DeviceNameAscii", "x=&amp;gt;x.__DeviceNameOffset", "String"],
 ["__NetNameUnicode", "x=&amp;gt;x.__NetNameOffsetUnicode", "String", {"encoding": "utf16"}],
 ["__DeviceNameUnicode", "x=&amp;gt;x.__DeviceNameOffsetUnicode", "String", {"encoding": "utf16"}],
 ["NetName", 0, "Value", {
 "value": "x=&amp;gt;if(condition=x.__NetNameOffset, then=x.__NetNameAscii, else=x.__NetNameUnicode)"
 }],
 ["DeviceName", 0, "Value", {
 "value": "x=&amp;gt;if(condition=x.__DeviceNameOffset, then=x.__DeviceNameAscii, else=x.__DeviceNameUnicode)"
 }]
 ]],

 # This is a comment
 ["VolumeID", 0, [
 ["__VolumeIDSize", 0, "uint32"],
 ["DriveType", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "0": "DRIVE_UNKNOWN",
 "1": "DRIVE_NO_ROOT_DIR",
 "2": "DRIVE_REMOVABLE",
 "3": "DRIVE_FIXED",
 "4": "DRIVE_REMOTE",
 "5": "DRIVE_CDROM",
 "6": "DRIVE_RAMDISK"
 }
 }],
 ["DriveSerialNumber", 8, "uint32"],
 ["__VolumeLabelOffset", 12, "uint32"],
 ["__VolumeLabelOffsetUnicode", 16, "uint32"],
 ["__VolumeLabelAscii", "x=&amp;gt;x.__VolumeLabelOffset", "String"],
 ["__VolumeLabelUnicode", "x=&amp;gt;x.__VolumeLabelOffsetUnicode", "String", {"encoding": "utf16"}],
 ["VolumeLabel", 0, "Value", {
 "value": 'x=&amp;gt;if(condition=x.__VolumeLabelOffset,
 then=x.__VolumeLabelAscii, else=x.__VolumeLabelUnicode)'
 }]
 ]],

 # Volume name
 ["ShellBag0x20", 0, [
 ["__Name", 3, "String"],
 ["Subtype", 2, "BitField", {
 "type": "uint8",
 "start_bit": 0,
 "end_bit": 1,
 }],
 ["__GUID", 4, "GUID"],
 ["__GUIDFlag", 3, "uint8"],

 # Name is only valid if the first bit is set.
 ["Name", 3, "Value", {
 "value": "x=&amp;gt;(x.__GUIDFlag = 0x80 &amp;amp;&amp;amp; GetClassName(GUID=x.__GUID.Value) ) ||
 (x.Subtype &amp;amp;&amp;amp; x.__Name) || ''",
 }],
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 LongName=x.Name,
 ShortName=x.Name,
 GUID=if(condition=x.__GUIDFlag = 0x80, then=x.__GUID.Value),
 Type="Volume"
 )'
 }]
 ]],

 ["ShellBag0x2f", 0, [

 ]],

 ["ShellBag0x2e", 0, [

 ]],

 # Marks the root class My Computer
 ["ShellBag0x1f", 0, [
 ["Type", 0, "uint8"],
 ["UserPropertyType", 4, "uint8"],
 ["UserPropertyName", 13, "String", {length: 3}],
 ["GUID", 4, "GUID"],
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt; ( x.UserPropertyType != 0x2f &amp;amp;&amp;amp;
 dict(
 LongName=GetClassName(GUID=x.GUID.Value) || "My Computer",
 GUID=x.GUID.Value,
 Type="Root"
 )) || dict(
 Type="UserPropertyType",
 LongName=x.UserPropertyName
 )'
 }]
 ]],

 # Represent a file or directory
 ["ShellBag0x30", 0, [
 ["Size", 0, "uint16"],
 ["Type", 2, "uint8"],
 ["SubType", 2, "Flags", {
 "type": "uint8",
 "bitmap": {
 "File": 1,
 "Directory": 0,
 "Unicode": 4,
 }
 }],
 ["__LastModificationTime", 8, "uint32"],
 ["LastModificationTime", 8, "FatTimestamp"],
 ["ShortName", 14, "String"],

 # Variable length search for the extension signature from the start of the struct.
 ["__pre", 0, "String", {
 "term_hex": "0400efbe"
 }],

 # The extension tag should be immediately after the search string.
 ["__ExtensionTag", "x=&amp;gt;len(list=x.__pre)", "uint32"],

 # Extension starts 4 bytes before the tag
 ["Extension", "x=&amp;gt;len(list=x.__pre) - 4", "Union", {
 "selector": "x=&amp;gt;format(format='%#x', args=x.__ExtensionTag)",
 "choices": {
 "0xbeef0004": "Beef0004",
 }
 }],

 # Put all the data together in a convenient location
 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;dict(
 Type=x.SubType,
 Modified=if(condition=x.__LastModificationTime, then=x.LastModificationTime),
 LastAccessed=if(condition=x.Extension.__LastAccessed, then=x.Extension.LastAccessed),
 CreateDate=if(condition=x.Extension.__CreateDate, then=x.Extension.CreateDate),
 ShortName=x.ShortName,
 LongName=x.Extension.LongName,
 MFTID=x.Extension.MFTReference.MFTID,
 MFTSeq=x.Extension.MFTReference.SequenceNumber
 )'
 }]
 ]],

 ["ShellBag0x32", 0, [
 ["Size", 0, "uint16"],
 ["ShellBagZipContents", 0, "ShellBagZipContents"],
 ["__ShellBagZipContentsValid", 0, Value, {
 value: "x=&amp;gt;x.Size &amp;gt; 0x28",
 }],

 ["__pre", 0, "String", {
 "term_hex": "0400efbe"
 }],

 # The extension tag should be immediately after the search string.
 ["__ExtensionTag", "x=&amp;gt;len(list=x.__pre)", "uint32"],

 # Extension starts 4 bytes before the tag
 ["Extension", "x=&amp;gt;len(list=x.__pre) - 4", "Union", {
 "selector": "x=&amp;gt;format(format='%#x', args=x.__ExtensionTag)",
 "choices": {
 "0xbeef0004": "Beef0004",
 }
 }],

 ["Description", 0, "Value", {
 "value": 'x=&amp;gt;if(condition=x.__ShellBagZipContentsValid AND NOT x.Extension.LongName,
 then=x.ShellBagZipContents.Description,
 else=dict(Type="File",
 LongName=x.Extension.LongName))',
 }],

 ]],

 ["Beef0004", 0, [
 ["Size", 0, "uint16"],
 ["Version", 2, "uint16"],
 ["__Signature", 4, "uint32"],
 ["Signature", 0, "Value", {
 "value": "x=&amp;gt;format(format='%#x', args=x.__Signature)"
 }],
 ["__CreateDate", 8, "uint32"],
 ["__LastAccessed", 12, "uint32"],

 ["CreateDate", 8, "FatTimestamp"],
 ["LastAccessed", 12, "FatTimestamp"],
 ["MFTReference", 20, "MFTReference"],
 ["LongName", "x=&amp;gt;if(condition=x.Version &amp;gt; 8, then=46, else=42)", "String", {
 "encoding": "utf16"
 }]
 ]],
 ["MFTReference", 0, [
 ["MFTID", 0, "BitField", {
 "type": "uint64",
 "start_bit": 0,
 "end_bit": 48,
 }],
 ["SequenceNumber", 0, "BitField", {
 "type": "uint64",
 "start_bit": 48,
 "end_bit": 64,
 }]
 ]],

 ["StringData",0,[
 ["TargetPath",0,"Value",{ "value":"x=&amp;gt; x.ParentOf.LinkInfo.Target.Path"}],
 ["Name",0,"Value",{ "value":"x=&amp;gt; x.ParentOf.__Name.StringData"}],
 ["RelativePath",0,"Value",{ "value":"x=&amp;gt; x.ParentOf.__RelativePath.StringData"}],
 ["WorkingDir",0,"Value",{ "value":"x=&amp;gt; x.ParentOf__WorkingDir.StringData"}],
 ["Arguments",0,"Value",{ "value":"x=&amp;gt; x.ParentOf.__Arguments.StringData"}],
 ["IconLocation",0,"Value",{ "value":"x=&amp;gt; x.ParentOf.__IconLocation.StringData"}],
 ]],

 ## StringDataBlock structs
 ["Name", "x=&amp;gt;x.Size + 2", [
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Characters", 0, "uint16"],
 ["Size", 0, "Value", {"value": "x=&amp;gt;x.Characters * 2"}],
 ["StringData", 2, "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.Size",
 "max_length": 10000,
 "term": "",
 }],
 ]],
 ["WorkingDir", "x=&amp;gt;x.Size + 2", [
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Characters", 0, "uint16"],
 ["Size", 0, "Value", {"value": "x=&amp;gt;x.Characters * 2"}],
 ["StringData", 2, "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.Size",
 "max_length": 10000,
 "term": "",
 }],
 ]],
 ["RelativePath", "x=&amp;gt;x.Size + 2", [
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Characters", 0, "uint16"],
 ["Size", 0, "Value", {"value": "x=&amp;gt;x.Characters * 2"}],
 ["StringData", 2, "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.Size",
 "max_length": 10000,
 "term": "",
 }],
 ]],
 ["Arguments", "x=&amp;gt;x.Size + 2", [
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Characters", 0, "uint16"],
 ["Size", 0, "Value", {"value": "x=&amp;gt;x.Characters * 2"}],
 ["SizeType", 0, "Value", {"value": "x=&amp;gt;format(format='%T',args=x.Size)"}],
 ["StringData", 2, "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.Size",
 "max_length": 50000,
 "term": "",
 }],
 ]],
 ["IconLocation", "x=&amp;gt;x.Size + 2", [
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Characters", 0, "uint16"],
 ["Size", 0, "Value", {"value": "x=&amp;gt;x.Characters * 2"}],
 ["StringData", 2, "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.Size",
 "max_length": 10000,
 "term": "",
 }],
 ]],
 ["ExtraData","x=&amp;gt;x.Size",[
 ["Offset",0,"Value",{"value":"x=&amp;gt;x.StartOf"}],
 ["Size",0,"uint32"],
 ["EndOf",0,"Value",{"value":"x=&amp;gt;x.EndOf"}],
 ["__Header",4,"uint32"],
 ["Header",0,"Value",{"value":"x=&amp;gt;'0x' + upcase(string=format(format='%08x',args=x.__Header))"}],
 ["BlockClass", 4, "Enumeration", {
 "type": "uint32",
 "map": {
 "EnvironmentVariable": 0xA0000001,
 "Console": 0xA0000002,
 "TrackerData": 0xA0000003,
 "CodePage": 0xA0000004,
 "SpecialFolder": 0xA0000005,
 "Darwin": 0xA0000006,
 "IconEnvironment": 0xA0000007,
 "Shim": 0xA0000008,
 "PropertyStore": 0xA0000009,
 "KnownFolder": 0xA000000B,
 "VistaAndAboveIDList": 0xA000000C,
 }}],
 ["Data", 0, "Union", {
 "selector": "x=&amp;gt;x.Header",
 "choices": {
 "0xA0000001": "EnvironmentVariableDataBlock",
 "0xA0000002": "ConsoleDataBlock",
 "0xA0000003": "TrackerDataBlock",
 "0xA0000004": "ConsoleFEDataBlock",
 "0xA0000005": "SpecialFolderDataBlock",
 "0xA0000006": "DarwinDataBlock",
 "0xA0000007": "IconEnvironmentDataBlock",
 "0xA0000008": "ShimDataBlock",
 "0xA0000009": "PropertyStoreDataBlock",
 "0xA000000B": "KnownFolderDataBlock",
 "0xA000000C": "VistaAndAboveIDListDataBlock",
 }
 }],
 ]],
 #0xA0000001
 ["EnvironmentVariableDataBlock", 0x00000314, [
 ["__DataBlockSize",0,"uint32"],
 ["__TargetAnsi", 8, "String", {"max_length": 260 }],
 ["__TargetUnicode", 268, "String", {
 "encoding": "utf16",
 "max_length": 520
 }],
 ["DataValue", 0, "Value",{
 "value": "x=&amp;gt;if(condition= x.__TargetAnsi=x.__TargetUnicode,
 then=x.__TargetAnsi,
 else=dict(Ascii=x.__TargetAnsi,Unicode=x.__TargetUnicode))" }],
 ]],
 #0xA0000002
 ["ConsoleDataBlock", 0x000000CC, [
 ["__DataBlockSize",0,"uint32"],
 ["FillAttributes",8,"Flags", {
 "type": "uint16",
 "bitmap": {
 "FOREGROUND_BLUE": 0,
 "FOREGROUND_GREEN": 1,
 "FOREGROUND_RED": 2,
 "FOREGROUND_INTENSITY": 3,
 "BACKGROUND_BLUE": 4,
 "BACKGROUND_GREEN": 5,
 "BACKGROUND_RED": 6,
 "BACKGROUND_INTENSITY": 7,
 }}],
 ["PopupFillAttributes",10,"Flags", {
 "type": "uint16",
 "bitmap": {
 "FOREGROUND_BLUE": 0,
 "FOREGROUND_GREEN": 1,
 "FOREGROUND_RED": 2,
 "FOREGROUND_INTENSITY": 3,
 "BACKGROUND_BLUE": 4,
 "BACKGROUND_GREEN": 5,
 "BACKGROUND_RED": 6,
 "BACKGROUND_INTENSITY": 7,
 }}],
 ["__ScreenBufferSizeX",12,"int16"],
 ["__ScreenBufferSizeY",14,"int16"],
 ["ScreenBufferSize",0,"Value",{
 "value":"x=&amp;gt;format(format='%v x %v',args=[x.__ScreenBufferSizeX,x.__ScreenBufferSizeY])"
 }],
 ["__WindowSizeX",16,"int16"],
 ["__WindowSizeY",18,"int16"],
 ["WindowSize",0,"Value",{
 "value":"x=&amp;gt;format(format='%v x %v',args=[x.__WindowSizeX,x.__WindowSizeY])"
 }],
 ["__WindowOriginX",20,"int16"],
 ["__WindowOriginY",22,"int16"],
 ["WindowOrigin",0,"Value",{
 "value":"x=&amp;gt;format(format='%v / %v',args=[x.__WindowOriginX,x.__WindowOriginY])"
 }],
 ["__FontSizeW",32,"int16"],
 ["__FontSizeH",34,"int16"],
 ["FontSize",0,"Value",{
 "value":"x=&amp;gt;if(condition= x.__FontSizeW=0,
 then= x.__FontSizeH,
 else= format(format='%v / %v',args=[x.__FontSizeW,x.__FontSizeH])) "
 }],
 ["__FontFamily", 36, "BitField", {
 type: "uint32",
 start_bit: 4,
 end_bit: 31,
 }],
 ["FontFamily", 0, "Value", {
 "value": "x=&amp;gt;get(item=dict(
 `0`='DONTCARE',
 `16`='ROMAN',
 `32`='SWISS',
 `48`='MODERN',
 `64`='SCRIPT',
 `80`='DECORATIVE',

 `1`='ROMAN',
 `2`='SWISS',
 `3`='MODERN',
 `4`='SCRIPT',
 `5`='DECORATIVE'),
 member=x.__FontFamily)"
 }],
 ["__FontPitch", 36, "BitField", {
 type: "uint32",
 start_bit: 0,
 end_bit: 3,
 }],
 # TODO: implement Flag select for FontPitch
 ["FontPitch", 0 ,"Value",{
 "value":"x=&amp;gt;format(format='0x%02x',args=x.__FontPitch)"
 }],
 ["__FontWeight",40,"uint32"],
 ["BoldFont", 0 ,"Value",{
 "value":"x=&amp;gt;if(condition= 700&amp;lt;=x.__FontWeight,
 then= True,
 else= False)"
 }],
 ["FaceName", 44, "String", {
 "encoding": "utf16",
 "length": 64,
 }],
 ["__CursorSize",108,"uint32"],
 ["CursorSize", 0 ,"Value",{
 "value":"x=&amp;gt; if(condition= x.__CursorSize &amp;lt;= 25,
 then= 'Small',
 else=if(condition= x.__CursorSize &amp;gt;= 26 AND x.__CursorSize &amp;lt;= 50,
 then= 'Medium',
 else=if(condition= x.__CursorSize &amp;gt;= 51 AND x.__CursorSize &amp;lt;= 100,
 else= 'Large',
 else= x.__CursorSize )))"
 }],
 ["__FullScreen",112,"uint32"],
 ["FullScreen", 0 ,"Value",{
 "value":"x=&amp;gt; if(condition= x.__FullScreen &amp;gt; 0,
 then= True,
 else= False )"
 }],
 ["__QuickEdit",116,"uint32"],
 ["QuickEdit", 0 ,"Value",{
 "value":"x=&amp;gt; if(condition= x.__QuickEdit &amp;gt; 0,
 then= True,
 else= False )"
 }],
 ["__InsertMode",120,"uint32"],
 ["InsertMode", 0 ,"Value",{
 "value":"x=&amp;gt; if(condition= x.__InsertMode &amp;gt; 0,
 then= True,
 else= False )"
 }],
 ["__AutoPosition",124,"uint32"],
 ["AutoPosition", 0 ,"Value",{
 "value":"x=&amp;gt; if(condition= x.__AutoPosition &amp;gt; 0,
 then= True,
 else= False )"
 }],
 ["HistoryBufferSize",128,"uint32"],
 ["NumberOfHistoryBuffers",132,"uint32"],
 ["__HistoryNoDup",136,"uint32"],
 ["HistoryDuplicatesAllowed", 0 ,"Value",{
 "value":"x=&amp;gt; if(condition= x.__HistoryNoDup &amp;gt; 0,
 then= True,
 else= False )"
 }],
 ["ColorTable", 140, "Array", {
 "type": "uint32",
 "count": 16 # Max count until sentinel
 }],
 ]],
 #0xA0000003
 ["TrackerDataBlock", 0x00000060, [
 ["__DataBlockSize",0,"uint32"],
 ["__MachineID", 16, "String"],
 ["MachineID", 0, "Value",{ "value": "x=&amp;gt;if(condition= x.__MachineID=~'[^ -~]+', then=Null, else=x.__MachineID )" }],
 ["MacAddress", 0, "Value",{ "value": "x=&amp;gt;if(condition=x.MachineID,then=strip(suffix=':',string=regex_replace(source=split(string=x.FileDroid,sep='-')[-1],re='.{2}',replace='$0:')))" }],
 ["__CreationTimeHex", 0, "Value",{ "value": "x=&amp;gt;if(condition=x.MachineID,then='0x' + x.FileDroid[15:18] + x.FileDroid[9:13] + x.FileDroid[0:8] )" }],
 ["CreationTime", 0, "Value",{ "value": "x=&amp;gt;timestamp(epoch=int(int=( int(int=x.__CreationTimeHex) - 0x01B21DD213814000) / 10000))" }],
 ["__Droid0", 32, "GUID"],
 ["__Droid1", 48, "GUID"],
 ["__DroidBirth0", 64, "GUID"],
 ["__DroidBirth1", 80, "GUID"],
 ["VolumeDroid", 0, "Value",{"value": "x=&amp;gt;if(condition=x.MachineID,then=x.__Droid0.Value)" }],
 ["VolumeDroidBirth", 0, "Value",{ "value": "x=&amp;gt;if(condition=x.MachineID,then=x.__DroidBirth0.Value)" }],
 ["FileDroid", 0, "Value",{"value": "x=&amp;gt;if(condition=x.MachineID,then=x.__Droid1.Value)" }],
 ["FileDroidBirth", 0, "Value",{ "value": "x=&amp;gt;if(condition=x.MachineID,then=x.__DroidBirth1.Value)" }],
 ]],
 #0xA0000004
 ["ConsoleFEDataBlock", 0x0000000C, [
 ["__DataBlockSize",0,"uint32"],
 ["CodePage",8,"uint32"],
 ["DataValue",0,"Value",{"value":"x=&amp;gt;x.CodePage"}],
 ]],
 #0xA0000005
 ["SpecialFolderDataBlock", 0x00000010, [
 ["__DataBlockSize",0,"uint32"],
 ["SpecialFolderId",8,"uint32"],
 ["IdOffset",12,"uint32"],
 ["DataValue",0,"Value",{"value":"x=&amp;gt;x.SpecialFolderId"}],
 ]],
 #0xA0000006
 ["DarwinDataBlock", 0x00000314, [
 ["__DataBlockSize",0,"uint32"],
 ["__DarwinDataAnsi", 8, "String", {"max_length": 260 }],
 ["__DarwinDataUnicode", 268, "String", {
 "encoding": "utf16",
 "max_length": 520
 }],
 ["DataValue", 0, "Value",{
 "value": "x=&amp;gt;if(condition= x.__DarwinDataAnsi=x.__DarwinDataUnicode,
 then=x.__DarwinDataAnsi,
 else=dict(Ascii=x.__DarwinDataAnsi,
 Unicode=x.__DarwinDataUnicode))" }],
 ]],
 #0xA0000007
 ["IconEnvironmentDataBlock", 0x00000314, [
 ["__DataBlockSize",0,"uint32"],
 ["__TargetAnsi", 8, "String", {"max_length": 260 }],
 ["__TargetUnicode", 268, "String", {
 "encoding": "utf16",
 "max_length": 520,
 }],
 ["DataValue", 0, "Value",{
 "value": "x=&amp;gt;if(condition= x.__TargetAnsi=x.__TargetUnicode,
 then=x.__TargetAnsi,
 else=dict(Ascii=x.__TargetAnsi,
 Unicode=x.__TargetUnicode))" }],
 ]],
 #0xA0000008
 ["ShimDataBlock", "x=&amp;gt;x.__DataBlockSize", [
 ["__DataBlockSize",0,"uint32"],
 ["LayerName", 8, "String", {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.__DataBlockSize - 8",
 "max_length": 10000
 }],
 ["DataValue",0,"Value",{"value":"x=&amp;gt;x.LayerName"}],
 ]],
 #0xA0000009
 ["PropertyStoreDataBlock", "x=&amp;gt;x.__DataBlockSize", [
 ["__DataBlockSize",0,"uint32"],
 ["PropertyStorage", 8, "Array", {
 "count": 1000,
 "type": "PropertyStorage",
 "sentinel": "x=&amp;gt;x.__DataBlockSize = 0"
 }],
 ["DataValue",0,"Value",{"value":"x=&amp;gt;x.PropertyStorage.PropertyValue"}],
 ]],
 #0xA000000B
 ["KnownFolderDataBlock", 0x00000314, [
 ["__DataBlockSize",0,"uint32"],
 ["__KnownFolderId", 8, "GUID"],
 ["GUID",0,"Value",{"value":"x=&amp;gt;x.__KnownFolderId.Value"}],
 ["__Offset", 24,"uint32"],
 ["KnownFolder", 0, "Value", {
 "value": "x=&amp;gt; get(item=KnownGUIDLookup, field=x.GUID)"
 }],
 ]],
 #0xA000000C
 ["VistaAndAboveIDListDataBlock", "x=&amp;gt;x.__BlockSize", [
 ["__DataBlockSize",0,"uint32"],
 ["IDList", 8, "ItemIDList"],
 ]],

 ["DocumentSummaryInformation", 10, [
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Type", 0, "uint32"],
 ]],

 ["PropertyStorage","x=&amp;gt;x.StorageSize", [
 ["StorageSize",0,"uint32"],
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf"}],
 ["Version",4,"String",{ "length":4 }], #Expect 1SPS / 0x53505331
 ["__Format", 8,"GUID"],
 ["Format", 0, "Value",{"value": "x=&amp;gt;x.__Format.Value" }],
 ["PropertyValue", 24, "Array", {
 "type": "PropertyValue",
 "count": 1000,
 "sentinel": "x=&amp;gt;x.__ValueSize = 0"
 }],
 ]],

 ["PropertyValue","x=&amp;gt;x.__ValueSize", [
 ["__ValueSize",0,"uint32"],
 ["ValueSize",0,"uint32"],
 ["Offset", 0, Value, {value: "x=&amp;gt;x.StartOf"}],
 ["__ID",4,"uint32"],
 ["GuidId",0,"Value",{"value": "x=&amp;gt;x.ParentOf.Format + '/' + str(str=x.__ID)"}],
 # These come from https://github.com/EricZimmerman/ExtensionBlocks/blob/master/ExtensionBlocks/Utils.cs
 ["Description", 0, "Value", {
 "value": "x=&amp;gt;PropertyValueDispatcher(x=x)"
 }],
 ["__DocumentSummaryInformation", 4, "DocumentSummaryInformation"],
 ["__NetworkInfo", 4, "Enumeration", {
 "type": "uint32",
 choices: {
 "5":"WNET Local Name",
 "6":"WNET Remote Name",
 "7":"WNET Comment",
 "8":"WNET Provider",
 }}],
 ["__STORAGE", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "2":"System.ItemFolderNameDisplay",
 "3":"Search ClassID",
 "4":"System.ItemTypeText",
 "8":"FileIndex",
 "9":"Search Last Change USN",
 "10":"System.ItemNameDisplay",
 "12":"System.Size",
 "13":"System.FileAttributes",
 "14":"System.DateModified",
 "15":"System.DateCreated",
 "16":"System.DateAccessed",
 "18":"File Allocation Size",
 "19":"Search Contents",
 "20":"Search ShortName",
 "21":"File FRN",
 "22":"Search Scope",
 "23":"Item Name Sort Override",
 "24":"Item Name Display Without Extension",
 "25":"Folder Name Display",
 }}],
 ["__SHELL_DETAILS", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "0":"Find Data",
 "1":"Network Resource",
 "2":"Description ID",
 "3":"Which Folder",
 "4":"Network Location",
 "5":"Computer Name",
 "6":"Namespace CLSID",
 "8":"Item Path Display Narrow",
 "9":"Perceived Type",
 "10":"Computer Simple Name",
 "11":"Item Type",
 "12":"File Count",
 "14":"Total File Size",
 "22":"Max Stack Count",
 "23":"List Description",
 "24":"Parsing Name",
 "25":"SFGAO Flags",
 "26":"Order",
 "27":"Computer Description",
 "29":"Contained Items",
 "30":"ParsingPath",
 "31":"Network Provider",
 "32":"Delegate ID List",
 "33":"Is SendTo Target",
 "34":"Hide On Desktop",
 "35":"Network Places Default Name",
 "36":"Storage System Type",
 "37":"Item SubType",
 }}],
 ["__CACHE", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "100":"Thumbnail Cache Id",
 "104":"Volume Id",
 "105":"Tooltip Thumbnail Stream",
 }}],
 ["__SEARCH", 4, "Enumeration", {
 "type": "uint32",
 "map": {
 "FolderPath": 0x00000006,
 "SearchRanking": 0x00000003,
 }}],
 ["__User", 4, "Enumeration", {
 "type": "uint32",
 "map": {
 "SID": 0x00000004,
 }}],
 ["__Share", 4, "Enumeration", {
 "type": "uint32",
 "map": {
 "Share Target Description": 0x00000002,
 }}],
 ["__Hash", 4, "Enumeration", {
 "type": "uint32",
 "map": {
 "WinX Hash": 0x00000002,
 }}],
 ["__FolderDisplay", 4, "Enumeration", {
 "type": "uint32",
 "map": {
 "Item Folder Path Display Narrow": 100,
 }}],
 ["__AppUserModel", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "2":"App User Model Relaunch Command",
 "3":"App User Model Relaunch Icon Resource",
 "4":"App User Model Relaunch Display Name Resource",
 "5":"App User Model ID",
 "6":"App User Model Is DestList Separator",
 "7":"App User Model Is DestList Link",
 "8":"App User Model Exclude From Show In New Install",
 "9":"App User Model Prevent Pinning",
 "10":"App User Model Best Shortcut",
 "11":"App User Model Is Dual Mode",
 "12":"App User Model Start Pin Option",
 "13":"App User Model Relevance",
 "14":"App User Model Host Environment",
 "15":"App User Model Package Install Path",
 "16":"App User Model Record State",
 "17":"App User Model Package Family Name",
 "18":"App User Model Installed By",
 "19":"App User Model Parent ID",
 "20":"App User Model Activation Context",
 "21":"App User Model Package Full Name",
 "22":"App User Model Package Relative Application ID",
 "23":"App User Model Excluded From Launcher",
 "24":"App User Model AppCompat ID",
 "25":"App User Model Run Flags",
 "26":"App User Model Toast Activator CLSID",
 "27":"App User Model DestList Provided Title",
 "28":"App User Model DestList Provided Description",
 "29":"App User Model DestList Logo Uri",
 "30":"App User Model DestList Provided Group Name",
 }}],
 ["__Software", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "2":"Publisher Display Name",
 "3":"Software Registered Owner",
 "4":"Software Registered Company",
 "5":"Software AppId",
 "6":"Software Support Url",
 "7":"Software Support Telephone",
 "8":"Software Help Link",
 "9":"Software Install Location",
 "10":"Software Install Source",
 "11":"Software Date Installed",
 "12":"Software Support Contact Name",
 "13":"Software ReadMe Url",
 "14":"Software Update Info Url",
 "15":"Software Times Used",
 "16":"Software Date Last Used",
 "17":"Software Tasks File Url",
 "18":"Software Parent Name",
 "19":"Software Product ID",
 "20":"Software Comments",
 "997":"Software Null Preview Total Size",
 "998":"Software Null Preview Subtitle",
 "999":"Software Null Preview Title",
 }}],
 ["__Tile", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "2":"Tile Small Image Location",
 "4":"Tile Background Color",
 "5":"Tile Foreground Color",
 "11":"Tile Display Name",
 "12":"Tile Image Location",
 "13":"Tile Wide 310x150 Logo Path",
 "14":"Tile Unknown Flags",
 "15":"Tile Badge Logo Path",
 "16":"Tile Suite Display Name",
 "17":"Tile Suite Sor tName",
 "18":"Tile Display Name Language",
 "19":"Tile Square 310x310 Logo Path",
 "20":"Tile Square 70x70 Logo Path",
 "21":"Tile Fence Post",
 "22":"Tile Install Progress",
 "23":"Tile Encoded Target Path",
 }}],
 ["__Document", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "3":"Subject",
 "4":"Author",
 "5":"Keywords",
 "6":"Comment",
 "7":"Document Template",
 "8":"Document Last Author",
 "9":"Document Revision Number",
 "10":"Document Total Editing Time",
 "11":"Document Date Printed",
 "12":"Document Date Created",
 "13":"Document Date Saved",
 "14":"Document Page Count",
 "15":"Document Word Count",
 "16":"Document Character Count",
 "17":"Thumbnail",
 "18":"Application Name",
 "19":"Document Security",
 "24":"High Keywords",
 "25":"Low Keywords",
 "26":"Medium Keywords",
 "27":"Thumbnail Stream",
 }}],
 # https://github.com/EricZimmerman/ExtensionBlocks/blob/58e35b8457bf3006f672c972619bc0fb913fb7e4/ExtensionBlocks/PropertySheet.cs#L104
 ["Type", 9, "uint16"],
 ["__Value", 13, "Union", {
 selector: "x=&amp;gt;format(format='%#02x', args=x.Type)",
 choices: {
 "0x1f": "LPWSTR",
 "0x0b": "BOOL",
 "0x00": "EmptyValue",
 "0x01": "EmptyValue",
 "0x02": "UINT16",
 "0x03": "UINT32",
 "0x04": "UINT8",
 "0x08": "LPWSTR",
 "0x0a": "UINT32",
 "0x13": "UINT32",
 "0x40": "FILETIME",
 "0x14": "UINT64",
 "0x15": "UINT64",
 "0x16": "UINT32",
 "0x17": "UINT32",
 "0x48": "GUID",
 }
 }],
 ["Value", 0, "Value", { "value": "x=&amp;gt;x.__Value.Value"}],
 ]],
 ["GUID", 16, [
 ["__D1", 0, "uint32"],
 ["__D2", 4, "uint16"],
 ["__D3", 6, "uint16"],
 ["__D4", 8, "String", {"term": "", "length": 2}],
 ["__D5", 10, "String", {"term": "", "length": 6}],
 ["Value", 0, "Value", { "value": "x=&amp;gt;upcase(string=
 format(format='%08x-%04x-%04x-%02x-%02x',
 args=[x.__D1, x.__D2, x.__D3, x.__D4, x.__D5]))" }],
 ]],
 ["Overlay", "x=&amp;gt;x.Length", [
 ["Header", 0, "Value", {"value": "x=&amp;gt;format(format='0x%08x',args=read_file(filename=OSPath,offset=x.StartOf + 4,length=4))"}],
 ["Offset", 0, "Value", {"value": "x=&amp;gt;x.StartOf + 4"}],
 ["Length", 0, "Value", {"value": "x=&amp;gt;len(list=read_file(filename=OSPath, offset=x.StartOf + 4))"}],
 ["Entropy", 0, "Value", {"value": "x=&amp;gt;entropy(string=read_file(filename=OSPath,offset=x.StartOf + 4))"}],
 ["Magic", 0, "Value", {"value": "x=&amp;gt;magic(accessor='data',path=read_file(filename=OSPath,offset=x.StartOf + 4))"}],
 ]],

 ["LPWSTR", 0, [
 ["Size", 0, "uint32"],
 ["String", 4, String, {
 "term_hex": "00",
 "length": "x=&amp;gt;x.Size * 2",
 "encoding": "utf16"
 }],
 ["Value", 0, Value, {value: "x=&amp;gt;x.String"}],
 ]],
 ["BOOL", 0, [
 ["_v", 0, "uint8"],
 ["Value", 0, Value, {value: "x=&amp;gt;x._v != 0"}],
 ]],
 ["UINT8", 0, [
 ["Value", 0, "uint8"],
 ]],
 ["FILETIME", 0, [
 ["Value", 0, "WinFileTime"],
 ]],
 ["UINT16", 0, [
 ["Value", 0, "uint16"],
 ]],
 ["UINT32", 0, [
 ["Value", 0, "uint32"],
 ]],
 ["UINT64", 0, [
 ["Value", 0, "uint64"],
 ]],
 ["EmptyValue", 0, [
 ["Value", 0, Value, {value: "x=&amp;gt;0"}],
 ]],
 ["Empty", 0, []],
 ]
 '''

 LET _longestName(ShortName, LongName) = if(
 condition=len(list=LongName) &amp;lt; len(list=ShortName),
 then=ShortName, else=LongName)

 LET _fixfilename(name) = regex_replace(source=name, re="\\\\$", replace="")


 LET _fixpath(data) = SELECT
 _fixfilename(name=_longestName(ShortName=S.ShortName,
 LongName=S.LongName)) || "?" AS Name
 FROM foreach(row=data)
 WHERE NOT Name =~ "^My Computer$"

 LET fixpath(data) = join(array=_fixpath(data=data).Name, sep="\\")

 // Pretty format the PropertyStorage
 LET property_store(Parsed) = SELECT * FROM foreach(
 row=Parsed.ExtraData.Data.PropertyStorage.PropertyValue,
 query={
 SELECT * FROM foreach(row=_value,
 query={
 SELECT GuidId,Description,Type,Value FROM foreach(row=_value)
 })})

 LET ShowHeader(Parsed) = dict(
 Headersize = Parsed.HeaderSize,
 LinkClsID = Parsed.LinkClsID,
 LinkFlags = Parsed.LinkFlags,
 FileAttributes = Parsed.FileAttributes,
 FileSize = Parsed.FileSize,
 CreationTime = Parsed.CreationTime,
 AccessTime = Parsed.AccessTime,
 WriteTime = Parsed.WriteTime,
 IconIndex = Parsed.IconIndex,
 ShowCommand = Parsed.ShowCommand,
 HotKey = Parsed.HotKey
 )

 LET ShowLinkTarget(ShellBag) = dict(
 LinkTarget=fixpath(data=ShellBag.Description),
 LinkTargetIDList=Parsed.LinkTargetIDList
 )

 LET ShowExtraData(Parsed) = to_dict(item={
 SELECT if(condition= BlockClass=~'^0x',
 then= 'Overlay',
 else= BlockClass ) as _key,
 if(condition= Data.DataValue,
 then= Data.DataValue, else=
 if(condition= NOT BlockClass =~ '^0x',
 then= Data,
 else= dict(
 Header=format(format='0x%x',args=read_file(filename=OSPath, offset=Offset,length=4)),
 Offset=Offset,
 Length=len(list=read_file(filename=OSPath, offset=Offset)),
 Entropy=entropy(string=read_file(filename=OSPath,offset=Offset)),
 Magic=magic(accessor='data',path=read_file(filename=OSPath,offset=Offset))
 ))) as _value
 FROM foreach(row=Parsed.ExtraData)
 })


sources:
 - query: |
 LET targets = SELECT OSPath, Mtime,Atime,Ctime,Btime,Size,
 read_file(filename=OSPath,offset=0,length=2) as _Header
 FROM glob(globs=TargetGlob)
 WHERE NOT IsDir AND _Header =~ '^L\x00$'

 LET lnk_files = SELECT *,
 parse_binary(filename=OSPath,
 profile=Profile, struct="ShellLinkHeader") AS Parsed
 FROM targets

 LET parsed_lnk_files = SELECT
 dict(OSPath=OSPath, Size=Size,
 Mtime=Mtime,Btime=Btime) as SourceFile,
 ShowHeader(Parsed=Parsed) as ShellLinkHeader,
 Parsed.LinkInfo as LinkInfo,
 ShowLinkTarget(ShellBag=Parsed.LinkTargetIDList.IDList.ShellBag) as LinkTarget,
 Parsed.StringData as StringData,
 ShowExtraData(Parsed=Parsed) as ExtraData,
 property_store(Parsed=Parsed) as PropertyStore,
 Parsed.Overlay as Overlay,
 Parsed
 FROM lnk_files

 -- Several dynamic functions to check propertystore for anormalities
 LET find_uid(propertystore) = SELECT regex_replace(source=Value,re='''S-1-5-\d{2}-\d+-\d+-\d+-''',replace='') as Value
 FROM propertystore WHERE Description = 'SID'
 LET find_oldpath(propertystore) = SELECT Value FROM propertystore WHERE Description = 'ParsingPath'
 LET find_oldsize(propertystore) = SELECT Value FROM propertystore WHERE Description = 'System.Size'

 LET results = SELECT Parsed,
 SourceFile,
 ShellLinkHeader,
 LinkInfo,
 LinkTarget,
 StringData,
 if(condition=PropertyStore,
 then= if(condition= ExtraData.Overlay,
 then= ExtraData + dict(PropertyStore=PropertyStore),
 else= if(condition= Overlay.Length &amp;gt; 4,
 then= ExtraData + dict(
 PropertyStore=PropertyStore
 ) + dict(Overlay=to_dict(item=Overlay)),
 else= ExtraData + dict(PropertyStore=PropertyStore))),
 else= if(condition= ExtraData.Overlay,
 then= ExtraData,
 else= if(condition= Overlay.Length &amp;gt; 4,
 then= ExtraData + dict(Overlay=to_dict(item=Overlay)),
 else= ExtraData
 )
 )) as ExtraData,
 find_uid(propertystore=PropertyStore)[0].Value as UID,
 find_oldpath(propertystore=PropertyStore)[0].Value as OldPath,
 find_oldsize(propertystore=PropertyStore)[0].Value as OldSize
 FROM parsed_lnk_files
 WHERE if(condition= IocRegex,
 then= format(format='%s\n%s\n%s\n%s\n%s\n%s\n%s\n%s\n%s\s%s',
 args=[
 StringData.TargetPath,
 StringData.Name,
 StringData.RelativePath,
 StringData.WorkingDir,
 StringData.Arguments,
 StringData.IconLocation,
 LinkTarget.LinkTarget,
 ExtraData.TrackerData.MachineID,
 ExtraData.TrackerData.MacAddress,
 join(array=PropertyStore.Value,sep='\n')
 ]) =~ IocRegex,
 else= True)
 AND NOT if(condition= IgnoreRegex,
 then= format(format='%s\n%s\n%s\n%s\n%s\n%s\n%s\n%s\n%s\\s%s',
 args=[
 StringData.TargetPath,
 StringData.Name,
 StringData.RelativePath,
 StringData.WorkingDir,
 StringData.Arguments,
 StringData.IconLocation,
 LinkTarget.LinkTarget,
 ExtraData.TrackerData.MachineID,
 ExtraData.TrackerData.MacAddress,
 join(array=PropertyStore.Value,sep='\n')
 ]) =~ IgnoreRegex,
 else= False)

 LET sus_cli(data) = dict(
 `Arguments have ticks` = data=~'''\^|\`|[a-z][\'\"]{2}[a-z]''',
 `Arguments have environment variables` = data=~'''\%|\$env:''',
 `Arguments have rare characters` = data=~'''\?\!\~\@''',
 `Arguments have leading space` = data=~ '^ ',
 `Arguments have http strings` = data=~'''(http|ftp)s?://''',
 `Arguments have UNC strings` = data=~'''(\s|^)\\\\[a-z0-9$_.-]+''',
 `Suspicious arguments` = data=~SusArgRegex
 )

 -- find largest base64 blob over 10 characters
 LET find_b64(data) = SELECT *
 FROM if(condition=data,
 then={
 SELECT Base64, len(list=Base64) as Length
 FROM parse_records_with_regex(accessor='data',file=data, regex='''(?P&amp;lt;Base64&amp;gt;(https?://[^\s]+/)*[A-Za-z0-9+/]{10,}={0,2})''')
 WHERE NOT Base64 =~ '^http' -- Implementing negative regex match: We exclude b64 strings with http prefix.
 ORDER BY Length DESC
 LIMIT 1
 },
 else=null )


 LET add_suspicious = SELECT *, dict(
 `Large Size` = SourceFile.Size &amp;gt; SusSize,
 `Startup Path` = SourceFile.OSPath =~ '''\\Startup\\''',
 `Zeroed Headers` = ( ShellLinkHeader.FileSize=0 AND ShellLinkHeader.CreationTime=~'^1601-01' AND len(list=LinkInfo.LinkInfoFlags)=0 ),
 `Hidden window` = ShellLinkHeader.ShowCommand = 'SHOWMINNOACTIVE',
 `Target Changed path` = lowcase(string=LinkInfo.Target.Path) != lowcase(string=OldPath) AND OldPath,
 `Target Changed size` = ( ShellLinkHeader.FileSize - OldSize != 0 ) AND ShellLinkHeader.FileSize AND OldSize,
 `Risky target` = StringData.TargetPath =~ RiskyExe || LinkInfo.Target.Path =~ RiskyExe || LinkTarget.LinkTarget =~ RiskyExe,
 `WebDAV` = LinkInfo.Target.RelativeLink.NetworkProviderType = 'WNNC_NET_DAV',
 `Line break in StringData.Name` = StringData.Name =~ '''\n''',
 `Suspicious argument size` = len(list=StringData.Arguments) &amp;gt; SusArgSize,
 `Environment variable script` = ExtraData.EnvironmentVariable =~ '''\.(bat|cmd|ps1|js|vbs|vbe|py)$''',
 `No Target with environment variable` = ExtraData.EnvironmentVariable AND StringData.Arguments AND NOT (StringData.TargetPath OR StringData.RelativePath),
 `Suspicious hostname` = ExtraData.TrackerData.MachineID AND SusHostnameRegex AND ExtraData.TrackerData.MachineID=~SusHostnameRegex,
 `Created in VM` = ExtraData.TrackerData.MacAddress =~ VmPrefixMAC,
 `Local Admin` = UID='500',
 `Cyrillic Language` = format(format='%s%s',args=[LinkTarget,ExtraData])=~ '''[\x{0400}-\x{04FF}]''',
 `Chinese Language` = format(format='%s%s',args=[LinkTarget,ExtraData])=~ '''[\x{4E00}-\x{9FCC}]''',
 `Korean Language` = format(format='%s%s',args=[LinkTarget,ExtraData])=~ '''[\x{3131}-\x{314e}|\x{314f}-\x{3163}|\x{ac00}-\x{d7a3}]''',
 `Persian Language` = format(format='%s%s',args=[LinkTarget,ExtraData])=~ '''[\x{0600}-\x{06FF}]''',
 `Vietnamese Language` = format(format='%s%s',args=[LinkTarget,ExtraData])=~ '''[\x{0102}\x{0103}\x{0110}\x{0111}\x{01A0}\x{01A1}\x{01AF}\x{01B0}\x{1EA0}-\x{1EF9}]''',
 `CodePage` = ExtraData.CodePage,
 `Has Overlay` = if(condition=ExtraData.Overlay, then=True)
 ) as Suspicious,
 regex_replace(source=base64decode(string=find_b64(data=StringData.Arguments)[0].Base64),re='''[^ -~\s]''',replace='') as ArgumentsDecoded,
 sus_cli(data=StringData.Arguments) as SuspiciousCli
 FROM results
 WHERE if(condition=SuspiciousOnly,
 then= join(array=Suspicious) =~ ''':(true|0x|\d)''' OR join(array=SuspiciousCli) =~ ''':(true|0x|\d)''' OR len(list=ArgumentsDecoded) &amp;gt; 20,
 else= True )

 LET add_suspiciousb64 = SELECT *
 if(condition= len(list=ArgumentsDecoded) &amp;gt; 20, then = dict(`Long Base64`=True) + sus_cli(data=ArgumentsDecoded)) as SuspiciousCliB64
 FROM add_suspicious

 LET upload_results = SELECT *,
 upload(file=SourceFile.OSPath) as UploadedLnk,
 UploadTarget &amp;amp;&amp;amp; upload(file=LinkTarget.LinkTarget) as UploadedTarget
 FROM add_suspiciousb64

 -- finally return rows and remove suspicious attributes that are not true
 SELECT
 SourceFile,
 ShellLinkHeader,
 LinkInfo,
 LinkTarget,
 if(condition= SuspiciousCliB64,
 then= to_dict(item=StringData) + dict(`DecodedBase64`=ArgumentsDecoded),
 else= StringData) as StringData,
 ExtraData,
 to_dict(item={SELECT * FROM items(item=Suspicious) WHERE _value }) +
 to_dict(item={SELECT * FROM items(item=SuspiciousCli) WHERE _value }) +
 to_dict(item={SELECT * FROM items(item=SuspiciousCliB64) WHERE _value })
 as Suspicious
 FROM if(condition=UploadLnk,
 then= upload_results,
 else= add_suspiciousb64 )

column_types:
 - name: SourceFile.Mtime
 type: timestamp
 - name: SourceFile.Btime
 type: timestamp
 - name: ShellLinkHeader.CreationTime
 type: timestamp
 - name: ShellLinkHeader.AccessTime
 type: timestamp
 - name: ShellLinkHeader.WriteTime
 type: timestamp

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.LocalHashes.Usn</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.localhashes.usn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.localhashes.usn/</guid><description>&lt;p>This artifact maintains a local (client side) database of file
hashes. It is then possible to query this database by using the
&lt;code>Generic.Forensic.LocalHashes.Query&lt;/code> artifact&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.LocalHashes.Usn
description: |
 This artifact maintains a local (client side) database of file
 hashes. It is then possible to query this database by using the
 `Generic.Forensic.LocalHashes.Query` artifact

type: CLIENT_EVENT

parameters:
 - name: PathRegex
 description: A regex to match the entire path (you can watch a directory or a file type).
 default: .
 type: regex

 - name: Device
 description: The NTFS drive to watch
 default: C:\\

 - name: HashDb
 description: Name of the local hash database
 default: hashdb.sqlite

 - name: SuppressOutput
 description: If this is set, the artifact does not return any rows to the server but will still update the local database.
 type: bool

 - name: UsnCheckPeriod
 type: int
 description: Dedup all file operations that occur within this period
 default: "10"

precondition: SELECT OS from info() where OS = "windows"

sources:
 - query: |
 -- Dont be too aggressive on the USN watching to conserve CPU usage
 LET NTFS_CACHE_TIME = 30
 LET USN_FREQUENCY = 60

 LET hash_db &amp;lt;= SELECT OSPath
 FROM Artifact.Generic.Forensic.LocalHashes.Init(HashDb=HashDb)

 LET path &amp;lt;= hash_db[0].OSPath

 LET _ &amp;lt;= log(message="Will use local hash database " + path)

 LET file_modifications = SELECT Device + OSPath AS OSPath
 FROM watch_usn(device=Device)
 WHERE OSPath =~ PathRegex

 -- The USN journal may contain multiple entries for the same
 -- file modification (e.g. TRUNCATE followed by APPEND and
 -- CLOSE). We therefore dedup all entries that happen within the
 -- period as a single modification.
 LET deduped = SELECT * FROM foreach(row={
 SELECT * FROM clock(period=UsnCheckPeriod, start=0)
 },
 query={
 -- Each time the fifo is accessed we pull all the rows and
 -- dedup the path, then clear the cache.
 SELECT * FROM fifo(
 query=file_modifications,
 max_rows=5000,
 max_age=6000, flush=TRUE)
 GROUP BY OSPath
 })

 -- Stat each file that was changed to get its size and hash
 LET files = SELECT * FROM foreach(row=deduped,
 query={
 SELECT OSPath, Size, hash(path=OSPath).MD5 AS Hash, now() AS Time
 FROM stat(filename=OSPath)
 WHERE Mode.IsRegular
 })

 -- For each file hashed, insert to the local database
 LET insertion = SELECT OSPath, Hash, Size, Time, {
 SELECT * FROM sqlite(file=path,
 query="INSERT into hashes (path, md5, timestamp, size) values (?,?,?,?)",
 args=[OSPath.String, Hash, Time, Size])
 } AS Insert
 FROM files
 WHERE Insert OR TRUE

 // If output is suppressed do not emit a row, but still update the local database.
 SELECT OSPath, Hash, Size, Time
 FROM insertion
 WHERE NOT SuppressOutput

column_types:
 - name: Time
 type: timestamp

 - name: Hash
 type: hash

 - name: ClientId
 type: client_id

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.NotepadParser</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.notepadparser/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.notepadparser/</guid><description>&lt;p>Parse the Windows 11 Notepad state files.&lt;/p>
&lt;p>Based on the research work published by ogmini. This artifact parses
the TabState and WindowState files and also uploads them for
preservation.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.NotepadParser
description: |
 Parse the Windows 11 Notepad state files.

 Based on the research work published by ogmini. This artifact parses
 the TabState and WindowState files and also uploads them for
 preservation.

reference:
 - https://github.com/ogmini/Notepad-State-Library
 - https://ogmini.github.io/tags.html#Windows-Notepad

author: ogmini https://ogmini.github.io/ and Mike Cohen

parameters:
 - name: WindowStateGlob
 default: C:/Users/*/AppData/Local*/Packages/Microsoft.WindowsNotepad*/LocalState/WindowState/*[01].bin
 - name: TabStateGlob
 default: C:/Users/*/AppData/Local*/Packages/Microsoft.WindowsNotepad*/LocalState/TabState/*.bin

export: |
 LET WinNotepadProfile &amp;lt;= '''[
 [WindowStateHeader, 0, [
 [Signature, 0, String, {
 length: 2,
 }],
 [Sequence, 2, leb128],
 [BytesToCRC, "x=&amp;gt;x.`@Sequence`.EndOf", leb128],
 [NumberTabs, "x=&amp;gt;x.`@BytesToCRC`.EndOf + 1", leb128],
 [Tabs, "x=&amp;gt;x.NumberTabs.EndOf", Array, {
 type: GUID,
 count: "x=&amp;gt;x.NumberTabs.Value",
 sentinel: "x=&amp;gt;x.__D1 = 0 AND x.__D2 = 0",
 }],
 [ActiveTab, "x=&amp;gt;x.Tabs.EndOf", leb128],
 ]],

 ["GUID", 16, [
 ["__D1", 0, "uint32"],
 ["__D2", 4, "uint16"],
 ["__D3", 6, "uint16"],
 ["__D4", 8, "String", {"term": "", "length": 2}],
 ["__D5", 10, "String", {"term": "", "length": 6}],
 ["Value", 0, "Value", { "value": "x=&amp;gt;upcase(string=
 format(format='%08x-%04x-%04x-%02x-%02x',
 args=[x.__D1, x.__D2, x.__D3, x.__D4, x.__D5]))" }],
 ]],

 [TabStateHeader, 0, [
 [Signature, 0, String, {
 length: 2,
 }],
 [Sequence, 2, leb128],
 [Type, "x=&amp;gt;x.Sequence.EndOf", leb128],
 [Header, 0, Union, {
 selector: "x=&amp;gt;x.Type.Value",
 choices: {
 "0": "TabStateHeaderUnsaved",
 "1": "TabStateHeaderSaved",
 },
 }],
 ]],

 [TabStateHeaderUnsaved, 0, [
 [Signature, 0, String, {
 length: 2,
 }],
 [Sequence, 2, leb128],
 [Type, "x=&amp;gt;x.Sequence.EndOf", leb128],

 [CursorPosition, "x=&amp;gt;x.Type.EndOf + 1", CursorPosition],
 [ConfigurationBlock, "x=&amp;gt;x.CursorPosition.EndOf", ConfigurationBlock],
 [ContentLength, "x=&amp;gt;x.ConfigurationBlock.EndOf", leb128],
 [Content, "x=&amp;gt;x.ContentLength.EndOf", String, {
 encoding: "utf16",
 length: "x=&amp;gt;x.ContentLength.Value * 2",
 max_length: 100000,
 }],
 [Unsaved, "x=&amp;gt;x.`@Content`.EndOf", uint8],
 [CRC32, "x=&amp;gt;x.`@Unsaved`.EndOf", uint32],
 ]],

 [TabStateHeaderSaved, 0, [
 [HeaderType, 0, Value, {
 value: "Saved",
 }],
 [Signature, 0, String, {
 length: 2,
 }],
 [Sequence, 2, leb128],
 [Type, "x=&amp;gt;x.Sequence.EndOf", leb128],
 [FilePathLength, "x=&amp;gt;x.Type.EndOf", leb128],
 [FilePath, "x=&amp;gt;x.FilePathLength.EndOf", String, {
 encoding: "utf16",
 length: "x=&amp;gt;x.FilePathLength.Value * 2",
 }],
 [SavedFileContentLength, "x=&amp;gt;x.`@FilePath`.EndOf", leb128],
 [EncodingType, "x=&amp;gt;x.SavedFileContentLength.EndOf", uint8],
 [CarriageReturnType, "x=&amp;gt;x.`@EncodingType`.EndOf", uint8],
 [__Timestamp, "x=&amp;gt;x.`@CarriageReturnType`.EndOf", leb128],
 [Timestamp, 0, Value, {
 value: "x=&amp;gt;timestamp(winfiletime=x.__Timestamp.Value)",
 }],
 [FileHash, "x=&amp;gt;x.__Timestamp.EndOf", String, {
 length: 32, term: "",
 }],
 [CursorPosition, "x=&amp;gt;x.`@FileHash`.EndOf + 2", CursorPosition],
 [ConfigurationBlock, "x=&amp;gt;x.CursorPosition.EndOf", ConfigurationBlock],
 [ContentLength, "x=&amp;gt;x.ConfigurationBlock.EndOf", leb128],
 [Content, "x=&amp;gt;x.ContentLength.EndOf", String, {
 encoding: "utf16",
 length: "x=&amp;gt;x.ContentLength.Value * 2",
 max_length: 100000,
 }],
 [Unsaved, "x=&amp;gt;x.`@Content`.EndOf", uint8],
 [CRC32, "x=&amp;gt;x.`@Unsaved`.EndOf", uint32],
 [UnsavedBuffers, "x=&amp;gt;x.`@CRC32`.EndOf", Array, {
 type: UnsavedBuffer,
 count: 100,
 sentinel: "x=&amp;gt;x.AdditionAction.Value = 0",
 }],
 ]],
 [ConfigurationBlock, "x=&amp;gt;x.MoreOptions.EndOf + x.MoreOptions.Value - x.OffsetOf", [
 ["WordWrap", 0, uint8],
 ["RightToLeft", 1, uint8],
 [ShowUnicode, 2, uint8],
 [MoreOptions, 3, leb128],
 ]],
 [CursorPosition, "x=&amp;gt;x.SelectionEndIndex.EndOf - x.OffsetOf", [
 [SelectionStartIndex, 0, leb128],
 [SelectionEndIndex, "x=&amp;gt;x.`@SelectionStartIndex`.RelEndOf", leb128],
 ]],

 [UnsavedBuffer, "x=&amp;gt;x.`@AddedChars`.EndOf + 4 - x.OffsetOf", [
 [Offset, 0, Value, {
 value: "x=&amp;gt;x.OffsetOf",
 }],
 [CursorPosition, 0, leb128],
 [DeletionAction, "x=&amp;gt;x.`@CursorPosition`.RelEndOf", leb128],
 [AdditionAction, "x=&amp;gt;x.`@DeletionAction`.RelEndOf", leb128],
 [AddedChars, "x=&amp;gt;x.`@AdditionAction`.RelEndOf", String, {
 encoding: "utf16",
 length: "x=&amp;gt;x.AdditionAction.Value * 2",
 max_length: 100000,
 }]
 ]],
 ]
 '''

column_types:
- name: Upload
 type: preview_upload


sources:
- name: TabState
 query:
 LET AllFiles = SELECT OSPath, Mtime, Size,
 upload(file=OSPath, mtime=Mtime) AS Upload
 FROM glob(globs=TabStateGlob)

 LET AllTabState = SELECT *, parse_binary(
 filename=OSPath,
 offset=0,
 profile=WinNotepadProfile,
 struct="TabStateHeader") AS _TabState
 FROM AllFiles
 WHERE _TabState.Header.Signature

 SELECT *,
 _TabState.Header.FilePath AS EditedFile,
 _TabState.Header.Timestamp AS EditTimestamp,
 _TabState.Header.Content AS Content,
 _TabState.Header.UnsavedBuffers.AddedChars AS UnsavedBuffers,
 Upload
 FROM AllTabState

- name: WindowState
 query:
 LET AllFiles = SELECT OSPath, Mtime, Size,
 upload(file=OSPath, mtime=Mtime) AS Upload
 FROM glob(globs=WindowStateGlob)

 LET AllTabState = SELECT *, parse_binary(
 filename=OSPath,
 offset=0,
 profile=WinNotepadProfile,
 struct="WindowStateHeader") AS _WindowState

 FROM AllFiles
 WHERE _WindowState.Signature = "NP"


 SELECT *,
 _WindowState.NumberOfTabs AS NumberOfTabs,
 _WindowState.Tabs.Value.Value AS Tabs,
 _WindowState.ActiveTab AS ActiveTab,
 Upload
 FROM AllTabState

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.PartitionTable</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.partitiontable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.partitiontable/</guid><description>&lt;p>Parses the raw disk for partition tables.&lt;/p>
&lt;p>This artifact also applies a magic() check to indicate the type of
partitions found. If a partition contains an NTFS filesystem, the
artifact will also list the top level directories. This allows a quick
overview of what type of partition this is (e.g. System/OS or data
drive).&lt;/p>
&lt;p>The artifact currently handles only GPT (Most common) and Primary Dos
partition tables.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.PartitionTable
description: |
 Parses the raw disk for partition tables.

 This artifact also applies a magic() check to indicate the type of
 partitions found. If a partition contains an NTFS filesystem, the
 artifact will also list the top level directories. This allows a quick
 overview of what type of partition this is (e.g. System/OS or data
 drive).

 The artifact currently handles only GPT (Most common) and Primary Dos
 partition tables.

parameters:
 - name: ImagePath
 default: "\\\\?\\GLOBALROOT\\Device\\Harddisk0\\DR0"
 description: Raw Device for main disk containing partition table to parse.
 - name: Accessor
 default: "raw_file"
 - name: SectorSize
 type: int
 default: 512
 - name: MagicRegex
 type: regex
 description: Filter partitions by their magic
 default: .
 - name: NameRegex
 type: regex
 description: Filter partitions by their magic
 default: .

export: |
 LET MBRProfile = '''[
 ["MBRHeader", 0, [
 ["Magic", 0x1FE, "uint16"],
 ["PrimaryPartitions", 0x1BE, Array, {
 type: "PrimaryPartition",
 count: 4,
 }],
 ]],
 ["PrimaryPartition", 16, [
 ["boot", 0, "uint8"],
 ["ptype", 4, "Enumeration", {
 type: "uint8",
 map: {
 "Unused": 0,
 "Dos Extended": 0x05,
 "Win95 Extended": 0x0f,
 "GPT Safety Partition": 0xee,
 "NTFS / exFAT": 7,
 "Hibernation": 0x12,
 "Linux": 0x83,
 "Linux Swap": 0x82,
 "Linux Extended": 0x85,
 }}],
 ["start_sec", 8, "uint32"],
 ["size_sec", 12, "uint32"],
 ]],
 ["GPTHeader", 0, [
 ["signature", 0, "String", {
 length: 8,
 }],
 ["version", 4, "uint32"],
 ["tab_start_lba", 72, "uint64"],
 ["tab_num", 80, "uint32"],
 ["tab_size", 84, "uint32"],
 ["entries", 0, "Profile", {
 type: "Array",
 offset: "x=&amp;gt;x.tab_start_lba * 512",
 type_options: {
 type: "GPTEntry",
 count: "x=&amp;gt;x.tab_num",
 }}]
 ]],
 ["GPTEntry", 128, [
 ["Offset", 0, "Value", {
 value: "x=&amp;gt;x.StartOf",
 }],
 ["type_guid", 0, GUID],
 ["id_guid", 16, GUID],
 ["start_lba", 32, "uint64"],
 ["end_lba", 40, "uint64"],
 ["flag", 48, "uint64"],
 ["name", 56, "String", {
 encoding: "utf16"
 }]
 ]],
 ["GUID", 16, [
 ["__D1", 0, "uint32"],
 ["__D2", 2, "uint16"],
 ["__D3", 4, "uint16"],
 ["__D4", 6, "String", {"term": "", "length": 2}],
 ["__D5", 8, "String", {"term": "", "length": 6}],
 ["Value", 0, "Value", {
 "value": "x=&amp;gt;format(format='{%08x-%04x-%04x-%02x-%02x}', args=[x.__D1, x.__D2, x.__D3, x.__D4, x.__D5])"
 }]
 ]]
 ]
 '''

sources:
 - query: |
 LET GPTHeader &amp;lt;= parse_binary(filename=ImagePath,
 accessor=Accessor,
 profile=MBRProfile,
 struct="GPTHeader",
 offset=SectorSize)

 LET PrimaryPartitions &amp;lt;= parse_binary(filename=ImagePath,
 accessor=Accessor,
 profile=MBRProfile,
 struct="MBRHeader",
 offset=0)

 -- Display GPT - this is by far the most common one on modern
 -- systems.
 LET GPT = SELECT * FROM if(condition=GPTHeader.signature =~ "EFI",
 then={
 SELECT start_lba * SectorSize AS StartOffset,
 end_lba * SectorSize AS EndOffset,
 humanize(bytes=(end_lba - start_lba) * SectorSize) AS Size,
 name
 FROM foreach(row=GPTHeader.entries)
 WHERE start_lba &amp;gt; 0
 })

 -- Display primary partitions
 LET PARTS = SELECT start_sec * SectorSize AS StartOffset,
 ( start_sec + size_sec ) * SectorSize AS EndOffset,
 humanize(bytes=size_sec * SectorSize) AS Size,
 ptype AS name
 FROM foreach(row=PrimaryPartitions.PrimaryPartitions)
 WHERE start_sec &amp;gt; 0

 -- Handle the correct partition types
 LET GetAccessor(Magic) =
 if(condition=Magic =~ "NTFS", then="raw_ntfs",
 else=if(condition=Magic =~ "FAT", then="fat",
 else=if(condition=Magic =~ "EXT[2-4]", then="ext4")))

 LET ListTopDirectory(PartitionPath, Magic) =
 SELECT * FROM if(condition=GetAccessor(Magic=Magic), then={
 SELECT OSPath.Path AS OSPath
 FROM glob(globs="/*",
 accessor=GetAccessor(Magic=Magic),
 root=PartitionPath)
 })

 LET PartitionList = SELECT StartOffset, EndOffset, Size, name,
 magic(accessor="data", path=read_file(
 accessor=Accessor,
 filename=ImagePath,
 offset=StartOffset, length=10240)) AS Magic,

 -- The OSPath to access the partition
 pathspec(
 DelegateAccessor="offset",
 Delegate=pathspec(
 DelegateAccessor=Accessor,
 DelegatePath=ImagePath,
 Path=format(format="%d", args=StartOffset))) AS _PartitionPath
 FROM chain(a=PARTS, b=GPT)
 WHERE name =~ NameRegex
 AND Magic =~ MagicRegex

 SELECT StartOffset, EndOffset, Size, name,
 ListTopDirectory(Magic=Magic,
 PartitionPath= _PartitionPath).OSPath AS TopLevelDirectory,
 Magic, _PartitionPath
 FROM PartitionList

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.Prefetch</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.prefetch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.prefetch/</guid><description>&lt;p>Windows keeps a cache of prefetch files. When an executable is run,
the system records properties about the executable to make it faster
to run next time. By parsing this information we are able to
determine when binaries are run in the past. On Windows10 we can see
the last 8 execution times and creation time (9 potential executions).&lt;/p>
&lt;p>There are several parameters available for this artifact.&lt;/p>
&lt;ul>
&lt;li>dateAfter enables search for prefetch evidence after this date.&lt;/li>
&lt;li>dateBefore enables search for prefetch evidence before this date.&lt;/li>
&lt;li>binaryRegex enables to filter on binary name, e.g evil.exe.&lt;/li>
&lt;li>hashRegex enables to filter on prefetch hash.&lt;/li>
&lt;/ul>
&lt;p>NOTE: The Prefetch file format is described extensively in libscca
and painstakingly reversed by Joachim Metz (Shouts and Thank
you!). Thanks to &lt;a href="https://github.com/secDre4mer" target="_blank" >https://github.com/secDre4mer&lt;/a>
 for additional
information.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.Prefetch
description: |
 Windows keeps a cache of prefetch files. When an executable is run,
 the system records properties about the executable to make it faster
 to run next time. By parsing this information we are able to
 determine when binaries are run in the past. On Windows10 we can see
 the last 8 execution times and creation time (9 potential executions).

 There are several parameters available for this artifact.
 - dateAfter enables search for prefetch evidence after this date.
 - dateBefore enables search for prefetch evidence before this date.
 - binaryRegex enables to filter on binary name, e.g evil.exe.
 - hashRegex enables to filter on prefetch hash.

 NOTE: The Prefetch file format is described extensively in libscca
 and painstakingly reversed by Joachim Metz (Shouts and Thank
 you!). Thanks to https://github.com/secDre4mer for additional
 information.

reference:
 - https://www.forensicswiki.org/wiki/Prefetch
 - https://github.com/libyal/libscca/blob/main/documentation/Windows%20Prefetch%20File%20(PF)%20format.asciidoc

parameters:
 - name: prefetchGlobs
 default: C:\Windows\Prefetch\*.pf
 - name: dateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 type: timestamp
 - name: dateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 type: timestamp
 - name: binaryRegex
 description: "Regex of executable name."
 type: regex
 - name: hashRegex
 description: "Regex of prefetch hash."
 type: regex
 - name: IncludeFilesAccessed
 description: Include all accessed files
 type: bool

export: |
 LET PrefetchProfile = '''[
 ["Header", 8, [
 ["Signature", 0, "String", {"length": 3}],
 ["UncompressedSize", 4, "unsigned long"],
 ["Data", 8, String, {
 length: "x=&amp;gt;x.UncompressedSize",
 term: "",
 max_length: 10000000,
 }],
 ["Decompressed", 0, "Value", {
 value: "x=&amp;gt;lzxpress_decompress(data=x.Data)"
 }],
 ]],
 ["SCCAHeader", 84, [
 ["Version", 0, "Enumeration", {
 type: "unsigned int",
 choices: {
 "17": "WinXP (17)",
 "23": "Vista (23)",
 "26": "Win8.1 (26)",
 "30": "Win10 (30)",
 "31": "Win11 (31)"
 }
 }],
 ["Signature", 4, "String", {"length": 4}],
 ["FileSize", 12, "unsigned long"],
 ["Executable", 16, "String", {
 encoding: "utf16",
 }],
 ["Hash", 76, "unsigned long"],

 # Hash is followed by a version specific info struct.
 ["Info", 84, "Union", {
 selector: "x=&amp;gt;x.Version",
 choices: {
 "WinXP (17)": "FileInformationWinXP",
 "Vista (23)": "FileInformationVista",
 "Win8.1 (26)": "FileInformationWin81",
 "Win10 (30)": "FileInformationWin10",
 "Win11 (31)": "FileInformationWin10"
 }
 }]
 ]],

 ["FileInformationWinXP", 68, [
 ["__FileMetricsOffset", 0, "unsigned long"],
 ["__NumberOfFileMetrics", 4, "unsigned long"],
 ["__TraceChainsArrayOffset", 8, "unsigned long"],
 ["__NumberOfTraceChains", 12, "unsigned long"],
 ["__FilenameOffset", 16, "unsigned long"],
 ["__FilenameSize", 20, "unsigned long"],
 ["__VolumesInformationOffset", 24, "unsigned long"],
 ["__NumberOfVolumes", 28, "unsigned long"],
 ["__VolumesInformationSize", 32, "unsigned long"],

 # This is realy just one time but we make it an
 # array to be compatible with the others.
 ["LastRunTimes", 36, "Array", {
 "type": "TimestampRecord",
 "count": 1
 }],
 ["RunCount", 60, "unsigned long"],

 # Metrics offset is absolute.
 ["Metrics", "x=&amp;gt;x.__FileMetricsOffset - x.StartOf", "Array", {
 type: "FileMetricsEntryV17",
 count: "x=&amp;gt;x.__NumberOfFileMetrics",
 }],
 ["VolumeInfo", "x=&amp;gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
 type: "VolumeInformation",
 count: "x=&amp;gt;x.__NumberOfVolumes",
 }],
 ]],

 ["FileInformationVista", 156, [
 ["__FileMetricsOffset", 0, "unsigned long"],
 ["__NumberOfFileMetrics", 4, "unsigned long"],
 ["__TraceChainsArrayOffset", 8, "unsigned long"],
 ["__NumberOfTraceChains", 12, "unsigned long"],
 ["__FilenameOffset", 16, "unsigned long"],
 ["__FilenameSize", 20, "unsigned long"],
 ["__VolumesInformationOffset", 24, "unsigned long"],
 ["__NumberOfVolumes", 28, "unsigned long"],
 ["__VolumesInformationSize", 32, "unsigned long"],

 # This is realy just one time but we make it an
 # array to be compatible with the others.
 ["LastRunTimes", 44, "Array", {
 "type": "TimestampRecord",
 "count": 1
 }],
 ["RunCount", 68, "unsigned long"],

 # Metrics offset is absolute.
 ["Metrics", "x=&amp;gt;x.__FileMetricsOffset - x.StartOf", "Array", {
 type: "FileMetricsEntryV23",
 count: "x=&amp;gt;x.__NumberOfFileMetrics",
 }],
 ["VolumeInfo", "x=&amp;gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
 type: "VolumeInformation",
 count: "x=&amp;gt;x.__NumberOfVolumes",
 }],
 ]],


 ["FileInformationWin81", 224, [
 ["__FileMetricsOffset", 0, "unsigned long"],
 ["__NumberOfFileMetrics", 4, "unsigned long"],
 ["__TraceChainsArrayOffset", 8, "unsigned long"],
 ["__NumberOfTraceChains", 12, "unsigned long"],
 ["__FilenameOffset", 16, "unsigned long"],
 ["__FilenameSize", 20, "unsigned long"],
 ["__VolumesInformationOffset", 24, "unsigned long"],
 ["__NumberOfVolumes", 28, "unsigned long"],
 ["__VolumesInformationSize", 32, "unsigned long"],

 # This is realy just one time but we make it an
 # array to be compatible with the others.
 ["LastRunTimes", 44, "Array", {
 "type": "TimestampRecord",
 "count": 8,
 }],
 ["RunCount", 124, "unsigned long"],

 # Metrics offset is absolute.
 ["Metrics", "x=&amp;gt;x.__FileMetricsOffset - x.StartOf", "Array", {
 type: "FileMetricsEntryV23",
 count: "x=&amp;gt;x.__NumberOfFileMetrics",
 }],
 ["VolumeInfo", "x=&amp;gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
 type: "VolumeInformation",
 count: "x=&amp;gt;x.__NumberOfVolumes",
 }],
 ]],

 ["FileInformationWin10", 224, [
 ["__FileMetricsOffset", 0, "unsigned long"],
 ["__NumberOfFileMetrics", 4, "unsigned long"],
 ["__TraceChainsArrayOffset", 8, "unsigned long"],
 ["__NumberOfTraceChains", 12, "unsigned long"],
 ["__FilenameOffset", 16, "unsigned long"],
 ["__FilenameSize", 20, "unsigned long"],
 ["__VolumesInformationOffset", 24, "unsigned long"],
 ["__NumberOfVolumes", 28, "unsigned long"],
 ["__VolumesInformationSize", 32, "unsigned long"],
 ["__TotalDirectoryCount", 36, "unsigned long"],
 ["LastRunTimes", 44, "Array", {
 "type": "TimestampRecord",
 "count": 8
 }],
 ["__RunCount1", 124, "unsigned long"],
 ["__RunCountPre", 120, "unsigned long"],
 ["__RunCount2", 116, "unsigned long"],
 ["RunCount", 0, Value, {
 value: "x=&amp;gt;if(condition=x.__RunCountPre=0, then=x.__RunCount1, else=x.__RunCount2)",
 }],
 ["ExecutablePath", "x=&amp;gt;x.__ExecutablePathOffset - x.OffsetOf", String, {
 length: "x=&amp;gt;x.__ExecutablePathSize * 2",
 encoding: "utf16",
 }],
 ["__ExecutablePathOffset", 128, "unsigned long"],
 ["__ExecutablePathSize", 132, "unsigned long"],

 # Metrics offset is absolute.
 ["Metrics", "x=&amp;gt;x.__FileMetricsOffset - x.StartOf", "Array", {
 type: "FileMetricsEntryV30",
 count: "x=&amp;gt;x.__NumberOfFileMetrics",
 }],
 ["VolumeInfo", "x=&amp;gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
 type: "VolumeInformation",
 count: "x=&amp;gt;x.__NumberOfVolumes",
 }],
 ]],

 ["TimestampRecord", 8, [
 ["Date", 0, "WinFileTime"],
 ["Int", 0, "unsigned long long"]
 ]],

 ["FileMetricsEntryV17", 20, [
 ["__FilenameOffset", 8, "unsigned long"],
 ["__FilenameLength", 12, "unsigned long"],
 ["Filename", 0, "Profile", {
 offset: "x=&amp;gt;x.ParentOf.__FilenameOffset + x.__FilenameOffset",
 type: "String",
 type_options: {
 encoding: "utf16",
 length: 1024,
 }
 }]
 ]],


 ["FileMetricsEntryV23", 32, [
 ["__FilenameOffset", 12, "unsigned long"],
 ["__FilenameLength", 16, "unsigned long"],
 ["__MFTFileReference", 24, "unsigned long"],
 ["Filename", 0, "Profile", {
 offset: "x=&amp;gt;x.ParentOf.__FilenameOffset + x.__FilenameOffset",
 type: "String",
 type_options: {
 encoding: "utf16",
 length: 1024,
 }
 }]
 ]],

 ["FileMetricsEntryV30", 32, [
 ["__FilenameOffset", 12, "unsigned long"],
 ["__FilenameLength", 16, "unsigned long"],
 ["__MFTFileReference", 24, "unsigned long"],
 ["Filename", 0, "Profile", {
 offset: "x=&amp;gt;x.ParentOf.__FilenameOffset + x.__FilenameOffset",
 type: "String",
 type_options: {
 encoding: "utf16",
 length: 1024,
 }
 }]
 ]],

 ["VolumeInformation", 40, [
 ["__DeviceOffset", 0, "unsigned long"],
 ["DeviceName", "x=&amp;gt;x.__DeviceOffset", "String", {
 encoding: utf16,
 length: "x=&amp;gt;x.__DeviceSize * 2",
 }],
 ["__DeviceSize", 4, "unsigned long"],
 ["DeviceCreationTime", 8, "WinFileTime"],
 ["VolumeSerialNumber", 12, "unsigned long"],
 ["VolumeSerialNumberHex", 0, Value, {
 value: "x=&amp;gt;format(format='%#x', args=x.VolumeSerialNumber)",
 }],
 ["__FileReferenceOffset", 20, "unsigned long"],
 ["__FileReferenceDataSize", 24, "unsigned long"],
 ["__DirectoryStringsOffset", 28, "unsigned long"],
 ["__NumDirectoryStrings", 32, "unsigned long"],
 ["__Directories", "x=&amp;gt;x.__DirectoryStringsOffset", "Array", {
 type: "DirectoryName",
 count: "x=&amp;gt;x.__NumDirectoryStrings",
 }],
 ["Directories", 0, Value, {
 value: "x=&amp;gt;x.__Directories.Name"
 }],
 ]],
 ["DirectoryName", "x=&amp;gt;x.Size * 2 + 4", [
 ["Size", 0, "uint8"],
 ["Name", 2, "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.Size * 2"
 }]
 ]]
 ]
 '''

 LET ParsePrefetch(PrefetchFile) = SELECT
 parse_binary(accessor="data", filename=Data,
 profile=PrefetchProfile, struct="SCCAHeader") AS SCCAHeader
 FROM switch(a={
 -- Handle compressed MAM prefetch files.
 SELECT
 parse_binary(filename=PrefetchFile, profile=PrefetchProfile, struct="Header") AS Header,
 parse_binary(filename=PrefetchFile, profile=PrefetchProfile, struct="Header").Decompressed AS Data
 FROM scope()
 WHERE Header.Signature = "MAM"
 },
 b={
 -- Handle uncompressed files
 SELECT read_file(filename=PrefetchFile, length=1024*1024) AS Data
 FROM scope()
 })
 WHERE SCCAHeader.Signature = "SCCA"

 // These functions help to resolve the Kernel Device Filenames
 // into a regular filename with drive letter.
 LET DriveReplaceLookup &amp;lt;= SELECT
 split(sep_string="\\", string=Name)[-1] AS Drive,
 upcase(string=SymlinkTarget) AS Target,
 len(list=SymlinkTarget) AS Len
 FROM winobj()
 WHERE Name =~ "^\\\\GLOBAL\\?\\?\\\\.:"

 LET _DriveReplace(Path) = SELECT Drive + Path[Len:] AS ResolvedPath
 FROM DriveReplaceLookup
 WHERE upcase(string=Path[:Len]) = Target

 LET DriveReplace(Path) = _DriveReplace(Path=Path)[0].ResolvedPath || Path

sources:
 - query: |
 // Parse prefetch files and apply non time filters
 LET pf = SELECT * FROM foreach(
 row={
 SELECT * FROM glob(globs=prefetchGlobs)
 },
 query={
 SELECT SCCAHeader AS _SCCAHeader,
 SCCAHeader.Executable AS Executable,
 SCCAHeader.FileSize AS FileSize,
 format(format="%#X", args=SCCAHeader.Hash) AS Hash,
 SCCAHeader.Version AS Version,
 filter(list=SCCAHeader.Info.LastRunTimes.Date, condition="x=&amp;gt;x.Unix &amp;gt; 0") AS LastRunTimes,
 SCCAHeader.Info.RunCount AS RunCount,
 SCCAHeader.Info.ExecutablePath AS ExecutablePath,
 DriveReplace(Path=SCCAHeader.Info.ExecutablePath) AS ExecutableDosPath,
 OSPath,
 Name AS PrefetchFileName,
 Btime as CreationTime,
 Mtime as ModificationTime,
 filter(list=SCCAHeader.Info.Metrics.Filename, regex=".exe$")[0] AS Binary,
 if(condition= IncludeFilesAccessed, then=SCCAHeader.Info.Metrics.Filename) AS FilesAccessed,
 if(condition= IncludeFilesAccessed, then=SCCAHeader.Info.VolumeInfo) AS VolumeInfo
 FROM ParsePrefetch(PrefetchFile=OSPath)
 WHERE
 if(condition=binaryRegex, then= Executable =~ binaryRegex, else=TRUE) AND
 if(condition=hashRegex, then= Hash =~ hashRegex, else=TRUE)
 })

 // Flattern to enable time filters. Remember VQL is lazy.
 LET executionTimes = SELECT * FROM flatten(
 query = {
 SELECT *,
 OSPath as FilteredPath,
 LastRunTimes as ExecutionTime
 FROM pf
 })
 WHERE
 if(condition=dateAfter, then=ExecutionTime &amp;gt; timestamp(string=dateAfter),
 else=TRUE) AND
 if(condition=dateBefore, then=ExecutionTime &amp;lt; timestamp(string=dateBefore),
 else=TRUE)
 LET creationTimes = SELECT * FROM flatten(
 query = {
 SELECT *,
 OSPath as FilteredPath,
 CreationTime as ExecutionTime
 FROM pf
 WHERE RunCount &amp;gt; 8
 })
 WHERE
 if(condition=dateAfter, then=ExecutionTime &amp;gt; timestamp(string=dateAfter),
 else=TRUE) AND
 if(condition=dateBefore, then=ExecutionTime &amp;lt; timestamp(string=dateBefore),
 else=TRUE)
 GROUP BY ExecutionTime

 // For stdOutput with timefilters we need to group by OSPath
 LET timeFiltered = SELECT FilteredPath
 FROM chain(
 a = { SELECT * FROM executionTimes },
 b = { SELECT * FROM creationTimes })
 GROUP BY FilteredPath

 LET timeFilteredStdOut = SELECT * FROM foreach(
 row={
 SELECT * FROM timeFiltered
 },
 query={
 SELECT *
 FROM pf
 WHERE OSPath = FilteredPath
 })

 SELECT *
 FROM if(condition = (dateBefore OR dateAfter),
 then={ SELECT * FROM timeFilteredStdOut },
 else={ SELECT * FROM pf })


column_types:
 - name: CreationTime
 type: timestamp
 - name: ModificationTime
 type: timestamp

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.Pst</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.pst/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.pst/</guid><description>&lt;p>Parses PST files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.Pst
description: |
 Parses PST files.

parameters:
 - name: PSTGlob
 description: Glob for locating PST files.
 default: "C:/Users/*/**.pst"
 - name: Accessor
 default: auto
 - name: SenderRegex
 type: regex
 default: .
 - name: ReceiverRegex
 type: regex
 default: .
 - name: SubjectRegex
 type: regex
 default: .
 - name: MessageRegex
 type: regex
 default: .
 - name: PathRegex
 type: regex
 default: .
 - name: AttachmentYaraRule
 description: |
 If specified, we Yara scan the attachment with this rule and
 only allow matched messages.
 - name: UploadAttachments
 description: If set we upload attachments
 type: bool

sources:
 - query: |
 LET X = scope()

 SELECT * FROM foreach(row={
 SELECT * FROM glob(globs=PSTGlob)
 }, query={
 SELECT *,
 if(condition=UploadAttachments, then={
 SELECT upload(
 file=pathspec(
 DelegateAccessor=Accessor,
 DelegatePath=OSPath,
 Path=Path),
 accessor="pst")
 FROM foreach(row=Attachments)
 }) AS Uploads,

 if(condition=AttachmentYaraRule, then={
 SELECT * FROM foreach(row=Attachments,
 query={
 SELECT String
 FROM yara(accessor="pst",
 files=pathspec(
 DelegateAccessor=Accessor,
 DelegatePath=OSPath,
 Path=Path),
 rules=AttachmentYaraRule, number=1)
 })
 }) AS YaraHit
 FROM parse_pst(filename=OSPath, accessor=Accessor)
 WHERE X.Sender =~ SenderRegex
 AND X.Receiver =~ ReceiverRegex
 AND X.Subject =~ SubjectRegex
 AND X.Message =~ MessageRegex
 AND X.Path =~ PathRegex
 })
 WHERE if(condition=AttachmentYaraRule, then=YaraHit, else=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.RDPCache</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.rdpcache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.rdpcache/</guid><description>&lt;p>This artifact parses, views and enables simplified upload of RDP
cache files.&lt;/p>
&lt;p>By default the artifact will parse .BIN RDPcache files.&lt;/p>
&lt;p>Filters include &lt;code>UserRegex&lt;/code> to target a user and &lt;code>Accessor&lt;/code> to target
VSS via ntfs_vss.&lt;/p>
&lt;p>Best combined with:&lt;/p>
&lt;ul>
&lt;li>Windows.EventLogs.RDPAuth to collect RDP focused event logs.&lt;/li>
&lt;li>Windows.Registry.RDP to collect user RDP MRU and server info&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.RDPCache
author: Matt Green - @mgreen27
description: |
 This artifact parses, views and enables simplified upload of RDP
 cache files.

 By default the artifact will parse .BIN RDPcache files.

 Filters include `UserRegex` to target a user and `Accessor` to target
 VSS via ntfs_vss.

 Best combined with:

 - Windows.EventLogs.RDPAuth to collect RDP focused event logs.
 - Windows.Registry.RDP to collect user RDP MRU and server info

reference:
 - https://github.com/ANSSI-FR/bmc-tools
 - https://github.com/BSI-Bund/RdpCacheStitcher

parameters:
 - name: RDPCacheGlob
 default: C:\{{Users,Windows.old\Users}\*\AppData\Local,Documents and Settings\*\Local Settings\Application Data}\Microsoft\Terminal Server Client\Cache\*
 - name: Accessor
 description: Set accessor to use. blank is default, file for api, ntfs for raw, ntfs_vss for vss
 - name: UserRegex
 default: .
 description: Regex filter of user to target. StartOf(^) and EndOf($)) regex may behave unexpectedly.
 type: regex
 - name: DateAfter
 type: timestamp
 description: "search for cache files modified after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for cache files modified before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: ParseCache
 description: If selected will parse .BIN RDPcache files.
 type: bool
 - name: Workers
 default: 100
 type: int
 description: Number of workers to use for ParseCache
 - name: UploadRDPCache
 description: If selected will upload raw cache files. Can be used for offline processing/preservation.
 type: bool

sources:
 - name: TargetFiles
 description: RDP BitmapCache files in scope.
 query: |
 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=DateAfter, else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=DateBefore, else=timestamp(epoch="2200-01-01"))
 
 LET results = SELECT OSPath, Size, Mtime, Atime, Ctime, Btime
 FROM glob(globs=RDPCacheGlob,accessor=Accessor)
 WHERE OSPath =~ UserRegex
 AND Mtime &amp;gt; DateAfterTime
 AND Mtime &amp;lt; DateBeforeTime

 LET upload_results = SELECT *, upload(file=OSPath) as CacheUpload
 FROM results

 SELECT * FROM if(condition= UploadRDPCache,
 then= upload_results,
 else= results )

 - name: Parsed
 description: Parsed RDP BitmapCache files.
 query: |
 LET PROFILE = '''[
 ["BIN_CONTAINER", 0, [
 [Magic, 0, String, {length: 8, term_hex : "FFFFFF" }],
 [Version, 8, uint32],
 [CachedFiles, 12, Array, {
 "type": "rgb32b",
 "count": 10000,
 "max_count": 2000,
 "sentinel": "x=&amp;gt;x.__Size &amp;lt; 15",
 }],
 ]],
 ["rgb32b","x=&amp;gt;x.__Size",[
 [__key1, 0, uint32],
 [__key1, 4, uint32],
 ["Width", 8, "uint16"],
 ["Height", 10, "uint16"],
 [DataLength, 0, Value,{ value: "x=&amp;gt; 4 * x.Width * x.Height"}],
 [DataOffset, 0, Value,{ "value": "x=&amp;gt;x.StartOf + 12"}],
 ["__Size", 0, Value,{ "value": "x=&amp;gt;x.DataLength + 12"}],
 ["Index", 0, Value,{ "value": "x=&amp;gt;count() - 1 "}],
 ]]]'''

 LET parse_rgb32b(data) = SELECT
 _value as Offset,
 _value + 3 as EndOffset,
 len(list=data) as Length,
 data[(_value):(_value + 3)] + unhex(string="FF") as Buffer
 FROM range(step=4,end=len(list=data))

 LET fix_bmp(data) = SELECT
 _value as Offset,
 _value + 255 as EndOffset,
 join(array=data[ (_value):(_value + 256 ) ],sep='') as Buffer
 FROM range(step=256, end= len(list=data) )
 ORDER BY Offset DESC

 LET parse_container = SELECT * OSPath,Name,Size as FileSize,
 read_file(filename=OSPath,length=12) as Header,
 parse_binary(filename=OSPath,profile=PROFILE,struct='BIN_CONTAINER') as Parsed
 FROM foreach(row={
 SELECT * FROM glob(globs=RDPCacheGlob,accessor=Accessor)
 WHERE OSPath =~ '\.bin$'
 AND OSPath =~ UserRegex
 AND NOT IsDir
 })

 LET find_index_differential = SELECT *, 0 - Parsed.CachedFiles.Index[0] as IndexDif
 FROM parse_container

 LET parse_cache = SELECT * FROM foreach(row=find_index_differential, query={
 SELECT OSPath, IndexDif,
 OSPath.Dirname + ( OSPath.Basename + '_' + format(format='%04v',args= Index + IndexDif ) + '.bmp' ) as BmpName,
 FileSize,Header,Width,Height,DataLength,DataOffset
 FROM foreach(row=Parsed.CachedFiles)
 })

 LET extract_data = SELECT *
 FROM foreach(row=parse_cache,query={
 SELECT
 OSPath,BmpName,FileSize,Header,Width,Height,DataLength,DataOffset,
 join(array=parse_rgb32b(data=read_file(filename=OSPath,offset=DataOffset,length=DataLength)).Buffer,sep='') as Data
 FROM scope()
 }, workers=Workers)

 -- change endianess for unint32
 LET pack_lt_l(data) = unhex(string=join(array=[
 format(format='%02x',args=unhex(string=format(format='%08x',args=data))[3]),
 format(format='%02x',args=unhex(string=format(format='%08x',args=data))[2]),
 format(format='%02x',args=unhex(string=format(format='%08x',args=data))[1]),
 format(format='%02x',args=unhex(string=format(format='%08x',args=data))[0])
 ],sep=''))

 -- build bmp file, adding appropriate header
 LET build_bmp(data,width,height) = join(array=[
 "BM",
 pack_lt_l(data=len(list=data) + 122),
 unhex(string="000000007A0000006C000000"),
 pack_lt_l(data=width),
 pack_lt_l(data=height),
 unhex(string="0100200003000000"),
 pack_lt_l(data=len(list=data)),
 unhex(string="000000000000000000000000000000000000FF0000FF0000FF000000000000FF"),
 " niW",
 unhex(string="00" * 36),
 unhex(string="000000000000000000000000"),
 data
 ], sep='')

 SELECT * FROM if(condition= ParseCache,
 then={
 SELECT
 BmpName, Header, Width, Height, DataLength, DataOffset,
 upload(
 file=build_bmp(data=join(array=fix_bmp(data=Data).Buffer,sep=''),
 width=Width, height=Height),
 name=BmpName,
 accessor='data' ) as BmpUpload,
 OSPath as SourceFile
 FROM extract_data
 ORDER BY BmpName
 },
 else= Null )


column_types:
 - name: BmpUpload
 type: upload_preview
 - name: CacheUpload
 type: upload_preview

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.RecentApps</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.recentapps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.recentapps/</guid><description>&lt;p>GUI Program execution launched on the Win10 system is tracked in the
RecentApps key.&lt;/p>
&lt;p>NOTE: This artifact is available up from Windows 10 1607 to 1709.
After that, the RecentApps key is no longer populated in the
referenced location. Previously existing data is not removed.&lt;/p>
&lt;p>DEPRECATION: This artifact is deprecated and will be removed
soon. It is replaced by the registry hunter.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.RecentApps
description: |
 GUI Program execution launched on the Win10 system is tracked in the
 RecentApps key.

 NOTE: This artifact is available up from Windows 10 1607 to 1709.
 After that, the RecentApps key is no longer populated in the
 referenced location. Previously existing data is not removed.

 DEPRECATION: This artifact is deprecated and will be removed
 soon. It is replaced by the registry hunter.

reference:
 - https://www.sans.org/security-resources/posters/windows-forensics-evidence-of/75/download
 - https://www.forensicfocus.com/forums/general/forensics-windows-registry-program-launch-history/
 - https://thinkdfir.com/2020/10/23/when-did-recentapps-go/

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: UserFilter
 default: ""
 description: If specified we filter by this user ID.
 type: regex

 - name: ExecutionTimeAfter
 default: ""
 type: timestamp
 description: If specified only show executions after this time.

 - name: RecentAppsKey
 default: Software\Microsoft\Windows\CurrentVersion\Search\RecentApps\*

 - name: UserHomes
 default: C:\Users\*\NTUSER.DAT

sources:
 - query: |
 LET TMP = SELECT * FROM foreach(
 row={
 SELECT OSPath AS HivePath FROM glob(globs=UserHomes)
 },
 query={
 SELECT timestamp(winfiletime=LastAccessedTime) AS LastExecution,
 timestamp(winfiletime=LastAccessedTime).Unix AS _LastExecutionTS,
 Key.OSPath as _OSPath,
 HivePath[2] AS User,
 AppId, AppPath, LaunchCount
 FROM read_reg_key(
 globs=RecentAppsKey,
 root=pathspec(
 DelegateAccessor="ntfs",
 DelegatePath=HivePath),
 accessor="raw_reg")
 })

 LET A1 = SELECT * FROM if(
 condition=UserFilter,
 then={
 SELECT * FROM TMP WHERE User =~ UserFilter
 }, else={ SELECT * FROM TMP})

 SELECT * FROM if(
 condition=ExecutionTimeAfter,
 then={
 SELECT * FROM A1 WHERE LastExecutionTS &amp;gt; ExecutionTimeAfter
 }, else={ SELECT * FROM A1})

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.RecycleBin</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.recyclebin/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.recyclebin/</guid><description>&lt;p>This artifact will parse the &lt;code>$I&lt;/code> files found in the &lt;code>$Recycle.Bin&lt;/code> folder to
obtain the time of deletion and the original path and file name.&lt;/p>
&lt;p>Supports Recycle Bin format found in Vista onwards. This will not parse INFO2
files found in the &amp;ldquo;Recycler&amp;rdquo; folder from XP and below.&lt;/p>
&lt;p>The layout of the Recycle Bin folder is in the in the form:&lt;/p>
&lt;pre>&lt;code> C:\$Recycle.Bin\%SID%\
&lt;/code>&lt;/pre>
&lt;p>Each folder contains the following files:&lt;/p>
&lt;pre>&lt;code>$R###### files; the original data
$I###### files; the &amp;quot;Recycled&amp;quot; file's metadata
&lt;/code>&lt;/pre>
&lt;p>The first file begins with the value &lt;code>$R&lt;/code> followed by a random string
– this file contains the actual contents of the recycled file.
The second file begins with &lt;code>$I&lt;/code> and ends in the same string as the
&lt;code>$R&lt;/code> file – this file contains the metadata for that specific file&lt;/p>
&lt;p>Limitations: This artifact uses the API to read available $I data. There may be additional unallocated but readable $I files referenced in the MFT that may be recoverable.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.RecycleBin
description: |
 This artifact will parse the `$I` files found in the `$Recycle.Bin` folder to
 obtain the time of deletion and the original path and file name.

 Supports Recycle Bin format found in Vista onwards. This will not parse INFO2
 files found in the "Recycler" folder from XP and below.

 The layout of the Recycle Bin folder is in the in the form:
 ```
 C:\$Recycle.Bin\%SID%\
 ```
 Each folder contains the following files:
 ```
 $R###### files; the original data
 $I###### files; the "Recycled" file's metadata
 ```
 The first file begins with the value `$R` followed by a random string
 – this file contains the actual contents of the recycled file.
 The second file begins with `$I` and ends in the same string as the
 `$R` file – this file contains the metadata for that specific file

 Limitations: This artifact uses the API to read available $I data. There may be additional unallocated but readable $I files referenced in the MFT that may be recoverable.

author: "Zach Stanford - @svch0st"

reference:
 - https://forensicswiki.xyz/wiki/index.php?title=Windows#Recycle_Bin
 - https://www.magnetforensics.com/blog/artifact-profile-recycle-bin/


parameters:
 - name: RecycleBinGlobs
 default: C:\$Recycle.Bin\**\$I*

 - name: AlsoUpload
 type: bool
 description: Also upload recovered files.

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 SELECT * FROM foreach(
 row={
 SELECT OSPath FROM glob(globs=RecycleBinGlobs)
 },
 query={
 SELECT
 timestamp(winfiletime=DeletedTime) as DeletedTimestamp,
 Name,
 FilePath as OriginalFilePath,
 FileSize,
 OSPath,
 regex_replace(source=OSPath, re="\\\\\\$I", replace="\\$$R") AS RecyclePath,
 if(condition=AlsoUpload, then=upload(
 file=regex_replace(source=OSPath, re="\\\\\\$I", replace="\\$$R"),
 name=FilePath
 )) AS Upload
 FROM parse_recyclebin(filename=OSPath)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.SAM</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.sam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.sam/</guid><description>&lt;p>Parses user account information from the SAM hive.&lt;/p>
&lt;p>Based on Omer Yampel&amp;rsquo;s parser&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.SAM
description: |
 Parses user account information from the SAM hive.

 Based on Omer Yampel's parser

reference:
 - https://github.com/yampelo/samparser/blob/master/samparser.py

parameters:
 - name: SAMPath
 description: Path to the SAM file to parse.
 default: C:/Windows/System32/Config/SAM

export: |
 // Reference: https://github.com/yampelo/samparser/blob/master/samparser.py
 LET Profile = '''
 [
 ["F", 0, [
 ["LastLoginDate", 8, "WinFileTime"],
 ["PasswordResetDate", 24, "WinFileTime"],
 ["PasswordFailDate", 40, "WinFileTime"],
 ["RID", 48, "uint32"],
 ["Flags", 56, "Flags", {
 "type": "uint16",
 "bitmap": {
 "Account Disabled": 0,
 "Home directory required": 1,
 "Password not required": 2,
 "Temporary duplicate account": 3,
 "Normal user account": 4,
 "MNS logon user account": 5,
 "Interdomain trust account": 6,
 "Workstation trust account": 7,
 "Server trust account": 8,
 "Password does not expire": 9,
 "Account auto locked": 10
 }
 }],
 ["FailedLoginCount", 64, "uint16"],
 ["LoginCount", 66, "uint16"],
 ]],
 ["V", 0, [
 ["AccountType", 4, "Enumeration", {
 "type": "uint32",
 "choices": {
 "188" : "Default Admin User",
 "212" : "Custom Limited Acct",
 "176" : "Default Guest Acct"
 }
 }],
 ["__username_offset", 12, "uint32"],
 ["__username_length", 16, "uint32"],
 ["username", "x=&amp;gt;x.__username_offset + 0xcc", "String", {
 "length": "x=&amp;gt;x.__username_length",
 "encoding": "utf16",
 }],
 ["__fullname_offset", 24, "uint32"],
 ["__fullname_length", 28, "uint32"],
 ["fullname", "x=&amp;gt;x.__fullname_offset + 0xcc", "String", {
 "length": "x=&amp;gt;x.__fullname_length",
 "encoding": "utf16",
 }],
 ["__comment_offset", 36, "uint32"],
 ["__comment_length", 40, "uint32"],
 ["comment", "x=&amp;gt;x.__comment_offset + 0xcc", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.__comment_length",
 }],

 ["__driveletter_offset", 84, "uint32"],
 ["__driveletter_length", 88, "uint32"],
 ["driveletter", "x=&amp;gt;x.__driveletter_offset + 0xcc", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.__driveletter_length",
 }],

 ["__logon_script_offset", 96, "uint32"],
 ["__logon_script_length", 100, "uint32"],
 ["logon_script", "x=&amp;gt;x.__logon_script_offset + 0xcc", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.__logon_script_length",
 }],

 ["__profile_path_offset", 108, "uint32"],
 ["__profile_path_length", 112, "uint32"],
 ["profile_path", "x=&amp;gt;x.__profile_path_offset + 0xcc", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.__profile_path_length",
 }],

 ["__workstation_offset", 120, "uint32"],
 ["__workstation_length", 124, "uint32"],
 ["workstation", "x=&amp;gt;x.__workstation_offset + 0xcc", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.__workstation_length",
 }],

 ["__lmpwd_hash_offset", 156, "uint32"],
 ["__lmpwd_hash_length", 160, "uint32"],
 ["lmpwd_hash", "x=&amp;gt;x.__lmpwd_hash_offset + 0xcc", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.__lmpwd_hash_length",
 }],

 ["__ntpwd_hash_offset", 168, "uint32"],
 ["__ntpwd_hash_length", 172, "uint32"],
 ["ntpwd_hash", "x=&amp;gt;x.__ntpwd_hash_offset + 0xcc", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.__ntpwd_hash_length",
 }]
 ]]
 ]
 '''

precondition:
 SELECT OS From info() where OS = 'windows'

sources:
 - name: Parsed
 query: |
 SELECT Key.OSPath.Path AS Key,
 Key.OSPath.DelegatePath AS Hive,
 get(field="F") AS _F,
 get(field="V") AS _V,
 get(field="SupplementalCredentials") AS _SupplementalCredentials,
 parse_binary(accessor="data", filename=F,
 profile=Profile, struct="F") AS ParsedF,
 parse_binary(accessor="data", filename=V,
 profile=Profile, struct="V") AS ParsedV
 FROM read_reg_key(
 globs='SAM\\Domains\\Account\\Users\\0*',
 root=pathspec(DelegatePath=SAMPath),
 accessor="raw_reg")
 WHERE _F AND _V

 - name: CreateTimes
 description: "Show the modified times of the \\SAM\\Domains\\Account\\Users\\Names keys"
 query: |
 SELECT Name AS Username, Mtime AS CreatedTime
 FROM glob(globs='SAM\\Domains\\Account\\Users\\Names\\*',
 root=pathspec(DelegatePath=SAMPath),
 accessor="raw_reg")
 WHERE Data.type =~ "Key"

column_types:
 - name: F
 type: hex
 - name: V
 type: hex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.Shellbags</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.shellbags/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.shellbags/</guid><description>&lt;p>Windows uses the Shellbag keys to store user preferences for GUI
folder display within Windows Explorer.&lt;/p>
&lt;p>This artifact uses the raw registry parser to inspect various user
registry hives around the filesystem for BagMRU keys. Different OS
versions may have slightly different locations for the MRU keys.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.Shellbags
description: |
 Windows uses the Shellbag keys to store user preferences for GUI
 folder display within Windows Explorer.

 This artifact uses the raw registry parser to inspect various user
 registry hives around the filesystem for BagMRU keys. Different OS
 versions may have slightly different locations for the MRU keys.

reference:
 - https://www.sans.org/blog/computer-forensic-artifacts-windows-7-shellbags/

parameters:
 - name: SearchSpecs
 type: csv
 description: Define locations of MRU bags in various registries.
 default: |
 HiveGlob,KeyGlob
 C:/Users/*/NTUSER.dat,\Software\Microsoft\Windows\Shell\BagMRU\**
 C:/Users/*/AppData/Local/Microsoft/Windows/UsrClass.dat,\Local Settings\Software\Microsoft\Windows\Shell\BagMRU\**


imports:
 # Link files use the same internal format as shellbags so we import
 # the profile here.
 - Windows.Forensics.Lnk

sources:
 - query: |
 LET AllHives = SELECT *
 FROM foreach(row=SearchSpecs,
 query={
 SELECT OSPath AS HivePath,
 KeyGlob
 FROM glob(globs=HiveGlob)
 WHERE log(message="Inspecting hive %v", args=HivePath)
 })

 -- Form a lookup key based on the hive and the components.
 LET MakeKey(Hive, Components) = regex_replace(
 re="\\\\", replace="/", source=Hive) + join(array=Components, sep="/")

 LET ShellValues &amp;lt;= SELECT
 *, MakeKey(Hive=Hive, Components=Components) AS LookupKey
 FROM foreach(row=AllHives,
 query={
 SELECT OSPath.DelegatePath AS Hive,
 OSPath.Path AS RegValue,
 OSPath.Components AS Components,
 Data.value AS RawData,
 parse_binary(profile=Profile,
 filename=Data.value,
 accessor="data",
 struct="ItemIDList") AS _Parsed,
 ModTime
 FROM glob(root=pathspec(DelegatePath=HivePath),
 globs=KeyGlob,
 accessor="raw_reg")
 WHERE Data.type =~ "BINARY"
 AND OSPath.Basename =~ "^[0-9]+$"
 })

 LET Lookup &amp;lt;= memoize(key="LookupKey", period=10000,
 query={
 SELECT LookupKey,
 _Parsed
 FROM ShellValues
 })

 LET GetRecord(Hive, Components) = get(
 item=Lookup, field=MakeKey(Hive=Hive, Components=Components))

 -- Recursive function to get the parents from the lookup cache.
 LET GetParents(Hive, Components) = SELECT
 LookupKey,
 _Parsed,
 _Parsed.ShellBag.Description.LongName ||
 _Parsed.ShellBag.Description.ShortName || "?" AS Name
 FROM chain(a={
 SELECT *
 FROM foreach(row=GetRecord(Hive=Hive, Components=Components))
 }, b={
 SELECT * FROM if(condition=Components,
 then={
 SELECT * FROM foreach(row=GetParents(Hive=Hive, Components=Components[:-1]))
 })
 })

 -- Shorter keys are higher in the directory heirarchy
 ORDER BY LookupKey

 // Compute the full path to the item by traversing the parents.
 LET GetFullPath(Hive, Components) = join(
 array=GetParents(Hive=Hive, Components=Components).Name, sep=" -&amp;gt; ")

 LET X = SELECT Hive,
 dirname(path=RegValue, path_type="registry") AS KeyPath,
 basename(path=RegValue) AS Slot,
 GetFullPath(Hive=Hive, Components=Components) AS FullPath,
 RawData AS _RawData,
 ModTime,
 get(item=Lookup, field=LookupKey)._Parsed AS _Parsed
 FROM ShellValues

 SELECT *, _Parsed.ShellBag.Description AS Description
 FROM X

column_types:
 - name: _RawData
 type: base64

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.SolarwindsSunburst</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.solarwindssunburst/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.solarwindssunburst/</guid><description>&lt;p>&amp;ldquo;SolarWinds.Orion.Core.BusinessLayer.dll is a SolarWinds digitally-signed component of the Orion software framework that contains a backdoor that communicates via HTTP to third party servers.&amp;rdquo;&lt;/p>
&lt;p>We can look for evidence of this dll by first performing a YARA search on the MFT across all drives, then applying an additional FireEye-supplied rule against the file found via MFT.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.SolarwindsSunburst

description: |
 "SolarWinds.Orion.Core.BusinessLayer.dll is a SolarWinds digitally-signed component of the Orion software framework that contains a backdoor that communicates via HTTP to third party servers."

 We can look for evidence of this dll by first performing a YARA search on the MFT across all drives, then applying an additional FireEye-supplied rule against the file found via MFT.

reference:
 - https://www.fireeye.com/blog/threat-research/2020/12/evasive-attacker-leverages-solarwinds-supply-chain-compromises-with-sunburst-backdoor.html

author: Wes Lambert - @therealwlambert

tools:
 - name: SunburstYARARules
 url: https://raw.githubusercontent.com/fireeye/sunburst_countermeasures/main/all-yara.yar

parameters:
 - name: yaraMFT
 type: yara
 description: "The term we will use to search the MFT"
 default: |
 rule Hit {
 strings:
 $a = "SolarWinds.Orion.Core.BusinessLayer.dll" wide nocase
 condition:
 any of them
 }
 - name: SizeMax
 type: int64
 description: "Entries in the MFT under this size in bytes."
 default: 1200000
 - name: SizeMin
 type: int64
 description: "Entries in the MFT over this size in bytes."
 default: 1000000

sources:
 - query: |
 LET yara_rules &amp;lt;= SELECT read_file(filename=OSPath) AS Rule,
 basename(path=OSPath) AS ToolName
 FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="SunburstYARARules", IsExecutable=FALSE)

 LET ntfs_drives = SELECT OSPath + '/$MFT'as Path, OSPath AS Device
 FROM glob(globs="/*", accessor="ntfs")

 LET MFTEntries = SELECT * from foreach(
 row=ntfs_drives,
 query={ SELECT Device, String.Offset AS Offset,
 String.HexData AS HexData,
 Device + "\\" + parse_ntfs(device=Device,
 mft=String.Offset / 1024).OSPath AS FilePath,
 parse_ntfs(device=Device,
 mft=String.Offset / 1024) AS MFT
 FROM yara(
 rules=yaraMFT, files=Device + "/$MFT",
 end=10000000000,
 number=1000,
 accessor="ntfs")}) WHERE MFT.Size &amp;gt; SizeMin AND MFT.Size &amp;lt; SizeMax

 LET yarasearch = SELECT Rule, String.Offset AS HitOffset,
 str(str=String.Data) AS HitContext,
 FileName,
 File.Size AS Size,
 File.ModTime AS ModTime
 FROM yara(
 rules=yara_rules[0].Rule, key="A",
 files=FilePath)
 LIMIT 1

 LET yarahits = SELECT * FROM if(condition=yara_rules,
 then={
 SELECT *
 FROM foreach(row=MFTEntries,query=yarasearch)
 })

 SELECT *,
 hash(path=FileName) AS Hash
 FROM yarahits

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.SRUM</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.srum/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.srum/</guid><description>&lt;p>Process the SRUM database.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.SRUM
description: |
 Process the SRUM database.

reference:
 - https://www.sans.org/cyber-security-summit/archives/file/summit-archive-1492184583.pdf
 - https://cyberforensicator.com/2017/08/06/windows-srum-forensics/

type: client

parameters:
 - name: SRUMLocation
 default: c:/windows/system32/sru/srudb.dat
 - name: accessor
 default: auto
 - name: ExecutableRegex
 default: .
 - name: NetworkConnectionsGUID
 default: "{DD6636C4-8929-4683-974E-22C046A43763}"
 type: hidden
 - name: ApplicationResourceUsageGUID
 default: "{D10CA2FE-6FCF-4F6D-848E-B2E99266FA89}"
 type: hidden
 - name: ExecutionGUID
 default: "{5C8CF1C7-7257-4F13-B223-970EF5939312}"
 type: hidden
 - name: NetworkUsageGUID
 default: "{973F5D5C-1D90-4944-BE8E-24B94231A174}"
 type: hidden
 - name: Upload
 description: Select to Upload the SRUM database file 'srudb.dat'
 type: bool

export: |
 LET ResolveESEId(OSPath, Accessor, Id) = cache(
 name="ESE",
 func=srum_lookup_id(file=OSPath, accessor=Accessor, id=Id),
 key=format(format="%v-%v-%v", args=[OSPath, Accessor, Id]))

imports:
 - Windows.Sys.AllUsers

sources:
 - name: Upload
 precondition:
 SELECT * FROM scope() WHERE Upload
 query: |
 SELECT upload(file=SRUMLocation, accessor=accessor) AS Upload
 FROM scope()

 - name: Execution Stats
 query: |
 LET SRUMFiles &amp;lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

 SELECT AutoIncId AS ID,
 TimeStamp,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=AppId) AS App,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=UserId) AS UserSid,
 LookupSIDCache(SID=srum_lookup_id(
 file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
 timestamp(winfiletime=EndTime) AS EndTime,
 DurationMS,
 NetworkBytesRaw
 FROM parse_ese(file=SRUMFiles.OSPath,
 accessor=accessor, table=ExecutionGUID)
 WHERE App =~ ExecutableRegex

 - name: Application Resource Usage
 query: |
 LET SRUMFiles &amp;lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

 SELECT AutoIncId as SRUMId,
 TimeStamp,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=AppId) AS App,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=UserId) AS UserSid,
 LookupSIDCache(SID=srum_lookup_id(
 file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
 ForegroundCycleTime,
 BackgroundCycleTime,
 FaceTime,
 ForegroundContextSwitches,
 BackgroundContextSwitches,
 ForegroundBytesRead,
 ForegroundBytesWritten,
 ForegroundNumReadOperations,
 ForegroundNumWriteOperations,
 ForegroundNumberOfFlushes,
 BackgroundBytesRead,
 BackgroundBytesWritten,
 BackgroundNumReadOperations,
 BackgroundNumWriteOperations,
 BackgroundNumberOfFlushes
 FROM parse_ese(file=SRUMFiles.OSPath,
 accessor=accessor, table=ApplicationResourceUsageGUID)
 WHERE App =~ ExecutableRegex

 - name: Network Connections
 query: |
 LET SRUMFiles &amp;lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

 SELECT AutoIncId as SRUMId,
 TimeStamp,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=AppId) AS App,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=UserId) AS UserSid,
 LookupSIDCache(SID=srum_lookup_id(
 file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
 InterfaceLuid,
 ConnectedTime,
 timestamp(winfiletime=ConnectStartTime) AS StartTime
 FROM parse_ese(file=SRUMFiles.OSPath,
 accessor=accessor, table=NetworkConnectionsGUID)
 WHERE App =~ ExecutableRegex

 - name: Network Usage
 query: |
 LET SRUMFiles &amp;lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

 SELECT AutoIncId as SRUMId,
 TimeStamp,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=AppId) AS App,
 ResolveESEId(OSPath=SRUMFiles.OSPath,
 Accessor=accessor, Id=UserId) AS UserSid,
 LookupSIDCache(SID=srum_lookup_id(
 file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
 UserId,
 BytesSent,
 BytesRecvd,
 InterfaceLuid,
 L2ProfileId,
 L2ProfileFlags
 FROM parse_ese(file=SRUMFiles.OSPath,
 accessor=accessor, table=NetworkUsageGUID)
 WHERE App =~ ExecutableRegex

 notebook:
 - type: vql_suggestion
 name: SRUM Network Usage summary
 template: |
 /*
 # SRUM Network Usage summary
 */
 SELECT Fqdn,
 count() as TotalEntries,
 min(item=TimeStamp) as Earliest,
 max(item=TimeStamp) as Latest,
 App,
 User,UserId,
 sum(item=BytesSent) as TotalSent,
 sum(item=BytesRecvd) as TotalRecvd,
 InterfaceLuid
 FROM source(artifact="Windows.Forensics.SRUM/Network Usage")
 GROUP BY App, User,InterfaceLuid
 ORDER BY TotalSent DESC

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.Timeline</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.timeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.timeline/</guid><description>&lt;p>Win10 records recently used applications and files in a “timeline”
accessible via the “WIN+TAB” key. The data is recorded in a SQLite
database.&lt;/p>
&lt;h2 id="notes">NOTES:&lt;/h2>
&lt;p>This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.Timeline
description: |
 Win10 records recently used applications and files in a “timeline”
 accessible via the “WIN+TAB” key. The data is recorded in a SQLite
 database.

 ## NOTES:

 This artifact is deprecated in favor of
 Generic.Forensic.SQLiteHunter and will be removed in future

parameters:
 - name: UserFilter
 default: ""
 description: If specified we filter by this user ID.
 type: regex

 - name: ExecutionTimeAfter
 default: ""
 type: timestamp
 description: If specified only show executions after this time.

 - name: Win10TimelineGlob
 default: C:\Users\*\AppData\Local\ConnectedDevicesPlatform\*\ActivitiesCache.db

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET timeline = SELECT * FROM foreach(
 row={
 SELECT OSPath
 FROM glob(globs=Win10TimelineGlob)
 },
 query={
 SELECT AppId, OSPath, LastModifiedTime
 FROM sqlite(file=OSPath, query="SELECT * FROM Activity")
 })

 LET TMP = SELECT get(
 item=parse_json_array(data=AppId).application,
 member="0") AS Application,
 parse_string_with_regex(
 string=OSPath,
 regex="\\\\L.(?P&amp;lt;User&amp;gt;[^\\\\]+)\\\\").User AS User,
 LastModifiedTime,
 LastModifiedTime.Unix as LastExecutionTS
 FROM timeline

 LET A1 = SELECT * FROM if(
 condition=UserFilter,
 then={
 SELECT * FROM TMP WHERE User =~ UserFilter
 }, else={ SELECT * FROM TMP})

 SELECT * FROM if(
 condition=ExecutionTimeAfter,
 then={
 SELECT * FROM A1 WHERE LastExecutionTS &amp;gt; ExecutionTimeAfter
 }, else={ SELECT * FROM A1})

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.UEFI</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.uefi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.uefi/</guid><description>&lt;p>This artifact enables disk analysis over an EFI System Partition (ESP).&lt;/p>
&lt;p>The artifact queries the specified physical disk, parses the partition table
to targets the ESPs File Allocation Table (FAT).&lt;/p>
&lt;p>The default artifact returns file information and PE enrichment, as typical
EFI files are in the PE format.&lt;/p>
&lt;p>We can look for anomalies in EFI such as:&lt;/p>
&lt;ul>
&lt;li>unexpected time stamps outside install / OS updates&lt;/li>
&lt;li>unexpected paths (EFI/ is typically the root folder on this partition)&lt;/li>
&lt;li>unexpected metadata: signer non-Microsoft or known vendor (note we expect
non-trusted certificates here as the Authenticode API does not service ESP
binaries)&lt;/li>
&lt;/ul>
&lt;p>NOTE: default returns EFI files, rerun with &lt;code>TargetGlob=**/*&lt;/code> glob and
return all files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.UEFI
author: Matt Green - @mgreen27
description: |
 This artifact enables disk analysis over an EFI System Partition (ESP).

 The artifact queries the specified physical disk, parses the partition table
 to targets the ESPs File Allocation Table (FAT).

 The default artifact returns file information and PE enrichment, as typical
 EFI files are in the PE format.

 We can look for anomalies in EFI such as:

 - unexpected time stamps outside install / OS updates
 - unexpected paths (EFI/ is typically the root folder on this partition)
 - unexpected metadata: signer non-Microsoft or known vendor (note we expect
 non-trusted certificates here as the Authenticode API does not service ESP
 binaries)

 NOTE: default returns EFI files, rerun with ```TargetGlob=**/*``` glob and
 return all files.

parameters:
 - name: ImagePath
 default: \\.\PhysicalDrive0
 description: Raw Device for main disk containing partition table to parse.
 - name: SectorSize
 type: int
 default: 512
 - name: TargetGlob
 default: "**/*.efi"
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
- query: |
 LET find_efi = SELECT StartOffset,EndOffset,
 Size AS PartitionSize,
 name AS PartitionName
 FROM Artifact.Windows.Forensics.PartitionTable(
 ImagePath=ImagePath, SectorSize=SectorSize)
 WHERE PartitionName =~ "EFI"

 LET find_files = SELECT * FROM foreach(row=find_efi,
 query={
 SELECT *,
 StartOffset as PartitionOffset,
 PartitionSize,
 PartitionName
 FROM glob(globs=TargetGlob,
 accessor="fat",
 root=pathspec(
 DelegateAccessor="offset",
 DelegatePath=pathspec(
 DelegateAccessor="raw_file",
 DelegatePath=ImagePath,
 Path=format(format="%d", args=StartOffset))))
 })

 SELECT
 dict(
 ImagePath=ImagePath,
 PartitionOffset=PartitionOffset,
 PartitionSize=PartitionSize,
 PartitionName=PartitionName
 ) as Partition,
 OSPath.Path as OSPath,
 Size, Mtime, Atime, Ctime, Btime,
 Data.first_cluster as FirstCluster,
 Data.attr AS Attr,
 Data.deleted as IsDeleted,
 Data.short_name AS ShortName,
 hash(accessor='fat',path=OSPath) as Hash,
 magic(accessor='fat',path=OSPath) as Magic,
 parse_pe(accessor='fat',file=OSPath) as PEInfo,
 authenticode(accessor='fat',filename=OSPath) as Authenticode
 FROM find_files

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.UserAccessLogs</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.useraccesslogs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.useraccesslogs/</guid><description>&lt;p>Parse and collect the SUM database&lt;/p>
&lt;p>UAL is a feature that can help server administrators quantify the number of
unique client requests of roles and services on a local server.&lt;/p>
&lt;p>The UAL only exists on Windows Server edition 2012 and above.&lt;/p>
&lt;p>NOTE: Unlike other tools, Velociraptor DOES NOT use the JET API to access the
database because it has a built-in ESE parser. This means that &lt;strong>you do not
need to repair the files using &lt;code>eseutil.exe&lt;/code>&lt;/strong> even though this is a commonly
recommended step in the references linked below. Velociraptor should have no
trouble parsing these files on a live system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.UserAccessLogs
description: |
 Parse and collect the SUM database

 UAL is a feature that can help server administrators quantify the number of
 unique client requests of roles and services on a local server.

 The UAL only exists on Windows Server edition 2012 and above.

 NOTE: Unlike other tools, Velociraptor DOES NOT use the JET API to access the
 database because it has a built-in ESE parser. This means that **you do not
 need to repair the files using `eseutil.exe`** even though this is a commonly
 recommended step in the references linked below. Velociraptor should have no
 trouble parsing these files on a live system.

reference:
 - https://advisory.kpmg.us/blog/2021/digital-forensics-incident-response.html
 - https://docs.microsoft.com/en-us/windows-server/administration/user-access-logging/manage-user-access-logging
 - https://www.crowdstrike.com/blog/user-access-logging-ual-overview/

export: |
 LET IPProfile = '''[
 ["IP4", 0, [
 ["A", 0, "uint8"],
 ["B", 1, "uint8"],
 ["C", 2, "uint8"],
 ["D", 3, "uint8"],
 ["IP", 0, "Value", {
 value: "x=&amp;gt; format(format='%d.%d.%d.%d', args=[x.A, x.B, x.C, x.D])"
 }]
 ]],
 ["IP6", 0, [
 ["A", 0, "uint16be"],
 ["B", 2, "uint16be"],
 ["C", 4, "uint16be"],
 ["D", 6, "uint16be"],
 ["E", 8, "uint16be"],
 ["F", 10, "uint16be"],
 ["G", 12, "uint16be"],
 ["H", 14, "uint16be"],
 ["IP", 0, "Value", {
 value: "x=&amp;gt; format(format='%04x:%04x:%04x:%04x:%04x:%04x:%04x:%04x', args=[x.A, x.B, x.C, x.D, x.E, x.F, x.G, x.H])"
 }]
 ]]
 ]'''

 -- Format the address - it can be IPv4, IPv6 or something else.
 LET FormatAddress(Address) = if(condition=len(list=Address) = 4,

 -- IPv4 address should be formatted in dot notation
 then=parse_binary(accessor="data",
 filename=Address, struct="IP4",
 profile=IPProfile).IP,

 else=if(condition=len(list=Address)=16,
 -- IPv6 addresses are usually shortened
 then=parse_binary(accessor="data",
 filename=Address, struct="IP6",
 profile=IPProfile).IP,

 -- We don't know what kind of address it is.
 else=format(format="%x", args=Address)))

 -- Get the Clients table from all snapshot files.
 LET SystemIdentity = SELECT OSPath FROM glob(globs=SUMGlob)
 WHERE Name =~ "SystemIdentity.mdb"

 -- Prepare a Role lookup to resolve the role GUID
 LET RoleLookup &amp;lt;= memoize(key="RoleGuid", query={
 SELECT * FROM foreach(row=SystemIdentity, query={
 SELECT * FROM parse_ese(file=OSPath, table="ROLE_IDS")
 WHERE log(message="RoleGuid " + RoleGuid)
 })
 })

parameters:
 - name: SUMGlob
 type: glob
 default: C:/Windows/System32/LogFiles/Sum/*
 description: A glob to file all SUM ESE databases on the system.
 - name: AlsoUpload
 type: bool
 description: If set we also upload the raw files.

sources:
 - name: SystemIdentity
 description: Parse the SystemIdentity database.
 query: |
 SELECT * FROM foreach(row=SystemIdentity, query={
 SELECT *, OSPath AS _OSPath
 FROM parse_ese(file=OSPath, table="SYSTEM_IDENTITY")
 })

 - name: Chained Databases
 query: |
 SELECT * FROM foreach(row=SystemIdentity, query={
 SELECT *, OSPath AS _OSPath
 FROM parse_ese(file=OSPath, table="CHAINED_DATABASES")
 })

 - name: RoleIds
 query: |
 SELECT * FROM foreach(row=SystemIdentity, query={
 SELECT *, OSPath AS _OSPath
 FROM parse_ese(file=OSPath, table="ROLE_IDS")
 })

 - name: Clients
 description: Dump the clients database from all ESE files
 query: |
 LET ContentDatabases = SELECT * FROM glob(globs=SUMGlob)
 WHERE Name =~ ".mdb" AND NOT Name =~ "SystemIdentity"

 -- The clients table has potentially 365 columns (1 per day) so we
 -- format it a bit better by putting the Day* columns in their own dict.
 LET GetClients(OSPath) = SELECT *, OSPath AS _OSPath
 FROM foreach(row={
 SELECT to_dict(item={
 SELECT _key, _value FROM items(item=_value)
 WHERE NOT _key =~ "Day"
 }) +
 dict(Days=to_dict(item={
 SELECT _key, _value FROM items(item=_value)
 WHERE _key =~ "Day"
 })) AS Value
 FROM items(item={
 SELECT *, get(item=RoleLookup, field=RoleGuid).RoleName AS RoleName,
 Address AS RawAddress,
 FormatAddress(Address=unhex(string=Address)) AS Address
 FROM parse_ese(file=OSPath, table="CLIENTS")
 })
 }, column="Value")

 -- Get the Clients table from all snapshot files.
 SELECT * FROM foreach(row=ContentDatabases, query={
 SELECT * FROM GetClients(OSPath=OSPath)
 })

 - name: VIRTUALMACHINES
 query: |
 SELECT * FROM foreach(row=ContentDatabases, query={
 SELECT *, OSPath AS _OSPath
 FROM parse_ese(file=OSPath, table="VIRTUALMACHINES")
 })

 - name: DNS
 query: |
 SELECT * FROM foreach(row=ContentDatabases, query={
 SELECT *, OSPath AS _OSPath
 FROM parse_ese(file=OSPath, table="DNS")
 })

 - name: Uploads
 query: |
 SELECT OSPath, if(condition=AlsoUpload, then=upload(file=OSPath))
 FROM glob(globs=SUMGlob)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Forensics.Usn</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.usn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.forensics.usn/</guid><description>&lt;p>This artifact parses the NTFS USN journal and allows filters to
assist investigative workflow.&lt;/p>
&lt;p>NTFS is a journal filesystem. This means that it maintains a journal
file where intended filesystem changes are written first, then the
filesystem is changed. This journal is called the USN journal in NTFS.&lt;/p>
&lt;p>Velociraptor can parse the USN journal from the filesystem. This
provides an indication of recent file changes. Typically the system
maintains the journal of around 30mb and depending on system
activity this can go back quite some time.&lt;/p>
&lt;p>Use this artifact to determine the times when a file was
modified/added from the journal. This will be present even if the
file was later removed.&lt;/p>
&lt;p>Availible filters are Filename, OSPath, MFT/Parent ID and time bounds.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Forensics.Usn
description: |
 This artifact parses the NTFS USN journal and allows filters to
 assist investigative workflow.

 NTFS is a journal filesystem. This means that it maintains a journal
 file where intended filesystem changes are written first, then the
 filesystem is changed. This journal is called the USN journal in NTFS.

 Velociraptor can parse the USN journal from the filesystem. This
 provides an indication of recent file changes. Typically the system
 maintains the journal of around 30mb and depending on system
 activity this can go back quite some time.

 Use this artifact to determine the times when a file was
 modified/added from the journal. This will be present even if the
 file was later removed.

 Availible filters are Filename, OSPath, MFT/Parent ID and time bounds.

type: CLIENT

parameters:
 - name: Device
 description: The NTFS drive to parse
 default: "C:\\"
 - name: MFTFile
 description: Alternatively provide an MFTFile to use for resolving paths.
 - name: USNFile
 description: Alternatively provide a previously extracted USN file to parse.
 - name: Accessor
 description: The accessor to use.
 - name: AllDrives
 description: Dump USN from all drives and VSC
 type: bool
 - name: FileNameRegex
 description: A regex to match the Filename field.
 default: .
 - name: PathRegex
 description: A regex to match the entire path (you can watch a directory or a file type).
 default: .
 type: regex
 - name: MFT_ID_Regex
 description: A regex to match the MFTId. e.g ^10225$ or ^(10225|232111)$
 default: .
 type: regex
 - name: Parent_MFT_ID_Regex
 description: A regex to match the MFTId. e.g ^10225$ or ^(10225|232111)$
 default: .
 type: regex
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: FastPaths
 type: bool
 description: When set use a faster but less accurate path reassembly algorithm.


sources:
 - precondition:
 SELECT OS From info() where OS =~ 'windows'

 query: |
 -- firstly set timebounds for performance
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

 -- If the user specified an MFTFile then ignore the device
 LET Device &amp;lt;= if(condition=MFTFile OR USNFile, then="",
 else=if(condition=Device,
 then=pathspec(parse=Device, path_type="ntfs")))

 LET Parse(MFT, USN, Accessor) = SELECT *
 FROM parse_usn(accessor=Accessor, fast_paths=FastPaths,
 mft_filename=MFT, usn_filename=USN)
 WHERE Filename =~ FileNameRegex
 AND _FileMFTID =~ MFT_ID_Regex
 AND _ParentMFTID =~ Parent_MFT_ID_Regex
 AND Timestamp &amp;lt; DateBeforeTime
 AND Timestamp &amp;gt; DateAfterTime
 AND _Links =~ PathRegex

 LET all_drives = SELECT * FROM foreach(
 row={
 SELECT OSPath[:1] AS Drive
 FROM glob(globs="/*/$Extend/$UsnJrnl:$J", accessor="ntfs")
 WHERE log(message=format(format="Processing Drive %v", args=Drive))
 }, query={
 SELECT Timestamp,
 Filename,
 Drive + OSPath AS OSPath,
 _Links,
 Reason,
 _FileMFTID as MFTId,
 _FileMFTSequence as Sequence,
 _ParentMFTID as ParentMFTId,
 _ParentMFTSequence as ParentSequence,
 FileAttributes,
 SourceInfo,
 Usn
 FROM Parse(MFT=Drive + "$MFT",
 USN=Drive + "$Extend/$UsnJrnl:$J",
 Accessor="ntfs")
 })

 SELECT *
 FROM if(condition=AllDrives, then=all_drives, else={
 SELECT * FROM if(condition=Device AND
 log(message=format(format="Processing Device %v", args=Device)),
 then={
 SELECT Timestamp,
 Filename,
 Device + OSPath AS OSPath,
 _Links,
 Reason,
 _FileMFTID as MFTId,
 _FileMFTSequence as Sequence,
 _ParentMFTID as ParentMFTId,
 _ParentMFTSequence as ParentSequence,
 FileAttributes,
 SourceInfo,
 Usn
 FROM Parse(MFT=Device + "$MFT",
 USN=Device + "$Extend/$UsnJrnl:$J",
 Accessor="ntfs")

 }, else={
 SELECT Timestamp,
 Filename,
 OSPath,
 _Links,
 Reason,
 _FileMFTID as MFTId,
 _FileMFTSequence as Sequence,
 _ParentMFTID as ParentMFTId,
 _ParentMFTSequence as ParentSequence,
 FileAttributes,
 SourceInfo,
 Usn
 FROM Parse(MFT=MFTFile,
 USN=USNFile, Accessor=Accessor)
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.KapeFiles.Extract</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.kapefiles.extract/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.kapefiles.extract/</guid><description>&lt;p>The Windows.KapeFiles.Targets artifact collects files into a Zip
file. Zip files cannot generally preserve timestamps since they
only have a single timestamp concept. Velociraptor will only record
the modified time in the zip file header itself but all the times
are present in the metadata file:&lt;/p>
&lt;p>&amp;ldquo;Windows.KapeFiles.Targets/All File Metadata.json&amp;rdquo;&lt;/p>
&lt;p>Sometimes, users wish to extract the contents of a collection to a
directory, and run an external tool over the data. Some such
external tools assume the file timestamps (e.g. prefetch files) are
meaningful. In this case we need to preserve the timestamps.&lt;/p>
&lt;p>You can use this artifact to extract the content of a collection
while preserving the timestamps. The artifact will read the metadata
file, unpack the contents of the container and set the timestamps on
the resulting file.&lt;/p>
&lt;p>NOTE: Windows allows 3 timestamps to be set (MAC time except for
Btime), while Linux only allows 2 timestamps (Modified and
Accessed).&lt;/p>
&lt;h2 id="example---command-line-invocation">Example - command line invocation&lt;/h2>
&lt;pre>&lt;code>velociraptor-v0.6.7-linux-amd64 artifacts collect Windows.KapeFiles.Extract --args ContainerPath=Collection-DESKTOP-2OR51GL-2021-07-16_06_56_50_-0700_PDT.zip --args OutputDirectory=/tmp/MyOutput/
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Windows.KapeFiles.Extract
description: |
 The Windows.KapeFiles.Targets artifact collects files into a Zip
 file. Zip files cannot generally preserve timestamps since they
 only have a single timestamp concept. Velociraptor will only record
 the modified time in the zip file header itself but all the times
 are present in the metadata file:

 "Windows.KapeFiles.Targets/All File Metadata.json"

 Sometimes, users wish to extract the contents of a collection to a
 directory, and run an external tool over the data. Some such
 external tools assume the file timestamps (e.g. prefetch files) are
 meaningful. In this case we need to preserve the timestamps.

 You can use this artifact to extract the content of a collection
 while preserving the timestamps. The artifact will read the metadata
 file, unpack the contents of the container and set the timestamps on
 the resulting file.

 NOTE: Windows allows 3 timestamps to be set (MAC time except for
 Btime), while Linux only allows 2 timestamps (Modified and
 Accessed).

 ## Example - command line invocation

 ```
 velociraptor-v0.6.7-linux-amd64 artifacts collect Windows.KapeFiles.Extract --args ContainerPath=Collection-DESKTOP-2OR51GL-2021-07-16_06_56_50_-0700_PDT.zip --args OutputDirectory=/tmp/MyOutput/
 ```

type: SERVER

parameters:
 - name: OutputDirectory
 description: Directory to write on (must be set).
 - name: ContainerPath
 description: Path to container (zip file) to unpack.

sources:
 - query: |
 LET MetadataFile = ("results", "Windows.KapeFiles.Targets/All File Metadata.json")
 LET UploadsFile = "uploads.json"

 // Path to the root of the container
 LET RootPathSpec = pathspec(DelegateAccessor="auto",
 path_type="zip",
 DelegatePath=ContainerPath)

 // The pathspec for where to store the file
 LET OutputPathSpec = pathspec()

 // Memoize the metadata stored in the container file so we can
 // quickly extract the file times.
 LET AllFileMetadata &amp;lt;= memoize(
 key="SourceFile",
 query={
 SELECT *
 FROM parse_jsonl(accessor="collector",
 filename=RootPathSpec + MetadataFile)
 })

 LET ALLUploads = SELECT *, ( RootPathSpec + _Components ).Path AS FileUpload,
 OutputPathSpec + _Components[2:] AS Dest,
 get(item=AllFileMetadata,
 field=vfs_path) AS Metadata
 FROM parse_jsonl(accessor="collector",
 filename=RootPathSpec + UploadsFile)
 WHERE Type != "idx"

 SELECT *, upload_directory(
 accessor="collector",
 output=OutputDirectory,
 mtime=Metadata.Modified,
 atime=Metadata.LastAccessed,
 ctime=Metadata.Created,
 name=Dest,
 file=RootPathSpec + _Components) AS UploadedFile
 FROM ALLUploads

&lt;/code>&lt;/pre></description></item><item><title>Windows.KapeFiles.Remapping</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.kapefiles.remapping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.kapefiles.remapping/</guid><description>&lt;p>This artifact automates the rebuilding of remapping rules to be able to
easily post-process the results of the Windows.KapeFiles.Targets.&lt;/p>
&lt;p>Use as follows in the flow notebook cell of a collection:&lt;/p>
&lt;pre>&lt;code class="language-vql">LET _ &amp;lt;=
 SELECT * FROM Artifact.Windows.KapeFiles.Remapping(ClientId=ClientId, FlowId=FlowId)

SELECT * FROM Artifact.Windows.System.TaskScheduler()
&lt;/code>&lt;/pre>
&lt;p>NOTE: Not all plugins are enabled in this mode for obvious reasons
(e.g. pslist, wmi etc).&lt;/p>
&lt;p>See &lt;a href="https://docs.velociraptor.app/blog/2022/2022-08-04-post-processing/" target="_blank" >https://docs.velociraptor.app/blog/2022/2022-08-04-post-processing/&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.KapeFiles.Remapping
description: |
 This artifact automates the rebuilding of remapping rules to be able to
 easily post-process the results of the Windows.KapeFiles.Targets.

 Use as follows in the flow notebook cell of a collection:

 ```vql
 LET _ &amp;lt;=
 SELECT * FROM Artifact.Windows.KapeFiles.Remapping(ClientId=ClientId, FlowId=FlowId)

 SELECT * FROM Artifact.Windows.System.TaskScheduler()
 ```

 NOTE: Not all plugins are enabled in this mode for obvious reasons
 (e.g. pslist, wmi etc).

 See https://docs.velociraptor.app/blog/2022/2022-08-04-post-processing/

type: CLIENT

parameters:
 - name: ClientId
 description: The ClientID of the collection we need to remap
 - name: FlowId
 description: The FlowID of the collection

export: |
 -- Get the base path of files in the filestore for this client id
 -- and flow id
 LET GetBasePath(FlowId, ClientId) = regex_transform(
 source="/clients/ClientId/collections/FlowId/uploads",
 map=dict(FlowId=FlowId, ClientId=ClientId))

 -- Get the registry mount for the users
 LET HiveMount(BasePath, Target) = regex_transform(source='''
 - type: mount
 from:
 accessor: raw_reg
 prefix: |-
 {
 "Path": "/",
 "DelegateAccessor": "fs",
 "DelegatePath": "BasePath"
 }
 path_type: registry
 "on":
 accessor: registry
 prefix: Target
 path_type: registry
 ''', map=dict(BasePath=BasePath, Target=Target), key=Target)

 -- Map regular files from the fs accessor to the designated accessor
 LET AccessorMount(Accessor, BasePath) = regex_transform(source='''
 - type: mount
 from:
 accessor: fs
 prefix: "BasePath/AccessorName"
 "on":
 accessor: AccessorName
 prefix: ""
 path_type: AccessorName
 ''', map=dict(BasePath=BasePath, AccessorName=Accessor), key=Accessor)

 -- ShadowMount just copy accessors into the new remapped environment.
 LET ShadowMount(Accessor) = regex_transform(source='''
 - type: shadow
 from:
 accessor: AccessorName
 "on":
 accessor: AccessorName
 ''', map=dict(AccessorName=Accessor), key=Accessor)

 -- Common mounts that are used in all cases.
 LET CommonMount = '''remappings:
 - type: permissions
 permissions:
 - COLLECT_CLIENT
 - FILESYSTEM_READ
 - FILESYSTEM_WRITE
 - READ_RESULTS
 - MACHINE_STATE
 - SERVER_ADMIN
 - type: impersonation
 os: windows
 hostname: Virtual Host
 env:
 - key: SystemRoot
 value: C:\Windows
 - key: WinDir
 value: C:\Windows
 disabled_functions:
 - amsi
 - lookupSID
 - token
 disabled_plugins:
 - users
 - certificates
 - handles
 - pslist
 - interfaces
 - modules
 - netstat
 - partitions
 - proc_dump
 - proc_yara
 - vad
 - winobj
 - wmi
 '''

 -- Build remapping parts by searching for registry hives to mount.
 LET Parts(BasePath) = SELECT * FROM chain(
 a={

 -- Mount all ntuser.dat hives that were fetched. Username is
 -- taken to be containing directory.
 SELECT OSPath,
 HiveMount(BasePath=OSPath.String,
 Target="HKEY_USERS/" + OSPath[-2]) AS Mount
 FROM glob(globs="*/C:/Users/*/ntuser.dat", accessor="fs", root=BasePath)
 WHERE NOT OSPath.Basename =~ "idx$"

 }, b={
 -- Mount the main system registry hives
 SELECT OSPath,
 HiveMount(BasePath=OSPath.String,
 Target="HKEY_LOCAL_MACHINE/" + OSPath[-1]) AS Mount
 FROM glob(globs="*/C:/Windows/System32/Config/{SOFTWARE,SYSTEM}",
 accessor="fs", root=BasePath)
 WHERE NOT OSPath.Basename =~ "idx$"

 }, e={
 SELECT ShadowMount(Accessor=_value) AS Mount
 FROM foreach(row=["raw_reg", "zip", "data", "scope", "gzip"])
 })

 -- Mount all files to be accessible by auto, ntfs and file accessor.
 LET GetRemappingByBase(BasePath) = join(array=CommonMount +
 AccessorMount(BasePath=BasePath, Accessor="auto") +
 AccessorMount(BasePath=BasePath, Accessor="ntfs") +
 AccessorMount(BasePath=BasePath, Accessor="file") +
 Parts(BasePath=BasePath).Mount, sep="")

 LET GetRemapping(FlowId, ClientId) = GetRemappingByBase(
 BasePath=GetBasePath(FlowId=FlowId, ClientId=ClientId))

sources:
 - query: |
 SELECT remap(clear=TRUE, config=GetRemapping) AS Remapping
 FROM scope()

&lt;/code>&lt;/pre></description></item><item><title>Windows.Memory.Acquisition</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.memory.acquisition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.memory.acquisition/</guid><description>&lt;p>Acquires a full memory image by using the built-in WinPmem driver.&lt;/p>
&lt;p>NOTE: This artifact usually transfers a lot of data. You should
increase the default timeout to allow it to complete.&lt;/p>
&lt;p>Memory images are typically susceptible to a lot of smear. To
minimize this we need to acquire memory as quickly as possible. This
artifact offers a few compression methods for the output
file. Reducing the size of the file will decrease time needed for IO
but will increase CPU requirements so this is a
trade-off. Empirically we found that using S2 compression gives a
reasonable compression and very high speed reducing acquisition time
from the no compression options significantly.&lt;/p>
&lt;p>To decompress the image you can use the &lt;a href="https://github.com/Velocidex/WinPmem/releases/download/v4.0.rc1/go-winpmem_amd64_1.0-rc1.exe" target="_blank" >Go WinPmem binary&lt;/a>
&lt;/p>
&lt;pre>&lt;code>go-winpmem.exe expand image.compressed image.raw
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Memory.Acquisition
description: |
 Acquires a full memory image by using the built-in WinPmem driver.

 NOTE: This artifact usually transfers a lot of data. You should
 increase the default timeout to allow it to complete.

 Memory images are typically susceptible to a lot of smear. To
 minimize this we need to acquire memory as quickly as possible. This
 artifact offers a few compression methods for the output
 file. Reducing the size of the file will decrease time needed for IO
 but will increase CPU requirements so this is a
 trade-off. Empirically we found that using S2 compression gives a
 reasonable compression and very high speed reducing acquisition time
 from the no compression options significantly.

 To decompress the image you can use the [Go WinPmem binary](https://github.com/Velocidex/WinPmem/releases/download/v4.0.rc1/go-winpmem_amd64_1.0-rc1.exe)

 ```
 go-winpmem.exe expand image.compressed image.raw
 ```

implied_permissions:
 - FILESYSTEM_WRITE

precondition: |
 SELECT OS FROM info()
 WHERE OS = 'windows'
 AND Architecture = "amd64"
 AND version(function='winpmem') &amp;gt;= 0

parameters:
 - name: ServiceName
 description: Override the name of the driver service to install.
 - name: DriverPath
 description: Where to unpack the driver before loading it.
 default: C:\Windows\Temp\winpmem.sys
 - name: Compression
 default: None
 type: choices
 description: Type of compression to use (Recommended None, S2 or Snappy).
 choices:
 - None
 - S2
 - Snappy
 - Gzip

sources:
 - query: |
 LET Tempfile &amp;lt;= tempfile(extension=".pmem")

 LET ImageInfo &amp;lt;= winpmem(
 driver_path=DriverPath,
 service=ServiceName,
 image_path=Tempfile,
 compression=Compression)

 SELECT ImageInfo, upload(file=Tempfile, name="PhysicalMemory.dd") AS Upload
 FROM stat(filename=Tempfile)
 WHERE log(message="Uploading %v bytes", args=Size)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Memory.Intezer</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.memory.intezer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.memory.intezer/</guid><description>&lt;p>Runs an Intezer agent scan on the endpoint.&lt;/p>
&lt;ul>
&lt;li>Scan: The scanner collects running code from memory and sends it to Intezer Analyze.
Scans take approximately five to ten minutes. The first scan may take additional time.&lt;/li>
&lt;/ul>
&lt;p>Please note: The scanner only collects executable code, not documents or any other
data that is not binary code.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Analyze: The collected modules are analyzed using Genetic Malware Analysis technology.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>View results: &lt;a href="https://analyze.intezer.com/" target="_blank" >https://analyze.intezer.com/&lt;/a>
 endpoint analysis report.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Memory.Intezer
description: |
 Runs an Intezer agent scan on the endpoint.

 - Scan: The scanner collects running code from memory and sends it to Intezer Analyze.
 Scans take approximately five to ten minutes. The first scan may take additional time.

 Please note: The scanner only collects executable code, not documents or any other
 data that is not binary code.

 - Analyze: The collected modules are analyzed using Genetic Malware Analysis technology.

 - View results: https://analyze.intezer.com/ endpoint analysis report.

author: Matt Green - @mgreen27

required_permissions:
 - EXECVE

tools:
 - name: Intezer
 url: https://analyze.intezer.com/api/scans/download

type: CLIENT

parameters:
 - name: ApiKey
 description: Intezer API key to scan with
 default:

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- first get context on target binary
 LET bin &amp;lt;= SELECT *
 FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="Intezer")

 -- execute payload
 SELECT * FROM execve(argv=[ bin.OSPath[0], '-k', ApiKey ])

&lt;/code>&lt;/pre></description></item><item><title>Windows.Memory.PEDump</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.memory.pedump/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.memory.pedump/</guid><description>&lt;p>This artifact dumps a PE file from memory and uploads the file to
the server.&lt;/p>
&lt;p>NOTE: The output is not exactly the same as the original binary:&lt;/p>
&lt;ol>
&lt;li>Relocations are not fixed&lt;/li>
&lt;li>Due to ASLR the base address of the binary will not be the same as the original.&lt;/li>
&lt;/ol>
&lt;p>The result is usually much better than the binaries dumped from a
physical memory image (using e.g. Volatility) because reading
process memory will page in any memory-mapped pages as we copy them
out. Therefore we do not expect to have holes in the produced binary
as is often the case in memory analysis.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Memory.PEDump
description: |
 This artifact dumps a PE file from memory and uploads the file to
 the server.

 NOTE: The output is not exactly the same as the original binary:
 1. Relocations are not fixed
 2. Due to ASLR the base address of the binary will not be the same as the original.

 The result is usually much better than the binaries dumped from a
 physical memory image (using e.g. Volatility) because reading
 process memory will page in any memory-mapped pages as we copy them
 out. Therefore we do not expect to have holes in the produced binary
 as is often the case in memory analysis.

parameters:
 - name: Pid
 type: int
 description: The pid to dump
 - name: BaseOffset
 type: int
 description: |
 The base offset to dump from memory. If not provided, we dump
 all pe files from the PID.
 - name: FilenameRegex
 default: .+exe$
 description: Applies to the PE mapping filename to upload

sources:
 - query: |
 LET GetFilename(MappingName, BaseOffset) = if(
 condition=MappingName,
 then=format(format="dump_%#x_%s", args=[BaseOffset, basename(path=MappingName)]),
 else=format(format="dump_%#x", args=BaseOffset))

 SELECT format(format="%#x", args=Address) AS Address, Size, MappingName,
 State, Type, Protection, ProtectionMsg, read_file(
 accessor="process",
 filename=format(format="/%d", args=Pid),
 offset=Address,
 length=10) AS Header,
 upload(file=pe_dump(pid=Pid, base_offset=Address),
 name=GetFilename(MappingName=MappingName, BaseOffset=Address)) AS Upload
 FROM vad(pid=Pid)
 WHERE Header =~ "^MZ" AND MappingName =~ FilenameRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Memory.ProcessDump</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.memory.processdump/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.memory.processdump/</guid><description>&lt;p>Dump process memory and upload to the server.&lt;/p>
&lt;p>Previously named Windows.Triage.ProcessMemory&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Memory.ProcessDump
description: |
 Dump process memory and upload to the server.

 Previously named Windows.Triage.ProcessMemory

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: ProcessRegex
 default: notepad
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: VelociraptorCompatible
 type: bool
 description: |
 If specified we upload a Velociraptor Compatible sparse file
 upload instead of a crash dump. This makes it easier to run
 post-processing using Velociraptor

sources:
 - query: |
 LET processes = SELECT Name as ProcessName, CommandLine, Pid
 FROM pslist()
 WHERE Name =~ ProcessRegex
 AND str(str=Pid) =~ PidRegex

 LET Regions(Pid) = SELECT dict(Offset=Address, Length=Size) AS Sparse
 FROM vad(pid=Pid)
 WHERE Protection =~ "r"

 LET UploadDump(Pid, ProcessName, CommandLine) =
 SELECT * FROM if(condition= VelociraptorCompatible,
 then={
 SELECT ProcessName, CommandLine, Pid,
 upload(accessor="sparse",
 file=pathspec(
 Path=serialize(item=Regions(Pid=Pid).Sparse),
 DelegateAccessor="process",
 DelegatePath=format(format="/%d", args=Pid)),
 name=pathspec(Path=format(format="%d.dd", args=Pid))) AS ProcessMemory
 FROM scope()
 }, else={
 SELECT ProcessName, CommandLine, Pid, OSPath,
 upload(file=OSPath) as CrashDump
 FROM proc_dump(pid=Pid)
 })

 SELECT * FROM foreach(
 row=processes,
 query={
 SELECT * FROM UploadDump(Pid=Pid, ProcessName = ProcessName, CommandLine = CommandLine)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Memory.ProcessInfo</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.memory.processinfo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.memory.processinfo/</guid><description>&lt;p>This artifact returns process information obtained by parsing the PEB directly.&lt;/p>
&lt;p>Renamed Windows.Forensics.ProcessInfo&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Memory.ProcessInfo
description: |
 This artifact returns process information obtained by parsing the PEB directly.

 Renamed Windows.Forensics.ProcessInfo

parameters:
 - name: ProcessNameRegex
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: ImagePathRegex
 default: .
 type: regex
 - name: CommandLineRegex
 default: .
 type: regex

sources:
- query: |
 LET profile = '''[
 ["PEB",0 , [
 # https://docs.microsoft.com/en-us/windows/win32/api/winternl/ns-winternl-peb
 ["ProcessParameters", 32, "Pointer", {
 "type": "ProcessParameters",
 }],
 ]],
 ["ProcessParameters", 0, [
 ["ImagePathName", 96, "UNICODE_STRING"],
 ["CommandLine", 112, "UNICODE_STRING"],
 ["CurrentDirectory", 56, "CURDIR"],
 ["EnvironmentSize", 1008, "uint64"],
 ["Environment", 128, "Pointer", {
 "type": "String",
 "type_options": {
 "length": "x=&amp;gt;x.EnvironmentSize",
 "encoding": "utf16",
 "max_length": 10000,
 "term": "",
 }}]
 ]],
 ["CURDIR", 0, [
 ["DosPath", 0, "UNICODE_STRING"],
 ]],
 ["UNICODE_STRING", 16, [
 ["Length", 0, "uint16"],
 ["Buffer", 8, "Pointer", {
 "type": "String",
 "type_options": {
 "encoding": "utf16",
 "length": "x=&amp;gt;x.Length",
 "term": "",
 }}],
 ]]
 ]'''

 LET ParsePeb(PID) = SELECT Name,
 format(format="%0#x", args=PebBaseAddress) AS PebBaseAddress, Pid,
 parse_binary(accessor="process",
 filename=format(format="/%v", args=PID),
 profile=profile,
 struct="PEB",
 offset=PebBaseAddress) AS Data
 FROM pslist(pid=PID)

 -- The Environment string consists of null terminated
 -- lines. Each line contains the variable name followed by an =
 -- sign and then the variable value.
 LET SplitEnv(EnvString) = SELECT parse_string_with_regex(
 string=_value, regex="^(?P&amp;lt;Name&amp;gt;[^=]*)=(?P&amp;lt;Value&amp;gt;.+)") AS Line
 FROM foreach(row=split(string=EnvString, sep="\x00"))
 WHERE Line

 -- Massage the parsed data into a structured table
 LET Calculate(PID) = SELECT Name, PebBaseAddress, Pid,
 Data.ProcessParameters.ImagePathName.Buffer AS ImagePathName,
 Data.ProcessParameters.CommandLine.Buffer AS CommandLine,
 Data.ProcessParameters.CurrentDirectory.DosPath.Buffer AS CurrentDirectory,
 -- Build an Env dict out of the parsed string.
 to_dict(item={
 SELECT Line.Name AS _key, Line.Value AS _value
 FROM SplitEnv(EnvString=Data.ProcessParameters.Environment)
 }) AS Env
 FROM ParsePeb(PID=PID)

 SELECT * FROM foreach(row={
 SELECT Pid FROM pslist()
 WHERE Name =~ ProcessNameRegex
 AND str(str=Pid) =~ PidRegex
 AND str(str=ImagePathName) =~ ImagePathRegex
 AND str(str=CommandLine) =~ CommandLineRegex
 }, query={
 SELECT * FROM Calculate(PID=Pid)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Network.ArpCache</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.network.arpcache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.network.arpcache/</guid><description>&lt;p>Address resolution cache, both static and dynamic (from ARP, NDP).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Network.ArpCache
description: Address resolution cache, both static and dynamic (from ARP, NDP).
parameters:
 - name: wmiQuery
 default: |
 SELECT AddressFamily, Store, State, InterfaceIndex, IPAddress,
 InterfaceAlias, LinkLayerAddress
 from MSFT_NetNeighbor
 - name: wmiNamespace
 default: ROOT\StandardCimv2

 - name: kMapOfState
 default: |
 {
 "0": "Unreachable",
 "1": "Incomplete",
 "2": "Probe",
 "3": "Delay",
 "4": "Stale",
 "5": "Reachable",
 "6": "Permanent",
 "7": "TBD"
 }

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 LET interfaces &amp;lt;=
 SELECT Index, HardwareAddr, IP
 FROM Artifact.Windows.Network.InterfaceAddresses()

 LET arp_cache = SELECT if(condition=AddressFamily=23,
 then="IPv6",
 else=if(condition=AddressFamily=2,
 then="IPv4",
 else=AddressFamily)) as AddressFamily,

 if(condition=Store=0,
 then="Persistent",
 else=if(condition=(Store=1),
 then="Active",
 else="?")) as Store,

 get(item=parse_json(data=kMapOfState),
 member=encode(string=State, type='string')) AS State,
 InterfaceIndex, IPAddress,
 InterfaceAlias, LinkLayerAddress
 FROM wmi(query=wmiQuery, namespace=wmiNamespace)

 SELECT * FROM foreach(
 row=arp_cache,
 query={
 SELECT AddressFamily, Store, State, InterfaceIndex,
 IP AS LocalAddress, HardwareAddr, IPAddress as RemoteAddress,
 InterfaceAlias, LinkLayerAddress AS RemoteMACAddress
 FROM interfaces
 WHERE InterfaceIndex = Index
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Network.InterfaceAddresses</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.network.interfaceaddresses/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.network.interfaceaddresses/</guid><description>&lt;p>Network interfaces and relevant metadata. This artifact works on all
supported OSs.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Generic.Network.InterfaceAddresses
description: |
 Network interfaces and relevant metadata. This artifact works on all
 supported OSs.

aliases:
 - Windows.Network.InterfaceAddresses

sources:
 - query: |
 LET interface_address =
 SELECT Index, MTU, Name,
 HardwareAddr.String AS HardwareAddr,
 Flags, Addrs
 from interfaces()

 SELECT Index, MTU, Name, HardwareAddr,
 Flags, Addrs.IP as IP, Addrs.Mask.String as Mask
 FROM flatten(query=interface_address)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Network.ListeningPorts</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.network.listeningports/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.network.listeningports/</guid><description>&lt;p>Processes with listening (bound) network sockets/ports.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Network.ListeningPorts
description: Processes with listening (bound) network sockets/ports.
sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 LET process &amp;lt;= SELECT Name, Pid from pslist()

 SELECT * from foreach(
 row={
 SELECT Pid AS PortPid, Laddr.Port AS Port,
 TypeString as Protocol, FamilyString as Family,
 Laddr.IP as Address
 FROM netstat() where Status = 'LISTEN'
 },
 query={
 SELECT Pid, Name, Port, Protocol, Family, Address
 FROM process where Pid = PortPid
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Network.Netstat</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.network.netstat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.network.netstat/</guid><description>&lt;p>Show information about open sockets. On windows the time when the
socket was first bound is also shown.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Network.Netstat
description: |
 Show information about open sockets. On windows the time when the
 socket was first bound is also shown.

sources:
- precondition: SELECT OS From info() where OS = 'windows'
 query: |
 LET processes &amp;lt;= SELECT Name, Pid AS ProcPid FROM pslist()
 SELECT Pid, {
 SELECT Name from processes
 WHERE Pid = ProcPid
 } AS Name, FamilyString as Family,
 TypeString as Type,
 Status,
 Laddr.IP, Laddr.Port,
 Raddr.IP, Raddr.Port,
 Timestamp
 FROM netstat()

&lt;/code>&lt;/pre></description></item><item><title>Windows.Network.NetstatEnriched</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.network.netstatenriched/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.network.netstatenriched/</guid><description>&lt;p>NetstatEnhanced adds additional data points to the Netstat artifact and
enables verbose search options.&lt;/p>
&lt;p>Examples include: Process name and path, Authenticode information or
network connection details.&lt;/p>
&lt;p>WARNING:
KillProcess - attempts to use Taskill to kill the processes returned.
DumpProcess - dumps the process as a sparse file for post-processing.&lt;/p>
&lt;p>Please only use these switches after scoping as there are no guardrails on
shooting yourself in the foot.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Network.NetstatEnriched
author: "Matt Green - @mgreen27"
description: |
 NetstatEnhanced adds additional data points to the Netstat artifact and
 enables verbose search options.

 Examples include: Process name and path, Authenticode information or
 network connection details.

 WARNING:
 KillProcess - attempts to use Taskill to kill the processes returned.
 DumpProcess - dumps the process as a sparse file for post-processing.

 Please only use these switches after scoping as there are no guardrails on
 shooting yourself in the foot.

required_permissions:
 - EXECVE

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: IPRegex
 description: "regex search over IP address fields."
 default: .
 type: regex
 - name: PortRegex
 description: "regex search over port fields."
 default: .
 type: regex
 - name: Family
 description: "IP version family selection"
 type: choices
 default: ALL
 choices:
 - ALL
 - IPv4
 - IPv6
 - name: FamilyMap
 type: hidden
 default: |
 Choice,Regex
 ALL,"."
 IPv4,"^IPv4$"
 IPv6,"^IPv6$"

 - name: Type
 description: "Transport protocol type selection"
 type: choices
 default: ALL
 choices:
 - ALL
 - TCP
 - UDP
 - name: TypeMap
 type: hidden
 default: |
 Choice,Regex
 ALL,"."
 TCP,"^TCP$"
 UDP,"^UDP$"

 - name: Status
 description: "TCP status selection"
 type: choices
 default: ALL
 choices:
 - ALL
 - ESTABLISHED
 - LISTENING
 - OTHER
 - name: StatusMap
 type: hidden
 default: |
 Choice,Regex
 ALL,"."
 ESTABLISHED,"^ESTAB$"
 LISTENING,"^LISTEN$"
 OTHER,"CLOS|SENT|RCVD|LAST|WAIT|DELETE"

 - name: ProcessNameRegex
 description: "regex search over source process name"
 default: ^(malware\.exe|.*)$
 type: regex
 - name: ProcessPathRegex
 description: "regex search over source process path"
 default: .
 type: regex
 - name: CommandLineRegex
 description: "regex search over source process commandline"
 default: .
 type: regex
 - name: HashRegex
 description: "regex search over source process hash"
 default: .
 type: regex
 - name: UsernameRegex
 description: "regex search over source process user context"
 default: .
 type: regex
 - name: AuthenticodeSubjectRegex
 description: "regex search over source Authenticode Subject"
 default: .
 type: regex
 - name: AuthenticodeIssuerRegex
 description: "regex search over source Authenticode Issuer"
 default: .
 type: regex
 - name: AuthenticodeVerified
 description: "Authenticode signiture selection"
 type: choices
 default: ALL
 choices:
 - ALL
 - TRUSTED
 - UNSIGNED
 - NOT TRUSTED
 - name: AuthenticodeVerifiedMap
 type: hidden
 default: |
 Choice,Regex
 ALL,"."
 TRUSTED,"^trusted$"
 UNSIGNED,"^unsigned$"
 NOT TRUSTED,"unsigned|disallowed|untrusted|error"
 - name: DumpProcess
 description: "WARNING: If selected will attempt to dump process from all results."
 type: bool
 - name: KillProcess
 description: "WARNING: If selected will attempt to kill process from all results."
 type: bool
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
 - name: Netstat
 query: |
 LET VerifiedRegex &amp;lt;= SELECT Regex
 FROM parse_csv(filename=AuthenticodeVerifiedMap, accessor="data")
 WHERE Choice=AuthenticodeVerified LIMIT 1
 LET StatusRegex &amp;lt;= SELECT Regex
 FROM parse_csv(filename=StatusMap, accessor="data")
 WHERE Choice=Status LIMIT 1
 LET FamilyRegex &amp;lt;= SELECT Regex
 FROM parse_csv(filename=FamilyMap, accessor="data")
 WHERE Choice=Family LIMIT 1
 LET TypeRegex &amp;lt;= SELECT Regex
 FROM parse_csv(filename=TypeMap, accessor="data")
 WHERE Choice=Type LIMIT 1

 LET process &amp;lt;= SELECT Pid as PsId,
 Ppid,
 Name,
 CommandLine,
 Exe,
 Hash,
 Authenticode,
 Username
 FROM Artifact.Windows.System.Pslist(
 DISABLE_DANGEROUS_API_CALLS=DISABLE_DANGEROUS_API_CALLS)
 WHERE Name =~ ProcessNameRegex
 AND Exe =~ ProcessPathRegex
 AND CommandLine =~ CommandLineRegex

 LET results = SELECT Pid,
 { SELECT Ppid FROM process WHERE PsId = Pid } as Ppid,
 { SELECT Name FROM process WHERE PsId = Pid } as Name,
 { SELECT Exe FROM process WHERE PsId = Pid } as Path,
 { SELECT CommandLine FROM process WHERE PsId = Pid } as CommandLine,
 { SELECT Hash FROM process WHERE PsId = Pid } as Hash,
 { SELECT Username FROM process WHERE PsId = Pid } as Username,
 { SELECT Authenticode FROM process WHERE PsId = Pid } as Authenticode,
 FamilyString as Family,
 TypeString as Type,
 Status,
 Laddr.IP as Laddr,
 Laddr.Port as Lport,
 Raddr.IP as Raddr,
 Raddr.Port as Rport,
 Timestamp
 FROM netstat()
 WHERE
 Name =~ ProcessNameRegex
 AND Path =~ ProcessPathRegex
 and CommandLine =~ CommandLineRegex
 and Username =~ UsernameRegex
 and ( Hash.MD5 =~ HashRegex
 or Hash.SHA1 =~ HashRegex
 or Hash.SHA256 =~ HashRegex
 or not Hash )
 and ( Authenticode.IssuerName =~ AuthenticodeIssuerRegex or not Authenticode )
 and ( Authenticode.SubjectName =~ AuthenticodeSubjectRegex or not Authenticode )
 and ( Authenticode.Trusted =~ VerifiedRegex.Regex[0] or not Authenticode )
 and Status =~ StatusRegex.Regex[0]
 and Family =~ FamilyRegex.Regex[0]
 and Type =~ TypeRegex.Regex[0]
 and ( format(format="%v", args=Laddr) =~ IPRegex
 or format(format="%v", args=Raddr) =~ IPRegex )
 and ( format(format="%v", args=Lport) =~ PortRegex
 or format(format="%v", args=Rport) =~ PortRegex )

 LET Regions(Pid) = SELECT dict(Offset=Address, Length=Size) AS Sparse
 FROM vad(pid=Pid)
 WHERE Protection =~ "r"
 LET dump = SELECT *,
 upload(accessor="sparse",
 file=pathspec(
 Path=serialize(item=Regions(Pid=Pid).Sparse),
 DelegateAccessor="process",
 DelegatePath=format(format="/%d", args=Pid)),
 name=pathspec(Path=format(format="%d.dd", args=Pid))) AS ProcessMemory
 FROM results
 LET kill = SELECT *, pskill(pid=Pid) AS KillProcess
 FROM results
 LET dumpandkill = SELECT *, pskill(pid=Pid) AS KillProcess
 FROM dump

 SELECT * FROM switch(
 a = {
 SELECT *, if(condition= KillProcess=Null,then='Success',else=KillProcess) AS KillProcess
 FROM if(condition= DumpProcess AND KillProcess, then= dumpandkill )},
 b = { SELECT * FROM if(condition= DumpProcess, then= dump )},
 c = {
 SELECT *, if(condition= KillProcess=Null,then='Success',else=KillProcess) AS KillProcess
 FROM if(condition= KillProcess, then= kill)
 },
 catch = results
 )

&lt;/code>&lt;/pre></description></item><item><title>Windows.Network.PacketCapture</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.network.packetcapture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.network.packetcapture/</guid><description>&lt;p>Run this artifact twice, the first time, set the StartTrace flag to
True to start the PCAP collection, this will have the VQL return a
single row (the TraceFile generated) When you want to stop
collecting, and transform this TraceFile to a PCAP, re-run this
artifact with StartTrace as false, and put path of the .etl file
created in the previous step in the TraceFile. This will then
convert the .etl to a PCAP and upload it.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Network.PacketCapture
author: Cybereason &amp;lt;omer.yampel@cybereason.com&amp;gt;
description: |
 Run this artifact twice, the first time, set the StartTrace flag to
 True to start the PCAP collection, this will have the VQL return a
 single row (the TraceFile generated) When you want to stop
 collecting, and transform this TraceFile to a PCAP, re-run this
 artifact with StartTrace as false, and put path of the .etl file
 created in the previous step in the TraceFile. This will then
 convert the .etl to a PCAP and upload it.

precondition: SELECT OS From info() where OS = 'windows'

tools:
 - name: etl2pcapng
 url: https://github.com/microsoft/etl2pcapng/releases/download/v1.4.0/etl2pcapng.zip

implied_permissions:
 - FILESYSTEM_WRITE
 - EXECVE

parameters:
 - name: StartTrace
 type: bool
 default: Y
 - name: TraceFile
 type: string
 default:

sources:
 - query: |
 LET tool_zip = SELECT * FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="etl2pcapng", IsExecutable=FALSE)

 LET ExePath &amp;lt;= tempfile(extension='.exe')

 LET etl2pcapbin &amp;lt;= SELECT
 copy(
 filename=pathspec(
 DelegatePath=tool_zip[0].OSPath,
 Path="etl2pcapng/x64/etl2pcapng.exe"),
 dest=ExePath,
 accessor='zip'
 ) AS file
 FROM scope()

 LET outfile &amp;lt;= tempfile(extension=".pcapng")

 LET stop_trace = SELECT * FROM execve(
 argv=['netsh', 'trace', 'stop'])

 LET convert_pcap = SELECT * FROM execve(
 argv=[etl2pcapbin[0].file, TraceFile, outfile])

 LET end_trace = SELECT * FROM chain(
 a=stop_trace,
 b=convert_pcap,
 c={SELECT upload(file=outfile) AS Upload FROM scope()},
 d={SELECT upload(file=TraceFile) AS Upload FROM scope()}
 )

 LET launch_trace =
 SELECT
 split(string=split(
 string=Stdout,
 sep="Trace File: ")[1],
 sep="\r\nAppend:")[0] as etl_file
 FROM execve(argv=["netsh", "trace", "start", "capture=yes"])
 WHERE log(message="stderr: " + Stderr), log(message="stdout: " + Stdout)

 SELECT * FROM if(
 condition=StartTrace,
 then={ SELECT * FROM launch_trace},
 else={ SELECT * FROM end_trace }
 )

&lt;/code>&lt;/pre></description></item><item><title>Windows.NTFS.ADSHunter</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.adshunter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.adshunter/</guid><description>&lt;p>This artifact hunts
for Alternate Data Streams on NTFS file systems.
Adversaries may use NTFS file attributes for covert storage to evade
detection.
Alternate Data Streams (ADS) are additional $DATA attributes for an MFT entry in
NTFS file systems. In NTFS, the primary $DATA attribute is
never named but subsequent $DATA attributes must be named.&lt;/p>
&lt;p>Targeting is via mix of path globs and include / exclude regex.&lt;/p>
&lt;ul>
&lt;li>TargetGlob is a glob to target for ADS. NOTE *** is recursive. To hit C drive we need to search for C:*&lt;/li>
&lt;li>AdsName is name in glob format: e.g &lt;em>, Zone.Identifier or Zone.&lt;/em>.&lt;/li>
&lt;li>AdsNameExclusion - A regex value, common ADS added to exclusions have been
added by default. The artifact also excludes NTFS system files by default.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.NTFS.ADSHunter
author: "Matt Green - @mgreen27"
description: |
 This artifact hunts
 for Alternate Data Streams on NTFS file systems.
 Adversaries may use NTFS file attributes for covert storage to evade
 detection.
 Alternate Data Streams (ADS) are additional $DATA attributes for an MFT entry in
 NTFS file systems. In NTFS, the primary $DATA attribute is
 never named but subsequent $DATA attributes must be named.

 Targeting is via mix of path globs and include / exclude regex.

 - TargetGlob is a glob to target for ADS. NOTE **\* is recursive. To hit C drive we need to search for C:\*
 - AdsName is name in glob format: e.g *, Zone.Identifier or Zone.*.
 - AdsNameExclusion - A regex value, common ADS added to exclusions have been
 added by default. The artifact also excludes NTFS system files by default.

reference:
 - https://attack.mitre.org/techniques/T1564/004/

type: CLIENT

parameters:
 - name: TargetGlob
 description: A Glob to search for target files. **\* is recursive. To hit C drive we need to search for C:\*
 default: C:\{*,**\*}
 - name: AdsNameGlob
 description: AdsName in glob format. e.g *, Zone.Identifier or Zone.*
 default: '*'
 - name: AdsNameExclusion
 description: Regex of ADS name to exclude.
 default: 'SmartScreen|WofCompressedData|encryptable|favicon|AFP_AfpInfo|OECustomProperty|Win32App_1|com\.dropbox|icasource|\{\w{8}-\w{4}-\w{4}-\w{4}-\w{12}\}\.(MetaData|SyncRootIdentity)'
 type: regex
 - name: AdsContentRegex
 description: ADS content to search for by regex.
 default: .
 type: regex
 - name: AdsContentExclusion
 description: ADS content to exclude by regex.
 type: regex
 - name: MinSize
 description: Optional - only include alternate data streams above this size in bytes.
 type: int
 - name: MaxSize
 description: Optional - only include alternate data streams below this size in bytes.
 type: int
 - name: UploadDataStream
 description: If selected wil upload non-resident data streams.
 type: bool

sources:
 - query: |
 -- Collect ADS entries using glob but exclude ntfs objects that contain ads
 LET ads_entries = SELECT OSPath,
 split(string=Name,sep=':')[1] as AdsName,
 Data.mft as Inode,
 Size,
 OSPath.Dirname + split(string=Name,sep=':')[0] as HostObject,
 dict(Mtime=Mtime,Atime=Atime,Ctime=Ctime,Btime=Btime) as HostTimestampsSI
 FROM glob(globs=TargetGlob + ":" + AdsNameGlob,
 accessor="ntfs",
 nosymlink='Y')
 WHERE
 NOT OSPath =~ '''[a-z]:\\(\$Extend\\|\$Secure|\$UpCase|\$BadClus|\$Bitmap|\$Repair)'''
 AND if(condition=MinSize,
 then= Size &amp;gt; MinSize,
 else= True )
 AND if(condition= MaxSize,
 then= Size &amp;lt; MaxSize,
 else= True )
 AND NOT if(condition=AdsNameExclusion,
 then= AdsName =~ AdsNameExclusion,
 else= False )

 -- Extract content and filter
 LET hits = SELECT *,
 read_file(filename=OSPath[0]+Inode, accessor="mft",offset=0,length=1024) as AdsContent -- only upload first 1k of each hit
 FROM ads_entries
 WHERE AdsContent =~ AdsContentRegex
 AND NOT if(condition=AdsContentExclusion,
 then= AdsContent =~ AdsContentExclusion,
 else= False )

 -- upload hits
 LET upload_hits = SELECT *,
 upload(file=OSPath,accessor='ntfs') as Upload
 FROM hits

 -- output rows
 SELECT * FROM if(condition=UploadDataStream,
 then= upload_hits,
 else= hits)
&lt;/code>&lt;/pre></description></item><item><title>Windows.NTFS.ExtendedAttributes</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.extendedattributes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.extendedattributes/</guid><description>&lt;p>Adversaries may use NTFS file attributes for defense evasion to hide malicious
data. This artifact parses NTFS Extended attributes ($EA).
The artifact firstly queries the MFT, then enriches NTFS data to check for
Extended Attributes. Several filters can be applied such as file search,
Extended Attribute size, name or content.&lt;/p>
&lt;p>NOTE:
By default an EAName exclusion has been applied to filter some common $EA names
found on Windows System. Recommended hunt would be by rare name or $EA size.
By default we only parse $EA and discard $EA_INFORMATION. $EA_INFORMATION
typically is very small and available in NtfsMetadata field of output.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.NTFS.ExtendedAttributes
author: "Matt Green - @mgreen27"
description: |
 Adversaries may use NTFS file attributes for defense evasion to hide malicious
 data. This artifact parses NTFS Extended attributes ($EA).
 The artifact firstly queries the MFT, then enriches NTFS data to check for
 Extended Attributes. Several filters can be applied such as file search,
 Extended Attribute size, name or content.

 NOTE:
 By default an EAName exclusion has been applied to filter some common $EA names
 found on Windows System. Recommended hunt would be by rare name or $EA size.
 By default we only parse $EA and discard $EA_INFORMATION. $EA_INFORMATION
 typically is very small and available in NtfsMetadata field of output.


reference:
 - https://attack.mitre.org/techniques/T1564/004/
 - https://posts.specterops.io/host-based-threat-modeling-indicator-design-a9dbbb53d5ea
 - http://inform.pucp.edu.pe/~inf232/Ntfs/ntfs_doc_v0.5/attributes/ea.html

parameters:
 - name: MFTDrive
 default: "C:"
 - name: HostPathRegex
 description: "Regex search over OSPath."
 default: "."
 type: regex
 - name: DateAfter
 type: timestamp
 description: "search for host files with timestamps after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for host files with timestamps before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: AllDrives
 type: bool
 description: "Select MFT search on all attached ntfs drives."
 - name: EANameRegex
 description: "$EA Name regex filter to include in results."
 default: .
 type: regex
 - name: EANameExclusion
 description: Regex of ADS name to exclude.
 default: ^(\$KERNEL\.PURGE\.(ESBCACHE|APPXFICACHE)|\$CI\.CATALOGHINT|\w{8}-\w{4}-\w{4}-\w{4}-\w{12}\.CSC\.\w+)$
 type: regex
 - name: EAContentRegex
 description: "$EA content to search for by regex."
 default: .
 type: regex
 - name: SizeMax
 type: int64
 description: "Total $EA attributes in the MFT under this size in bytes."
 default: 100000
 - name: SizeMin
 type: int64
 description: "Total $EA attributes in the MFT over this size in bytes."
 default: 0
 - name: UploadHits
 type: bool
 description: "Upload complete complete attribute data."

sources:
 - query: |
 LET Profile = '''[
 ["EAData", 0, [
 ["Entries", 0, "Array",{
 "type": "EA",
 "count": 99 }],
 ]],
 ["EA", "x=&amp;gt;x.__NextOffset", [
 ["__NextOffset", 0, "uint32"],
 ["__NameLength", 5, "uint8"],
 ["__ValueLength", 6, "uint16"],
 ["Name", 8, String, {
 length: "x=&amp;gt;x.__NameLength" }],
 ["Flags", 4, "uint8"],
 ["ValueLength", 6, "uint16"],
 ["Value", "x=&amp;gt;9 + x.__NameLength", "String",{
 term: "********** NO TERM **********",
 length: "x=&amp;gt;x.__ValueLength",
 max_length: 10000 }],
 ]]
 ]'''

 -- find all MFT entries with an $EA - ignore VSS
 LET mft_entries = SELECT *,
 parse_ntfs(mft=EntryNumber, device=MFTDrive ) as NtfsMetadata
 FROM Artifact.Windows.NTFS.MFT(
 MFTDrive=MFTDrive,
 Accessor='ntfs',
 PathRegex=HostPathRegex,
 DateAfter=DateAfter,
 DateBefore=DateBefore,
 AllDrives=AllDrives)
 WHERE -- NOT OSPath =~ 'HarddiskVolumeShadowCopy' AND
 NtfsMetadata.Attributes.Type =~ '^\\$EA'

 -- enrich results for size filter, dropping metadata field output as this attribute is viewable in Ntfs field.
 LET enriched_results = SELECT OSPath,NtfsMetadata,
 --{ SELECT * FROM NtfsMetadata.Attributes WHERE Type = '$EA_INFORMATION'} as _EA_INFORMATION_Metadata,
 { SELECT * FROM NtfsMetadata.Attributes WHERE Type = '$EA'} as _EA_Metadata
 FROM mft_entries
 WHERE _EA_Metadata.Size &amp;gt; SizeMin AND _EA_Metadata.Size &amp;lt; SizeMax

 -- parse EA attribute
 LET parse_ea = SELECT OSPath, NtfsMetadata, _EA_Metadata,
 parse_binary(accessor="mft",
 filename=NtfsMetadata.Device + _EA_Metadata.Inode,
 profile=Profile, struct="EAData").Entries AS EA
 FROM enriched_results

 -- flattern results and output a row for each EA parsed
 LET flatten_results = SELECT OSPath, NtfsMetadata, EA, _EA_Metadata
 FROM flatten(
 query={
 SELECT *
 {
 SELECT Name,Value,Flags,ValueLength
 FROM foreach(row=EA)
 } as EA
 FROM parse_ea
 WHERE EA.Name =~ EANameRegex
 AND NOT if(condition=EANameExclusion,
 then= EA.Name =~ EANameExclusion,
 else= False )
 AND EA.Value =~ EAContentRegex
 })

 -- upload extended EA data
 LET upload_hits=SELECT OSPath, NtfsMetadata, EA,
 upload(file=NtfsMetadata.Device + _EA_Metadata.Inode,accessor='mft') AS Upload
 --upload(file=Ntfs.Device + _EA_INFORMATION_Metadata.Inode,accessor='mft') AS EA_INFORMATION_Upload
 FROM flatten_results

 -- return rows
 SELECT *
 FROM if(condition=UploadHits,
 then=upload_hits,
 else=flatten_results)

&lt;/code>&lt;/pre></description></item><item><title>Windows.NTFS.I30</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.i30/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.i30/</guid><description>&lt;p>Carve the $I30 index stream for a directory.&lt;/p>
&lt;p>This can reveal previously deleted files. Optionally upload the I30
stream to the server as well.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.NTFS.I30
description: |
 Carve the $I30 index stream for a directory.

 This can reveal previously deleted files. Optionally upload the I30
 stream to the server as well.

parameters:
 - name: DirectoryGlobs
 default: C:\Users\*

 - name: SlackOnly
 description: "Select to return only entries from Slack space."
 type: bool

 - name: AlsoUpload
 description: Select to also upload the raw $I30 stream.
 type: bool

sources:
 - name: UploadI30Streams
 precondition:
 SELECT * FROM info() where OS = 'windows' AND AlsoUpload

 query: |
 LET inodes = SELECT OSPath, Data.mft AS MFT,
 parse_ntfs(device=OSPath, inode=Data.mft) AS MFTInfo
 FROM glob(globs=DirectoryGlobs, accessor="ntfs")
 WHERE IsDir

 LET upload_streams = SELECT * FROM foreach(
 row=MFTInfo.Attributes,
 query={
 SELECT _value.Type AS Type,
 _value.TypeId AS TypeId,
 _value.Id AS Id,
 _value.Inode AS Inode,
 _value.Size AS Size,
 _value.Name AS Name,
 _value.OSPath AS OSPath,
 upload(accessor="mft",
 file=MFTInfo.Device + _value.Inode,
 name=pathspec(Path=_value.OSPath + "/" + _value.Inode)) AS IndexUpload
 FROM scope()
 WHERE Type =~ "INDEX_"
 })

 SELECT * FROM foreach(row=inodes, query=upload_streams)

 - name: AnalyzeI30
 precondition:
 SELECT * FROM info() where OS = 'windows'

 query: |
 LET inodes = SELECT OSPath, Data.mft AS MFT,
 parse_ntfs(device=OSPath, inode=Data.mft) AS MFTInfo
 FROM glob(globs=DirectoryGlobs, accessor="ntfs")
 WHERE IsDir

 SELECT * FROM foreach(
 row=inodes,
 query={
 SELECT OSPath, Name, NameType, Size, AllocatedSize,
 IsSlack, SlackOffset, Mtime, Atime, Ctime, Btime, MFTId
 FROM parse_ntfs_i30(device=MFTInfo.Device, inode=MFT)
 WHERE IsSlack = true or NOT SlackOnly
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.NTFS.MFT</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.mft/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.mft/</guid><description>&lt;p>Parses $MFT files and returns rows of each in scope MFT record.&lt;/p>
&lt;p>This artifact can be used as the basis for other artifacts where the MFT needs
to be queried or for deleted file recovery.&lt;/p>
&lt;p>For deleted file recovery: Take the MFT ID of a file of interest and provide
it to the Windows.NTFS.Recover artifact.&lt;/p>
&lt;p>To query all attached NTFS drives: select the AllDrives option.&lt;/p>
&lt;p>I have added several filters to uplift search capabilities from the original
MFT artifact. Due to the multi-drive features, the MFTPath will output the MFT
path of the entry.&lt;/p>
&lt;p>Available filters include:&lt;/p>
&lt;ul>
&lt;li>PathRegex (OSPath): e.g &lt;code>^C:\\folder\\file\.ext$&lt;/code> or partial &lt;code>\\folder\\folder2\\&lt;/code> or &lt;code>string|string2|string3&lt;/code>&lt;/li>
&lt;li>Fileregex: &lt;code>^filename.ext$&lt;/code> or partial &lt;code>string1|string2&lt;/code>&lt;/li>
&lt;li>Time bounds to select files with a timestamp within time ranges&lt;/li>
&lt;li>FileSize bounds&lt;/li>
&lt;li>MFTDrive: drive to target collection and show as source in results during offline processing.&lt;/li>
&lt;li>MFTPath: optional filter for offline MFT processing.&lt;/li>
&lt;/ul>
&lt;h4 id="notes">NOTES&lt;/h4>
&lt;ul>
&lt;li>It is generally more efficient to filter on filename.&lt;/li>
&lt;li>Multiple filters are cumulative.&lt;/li>
&lt;li>OSPath output now uses expected Windows backslash &amp;ldquo;&lt;code>\&lt;/code>&amp;rdquo;.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.NTFS.MFT
author: "Matt Green - @mgreen27"
description: |
 Parses $MFT files and returns rows of each in scope MFT record.

 This artifact can be used as the basis for other artifacts where the MFT needs
 to be queried or for deleted file recovery.

 For deleted file recovery: Take the MFT ID of a file of interest and provide
 it to the Windows.NTFS.Recover artifact.

 To query all attached NTFS drives: select the AllDrives option.

 I have added several filters to uplift search capabilities from the original
 MFT artifact. Due to the multi-drive features, the MFTPath will output the MFT
 path of the entry.

 Available filters include:

 - PathRegex (OSPath): e.g `^C:\\folder\\file\.ext$` or partial `\\folder\\folder2\\` or `string|string2|string3`
 - Fileregex: `^filename.ext$` or partial `string1|string2`
 - Time bounds to select files with a timestamp within time ranges
 - FileSize bounds
 - MFTDrive: drive to target collection and show as source in results during offline processing.
 - MFTPath: optional filter for offline MFT processing.

 #### NOTES

 - It is generally more efficient to filter on filename.
 - Multiple filters are cumulative.
 - OSPath output now uses expected Windows backslash "`\`".

parameters:
 - name: MFTDrive
 description: |
 The path to to the drive that holds the MFT file (can be a pathspec). This
 drive is also used for results for offline processing.
 default: "C:"
 - name: MFTPath
 description: Optional path to MFT file for offline processing.
 default:
 - name: Accessor
 default: ntfs
 - name: AllNtfs
 type: bool
 description: "Return all NTFS metadata with results."
 - name: PathRegex
 description: "Regex search over OSPath."
 default: "."
 type: regex
 - name: FileRegex
 description: "Regex search over File Name"
 default: "."
 type: regex
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: SizeMax
 type: int64
 description: "Entries in the MFT under this size in bytes."
 - name: SizeMin
 type: int64
 description: "Entries in the MFT over this size in bytes."
 - name: AllDrives
 type: bool
 description: "Select MFT search on all attached ntfs drives."
 - name: NTFS_INCLUDE_SHORT_NAMES
 description: See all names referencing the file including short names.
 type: bool

sources:
 - query: |
 -- Cater for older clients which do not have the Links column.
 LET parse_mft_version(filename, accessor, prefix) = SELECT *
 FROM if(condition=version(plugin="parse_mft") &amp;gt; 1,
 then={ SELECT *
 FROM parse_mft(
 filename=filename, accessor=accessor, prefix=prefix)
 },

 -- Older versions do not have the prefix parameter in
 -- the plugin and need the prefix prepended to the
 -- OSPath
 else={ SELECT *,
 prefix + OSPath AS Links,
 prefix + OSPath AS OSPath
 FROM parse_mft(
 filename=filename, accessor=accessor)
 })

 -- The path to to the drive that holds the MFT file (can be a pathspec)
 LET Drive &amp;lt;= pathspec(parse=MFTDrive, path_type="ntfs")

 -- time testing
 LET time_test(stamp) =
 if(condition= DateBefore AND DateAfter,
 then= stamp &amp;lt; DateBefore AND stamp &amp;gt; DateAfter,
 else=
 if(condition=DateBefore,
 then= stamp &amp;lt; DateBefore,
 else=
 if(condition= DateAfter,
 then= stamp &amp;gt; DateAfter,
 else= True
 )))

 -- find all ntfs drives
 LET ntfs_drives = SELECT
 OSPath AS Drive,
 OSPath + '$MFT' AS MFTFilename
 FROM glob(globs="/*", accessor="ntfs")
 WHERE log(message="Processing " + MFTFilename)

 -- function returning MFT entries
 -- Only check the filename - should be very quick
 LET mftsearch_with_filename(Drive, MFTPath) =
 SELECT EntryNumber, InUse, ParentEntryNumber,
 OSPath,
 Links AS _Links,
 FileName, FileSize, ReferenceCount, IsDir,
 Created0x10, Created0x30,
 LastModified0x10, LastModified0x30,
 LastRecordChange0x10, LastRecordChange0x30,
 LastAccess0x10,LastAccess0x30,
 HasADS, SI_Lt_FN, USecZeros, Copied,
 FileNames, FileNameTypes
 FROM parse_mft_version(filename=MFTPath,
 accessor=Accessor, prefix=Drive)
 WHERE FileName =~ FileRegex
 AND Links =~ PathRegex

 -- Check only one date bound
 LET mftsearch_after_date(Drive, MFTPath) =
 SELECT
 EntryNumber, InUse, ParentEntryNumber,
 OSPath,
 Links AS _Links,
 FileName, FileSize, ReferenceCount, IsDir,
 Created0x10, Created0x30,
 LastModified0x10, LastModified0x30,
 LastRecordChange0x10, LastRecordChange0x30,
 LastAccess0x10,LastAccess0x30,
 HasADS, SI_Lt_FN, USecZeros, Copied,
 FileNames, FileNameTypes
 FROM parse_mft_version(filename=MFTPath,
 accessor=Accessor, prefix=Drive)
 WHERE
 ( Created0x10 &amp;gt; DateAfter
 OR Created0x30 &amp;gt; DateAfter
 OR LastModified0x10 &amp;gt; DateAfter
 OR LastModified0x30 &amp;gt; DateAfter
 OR LastRecordChange0x10 &amp;gt; DateAfter
 OR LastRecordChange0x30 &amp;gt; DateAfter)
 AND FileName =~ FileRegex
 AND Links =~ PathRegex

 LET mftsearch_before_date(Drive, MFTPath) =
 SELECT EntryNumber, InUse, ParentEntryNumber,
 OSPath,
 Links AS _Links,
 FileName, FileSize, ReferenceCount, IsDir,
 Created0x10, Created0x30,
 LastModified0x10, LastModified0x30,
 LastRecordChange0x10, LastRecordChange0x30,
 LastAccess0x10,LastAccess0x30,
 HasADS, SI_Lt_FN, USecZeros, Copied,
 FileNames, FileNameTypes
 FROM parse_mft_version(filename=MFTPath,
 accessor=Accessor, prefix=Drive)
 WHERE
 ( Created0x10 &amp;lt; DateBefore
 OR Created0x30 &amp;lt; DateBefore
 OR LastModified0x10 &amp;lt; DateBefore
 OR LastModified0x30 &amp;lt; DateBefore
 OR LastRecordChange0x10 &amp;lt; DateBefore
 OR LastRecordChange0x30 &amp;lt; DateBefore)
 AND FileName =~ FileRegex
 AND Links =~ PathRegex

 -- Check everything can be slow.
 LET mftsearch_full(Drive, MFTPath) =
 SELECT EntryNumber, InUse, ParentEntryNumber,
 OSPath,
 Links AS _Links,
 FileName, FileSize, ReferenceCount, IsDir,
 Created0x10, Created0x30,
 LastModified0x10, LastModified0x30,
 LastRecordChange0x10, LastRecordChange0x30,
 LastAccess0x10,LastAccess0x30,
 HasADS, SI_Lt_FN, USecZeros, Copied,
 FileNames, FileNameTypes
 FROM parse_mft_version(filename=MFTPath,
 accessor=Accessor, prefix=Drive)
 WHERE FileName =~ FileRegex
 AND Links =~ PathRegex
 AND if(condition=SizeMax,
 then=FileSize &amp;lt; atoi(string=SizeMax),
 else=TRUE)
 AND if(condition=SizeMin,
 then=FileSize &amp;gt; atoi(string=SizeMin),
 else=TRUE)
 AND
 ( time_test(stamp=Created0x10)
 OR time_test(stamp=Created0x30)
 OR time_test(stamp=LastModified0x10)
 OR time_test(stamp=LastModified0x30)
 OR time_test(stamp=LastRecordChange0x10)
 OR time_test(stamp=LastRecordChange0x30)
 OR time_test(stamp=LastAccess0x10)
 OR time_test(stamp=LastAccess0x30))

 -- Choose a query to run depending on the user's choices.
 LET mftsearch(Drive, MFTPath) = SELECT * FROM if(
 -- only need to do a filename comparison
 condition=NOT DateAfter AND NOT DateBefore AND NOT SizeMin AND NOT SizeMax,
 then={ SELECT *
 FROM mftsearch_with_filename(Drive=Drive, MFTPath=MFTPath) },
 else={ SELECT * FROM if(

 -- Only DateAfter is set
 condition=NOT DateBefore AND NOT SizeMin AND NOT SizeMax,
 then={ SELECT *
 FROM mftsearch_after_date(Drive=Drive, MFTPath=MFTPath)},
 else={ SELECT * FROM if(

 -- Only Date Before is set
 condition=NOT DateAfter AND NOT SizeMin AND NOT SizeMax,
 then={ SELECT *
 FROM mftsearch_before_date(Drive=Drive, MFTPath=MFTPath)},
 else={ SELECT *
 FROM mftsearch_full(Drive=Drive, MFTPath=MFTPath)})
 })
 })

 -- include all attached drives
 LET all_drives = SELECT * FROM foreach(row={
 SELECT * FROM ntfs_drives
 },
 query={
 SELECT *, Drive
 FROM mftsearch(
 Drive=Drive,
 MFTPath=MFTFilename)
 })

 -- return results
 LET results = SELECT *
 FROM if(condition=AllDrives,
 then={
 SELECT * FROM all_drives
 },
 else={
 SELECT * FROM mftsearch(Drive=Drive,
 MFTPath=if(condition= MFTPath ,
 then= MFTPath,
 else= Drive + "$MFT"))
 })
 -- enrich results with NtfsMetadata is requests
 LET enriched_results = SELECT *,
 parse_ntfs(mft=EntryNumber, device=Drive ) as NtfsMetadata
 FROM results

 -- return rows
 SELECT * FROM if(condition=AllNtfs,
 then= enriched_results,
 else= results)

&lt;/code>&lt;/pre></description></item><item><title>Windows.NTFS.Recover</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.recover/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.ntfs.recover/</guid><description>&lt;p>Attempt to recover deleted files.&lt;/p>
&lt;p>This artifact uploads all streams from an MFTId. If the MFT entry is not
allocated there is a chance that the cluster that contains the actual data of
the file will still be intact on the disk. Therefore it may be possible to
recover such deleted files, which is what this artifact attempts to do.&lt;/p>
&lt;p>A common use is to recover deleted directory entries using the
&lt;code>Windows.NTFS.I30&lt;/code> artifact to identify MFT entries of interest. This artifact
can then be used to attempt recovery of the file data.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.NTFS.Recover
description: |
 Attempt to recover deleted files.

 This artifact uploads all streams from an MFTId. If the MFT entry is not
 allocated there is a chance that the cluster that contains the actual data of
 the file will still be intact on the disk. Therefore it may be possible to
 recover such deleted files, which is what this artifact attempts to do.

 A common use is to recover deleted directory entries using the
 `Windows.NTFS.I30` artifact to identify MFT entries of interest. This artifact
 can then be used to attempt recovery of the file data.

parameters:
 - name: MFTId
 default: "81978"
 - name: Drive
 default: '\\.\C:'

precondition:
 SELECT * FROM info() where OS = 'windows'

sources:
 - name: Upload
 query: |
 LET Parsed &amp;lt;= parse_ntfs(device=Drive, inode=MFTId)

 SELECT *, upload(accessor="mft", file=Drive + Inode,
 name=Parsed.OSPath + Inode) AS IndexUpload
 FROM foreach(
 row=Parsed.Attributes,
 query={
 SELECT _value.Type AS Type,
 _value.TypeId AS TypeId,
 _value.Id AS Id,
 _value.Inode AS Inode,
 _value.Size AS Size,
 _value.Name AS Name
 FROM scope()
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.OSQuery.Generic</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.osquery.generic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.osquery.generic/</guid><description>&lt;p>OSQuery is an excellent tool for querying system state across the
three supported Velociraptor platform (Windows/Linux/MacOS).&lt;/p>
&lt;p>You can read more about OSQuery on &lt;a href="https://osquery.io/" target="_blank" >https://osquery.io/&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.OSQuery.Generic
description: |
 OSQuery is an excellent tool for querying system state across the
 three supported Velociraptor platform (Windows/Linux/MacOS).

 You can read more about OSQuery on https://osquery.io/

reference:
 - https://osquery.io/
 - https://github.com/osquery/osquery

# I am not actually sure if OSQuery allows arbitrary command execution via SQL?
required_permissions:
 - EXECVE

precondition: SELECT OS From info() where OS = 'windows'

tools:
 - name: OSQueryWindows
 github_project: Velocidex/OSQuery-Releases
 github_asset_regex: windows-amd64.exe

parameters:
 - name: Query
 default: "SELECT * FROM osquery_info"

sources:
 - query: |
 LET binary &amp;lt;= SELECT OSPath
 FROM Artifact.Generic.Utils.FetchBinary(ToolName="OSQueryWindows")

 LET result = SELECT * FROM execve(
 argv=[binary[0].OSPath, "--json", Query],
 length=1000000)

 SELECT * FROM foreach(row=result,
 query={
 SELECT * FROM parse_json_array(data=Stdout)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Packs.LateralMovement</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.packs.lateralmovement/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.packs.lateralmovement/</guid><description>&lt;p>Detect evidence of lateral movement.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Packs.LateralMovement
description: |
 Detect evidence of lateral movement.

precondition: SELECT OS From info() where OS = 'windows'

reference:
 - https://digital-forensics.sans.org/media/SANS_Poster_2018_Hunt_Evil_FINAL.pdf

sources:
 - name: AlternateLogon
 query: |
 SELECT * FROM Artifact.Windows.EventLogs.AlternateLogon()

 - name: WMIC
 query: |
 SELECT * FROM Artifact.Windows.Forensics.Prefetch()
 WHERE Executable =~ "wmic.exe"
 - name: ShimCache
 query: |
 SELECT * FROM Artifact.Windows.Registry.AppCompatCache()
 WHERE Name =~ "wmic.exe"
 - name: BAM
 query: |
 SELECT * FROM Artifact.Windows.Forensics.Bam()
 WHERE Binary =~ "wmic.exe"
 - name: AmCache
 query: |
 SELECT * FROM Artifact.Windows.System.Amcache()
 WHERE Binary =~ "wmic.exe"

&lt;/code>&lt;/pre></description></item><item><title>Windows.Packs.Persistence</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.packs.persistence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.packs.persistence/</guid><description>&lt;p>This artifact pack collects various persistence mechanisms in Windows.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Packs.Persistence
description: |
 This artifact pack collects various persistence mechanisms in Windows.

precondition:
 SELECT OS from info() where OS = "windows"

sources:
 - name: WMI Event Filters
 query: |
 SELECT * FROM Artifact.Windows.Persistence.PermanentWMIEvents()

 - name: Startup Items
 query: |
 SELECT * FROM Artifact.Windows.Sys.StartupItems()

 - name: Debug Bootstraping
 query: |
 SELECT * FROM Artifact.Windows.Persistence.Debug()

&lt;/code>&lt;/pre></description></item><item><title>Windows.Persistence.Debug</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.debug/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.debug/</guid><description>&lt;p>Windows allows specific configuration of various executables via a
registry key. Some keys allow defining a debugger to attach to a
program as it is run. If this debugger is launched for commonly used
programs (e.g. notepad) then another program can be launched at the
same time (with the same privileges).&lt;/p>
&lt;p>There is an additional key for x86 executables &lt;code>HKEY_LOCAL_MACHINE\ SOFTWARE\wow6432node\Microsoft\Windows NT\CurrentVersion\Image File Execution Options\*&lt;/code> however this is kept inline with the x64 key and
therefore does not need to be processed.&lt;/p>
&lt;p>Limitations: This queries the live registry and therefore does not
parse data in Windows.old or Regback folders, or VSS.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Persistence.Debug
description: |
 Windows allows specific configuration of various executables via a
 registry key. Some keys allow defining a debugger to attach to a
 program as it is run. If this debugger is launched for commonly used
 programs (e.g. notepad) then another program can be launched at the
 same time (with the same privileges).

 There is an additional key for x86 executables `HKEY_LOCAL_MACHINE\
 SOFTWARE\wow6432node\Microsoft\Windows NT\CurrentVersion\Image File
 Execution Options\*` however this is kept inline with the x64 key and
 therefore does not need to be processed.

 Limitations: This queries the live registry and therefore does not
 parse data in Windows.old or Regback folders, or VSS.

reference:
 - https://attack.mitre.org/techniques/T1183/

parameters:
 - name: imageFileExecutionOptions
 default: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options\*

sources:
 - query: |
 LET X = scope()
 SELECT Key.ModTime as KeyLastWriteTimestamp,
 Key.OSPath as _Key,
 Key.Name AS Program,
 X.Debugger AS Debugger
 FROM read_reg_key(globs=imageFileExecutionOptions)
 WHERE Debugger
 Order By KeyLastWriteTimestamp

&lt;/code>&lt;/pre></description></item><item><title>Windows.Persistence.PermanentWMIEvents</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.permanentwmievents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.permanentwmievents/</guid><description>&lt;p>This artifact reports currently deployed permanent WMI Event Consumers. The
artifact collects Binding information, then presents associated Filters
and Consumers.&lt;/p>
&lt;p>NOTE: the artifact does not report on individual eventing classes. A separate
wmi query will need to be made for unlinked components that may reside in the
WMI datastore.&lt;/p>
&lt;p>WMI Eventing components:&lt;/p>
&lt;ul>
&lt;li>__FilterToConsumerBinding - ties together Filter + Consumer&lt;/li>
&lt;li>__EventFilter - trigger condition&lt;/li>
&lt;li>__EventConsumer - payload&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Persistence.PermanentWMIEvents
author: Matt Green - @mgreen27
description: |
 This artifact reports currently deployed permanent WMI Event Consumers. The
 artifact collects Binding information, then presents associated Filters
 and Consumers.

 NOTE: the artifact does not report on individual eventing classes. A separate
 wmi query will need to be made for unlinked components that may reside in the
 WMI datastore.

 WMI Eventing components:

 - __FilterToConsumerBinding - ties together Filter + Consumer
 - __EventFilter - trigger condition
 - __EventConsumer - payload

reference:
 - https://attack.mitre.org/techniques/T1546/003/

parameters:
 - name: AllRootNamespaces
 description: Select to scan all ROOT namespaces. This setting over rides specific namespaces configured below.
 type: bool
 - name: Namespaces
 description: Add a list of target namespaces.
 type: csv
 default: |
 namespace
 root/subscription
 root/default

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET namespaces &amp;lt;= SELECT * FROM if(condition=AllRootNamespaces,
 then= {
 SELECT 'root/' + Name as namespace
 FROM wmi(namespace='ROOT',query='SELECT * FROM __namespace' )
 WHERE namespace
 },
 else= Namespaces )

 LET FilterToConsumerBinding &amp;lt;= SELECT * FROM foreach(
 row=namespaces,
 query={
 SELECT parse_string_with_regex(string=Consumer,
 regex=['((?P&amp;lt;namespace&amp;gt;^[^:]+):)?(?P&amp;lt;Type&amp;gt;.+?)\\.Name="(?P&amp;lt;Name&amp;gt;.+)"']) as Consumer,
 parse_string_with_regex(string=Filter,regex=['((?P&amp;lt;namespace&amp;gt;^[^:]+):)?(?P&amp;lt;Type&amp;gt;.+?)\\.Name="(?P&amp;lt;Name&amp;gt;.+)"']) as Filter
 FROM wmi(
 query="SELECT * FROM __FilterToConsumerBinding",namespace=namespace)
 },workers=len(list=namespaces))

 SELECT * FROM foreach(
 row=namespaces,
 query={
 SELECT {
 SELECT * FROM wmi(
 query="SELECT * FROM " + Consumer.Type,
 namespace=if(condition=Consumer.namespace,
 then=Consumer.namespace,
 else=namespace)) WHERE Name = Consumer.Name
 } AS ConsumerDetails,
 {
 SELECT * FROM wmi(
 query="SELECT * FROM " + Filter.Type,
 namespace=if(condition=Filter.namespace,
 then=Filter.namespace,
 else=namespace)) WHERE Name = Filter.Name
 } AS FilterDetails,
 namespace as Namespace
 FROM FilterToConsumerBinding
 WHERE (FilterDetails OR ConsumerDetails)
 },workers=len(list=namespaces))
&lt;/code>&lt;/pre></description></item><item><title>Windows.Persistence.PowershellProfile</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.powershellprofile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.powershellprofile/</guid><description>&lt;p>This Artifact will search and parse PowerShell profile scripts.&lt;/p>
&lt;p>PowerShell supports several profiles depending on the user or host program.
Adversaries may create or modify these profiles to include arbitrary commands,
functions, modules, and/or PowerShell drives to gain persistence. When a
backdoored PowerShell session is opened the modified script will be executed
unless the -NoProfile flag is used when it is launched.&lt;/p>
&lt;p>The artifact will by default search both User profiles and System-wide
configured profiles. The user can also target and exclude specific content
with relevant regex filters.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Persistence.PowershellProfile
author: Matt Green - @mgreen27
description: |
 This Artifact will search and parse PowerShell profile scripts.

 PowerShell supports several profiles depending on the user or host program.
 Adversaries may create or modify these profiles to include arbitrary commands,
 functions, modules, and/or PowerShell drives to gain persistence. When a
 backdoored PowerShell session is opened the modified script will be executed
 unless the -NoProfile flag is used when it is launched.

 The artifact will by default search both User profiles and System-wide
 configured profiles. The user can also target and exclude specific content
 with relevant regex filters.

reference:
 - https://attack.mitre.org/techniques/T1546/013/

type: CLIENT

parameters:
 - name: UserProfileGlob
 default: '\Documents\{WindowsPowerShell,Powershell}\{Profile,Microsoft.*_profile}.ps1'
 description: Glob for PowerShell user profiles.
 - name: PSHomeProfileGlob
 default: 'C:\Windows\System32\{WindowsPowerShell,Powershell}\v1.0\{Profile,Microsoft.*_profile}.ps1'
 description: Glob for PowerShell PSHome profiles.
 - name: SearchStrings
 default: .
 type: regex
 description: regex to filter for in profile content
 - name: StringWhiteList
 default:
 type: regex
 description: regex to filter out in profile content

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- First extract potential glob path for each user
 LET UserTargets = SELECT Name as Username,
 expand(path=Directory) + UserProfileGlob as ProfileGlob
 FROM Artifact.Windows.Sys.Users()
 WHERE Directory

 -- Search for both Powershell System and User profiles.
 SELECT OSPath, Size,
 read_file(filename=OSPath) as Content,
 dict( Mtime=Mtime,
 Atime=Atime,
 Ctime=Ctime,
 Btime=Btime ) as Timestamps,
 hash(path=OSPath) as Hash
 FROM glob(globs=UserTargets.ProfileGlob + PSHomeProfileGlob)
 WHERE
 Content =~ SearchStrings
 AND NOT if(condition=StringWhiteList,
 then= Content=~StringWhiteList,
 else= False)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Persistence.PowershellRegistry</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.powershellregistry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.powershellregistry/</guid><description>&lt;p>A common method of persistence is to install a hook into a user profile
registry hive, using PowerShell. When the user logs in, the PowerShell script
downloads a payload and executes it.&lt;/p>
&lt;p>This artifact searches the user&amp;rsquo;s profile registry hive for signatures related
to general PowerShell execution. We use a YARA signature specifically
targeting the user&amp;rsquo;s profile which we extract by using raw NTFS parsing (in
case the user is currently logged on and the registry hive is locked).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Persistence.PowershellRegistry
description: |
 A common method of persistence is to install a hook into a user profile
 registry hive, using PowerShell. When the user logs in, the PowerShell script
 downloads a payload and executes it.

 This artifact searches the user's profile registry hive for signatures related
 to general PowerShell execution. We use a YARA signature specifically
 targeting the user's profile which we extract by using raw NTFS parsing (in
 case the user is currently logged on and the registry hive is locked).

parameters:
 - name: yaraRule
 type: yara
 default: |
 rule PowerShell {
 strings:
 $a = /ActiveXObject.{,500}eval/ wide nocase

 condition:
 any of them
 }
 - name: userRegex
 default: .
 type: regex

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 SELECT * from foreach(
 row={
 SELECT Name,
 expand(path=Directory) AS HomeDir
 FROM Artifact.Windows.Sys.Users()
 WHERE HomeDir and Gid AND Name =~ userRegex
 },
 query={
 SELECT File.OSPath As OSPath,
 String.Offset AS Off,
 String.HexData As Hex,
 upload(file=File.FullPath, accessor="auto") AS Upload
 FROM yara(
 files=HomeDir + "\\ntuser.dat",
 rules=yaraRule, context=50)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Persistence.Wow64cpu</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.wow64cpu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.persistence.wow64cpu/</guid><description>&lt;p>Checks for wow64cpu.dll replacement Autorun in Windows 10.
&lt;a href="http://www.hexacorn.com/blog/2019/07/11/beyond-good-ol-run-key-part-108-2/" target="_blank" >http://www.hexacorn.com/blog/2019/07/11/beyond-good-ol-run-key-part-108-2/&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Persistence.Wow64cpu
description: |
 Checks for wow64cpu.dll replacement Autorun in Windows 10.
 http://www.hexacorn.com/blog/2019/07/11/beyond-good-ol-run-key-part-108-2/

author: Matt Green - @mgreen27

parameters:
 - name: TargetRegKey
 default: HKEY_LOCAL_MACHINE\Software\Microsoft\Wow64\**
sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 SELECT OSPath.Dirname as KeyPath,
 Name as KeyName,
 Data.value as Value,
 Mtime AS LastModified
 FROM glob(globs=split(string=TargetRegKey, sep=","), accessor="registry")
 WHERE Data.value and
 not (Name = "@" and (Data.value =~ "(wow64cpu.dll|wowarmhw.dll|xtajit.dll)"))

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.AppCompatCache</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.appcompatcache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.appcompatcache/</guid><description>&lt;p>This artifact parses AppCompatCache (shimcache) from target hives.&lt;/p>
&lt;p>AppCompatCache, also known as Shimcache, is a component of the Application
Compatibility Database, which was created by Microsoft and used by the Windows
operating system to identify application compatibility issues. This helps
developers troubleshoot legacy functions and contains data related to Windows
features.&lt;/p>
&lt;p>Note:&lt;/p>
&lt;ul>
&lt;li>Windows 10+ systems Execution flag of 1 indicates execution.&lt;/li>
&lt;li>The appcompatcache artifact does not currently support execution flag in
Windows 7 and 8 / 8.1 Systems.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.AppCompatCache
author: Matt Green - @mgreen27
description: |
 This artifact parses AppCompatCache (shimcache) from target hives.

 AppCompatCache, also known as Shimcache, is a component of the Application
 Compatibility Database, which was created by Microsoft and used by the Windows
 operating system to identify application compatibility issues. This helps
 developers troubleshoot legacy functions and contains data related to Windows
 features.

 Note:

 - Windows 10+ systems Execution flag of 1 indicates execution.
 - The appcompatcache artifact does not currently support execution flag in
 Windows 7 and 8 / 8.1 Systems.


reference:
 - https://www.mandiant.com/resources/caching-out-the-val

parameters:
 - name: AppCompatCacheKey
 default: HKEY_LOCAL_MACHINE/System/ControlSet*/Control/Session Manager/AppCompatCache/AppCompatCache

precondition: SELECT OS From info() where OS = 'windows'

export: |
 LET AppCompatCacheParser &amp;lt;= '''[
 ["HeaderWin10", "x=&amp;gt;x.HeaderSize", [
 ["HeaderSize", 0, "unsigned int"],
 ["Entries", "x=&amp;gt;x.HeaderSize", Array, {
 type: "Entry",
 sentinel: "x=&amp;gt;x.Size = 0",
 count: 10000,
 }]
 ]],
 ["HeaderWin8", 128, [
 ["Entries", 128, Array, {
 type: "EntryWin8",
 sentinel: "x=&amp;gt;x.EntrySize = 0",
 count: 10000,
 }]
 ]],

 ["EntryWin8", "x=&amp;gt;x.EntrySize + 12", [
 ["Signature", 0, "String", {
 length: 4,
 }],
 ["EntrySize", 8, "unsigned int"],
 ["PathSize", 12, "uint16"],
 ["Path", 14, "String", {
 length: "x=&amp;gt;x.PathSize",
 encoding: "utf16",
 }],
 ["LastMod", "x=&amp;gt;x.PathSize + 14 + 10", "WinFileTime"],
 ["Execution", 0, "Value",{"value":"N/A"}],
 ]],

 ["Entry", "x=&amp;gt;x.Size + 12", [
 ["Signature", 0, "String", {
 length: 4,
 }],
 ["Size", 8, "unsigned int"],
 ["PathSize", 12, "uint16"],
 ["Path", 14, "String", {
 length: "x=&amp;gt;x.PathSize",
 encoding: "utf16",
 }],
 ["LastMod", "x=&amp;gt;x.PathSize + 14", "WinFileTime"],
 ["DataSize", "x=&amp;gt;x.PathSize + 14 + 8", "uint32"],
 ["Data", "x=&amp;gt;x.PathSize + 14 + 8 + 4" , "String", {
 length: "x=&amp;gt;x.DataSize",
 }],

 # The last byte of the Data block is 1 for execution
 ["Execution", "x=&amp;gt;x.PathSize + 14 + 8 + 4 + x.DataSize - 4", "uint32"]
 ]],

 # This is the Win7 parser but we don't use it right now.
 ["HeaderWin7x64", 128, [
 ["Signature", 0, "uint32"],
 ["Entries", 128, "Array", {
 count: 10000,
 sentinel: "x=&amp;gt;x.PathSize = 0",
 type: EntryWin7x64,
 }]
 ]],
 ["EntryWin7x64", 48, [
 ["PathSize", 0, "uint16"],
 ["PathOffset", 8, "uint32"],
 ["Path", "x=&amp;gt;x.PathOffset - x.StartOf", "String", {
 encoding: "utf16",
 length: "x=&amp;gt;x.PathSize",
 }],
 ["LastMod", 16, "WinFileTime"],
 ["Execution", 0, "Value",{"value":"N/A"}],

 ]]

 ]'''

 LET AppCompatCacheWin10(Blob) = parse_binary(
 accessor="data",
 filename=Blob,
 profile=AppCompatCacheParser,
 struct="HeaderWin10")

 LET AppCompatCacheWin8(Blob) = parse_binary(
 accessor="data",
 filename=Blob,
 profile=AppCompatCacheParser,
 struct="HeaderWin8")

 LET AppCompatCache(Blob) = SELECT *
 FROM foreach(
 row=if(
 condition=AppCompatCacheWin10(Blob=Blob).HeaderSize IN (52, 48),
 then=AppCompatCacheWin10(Blob=Blob).Entries,
 else=AppCompatCacheWin8(Blob=Blob).Entries))


sources:
 - query: |
 -- first find all ControlSet Keys in scope
 LET AppCompatKeys &amp;lt;= SELECT OSPath FROM glob(globs=AppCompatCacheKey, accessor='registry')

 -- when greater than one key we need to extract results and order later
 LET results &amp;lt;= SELECT
 ModificationTime,
 Name as Path,
 ExecutionFlag,
 ControlSet,
 Key
 FROM foreach(
 row={
 SELECT OSPath FROM glob(accessor='registry',
 globs=AppCompatCacheKey)
 }, query={
 SELECT OSPath AS Key, Path AS Name,
 LastMod AS ModificationTime,
 Execution as ExecutionFlag,
 OSPath[2] as ControlSet
 FROM AppCompatCache(Blob=read_file(
 accessor='registry', filename=OSPath))
 })

 -- find position of entry for each ControlSet. Lower numbers more recent
 LET ControlSetPosition(cs) = SELECT *, count() - 1 as Position
 FROM results WHERE ControlSet = cs
 LET position = SELECT ControlSetPosition(cs=ControlSet) as Results
 FROM foreach(
 row={
 SELECT ControlSet, count(items=ControlSet) as Entries
 FROM results GROUP BY ControlSet
 })

 LET mutli_controlset = SELECT *
 FROM foreach(
 row=position.Results,
 query={
 SELECT * FROM foreach(row=_value)
 })

 -- output results
 SELECT
 Position,
 ModificationTime,
 Path,
 ExecutionFlag,
 ControlSet,
 Key
 FROM if(condition= len(list=AppCompatKeys.OSPath)=1,
 then={
 SELECT *, count() - 1 as Position FROM results
 },
 else= mutli_controlset )
&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.BackupRestore</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.backuprestore/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.backuprestore/</guid><description>&lt;p>This artifact will return BackupRestore configuration.&lt;/p>
&lt;p>Applications that request or perform backup and restore operations can use
these keys to communicate with each other or with features such as the
Volume Shadow Copy Service (VSS) and Windows Backup.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.BackupRestore
author: Matt Green - @mgreen27
description: |
 This artifact will return BackupRestore configuration.

 Applications that request or perform backup and restore operations can use
 these keys to communicate with each other or with features such as the
 Volume Shadow Copy Service (VSS) and Windows Backup.

reference:
 - https://andreafortuna.org/2017/10/02/volume-shadow-copies-in-forensic-analysis/
 - https://docs.microsoft.com/en-us/windows/win32/backup/registry-keys-for-backup-and-restore

parameters:
 - name: KeyGlob
 default: HKEY_LOCAL_MACHINE\SYSTEM\*ControlSet*\Control\BackupRestore\**

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- output rows and dedup on unique values for each
 SELECT ModTime,OSPath,
 Name as KeyName,
 Data.value as KeyValue,
 Data.type as KeyType
 FROM glob(globs=KeyGlob, accessor="registry")
 WHERE NOT KeyType ='key'
 GROUP BY ModTime, KeyName,KeyValue,KeyType

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.EnabledMacro</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.enabledmacro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.enabledmacro/</guid><description>&lt;p>Checks for Registry key indicating macro was enabled by user.&lt;/p>
&lt;p>HKEY_USERS*\Software\Microsoft\Office*\Security\Trusted Documents\TrustRecords reg keys for values ending in FFFFFF7F
&lt;a href="http://az4n6.blogspot.com/2016/02/more-on-trust-records-macros-and.html" target="_blank" >http://az4n6.blogspot.com/2016/02/more-on-trust-records-macros-and.html&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.EnabledMacro
description: |
 Checks for Registry key indicating macro was enabled by user.

 HKEY_USERS\*\Software\Microsoft\Office\*\Security\Trusted Documents\TrustRecords reg keys for values ending in FFFFFF7F
 http://az4n6.blogspot.com/2016/02/more-on-trust-records-macros-and.html

author: "@mgreen27"

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
 default: Software\Microsoft\Office\*\*\Security\Trusted Documents\TrustRecords\*
 - name: userRegex
 default: .
 type: regex

sources:
 - query: |
 LET UserProfiles = Select Name as Username,
 {
 SELECT OSPath FROM glob(
 root=expand(path=Directory),
 globs="/NTUSER.DAT",
 accessor="auto")
 } as NTUser,
 expand(path=Directory) as Directory
 FROM Artifact.Windows.Sys.Users()
 WHERE Directory and NTUser and Name =~ userRegex

 SELECT * FROM foreach(
 row={
 SELECT Username,NTUser FROM UserProfiles
 },
 query={
 SELECT Name as Document,
 Username,
 NTUser as Userhive,
 OSPath.Dirname AS Key,
 Mtime AS LastModified
 FROM glob(
 globs=KeyGlob,
 root=pathspec(DelegatePath=NTUser),
 accessor="raw_reg")
 WHERE Data.type =~ "BINARY"
 and encode(string=Data.value, type="hex") =~ "ffffff7f$"
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.EnableUnsafeClientMailRules</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.enableunsafeclientmailrules/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.enableunsafeclientmailrules/</guid><description>&lt;p>Checks for Outlook EnableUnsafeClientMailRules = 1 (turned on).
This registry key enables execution from Outlook inbox rules which can be used as a persistence mechanism.
Microsoft has released a patch to disable execution but attackers can reenable by changing this value to 1.&lt;/p>
&lt;p>HKEY_USERS*\Software\Microsoft\Office*\Outlook\Security\EnableUnsafeClientMailRules = 0 (expected)
&lt;a href="https://support.microsoft.com/en-us/help/3191893/how-to-control-the-rule-actions-to-start-an-application-or-run-a-macro" target="_blank" >https://support.microsoft.com/en-us/help/3191893/how-to-control-the-rule-actions-to-start-an-application-or-run-a-macro&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.EnableUnsafeClientMailRules
description: |
 Checks for Outlook EnableUnsafeClientMailRules = 1 (turned on).
 This registry key enables execution from Outlook inbox rules which can be used as a persistence mechanism.
 Microsoft has released a patch to disable execution but attackers can reenable by changing this value to 1.

 HKEY_USERS\*\Software\Microsoft\Office\*\Outlook\Security\EnableUnsafeClientMailRules = 0 (expected)
 https://support.microsoft.com/en-us/help/3191893/how-to-control-the-rule-actions-to-start-an-application-or-run-a-macro

author: "@mgreen27"

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
 default: Software\Microsoft\Office\*\Outlook\Security\
 - name: userRegex
 default: .
 type: regex

sources:
 - query: |
 LET UserProfiles = Select Name as Username,
 {
 SELECT OSPath FROM glob(root=expand(path=Directory),
 globs="/NTUSER.DAT", accessor="auto")
 } as NTUser,
 expand(path=Directory) as Directory
 FROM Artifact.Windows.Sys.Users()
 WHERE Directory and NTUser and Name =~ userRegex

 SELECT * FROM foreach(
 row={
 SELECT Username, NTUser FROM UserProfiles
 },
 query={
 SELECT Username,
 NTUser as Userhive,
 Key.OSPath.Path as Key,
 key.Mtime AS LastModified,
 EnableUnsafeClientMailRules,
 OutlookSecureTempFolder
 FROM read_reg_key(
 globs=KeyGlob,
 root=pathspec(DelegatePath=OSPath),
 accessor="raw_reg")
 WHERE EnableUnsafeClientMailRules = 1
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.MountPoints2</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.mountpoints2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.mountpoints2/</guid><description>&lt;p>This detection will collect any items in the MountPoints2 registry key.
With a &amp;ldquo;$&amp;rdquo; in the share path. This key will store all remotely mapped
drives unless removed so is a great hunt for simple admin $ mapping based
lateral movement.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.MountPoints2
description: |
 This detection will collect any items in the MountPoints2 registry key.
 With a "$" in the share path. This key will store all remotely mapped
 drives unless removed so is a great hunt for simple admin $ mapping based
 lateral movement.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
 default: Software\Microsoft\Windows\CurrentVersion\Explorer\MountPoints2\*
 - name: MountPointFilterRegex
 type: regex
 default: "\\$"

sources:
 - query: |
 SELECT regex_replace(
 source=OSPath.Basename,
 re="#",
 replace="\\") as MountPoint,
 Mtime as ModifiedTime,
 Username,
 OSPath.DelegatePath as Hive,
 OSPath.Path as Key
 FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
 WHERE OSPath =~ MountPointFilterRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.NTUser</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.ntuser/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.ntuser/</guid><description>&lt;p>This artifact searches for keys or values within the user&amp;rsquo;s
NTUser.dat registry hives.&lt;/p>
&lt;p>When a user logs into a windows machine the system creates their own
&amp;ldquo;profile&amp;rdquo; which consists of a registry hive mapped into the
HKEY_USERS hive. This hive file is locked while the user is
logged in. If the user is not logged in, the file is not mapped at
all.&lt;/p>
&lt;p>This artifact bypasses the locking mechanism by parsing the raw NTFS
filesystem to recover the registry hives. We then parse the registry
hives to search for the glob provided.&lt;/p>
&lt;p>This artifact is designed to be reused by other artifacts that need
to access user data.&lt;/p>

&lt;div class="mynotices note">
 &lt;div heading="note">&lt;p>Any artifacts that look into the HKEY_USERS registry hive should
be using the &lt;code>Windows.Registry.NTUser&lt;/code> artifact instead of
accessing the hive via the API. The API only makes the currently
logged in users available in that hive, so if we rely on the
windows API we will miss any settings for the users not
currently logged on.&lt;/p>
&lt;/div>
&lt;/div>


&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.NTUser
description: |
 This artifact searches for keys or values within the user's
 NTUser.dat registry hives.

 When a user logs into a windows machine the system creates their own
 "profile" which consists of a registry hive mapped into the
 HKEY_USERS hive. This hive file is locked while the user is
 logged in. If the user is not logged in, the file is not mapped at
 all.

 This artifact bypasses the locking mechanism by parsing the raw NTFS
 filesystem to recover the registry hives. We then parse the registry
 hives to search for the glob provided.

 This artifact is designed to be reused by other artifacts that need
 to access user data.

 
&lt;div class="mynotices note">
 &lt;div heading="note">&lt;pre>&lt;code>Any artifacts that look into the HKEY_USERS registry hive should
be using the `Windows.Registry.NTUser` artifact instead of
accessing the hive via the API. The API only makes the currently
logged in users available in that hive, so if we rely on the
windows API we will miss any settings for the users not
currently logged on.
&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>



precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
 default: Software\Microsoft\Windows\CurrentVersion\Explorer\ComDlg32\**
 - name: userRegex
 default: .
 type: regex

export: |
 // HivePath: The path to the hive on disk
 // RegistryPath: The path in the registry to mount the hive
 // RegMountPoint: The path inside the hive to mount (usually /)
 LET _map_file_to_reg_path(HivePath, RegistryPath, RegMountPoint, Accessor, Description) = dict(
 type="mount", description=Description,
 `from`=dict(accessor='raw_reg',
 prefix=pathspec(
 Path=RegMountPoint,
 DelegateAccessor=Accessor,
 DelegatePath=HivePath),
 path_type='registry'),
 `on`=dict(accessor='registry',
 prefix=RegistryPath,
 path_type='registry'))

 -- This needs to always be mapped because it is normally denied through the API
 LET _required_mappings = (
 _map_file_to_reg_path(
 HivePath="C:/Windows/System32/Config/SECURITY",
 RegistryPath="HKEY_LOCAL_MACHINE\\Security",
 RegMountPoint="/",
 Accessor='ntfs',
 Description="Map SECURITY Hive to HKEY_LOCAL_MACHINE"),
 )

 LET _standard_mappings = (
 _map_file_to_reg_path(
 HivePath="C:/Windows/System32/Config/SYSTEM",
 RegistryPath="HKEY_LOCAL_MACHINE\\System\\CurrentControlSet",
 RegMountPoint="/ControlSet001",
 Accessor='ntfs',
 Description="Map SYSTEM Hive to CurrentControlSet"),
 _map_file_to_reg_path(
 HivePath="C:/Windows/System32/Config/SOFTWARE",
 RegistryPath="HKEY_LOCAL_MACHINE\\Software",
 RegMountPoint="/",
 Accessor='ntfs',
 Description="Map Software hive to HKEY_LOCAL_MACHINE"),
 _map_file_to_reg_path(
 HivePath="C:/Windows/System32/Config/System",
 RegistryPath="HKEY_LOCAL_MACHINE\\System",
 RegMountPoint="/",
 Accessor='ntfs',
 Description="Map System hive to HKEY_LOCAL_MACHINE")
 )

 LET _make_ntuser_mappings(Accessor, Hive, Subpath) = SELECT _map_file_to_reg_path(
 HivePath=NTUserPath,
 RegMountPoint="/",
 Accessor=Accessor,
 Description=format(format="Map NTUSER.dat from User %v to HKEY_USERS", args=NTUserPath[2]),
 -- This is technically the SID but it is clearer to just use the username
 RegistryPath="HKEY_USERS\\" + NTUserPath[2] + Subpath) AS Mapping
 FROM foreach(row={
 SELECT pathspec(parse=expand(path=Directory),
 path_type="windows") + Hive AS NTUserPath
 FROM Artifact.Windows.Sys.Users()
 }, query={
 -- Verify the file actually exists
 SELECT NTUserPath FROM stat(filename=NTUserPath)
 })

 LET _user_mappings =
 _make_ntuser_mappings(Accessor='auto', Hive="NTUser.dat", Subpath="").Mapping +
 _make_ntuser_mappings(Accessor='auto',
 Hive="\\AppData\\Local\\Microsoft\\Windows\\UsrClass.dat",
 Subpath="\\Software\\Classes", Subpath="\\Software\\Classes").Mapping

 // Use this like `LET _ &amp;lt;= MapRawRegistryHives`
 LET MapRawRegistryHives =remap(config=dict(
 remappings=_user_mappings + _standard_mappings + _required_mappings))

sources:
 - query: |
 LET UserProfiles = SELECT Uid,
 Gid,
 Name || "" as Username,
 Description,
 UUID,
 {
 SELECT OSPath FROM glob(
 root=expand(path=Directory),
 globs="/NTUSER.DAT",
 accessor="auto")
 } as OSPath,
 expand(path=Directory) as Directory
 FROM Artifact.Windows.Sys.Users()
 WHERE Directory and OSPath AND Username =~ userRegex

 SELECT * FROM foreach(
 row={
 SELECT * FROM UserProfiles
 },
 query={
 SELECT OSPath, OSPath, Data, Mtime AS Mtime,
 Username, Description, Uid, Gid, UUID, Directory
 FROM glob(
 globs=KeyGlob,
 root=pathspec(
 DelegateAccessor="ntfs",
 DelegatePath=OSPath,
 Path="/"),
 accessor="raw_reg")
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.NTUser.Upload</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.ntuser.upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.ntuser.upload/</guid><description>&lt;p>This artifact collects all the user&amp;rsquo;s NTUser.dat registry hives.&lt;/p>
&lt;p>When a user logs into a windows machine the system creates their own
&amp;ldquo;profile&amp;rdquo; which consists of a registry hive mapped into the
HKEY_USERS hive. This hive file is locked while the user is
logged in.&lt;/p>
&lt;p>This artifact bypasses the locking mechanism by extracting the
registry hives using raw NTFS parsing. We then just upload all hives
to the server.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.NTUser.Upload
description: |
 This artifact collects all the user's NTUser.dat registry hives.

 When a user logs into a windows machine the system creates their own
 "profile" which consists of a registry hive mapped into the
 HKEY_USERS hive. This hive file is locked while the user is
 logged in.

 This artifact bypasses the locking mechanism by extracting the
 registry hives using raw NTFS parsing. We then just upload all hives
 to the server.

parameters:
 - name: userRegex
 default: .
 type: regex

sources:
 - precondition: |
 SELECT OS From info() where OS = 'windows'
 query: |
 LET users = SELECT
 Name,
 expand(path=Directory) AS HomeDir
 FROM Artifact.Windows.Sys.Users()
 WHERE HomeDir AND Name =~ userRegex

 SELECT upload(file=HomeDir + "\\ntuser.dat",
 accessor="auto") as Upload
 FROM users

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.PortProxy</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.portproxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.portproxy/</guid><description>&lt;p>This artifact will return any items in the Windows PortProxy service
registry path. The most common configuration of this service is via the
LOLBin &lt;code>netsh.exe&lt;/code>. Metaspoit and other common attack tools also have
configuration modules.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.PortProxy
description: |
 This artifact will return any items in the Windows PortProxy service
 registry path. The most common configuration of this service is via the
 LOLBin `netsh.exe`. Metaspoit and other common attack tools also have
 configuration modules.

reference:
 - Port Proxy detection (http://www.dfirnotes.net/portproxy_detection/)
 - ATT&amp;amp;CK T1090 - Connection Proxy (https://attack.mitre.org/techniques/T1090/) \
 Adversaries may use a connection proxy to direct network traffic between
 systems or act as an intermediary for network communications to a command
 and control server to avoid direct connections to their infrastructure.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
 default: HKEY_LOCAL_MACHINE\SYSTEM\*ControlSet*\services\PortProxy\**

sources:
 - name: PortProxy
 query: |
 SELECT OSPath,
 OSPath[-3] AS ProxyType,
 OSPath[-2] AS Protocol,
 regex_replace(source=OSPath.Basename, re="/", replace=":") as Listening,
 regex_replace(source=Data.value, re="/", replace=":") as Destination,
 Mtime as ModifiedTime,
 Type
 FROM glob(globs=KeyGlob, accessor="registry")
 WHERE Type


reports:
 - type: CLIENT
 template: |

 Port Forwarding: PortProxy
 ==========================
 {{ .Description }}

 {{ define "report" }}
 LET report = SELECT Protocol,
 ProxyType,
 Listening,
 Destination,
 ModifiedTime,
 ProxyType + Protocol + Listening + Destination as ServiceKey
 FROM source(source='PortProxy')
 GROUP BY ServiceKey
 {{ end }}

 {{ Query "report" "SELECT ProxyType, Protocol, Listening, Destination, ModifiedTime FROM report" | Table }}

 - type: HUNT
 template: |

 Port Forwarding: PortProxy
 ==========================
 {{ .Description }}

 {{ define "report" }}
 LET report = SELECT Fqdn,
 Protocol,
 ProxyType,
 Listening,
 Destination,
 ModifiedTime,
 ProxyType + Protocol + Listening + Destination as ServiceKey
 FROM source(source='PortProxy')
 GROUP BY ServiceKey
 {{ end }}

 {{ Query "report" "SELECT Fqdn, ProxyType, Protocol, Listening, Destination, ModifiedTime FROM report" | Table }}

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.PuttyHostKeys</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.puttyhostkeys/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.puttyhostkeys/</guid><description>&lt;p>This artifact extracts PuTTY SSH host keys.&lt;/p>
&lt;p>As a security measure PuTTY and its companion utilities PSCP, PSFTP, and Plink
records the host key for each server connected to, in the Windows Registry.&lt;/p>
&lt;ul>
&lt;li>Output KeyName: &lt;code>ssh-ed12345@22:27.27.27.27&lt;/code>&lt;/li>
&lt;li>To search for a specific IP: &lt;code>TargetKeyName =~ ':\&amp;lt;IP\&amp;gt;$'&lt;/code>&lt;/li>
&lt;li>To search for a specific PORT: &lt;code>TargetKeyName =~ '@\&amp;lt;PORT\&amp;gt;:.+$'&lt;/code>&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.PuttyHostKeys
author: Matt Green - @mgreen27
description: |
 This artifact extracts PuTTY SSH host keys.

 As a security measure PuTTY and its companion utilities PSCP, PSFTP, and Plink
 records the host key for each server connected to, in the Windows Registry.

 - Output KeyName: `ssh-ed12345@22:27.27.27.27`
 - To search for a specific IP: `TargetKeyName =~ ':\&amp;lt;IP\&amp;gt;$'`
 - To search for a specific PORT: `TargetKeyName =~ '@\&amp;lt;PORT\&amp;gt;:.+$'`


type: CLIENT

parameters:
 - name: KeyGlob
 default: Software\SimonTatham\Putty\SshHostKeys\**
 - name: TargetUser
 default: .
 - name: TargetKeyName
 default: .
 - name: TargetKeyValue
 default: .

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET HKEY_USERS &amp;lt;= pathspec(path_type="registry", Path="HKEY_USERS")

 SELECT
 Mtime,
 Username,
 OSPath.Basename AS KeyName,
 Data.value AS KeyValue,
 HKEY_USERS + UUID + OSPath.Dirname AS Key,
 OSPath.DelegatePath AS SourcePath
 FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob,userRegex=TargetUser)
 WHERE KeyName =~ TargetKeyName
 AND KeyValue =~ TargetKeyValue


&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.RDP</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.rdp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.rdp/</guid><description>&lt;p>This artifact will collect historical RDP server names and MRU items stored
in each users NTUser.dat&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Servers - list of all RDP connections that have ever been established by
this user.&lt;br>
UsernameHint shows the username used to connect to the RDP/RDS host.&lt;br>
CertHash variable contains the RDP server SSL certificate thumbprint.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MRU 10 - Most recently used RDP connections&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>UserRegex and SidRegex can be used to target a specific user.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.RDP
author: Matt Green - @mgreen27
description: |
 This artifact will collect historical RDP server names and MRU items stored 
 in each users NTUser.dat
 
 1. Servers - list of all RDP connections that have ever been established by 
 this user. 
 UsernameHint shows the username used to connect to the RDP/RDS host. 
 CertHash variable contains the RDP server SSL certificate thumbprint.

 2. MRU 10 - Most recently used RDP connections 
 
 UserRegex and SidRegex can be used to target a specific user.

type: CLIENT

parameters:
 - name: KeyGlob
 default: Software\Microsoft\Terminal Server Client\{Default,Servers}\**
 - name: UserRegex
 default: .
 description: Regex filter to select a target username
 type: regex
 - name: SidRegex
 default: .
 description: Regex filter to select a target SID
 type: regex
 

precondition: SELECT OS From info() where OS = 'windows'
 
sources:
 - name: Servers
 query: |
 LET servers &amp;lt;= SELECT 
 Mtime as LastWriteTime,
 basename(path=OSPath.Dirname) as Server,
 OSPath.Basename as KeyName,
 Data.value as KeyValue,
 Data.data_len as ValueLength,
 OSPath.Dirname.Path as Key,
 OSPath.DelegatePath as HiveName,
 OSPath,
 Username,
 UUID as SID
 FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
 WHERE NOT Data.type = 'Key'
 AND OSPath =~ '''Terminal Server Client\\\\Servers\\'''

 LET find_value(path, sid, keyname ) = SELECT KeyValue,
 format(format='%x',args=read_file(accessor='data',filename=KeyValue,length=ValueLength)) as CertHash
 FROM servers 
 WHERE KeyName = keyname AND Key=path AND SID=sid
 
 LET results = SELECT 
 Username || dirname(path=HiveName).Basename as Username, 
 SID,
 HiveName,
 Key, 
 LastWriteTime,
 Server
 FROM servers
 WHERE Username =~ UserRegex AND SID =~ SidRegex
 GROUP BY SID,Key,HiveName,LastWriteTime
 
 
 SELECT *
 find_value(path=Key,sid=SID,keyname='UsernameHint')[0].KeyValue as UsernameHint,
 find_value(path=Key,sid=SID,keyname='CertHash')[0].CertHash as CertHash
 FROM results

 - name: Mru
 query: |
 LET mru &amp;lt;= SELECT 
 Mtime as LastWriteTime,
 OSPath.Basename as KeyName,
 Data.value as KeyValue,
 OSPath.Dirname.Path as Key,
 OSPath.DelegatePath as HiveName,
 Username,
 UUID as SID
 FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
 WHERE NOT Data.type = 'Key'
 AND OSPath =~ '''Terminal Server Client\\\\Default\\\\MRU'''
 
 LET find_mru(sid) = SELECT KeyValue FROM mru 
 WHERE SID=sid
 
 LET results = SELECT *,
 Username || dirname(path=HiveName).Basename as Username
 FROM mru 
 WHERE Username =~ UserRegex AND SID =~ SidRegex
 GROUP BY Sid,HiveName
 
 SELECT 
 Username,
 SID, 
 HiveName,
 Key,
 LastWriteTime,
 find_mru(sid=SID).KeyValue as Mru
 FROM results
&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.RecentDocs</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.recentdocs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.recentdocs/</guid><description>&lt;p>This artifact extracts RecentDocs MRU from the target.&lt;/p>
&lt;p>By default the artifact will target all users on the machine when run in
live mode but can be targeted directly using the HiveGlob parameter.&lt;/p>
&lt;p>Output includes LastWriteTime of key and a list of MRU items in the
order specified in the MRUListEx key value.
MruEntries has the format: [KeyName] := [Parsed Key value]&lt;/p>
&lt;p>Available filters include:
- Time bounds to select LastWrite timestamp within time ranges.
- EntryRegex to target specific entry values
- UserRegex to target specific users. Note: this filter does not work
when using HiveGlob.
- SidRegex to target a specific SID.&lt;/p>
&lt;p>Note: both UserRegex and SidRegex does not work when using HiveGlob
and all MRU will be returned.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.RecentDocs
author: Matt Green - @mgreen27
description: |
 This artifact extracts RecentDocs MRU from the target.

 By default the artifact will target all users on the machine when run in
 live mode but can be targeted directly using the HiveGlob parameter.

 Output includes LastWriteTime of key and a list of MRU items in the
 order specified in the MRUListEx key value.
 MruEntries has the format: [KeyName] := [Parsed Key value]

 Available filters include:
 - Time bounds to select LastWrite timestamp within time ranges.
 - EntryRegex to target specific entry values
 - UserRegex to target specific users. Note: this filter does not work
 when using HiveGlob.
 - SidRegex to target a specific SID.

 Note: both UserRegex and SidRegex does not work when using HiveGlob
 and all MRU will be returned.

parameters:
 - name: KeyGlob
 type: hidden
 default: Software\Microsoft\Windows\CurrentVersion\Explorer\RecentDocs\**
 - name: HiveGlob
 description: "optional hive glob to target for offline processing."
 - name: DateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 type: timestamp
 - name: DateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 type: timestamp
 - name: EntryRegex
 default: .
 description: "regex filter for document/entry name."
 - name: UserRegex
 default: .
 description: "regex filter for username over standard query."
 - name: SidRegex
 default: .
 description: "regex filter for user SID over standard query."
 - name: Profile
 type: hidden
 default: |
 [
 ["Target", 0, [
 ["Filename", 0, "String", {
 encoding: "utf16",
 }],
 ]]
 ]

sources:
 - query: |
 -- time testing
 LET time_test(stamp) =
 if(condition= DateBefore AND DateAfter,
 then= stamp &amp;lt; DateBefore AND stamp &amp;gt; DateAfter,
 else=
 if(condition=DateBefore,
 then= stamp &amp;lt; DateBefore,
 else=
 if(condition= DateAfter,
 then= stamp &amp;gt; DateAfter,
 else= True
 )))


 -- dynamic function to extract RecentDocs order from MRUListEx data value
 LET find_order(value) = SELECT
 parse_binary(accessor='data',
 filename=substr(str=value,start=_value,end=_value + 4),
 struct='uint32') as Int
 FROM range(end=len(list=value),start=0,step=4)
 WHERE NOT Int = 4294967295

 -- NTUser method is most accurate
 LET NTUserValues = SELECT
 Mtime,
 OSPath.Components[-2] AS Type,
 OSPath.Components[-1] AS Name,
 if(condition= OSPath.Basename = 'MRUListEx',
 then= find_order(value=Data.value).Int,
 else= parse_binary(
 accessor="data",
 filename=Data.value,
 profile=Profile, struct="Target").Filename ) as Value,
 Data,
 OSPath.DelegatePath as HiveName,
 OSPath,
 Username,
 UUID
 FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
 WHERE Username =~ UserRegex
 AND UUID =~ SidRegex
 AND Data.type =~ 'BINARY'


 -- Glob method allows offline processing but cannot filter by user
 LET GlobValues = SELECT
 Mtime,
 OSPath.Components[-2] AS Type,
 OSPath.Components[-1] AS Name,
 if(condition= OSPath.Basename = 'MRUListEx',
 then= find_order(value=Data.value).Int,
 else= parse_binary(
 accessor="data",
 filename=Data.value,
 profile=Profile,
 struct="Target").Filename ) as Value,
 Data,
 OSPath.DelegatePath as HiveName,
 OSPath
 FROM glob(
 globs=KeyGlob,
 root=pathspec(DelegatePath=HiveGlob),
 accessor="raw_reg")
 WHERE Data.type =~ 'BINARY'

 -- precalculate all hive values for performance
 LET AllValues &amp;lt;= SELECT * FROM if(condition= HiveGlob,
 then={ SELECT * FROM GlobValues},
 else={ SELECT * FROM NTUserValues} )
 WHERE time_test(stamp=Mtime)


 -- memorise for lookup / performance
 LET Items &amp;lt;= memoize(query={
 SELECT Type, Name, Value,
 Type + ':' + Name + ':' + HiveName AS Key
 FROM AllValues
 }, key="Key")


 -- flattern output then add lookup of processed data
 LET flat_data(type,hivename) = SELECT *,
 str(str=Value) + ' := ' +
 get(item=Items, field=str(str=Type) + ':' +
 str(str=Value) + ':' + str(str=hivename) ).Value AS Value
 FROM flatten(query={
 SELECT Mtime, Type, Name, Value,HiveName
 FROM AllValues
 WHERE Name = 'MRUListEx'
 AND Type = type AND HiveName = hivename
 })
 GROUP BY Value


 -- prep results
 LET results = SELECT Mtime as LastWriteTime, Type,
 flat_data(type=Type, hivename=HiveName).Value as MruEntries,
 OSPath.Path as Key,
 HiveName,
 if(condition=HiveGlob,
 then='', else=Username) as Username,
 if(condition=HiveGlob,
 then='', else=UUID) as UUID
 FROM AllValues
 WHERE Name = 'MRUListEx'


 -- print rows, remove Username/SID from offline
 SELECT * FROM if(condition=HiveGlob,
 then = {
 SELECT LastWriteTime, Type,
 if(condition= NOT MruEntries[0],
 then= Null,
 else= MruEntries) as MruEntries,
 Key, HiveName
 FROM results
 },
 else={
 SELECT LastWriteTime, Type,
 if(condition= NOT MruEntries[0],
 then= Null,
 else= MruEntries) as MruEntries,
 Key, HiveName, Username, UUID
 FROM results
 })
 WHERE format(format='%v', args=MruEntries) =~ EntryRegex

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.Sysinternals.Eulacheck</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.sysinternals.eulacheck/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.sysinternals.eulacheck/</guid><description>&lt;p>Checks for the Accepted Sysinternals EULA from the registry key
&amp;ldquo;HKCU\Software\Sysinternals[TOOL]&amp;quot;. When a Sysinternals tool is
first run on a system, the EULA must be accepted. This writes a
value called EulaAccepted under that key.&lt;/p>
&lt;p>Note: This artifact uses HKEY_USERS and therefore will not detect
users that are not currently logged on.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.Sysinternals.Eulacheck
description: |
 Checks for the Accepted Sysinternals EULA from the registry key
 "HKCU\Software\Sysinternals\[TOOL]\". When a Sysinternals tool is
 first run on a system, the EULA must be accepted. This writes a
 value called EulaAccepted under that key.

 Note: This artifact uses HKEY_USERS and therefore will not detect
 users that are not currently logged on.

parameters:
 - name: Sysinternals_Reg_Key
 default: HKEY_USERS\*\Software\Sysinternals\*
 - name: userRegex
 default: .
 type: regex

imports:
 - Windows.Registry.NTUser

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 name: RegistryAPI
 query: |
 LET users &amp;lt;= SELECT Name, UUID
 FROM Artifact.Windows.Sys.Users()
 WHERE Name =~ userRegex

 SELECT Key.Name as ProgramName,
 Key.OSPath as Key,
 Key.Mtime AS TimeAccepted,
 {
 SELECT Name FROM users WHERE UUID=regex_replace(
 source=Key.OSPath, re=".+\\\\(S-[^\\\\]+)\\\\.+", replace="$1")
 } as User,
 EulaAccepted
 FROM read_reg_key(globs=split(string=Sysinternals_Reg_Key, sep=',[\\s]*'))

 - name: RawRegistry
 description: Detect keys using Raw Registry Analysis
 query: |
 -- Apply Raw Registry Mappings
 LET _ &amp;lt;= MapRawRegistryHives

 -- Make sure to call the other sources otherwise we get recursion errors!
 SELECT *
 FROM Artifact.Windows.Registry.Sysinternals.Eulacheck(source="RegistryAPI")

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.UserAssist</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.userassist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.userassist/</guid><description>&lt;p>Windows systems maintain a set of keys in the registry database
(UserAssist keys) to keep track of programs that executed. The
number of executions and last execution date and time are available
in these keys.&lt;/p>
&lt;p>The information within the binary UserAssist values contains only
statistical data on the applications launched by the user via
Windows Explorer. Programs launched via the command­line (cmd.exe)
do not appear in these registry keys.&lt;/p>
&lt;p>From a forensics perspective, being able to decode this information
can be very useful.&lt;/p>
&lt;p>Limitations: Additional data not parsed by Velociraptor is the FocusTime
and FocusCount however these are not reliable.
Also please note that some methods of viewing an executable will update
the associated UserAssist key, and some methods of accessing an executable
will not update the execution counter or time. Therefore there may be
some executions that have a 0 time and 0 runcount.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.UserAssist
description: |
 Windows systems maintain a set of keys in the registry database
 (UserAssist keys) to keep track of programs that executed. The
 number of executions and last execution date and time are available
 in these keys.

 The information within the binary UserAssist values contains only
 statistical data on the applications launched by the user via
 Windows Explorer. Programs launched via the command­line (cmd.exe)
 do not appear in these registry keys.

 From a forensics perspective, being able to decode this information
 can be very useful.

 Limitations: Additional data not parsed by Velociraptor is the FocusTime
 and FocusCount however these are not reliable.
 Also please note that some methods of viewing an executable will update
 the associated UserAssist key, and some methods of accessing an executable
 will not update the execution counter or time. Therefore there may be
 some executions that have a 0 time and 0 runcount.

reference:
 - https://www.aldeid.com/wiki/Windows-userassist-keys

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: UserFilter
 default: ""
 description: If specified we filter by this username.
 type: regex

 - name: ExecutionTimeAfter
 default: ""
 type: timestamp
 description: If specified only show executions after this time.

 - name: UserAssistKey
 default: Software\Microsoft\Windows\CurrentVersion\Explorer\UserAssist\*\Count\*

export:
 LET userAssistProfile = '''
 [
 ["Header", 0, [
 ["NumberOfExecutions", 4, "uint32"],
 ["LastExecution", 60, "uint64"]
 ]]
 ]
 '''

sources:
 - query: |
 LET TMP = SELECT OSPath.Path AS _KeyPath,
 parse_string_with_regex(
 string=OSPath.Path,
 regex="^.+Count\\\\\"?(?P&amp;lt;Name&amp;gt;.+?)\"?$") AS Name,
 OSPath,
 parse_binary(
 filename=Data.value,
 accessor="data",
 profile=userAssistProfile,
 struct="Header"
 ) As ParsedUserAssist,
 Username AS User
 FROM Artifact.Windows.Registry.NTUser(KeyGlob=UserAssistKey)

 LET UserAssist = SELECT _KeyPath,
 if(condition=Name.Name,
 then=rot13(string=Name.Name),
 else=OSPath.Path) AS Name,
 User,
 timestamp(winfiletime=ParsedUserAssist.LastExecution) As LastExecution,
 timestamp(winfiletime=ParsedUserAssist.LastExecution).Unix AS LastExecutionTS,
 ParsedUserAssist.NumberOfExecutions AS NumberOfExecutions
 FROM TMP
 ORDER BY LastExecution
 LET A1 = SELECT * FROM if(
 condition=UserFilter,
 then={
 SELECT * FROM UserAssist WHERE User =~ UserFilter
 },
 else={ SELECT * FROM UserAssist})

 SELECT * FROM if(
 condition=ExecutionTimeAfter,
 then={
 SELECT * FROM A1 WHERE LastExecutionTS &amp;gt; ExecutionTimeAfter
 },
 else={ SELECT * FROM A1})

&lt;/code>&lt;/pre></description></item><item><title>Windows.Registry.WDigest</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.registry.wdigest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.registry.wdigest/</guid><description>&lt;p>Find WDigest registry values on the filesystem. The artifact will also use
GROUP BY to limit all ControlSet output to a single row.&lt;/p>
&lt;p>To prevent a clear-text password from being placed in
LSASS, the following registry key needs to be set to “0” (Digest
Disabled):&lt;/p>
&lt;ul>
&lt;li>HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\SecurityProviders\WDigest
“UseLogonCredential”(DWORD)
“Negotiate”(DWORD)&lt;/li>
&lt;/ul>
&lt;p>These registry keys are worth monitoring in an environment as an
attacker may wish to set it to 1 to enable Digest password support
which forces “clear-text” passwords to be placed in LSASS on any
version of Windows from Windows 7 / 2008R2 up to Windows 10 /
2012R2. Furthermore, Windows 8.1 / 2012 R2 and newer do not have a
“UseLogonCredential” DWORD value, so the key needs to be
added. The existence of the key is suspicious, if not expected.&lt;/p>
&lt;ul>
&lt;li>ATT&amp;amp;CK tactic: Defense Evasion, Credential Access&lt;/li>
&lt;li>ATT&amp;amp;CK technique: T1112, T1003.001&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Registry.WDigest
author: Eduardo Mattos - @eduardfir, Matt Green - @mgreen27
description: |
 Find WDigest registry values on the filesystem. The artifact will also use
 GROUP BY to limit all ControlSet output to a single row.

 To prevent a clear-text password from being placed in
 LSASS, the following registry key needs to be set to “0” (Digest
 Disabled):

 - HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\SecurityProviders\WDigest
 “UseLogonCredential”(DWORD)
 “Negotiate”(DWORD)

 These registry keys are worth monitoring in an environment as an
 attacker may wish to set it to 1 to enable Digest password support
 which forces “clear-text” passwords to be placed in LSASS on any
 version of Windows from Windows 7 / 2008R2 up to Windows 10 /
 2012R2. Furthermore, Windows 8.1 / 2012 R2 and newer do not have a
 “UseLogonCredential” DWORD value, so the key needs to be
 added. The existence of the key is suspicious, if not expected.

 * ATT&amp;amp;CK tactic: Defense Evasion, Credential Access
 * ATT&amp;amp;CK technique: T1112, T1003.001

reference:
 - https://medium.com/blue-team/preventing-mimikatz-attacks-ed283e7ebdd5

type: CLIENT
precondition:
 SELECT * FROM info() where OS = 'windows'

parameters:
 - name: WDigestGlob
 default: HKEY_LOCAL_MACHINE\SYSTEM\*ControlSet*\Control\SecurityProviders\WDigest\**
 description: Use a glob to define the files that will be searched.
 - name: ShowAllValues
 type: bool
 description: Show all key values. It may be suspicious if these keys exist.


sources:
 - query: |
 SELECT
 ModTime as LastModified,
 OSPath as KeyPath,
 Name as KeyName,
 Data.type as KeyType,
 Data.value as KeyValue
 FROM glob(globs=WDigestGlob, accessor="registry")
 WHERE KeyType = "DWORD"
 AND KeyName =~ "UseLogonCredential|Negotiate"
 AND NOT if(condition= ShowAllValues,
 then= False,
 else= KeyValue = 0)
 GROUP BY LastModified, KeyName, KeyType, KeyValue,
 regex_replace(source=OSPath,
 re='''[^\\]+ControlSet[^\\]+''',replace='CurrentControlSet')

column_types:
 - name: LastModified
 type: timestamp

&lt;/code>&lt;/pre></description></item><item><title>Windows.Remediation.Quarantine</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.quarantine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.quarantine/</guid><description>&lt;p>Applies quarantine via Windows local IPsec policy.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>By default the current client configuration is applied as an
exclusion using resolved IP address at time of application.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A configurable lookup table is also used to generate
additional entries using the same syntax as &lt;code>netsh ipsec&lt;/code>
configuration.&lt;/p>
&lt;ul>
&lt;li>DNS and DHCP entries are allowed by default.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>An optional MessageBox may also be configured to alert all
logged in users.&lt;/p>
&lt;ul>
&lt;li>The message will be truncated to 256 characters.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>After policy application, connection back to the Velociraptor
frontend is tested and the policy removed if connection
unavailable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>To remove policy, select the RemovePolicy checkbox.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>To update policy, simply rerun the artifact.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>NOTE:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Remember DNS resolution may change. It is highly recommended
to plan policy accordingly and not rely on DNS lookups.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Local IPsec policy cannot be applied when Domain IPsec policy
is already enforced. Please configure at GPO level in this case.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>This artifact deliberately does not support connecting back on
plain HTTP! We only support the HTTPS or WSS protocols because
this is the recommended connectivity mechanism between server
and client.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Remediation.Quarantine
description: |
 Applies quarantine via Windows local IPsec policy.

 - By default the current client configuration is applied as an
 exclusion using resolved IP address at time of application.

 - A configurable lookup table is also used to generate
 additional entries using the same syntax as `netsh ipsec`
 configuration.

 - DNS and DHCP entries are allowed by default.

 - An optional MessageBox may also be configured to alert all
 logged in users.

 - The message will be truncated to 256 characters.

 - After policy application, connection back to the Velociraptor
 frontend is tested and the policy removed if connection
 unavailable.

 - To remove policy, select the RemovePolicy checkbox.

 - To update policy, simply rerun the artifact.

 NOTE:

 - Remember DNS resolution may change. It is highly recommended
 to plan policy accordingly and not rely on DNS lookups.

 - Local IPsec policy cannot be applied when Domain IPsec policy
 is already enforced. Please configure at GPO level in this case.

 - This artifact deliberately does not support connecting back on
 plain HTTP! We only support the HTTPS or WSS protocols because
 this is the recommended connectivity mechanism between server
 and client.

author: Matt Green - @mgreen27

reference:
 - https://mgreen27.github.io/posts/2020/07/23/IPSEC.html

required_permissions:
 - EXECVE
 - NETWORK

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: PolicyName
 default: "VelociraptorQuarantine"
 - name: RuleLookupTable
 type: csv
 default: |
 Action,SrcAddr,SrcMask,SrcPort,DstAddr,DstMask,DstPort,Protocol,Mirrored,Description
 Permit,me,,0,any,,53,udp,yes,DNS
 Permit,me,,0,any,,53,tcp,yes,DNS TCP
 Permit,me,,68,any,,67,udp,yes,DHCP
 Block,any,,,any,,,,yes,All other traffic

 - name: MessageBox
 description: |
 Optional message box notification to send to logged in users. 256
 character limit.

 - name: RemovePolicy
 type: bool
 description: Tickbox to remove policy.

 - name: VelociraptorURL
 description: |
 A URL for allowing connections back to the
 Velociraptor server. If not specified we use the first URL in the
 client's configuration file.

sources:
 - query: |
 LET AllURLs &amp;lt;= filter(list=config.server_urls + VelociraptorURL, regex='.+')

 // If a MessageBox configured truncate to 256 character limit
 LET MessageBox &amp;lt;= parse_string_with_regex(
 regex='^(?P&amp;lt;Message&amp;gt;.{0,255}).*',
 string=MessageBox).Message

 // Normalise Action
 LET normalise_action(Action)=if(condition= lowcase(string=Action)= 'permit',
 then= 'Permit',
 else= if(condition= lowcase(string=Action)= 'block',
 then= 'Block'))

 // extract configurable policy from lookuptable
 LET configurable_policy &amp;lt;= SELECT
 normalise_action(Action=Action) AS Action,
 SrcAddr,SrcMask,SrcPort,
 DstAddr,DstMask,DstPort,
 Protocol,Mirrored,Description
 FROM RuleLookupTable

 // Parse a URL to get domain name.
 LET get_domain(URL) = split(string=url(parse=URL).Host, sep=":")[0]

 // Parse a URL to get the port or use 443. We deliberately do
 // not support plain http!
 LET get_port(URL) = if(condition=url(parse=URL).Host =~ ":",
 then=split(string=url(parse=URL).Host, sep=":")[1],
 else="443")

 // extract Velociraptor config for policy
 LET extracted_config &amp;lt;= SELECT * FROM foreach(
 row= AllURLs,
 query={
 SELECT
 'Permit' AS Action,
 'me' AS SrcAddr,
 '' As SrcMask,
 '0' AS SrcPort,
 get_domain(URL=_value) AS DstAddr,
 '' As DstMask,
 get_port(URL=_value) AS DstPort,
 'tcp' AS Protocol,
 'yes' AS Mirrored,
 'VelociraptorFrontEnd' AS Description,
 _value AS URL
 FROM scope()
 })

 // build policy with extracted config and lookuptable
 LET policy &amp;lt;= SELECT *
 FROM chain(
 a=extracted_config,
 b=configurable_policy
 )
 WHERE Action =~ '^(Permit|Block)$'

 // Removes empty options from the command line
 LET clean_cmdline(CMD) = filter(list=CMD, regex='^(\\w+|\\w+=.+)$')

 LET delete_cmdline = clean_cmdline(
 CMD=('netsh','ipsec','static','delete','policy', 'name=' + PolicyName))

 LET create_cmdline = clean_cmdline(
 CMD=('netsh','ipsec','static','add','policy', 'name=' + PolicyName))

 LET action_cmdline(Action) = clean_cmdline(
 CMD=('netsh','ipsec','static','add','filteraction',
 'name=' + PolicyName + ' ' + Action + 'Action',
 'action=' + Action))

 LET rule_cmdline(Action) = clean_cmdline(
 CMD=('netsh','ipsec','static','add','rule',
 'name=' + PolicyName + ' ' + Action + 'Rule',
 'policy=' + PolicyName,
 'filterlist=' + PolicyName + ' ' + Action + 'FilterList',
 'filteraction=' + PolicyName + ' ' + Action + 'Action'))

 LET enable_cmdline = clean_cmdline(
 CMD=('netsh','ipsec','static','set','policy',
 'name=' + PolicyName, 'assign=y'))

 // Emit the message if no output is emitted, otherwise emit the output.
 LET combine_results(Stdout, Stderr, ReturnCode, Message) = if(
 condition=Stdout =~ "[^\\s]", then=Stdout,
 else= if(condition=Stderr =~ "[^\\s]", then=Stderr,
 else= if(condition= ReturnCode=0,
 then=Message )))

 // delete old or unwanted policy
 LET delete_policy = SELECT
 timestamp(epoch=now()) as Time,
 PolicyName + ' IPsec policy removed.' AS Result
 FROM execve(argv=delete_cmdline, length=10000)

 // first step is creating IPsec policy
 LET create_policy = SELECT
 timestamp(epoch=now()) as Time,
 combine_results(Stdout=Stdout, Stderr=Stderr,
 ReturnCode=ReturnCode,
 Message=PolicyName + ' IPsec policy created.') AS Result
 FROM execve(argv=create_cmdline, length=10000)

 LET entry_cmdline(Action, SrcAddr, SrcPort, SrcMask,
 DstAddr, DstPort, DstMask, Protocol,
 Mirrored, Description) = clean_cmdline(
 CMD=('netsh','ipsec','static','add','filter',
 format(format='filterlist=%s %sFilterList', args=[PolicyName, Action]),
 format(format='srcaddr=%v', args=SrcAddr),
 format(format='srcmask=%v', args=SrcMask),
 format(format='srcport=%v', args=SrcPort),
 format(format='dstaddr=%v', args=DstAddr),
 format(format='dstmask=%v', args=DstMask),
 format(format='dstport=%v', args=DstPort),
 format(format='protocol=%v', args=Protocol),
 format(format='mirrored=%v', args=Mirrored),
 format(format='description=%v', args=Description)))

 // second step is to create policy filters
 LET create_filters = SELECT * FROM foreach(row=policy,
 query={
 SELECT
 timestamp(epoch=now()) as Time,
 combine_results(Stdout=Stdout, Stderr=Stderr,
 ReturnCode=ReturnCode,
 Message='Entry added: ' +
 join(array=entry_cmdline(Action=Action,
 SrcAddr=SrcAddr, SrcPort=SrcPort, SrcMask=SrcMask,
 DstAddr=DstAddr, DstPort=DstPort, DstMask=DstMask,
 Protocol=Protocol, Mirrored=Mirrored,
 Description=Description), sep=" ")) AS Result
 FROM execve(argv=entry_cmdline(Action=Action,
 SrcAddr=SrcAddr, SrcPort=SrcPort, SrcMask=SrcMask,
 DstAddr=DstAddr, DstPort=DstPort, DstMask=DstMask,
 Protocol=Protocol, Mirrored=Mirrored,
 Description=Description), length=10000)
 })

 // third step is to create policy filter actions
 LET create_actions = SELECT * FROM foreach(
 row= {
 SELECT Action
 FROM policy
 GROUP BY Action
 },
 query={
 SELECT
 timestamp(epoch=now()) as Time,
 combine_results(Stdout=Stdout, Stderr=Stderr,
 ReturnCode=ReturnCode,
 Message='FilterAction added: ' +
 join(array=action_cmdline(Action=Action), sep=" ")) AS Result
 FROM execve(argv=action_cmdline(Action=Action), length=10000)
 })

 // fourth step combines action lists and actions in a Rule
 LET create_rules = SELECT * FROM foreach(
 row= {
 SELECT Action
 FROM policy
 GROUP BY Action
 },
 query={
 SELECT
 timestamp(epoch=now()) as Time,
 combine_results(Stdout=Stdout, Stderr=Stderr,
 ReturnCode=ReturnCode,
 Message='Rule added: ' +
 join(array=rule_cmdline(Action=Action), sep=" ")) AS Result
 FROM execve(argv=rule_cmdline(Action=Action), length=10000)
 })

 // fith step is to enable our IPsec policy
 LET enable_policy = SELECT
 timestamp(epoch=now()) as Time,
 combine_results(Stdout=Stdout, Stderr=Stderr,
 ReturnCode=ReturnCode,
 Message=PolicyName + ' IPsec policy applied.') AS Result
 FROM execve(argv=enable_cmdline, length=10000)

 // test connection to a frontend server
 LET test_connection = SELECT * FROM foreach(
 row={
 SELECT * FROM policy
 WHERE Description = 'VelociraptorFrontEnd'
 },
 query={
 SELECT *
 Url,
 response
 FROM
 -- Always use https even when configured for wss
 http_client(url=url(
 scheme='https',
 host=DstAddr + ':' + DstPort,
 path='/server.pem').String)

 WHERE Response = 200
 LIMIT 1
 })

 // final check to keep or remove policy
 LET final_check = SELECT * FROM if(condition= test_connection,
 then={
 SELECT
 timestamp(epoch=now()) as Time,
 if(condition=MessageBox,
 then= PolicyName + ' connection test successful. MessageBox sent.',
 else= PolicyName + ' connection test successful.'
 ) AS Result
 FROM if(condition=MessageBox,
 then= {
 SELECT * FROM execve(argv=['msg','*',MessageBox])
 },
 else={
 SELECT * FROM scope()
 })
 },
 else={
 SELECT
 timestamp(epoch=now()) as Time,
 PolicyName + ' failed connection test. Removing IPsec policy.' AS Result
 FROM delete_policy
 })

 // Execute content
 SELECT * FROM if(condition=RemovePolicy,
 then=delete_policy,
 else={
 SELECT * FROM chain(
 a=delete_policy,
 b=create_policy,
 c=create_filters,
 d=create_actions,
 e=create_rules,
 g=enable_policy,
 h=final_check)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Remediation.QuarantineMonitor</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.quarantinemonitor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.quarantinemonitor/</guid><description>&lt;p>An event query that will ensure the client is quarantined.&lt;/p>
&lt;p>We re-calculate the quarantine every 10 minutes by default to
account for changes in DNS/connectivity details. When the query is
terminated, we undo the quarantine.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Remediation.QuarantineMonitor
description: |
 An event query that will ensure the client is quarantined.

 We re-calculate the quarantine every 10 minutes by default to
 account for changes in DNS/connectivity details. When the query is
 terminated, we undo the quarantine.

type: CLIENT_EVENT

required_permissions:
 - EXECVE

parameters:
 - name: PolicyName
 default: "VelociraptorQuarantine"
 - name: RuleLookupTable
 type: csv
 default: |
 Action,SrcAddr,SrcMask,SrcPort,DstAddr,DstMask,DstPort,Protocol,Mirrored,Description
 Permit,me,,0,any,,53,udp,yes,DNS
 Permit,me,,0,any,,53,tcp,yes,DNS TCP
 Permit,me,,68,any,,67,udp,yes,DHCP
 Block,any,,,any,,,,yes,All other traffic
 - name: MessageBox
 description: |
 Optional message box notification to send to logged in users. 256
 character limit.
 - name: ReloadPeriod
 description: Reload the ipsec policy every this many seconds on the endpoint.
 default: "600"
 type: int

precondition:
 SELECT OS FROM info() WHERE OS = "windows"
 AND version(function="atexit") &amp;gt;= 0

sources:
 - query: |
 -- When the query is done we unset the policy.
 LET _ &amp;lt;= atexit(query={
 SELECT * FROM Artifact.Windows.Remediation.Quarantine(
 PolicyName=PolicyName, RemovePolicy=TRUE)
 })

 SELECT * FROM foreach(
 row={
 SELECT * FROM clock(period=ReloadPeriod, start=now())
 WHERE log(message="Setting quarantine policy")
 },
 query={
 SELECT * FROM Artifact.Windows.Remediation.Quarantine(
 PolicyName=PolicyName, RuleLookupTable=RuleLookupTable,
 MessageBox=MessageBox)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Remediation.ScheduledTasks</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.scheduledtasks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.scheduledtasks/</guid><description>&lt;p>Remove malicious task from the Windows scheduled task list.&lt;/p>
&lt;p>WARNING: Removing scheduled tasks is potentially dangerous! You need to test
this thoroughly before deploying this artifact widely to clients.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Remediation.ScheduledTasks
description: |
 Remove malicious task from the Windows scheduled task list.

 WARNING: Removing scheduled tasks is potentially dangerous! You need to test
 this thoroughly before deploying this artifact widely to clients.

type: CLIENT

required_permissions:
 - EXECVE

parameters:
 - name: script
 default: |
 Unregister-ScheduledTask -TaskName "%s" -Confirm:$false
 - name: TasksPath
 default: c:/Windows/System32/Tasks/**
 - name: ArgumentRegex
 default: ThisIsAUniqueName
 type: regex
 - name: CommandRegEx
 default: ThisIsAUniqueName
 type: regex
 - name: PowerShellExe
 default: "C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe"
 - name: ReallyDoIt
 type: bool
 default: N

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET task_paths = SELECT Name, OSPath
 FROM glob(globs=TasksPath)
 WHERE NOT IsDir

 LET parse_task = select OSPath, Name, parse_xml(
 accessor='data',
 file=regex_replace(
 source=utf16(string=Data),
 re='&amp;lt;[?].+?&amp;gt;',
 replace='')) AS XML
 FROM read_file(filenames=OSPath)

 LET tasks = SELECT OSPath, Name,
 XML.Task.Actions.Exec.Command as Command,
 XML.Task.Actions.Exec.Arguments as Arguments,
 XML.Task.Actions.ComHandler.ClassId as ComHandler,
 XML.Task.Principals.Principal.UserId as UserId,
 XML as _XML
 FROM foreach(row=task_paths, query=parse_task)
 WHERE (Arguments =~ ArgumentRegex AND Command =~ CommandRegEx) AND
 log(message="Removing task %v", args=Name)

 SELECT * FROM foreach(row=tasks,
 query={
 SELECT * FROM if(condition= ReallyDoIt='Y',
 then={
 SELECT OSPath, Name, Command, Arguments, ComHandler, UserId, _XML
 FROM execve(argv=[PowerShellExe,
 "-ExecutionPolicy", "Unrestricted", "-encodedCommand",
 base64encode(string=utf16_encode(
 string=format(format=script, args=[Name])))
 ])
 }, else={
 SELECT OSPath, Name, Command, Arguments, ComHandler, UserId, _XML
 FROM scope()
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Remediation.Sinkhole</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.sinkhole/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.remediation.sinkhole/</guid><description>&lt;p>&lt;strong>Apply a Sinkhole via Windows hosts file modification&lt;/strong>
This content will modify the Windows hosts file by a configurable
lookup table.&lt;/p>
&lt;p>On application, the original configuration is backed up.
When reapplying a sinkhole, the original configuration is restored then
changes applied to maintain integrity of the restore process.
If RestoreBackup is selected the artifact will restore the backup
configuration, then delete the backup with no further processing.&lt;/p>
&lt;p>NOTE:
Modifying the hosts file may cause network communication issues. I have
disabled any sinkhole settings on the Velociraptor agent configuration
but there are no rail guards on other domains. Use with caution.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Remediation.Sinkhole
description: |
 **Apply a Sinkhole via Windows hosts file modification**
 This content will modify the Windows hosts file by a configurable
 lookup table.

 On application, the original configuration is backed up.
 When reapplying a sinkhole, the original configuration is restored then
 changes applied to maintain integrity of the restore process.
 If RestoreBackup is selected the artifact will restore the backup
 configuration, then delete the backup with no further processing.

 NOTE:
 Modifying the hosts file may cause network communication issues. I have
 disabled any sinkhole settings on the Velociraptor agent configuration
 but there are no rail guards on other domains. Use with caution.

author: Matt Green - @mgreen27

required_permissions:
 - EXECVE

implied_permissions:
 - FILESYSTEM_WRITE

type: CLIENT

parameters:
 - name: HostsFile
 description: Path to hosts file
 default: C:\Windows\System32\drivers\etc\hosts
 - name: HostsFileBackup
 description: Name to backup original hosts file. If reapplying the artifact this file is used as the base.
 default: C:\Windows\System32\drivers\etc\hosts.velociraptor.backup
 - name: CommentPrefix
 description: Prefix to add to description in hosts file comments.
 default: "Velociraptor sinkhole"
 - name: RestoreBackup
 description: "Restore hosts file backup"
 type: bool
 - name: SinkholeTable
 description: Table of Domains to add to or modify in hosts file.
 type: csv
 default: |
 Domain,Sinkhole,Description
 evil.com,127.0.0.1,Evilcorp C2 domain


sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- Extract sink hole requirements from table
 LET changes &amp;lt;= SELECT
 Domain,
 Sinkhole,
 if(condition=Description,
 then= CommentPrefix + ': ' + Description,
 else= CommentPrefix) as Description
 FROM SinkholeTable

 -- Check for backup to determine if sinkhole applied
 LET check_backup = SELECT OSPath FROM stat(filename=HostsFileBackup)
 WHERE log(message="Found backup at %v", args=OSPath)

 -- Backup old config
 LET backup = copy(filename=HostsFile,dest=HostsFileBackup)

 -- Restore old config
 LET restore = SELECT * FROM chain(
 z=log(message="Will restore from backup"),
 a=copy(filename=HostsFileBackup,dest=HostsFile),
 b={
 SELECT *
 FROM if(condition=RestoreBackup,
 then={
 SELECT *
 FROM execve(argv=['cmd.exe', '/c',
 'del','/F',HostsFileBackup])
 })
 })

 -- Write hosts file
 LET write(DataBlob) = copy(filename=DataBlob,dest=HostsFile,accessor='data')

 -- FlushDNS
 LET flushdns = SELECT *
 FROM execve(argv=['cmd.exe', '/c','ipconfig','/flushdns'])

 -- Find existing entries to modify
 LET existing &amp;lt;= SELECT
 parse_string_with_regex(
 string=Line,
 regex=[
 "^\\s+(?P&amp;lt;Resolution&amp;gt;[^\\s]+)\\s+" +
 "(?P&amp;lt;Hostname&amp;gt;[^\\s]+)\\s*\\S*$"
 ]) as Record,
 Line
 FROM parse_lines(filename=HostsFile)
 WHERE
 Record AND Line
 AND NOT Line =~ '^#'

 -- Parse a URL to get domain name.
 LET get_domain(URL) = parse_string_with_regex(
 string=URL, regex='^https?://(?P&amp;lt;Domain&amp;gt;[^:/]+)').Domain

 -- extract Velociraptor config for policy
 LET extracted_config &amp;lt;= SELECT * FROM foreach(
 row=config.server_urls,
 query={
 SELECT get_domain(URL=_value) AS Domain
 FROM scope()
 })

 -- Set existing entries to sinkholed values
 LET find_modline &amp;lt;= SELECT * FROM foreach(row=changes,
 query={
 SELECT
 format(format='\t%v\t\t%v\t\t# %v',
 args=[Sinkhole,Domain,Description]) as Line,
 Domain,
 'modification' as Type
 FROM existing
 WHERE
 Record.Hostname = Domain
 AND NOT Domain in extracted_config.Domain
 GROUP BY Line
 })

 -- Add new hostsfile entries
 LET find_newline &amp;lt;= SELECT * FROM foreach(row=changes,
 query={
 SELECT
 format(format='\t%v\t\t%v\t\t# %v',
 args=[Sinkhole,Domain,Description]) as Line,
 Domain,
 'new entry' as Type
 FROM scope()
 WHERE
 NOT Domain in find_modline.Domain
 AND NOT Domain in extracted_config.Domain
 })

 -- Determine which lines should stay the same
 LET find_line &amp;lt;= SELECT
 Line,
 Record.Hostname as Domain,
 'old entry' as Type
 FROM existing
 WHERE
 NOT Domain in find_modline.Domain
 AND NOT Domain in find_newline.Domain

 -- Add all lines to staging object
 LET build_lines &amp;lt;= SELECT Line FROM chain(
 a=find_modline,
 b=find_newline,
 c=find_line
 )

 -- Join lines from staging object
 LET HostsData = join(array=build_lines.Line,sep='\r\n')

 -- Force start of backup or restore if applicable
 LET backup_restore &amp;lt;= if(
 condition= RestoreBackup AND log(message="Will attempt to restore backup"),
 then= if(
 condition= check_backup,
 then= restore,
 -- then= { SELECT * FROM restore },
 else= log(message='Can not restore hosts file as backup does not exist.')),

 else= if(
 condition= check_backup,
 then={
 SELECT * FROM chain(
 a= log(message='Backup hosts file already exists.'),
 b= restore)
 },
 else= backup)
 )

 -- Do kick off logic
 LET do_it &amp;lt;= SELECT * FROM if(condition= NOT RestoreBackup,
 then= {
 SELECT * FROM chain(
 a= log(message='Adding hosts entries.'),
 b= write(DataBlob=HostsData),
 c= flushdns
 )})

 -- Finally show resultant HostsFile
 SELECT * FROM Artifact.Windows.System.HostsFile(HostsFile=HostsFile)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Search.FileFinder</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.search.filefinder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.search.filefinder/</guid><description>&lt;p>Find files on the filesystem using the filename or content.&lt;/p>
&lt;h2 id="performance-note">Performance Note&lt;/h2>
&lt;p>This artifact can be quite expensive, especially if we search file
content. It will require opening each file and reading its entire
content. To minimize the impact on the endpoint we recommend this
artifact is collected with a rate limited way (about 20-50 ops per
second).&lt;/p>
&lt;p>This artifact is useful in the following scenarios:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>We need to locate all the places on our network where customer
data has been copied.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We’ve identified malware in a data breach, named using short
random strings in specific folders and need to search for other
instances across the network.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We believe our user account credentials have been dumped and
need to locate them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We need to search for exposed credit card data to satisfy PCI
requirements.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We have a sample of data that has been disclosed and need to
locate other similar files&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Search.FileFinder
description: |
 Find files on the filesystem using the filename or content.


 ## Performance Note

 This artifact can be quite expensive, especially if we search file
 content. It will require opening each file and reading its entire
 content. To minimize the impact on the endpoint we recommend this
 artifact is collected with a rate limited way (about 20-50 ops per
 second).

 This artifact is useful in the following scenarios:

 * We need to locate all the places on our network where customer
 data has been copied.

 * We’ve identified malware in a data breach, named using short
 random strings in specific folders and need to search for other
 instances across the network.

 * We believe our user account credentials have been dumped and
 need to locate them.

 * We need to search for exposed credit card data to satisfy PCI
 requirements.

 * We have a sample of data that has been disclosed and need to
 locate other similar files


precondition:
 SELECT * FROM info() where OS = 'windows'

parameters:
 - name: SearchFilesGlobTable
 type: csv
 default: |
 Glob
 C:/Users/SomeUser/*
 description: Specify multiple globs to search for.

 - name: Accessor
 default: auto
 description: The accessor to use
 type: choices
 choices:
 - auto
 - registry
 - file
 - ntfs
 - ntfs_vss

 - name: YaraRule
 type: yara
 default:
 description: A yara rule to search for matching files.

 - name: Upload_File
 default: N
 type: bool

 - name: Calculate_Hash
 default: N
 type: bool

 - name: MoreRecentThan
 default: ""
 type: timestamp

 - name: ModifiedBefore
 default: ""
 type: timestamp

 - name: VSS_MAX_AGE_DAYS
 type: int
 description: |
 If larger than 0 we restrict VSS age to this many days
 ago. Otherwise we find all VSS.

 - name: UPLOAD_IS_RESUMABLE
 type: bool
 default: Y
 description: If set, file uploads will be asynchronous and resumable.

sources:
 - query: |
 LET file_search = SELECT OSPath,
 get(item=Data, field="mft") as Inode,
 Mode.String AS Mode, Size,
 Mtime AS MTime,
 Atime AS ATime,
 Btime AS BTime,
 Ctime AS CTime, "" AS Keywords,
 IsDir, Data
 FROM glob(globs=SearchFilesGlobTable.Glob,
 accessor=Accessor)

 LET more_recent = SELECT * FROM if(
 condition=MoreRecentThan,
 then={
 SELECT * FROM file_search
 WHERE MTime &amp;gt; MoreRecentThan
 }, else=file_search)

 LET modified_before = SELECT * FROM if(
 condition=ModifiedBefore,
 then={
 SELECT * FROM more_recent
 WHERE MTime &amp;lt; ModifiedBefore
 AND MTime &amp;gt; MoreRecentThan
 }, else=more_recent)

 LET keyword_search = SELECT * FROM if(
 condition=YaraRule,
 then={
 SELECT * FROM foreach(
 row={
 SELECT * FROM modified_before
 WHERE NOT IsDir
 },
 query={
 SELECT OSPath, Inode, Mode,
 Size, MTime, ATime, CTime, BTime,
 str(str=String.Data) As Keywords, IsDir, Data

 FROM yara(files=OSPath,
 key="A",
 rules=YaraRule,
 accessor=Accessor)
 })
 }, else=modified_before)

 SELECT OSPath, Inode, Mode, Size, MTime, ATime,
 CTime, BTime, Keywords, IsDir,
 if(condition=Upload_File and NOT IsDir,
 then=upload(file=OSPath, accessor=Accessor)) AS Upload,
 if(condition=Calculate_Hash and NOT IsDir,
 then=hash(path=OSPath, accessor=Accessor)) AS Hash,
 Data
 FROM keyword_search

column_types:
 - name: Modified
 type: timestamp
 - name: ATime
 type: timestamp
 - name: MTime
 type: timestamp
 - name: CTime
 type: timestamp
 - name: Upload
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.Search.SMBFileFinder</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.search.smbfilefinder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.search.smbfilefinder/</guid><description>&lt;p>Find files on a remote filesystem using the filename or content.&lt;/p>
&lt;h2 id="security-note">Security Note&lt;/h2>
&lt;p>To access a remote share we require the credentials of a
domain user. Currently only username/password are supported (i.e. no
Kerberose). You should use Group Policy to create a user with read
only access to the remote share.&lt;/p>
&lt;h2 id="performance-note">Performance Note&lt;/h2>
&lt;p>This artifact can be quite expensive slow and generate a lot of
network data, especially if we search file content. It will require
opening each file and reading its entire content. To minimize the
impact on the endpoint we recommend this artifact is collected with
a rate limited way (about 20-50 ops per second).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Search.SMBFileFinder
description: |
 Find files on a remote filesystem using the filename or content.

 ## Security Note

 To access a remote share we require the credentials of a
 domain user. Currently only username/password are supported (i.e. no
 Kerberose). You should use Group Policy to create a user with read
 only access to the remote share.

 ## Performance Note

 This artifact can be quite expensive slow and generate a lot of
 network data, especially if we search file content. It will require
 opening each file and reading its entire content. To minimize the
 impact on the endpoint we recommend this artifact is collected with
 a rate limited way (about 20-50 ops per second).

parameters:
 - name: ServerName
 default: 127.0.0.1:445
 description: |
 The name of the server to contact. If a port is not specified we
 use port 445

 - name: Username
 default: Guest
 type: redacted
 description: The name of a network user to access the remote share with.

 - name: Password
 default: password
 type: redacted
 description: The password to use for accessing the remote share.

 - name: SearchFilesGlob
 default: C$\Users\*
 description: |
 Use a glob to define the files that will be searched. The glob
 must contain the share name as the first component.

 - name: SearchFilesGlobTable
 type: csv
 default: |
 Glob
 C$/Users/SomeUser/*
 description: Alternative specify multiple globs in a table

 - name: YaraRule
 type: yara
 default:
 description: A yara rule to search for matching files.

 - name: Upload_File
 default: N
 type: bool

 - name: Calculate_Hash
 default: N
 type: bool

 - name: MoreRecentThan
 default: ""
 type: timestamp

 - name: ModifiedBefore
 default: ""
 type: timestamp


sources:
 - query: |
 LET SMB_CREDENTIALS &amp;lt;= set(item=dict(), field=ServerName,
 value=format(format="%s:%s", args=[Username, Password]))

 LET file_search = SELECT OSPath,
 get(item=Data, field="mft") as Inode,
 Mode.String AS Mode, Size,
 Mtime AS MTime,
 Atime AS ATime,
 Btime AS BTime,
 Ctime AS CTime, "" AS Keywords,
 IsDir, Data
 FROM glob(globs=SearchFilesGlobTable.Glob + SearchFilesGlob,
 root=ServerName,
 accessor="smb")

 LET more_recent = SELECT * FROM if(
 condition=MoreRecentThan,
 then={
 SELECT * FROM file_search
 WHERE MTime &amp;gt; MoreRecentThan
 }, else=file_search)

 LET modified_before = SELECT * FROM if(
 condition=ModifiedBefore,
 then={
 SELECT * FROM more_recent
 WHERE MTime &amp;lt; ModifiedBefore
 AND MTime &amp;gt; MoreRecentThan
 }, else=more_recent)

 LET keyword_search = SELECT * FROM if(
 condition=YaraRule,
 then={
 SELECT * FROM foreach(
 row={
 SELECT * FROM modified_before
 WHERE NOT IsDir
 },
 query={
 SELECT OSPath, Inode, Mode,
 Size, MTime, ATime, CTime, BTime,
 str(str=String.Data) As Keywords, IsDir, Data

 FROM yara(files=OSPath,
 key="A",
 rules=YaraRule,
 accessor="smb")
 })
 }, else=modified_before)

 SELECT OSPath, Inode, Mode, Size, MTime, ATime,
 CTime, BTime, Keywords, IsDir,
 if(condition=Upload_File and NOT IsDir,
 then=upload(file=OSPath, accessor="smb")) AS Upload,
 if(condition=Calculate_Hash and NOT IsDir,
 then=hash(path=OSPath, accessor="smb")) AS Hash,
 Data
 FROM keyword_search

column_types:
 - name: Modified
 type: timestamp
 - name: ATime
 type: timestamp
 - name: MTime
 type: timestamp
 - name: CTime
 type: timestamp
 - name: Upload
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.Search.VSS</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.search.vss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.search.vss/</guid><description>&lt;p>This artifact will find all relevant files in the VSS. Typically
used to out deduplicated paths for processing by other artifacts.&lt;/p>
&lt;p>NOTE: This used to be more complicated but now delegates to the
&amp;ldquo;ntfs_vss&amp;rdquo; accessor to do all the work.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Search.VSS
description: |
 This artifact will find all relevant files in the VSS. Typically
 used to out deduplicated paths for processing by other artifacts.

 NOTE: This used to be more complicated but now delegates to the
 "ntfs_vss" accessor to do all the work.

author: Matt Green - @mgreen27

precondition: SELECT * FROM info() where OS = 'windows'

parameters:
 - name: SearchFilesGlob
 default: C:\Windows\System32\winevt\Logs\Security.evtx
 description: Use a glob to define the files that will be searched.

 - name: VSS_MAX_AGE_DAYS
 type: int
 description: |
 If larger than 0 we restrict VSS age to this many days
 ago. Otherwise we find all VSS.

sources:
 - query: |
 SELECT * FROM glob(globs=SearchFilesGlob, accessor="ntfs_vss")
 ORDER BY OSPath

&lt;/code>&lt;/pre></description></item><item><title>Windows.Search.WSLFileFinder</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.search.wslfilefinder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.search.wslfilefinder/</guid><description>&lt;p>Find files within the VHDX containers of the Windows Subsystem for
Linux (WSL) images.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Search.WSLFileFinder
description: |
 Find files within the VHDX containers of the Windows Subsystem for
 Linux (WSL) images.

precondition:
 SELECT * FROM info() where OS = 'windows'

parameters:
 - name: VHDXGlob
 description: Where to look for VHDX containers.
 default: "C:/Users/*/AppData/Local/wsl/**/*.vhdx"

 - name: SearchFilesGlob
 default: /home/*
 description: Use a glob to define the files that will be searched.

 - name: SearchFilesGlobTable
 type: csv
 default: |
 Glob
 /home/someuser/*
 description: Alternative specify multiple globs in a table

 - name: YaraRule
 type: yara
 default:
 description: A yara rule to search for matching files.

 - name: Upload_File
 default: N
 type: bool

 - name: Calculate_Hash
 default: N
 type: bool

 - name: MoreRecentThan
 default: ""
 type: timestamp

 - name: ModifiedBefore
 default: ""
 type: timestamp

 - name: ExcludePathRegex
 default: "^/(proc|sys|run|snap)"
 type: regex
 description: If this regex matches the path of any directory we do not even descend inside of it.

 - name: DoNotFollowSymlinks
 type: bool
 default: N
 description: If specified we are allowed to follow symlinks while globbing

sources:
 - query: |
 SELECT * FROM foreach(row={
 SELECT OSPath AS VHDXPath FROM glob(globs=VHDXGlob)
 WHERE log(message="Found VHDX file at %v", args=VHDXPath, dedup=-1)
 }, query={
 SELECT VHDXPath, OSPath.Path AS OSPath, *
 FROM Artifact.Linux.Search.FileFinder(
 SearchFilesGlob=SearchFilesGlob,
 SearchFilesGlobTable=SearchFilesGlobTable,
 YaraRule=YaraRule,
 Upload_File=Upload_File,
 Calculate_Hash=Calculate_Hash,
 MoreRecentThan=MoreRecentThan,
 ModifiedBefore=ModifiedBefore,
 ExcludePathRegex=ExcludePathRegex,
 DoNotFollowSymlinks=DoNotFollowSymlinks,
 LocalFilesystemOnly=FALSE,
 ACCESSOR="raw_ext4",
 ROOT=pathspec(DelegateAccessor="vhdx", DelegatePath=VHDXPath))
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Search.Yara</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.search.yara/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.search.yara/</guid><description>&lt;p>Searches for a specific malicious file or set of files by a YARA rule.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Search.Yara
description: |
 Searches for a specific malicious file or set of files by a YARA rule.

parameters:
 - name: nameRegex
 description: Only file names that match this regular expression will be scanned.
 default: "(exe|txt|dll|php)$"
 type: regex
 - name: AlsoUpload
 type: bool
 description: Also upload matching files.
 - name: yaraRule
 type: yara
 description: The YARA Rule to search for.
 default: |
 rule Hit {
 strings:
 $a = "Keyword" nocase wide ascii
 condition:
 any of them
 }

 - name: NTFS_CACHE_TIME
 type: int
 description: How often to flush the NTFS cache. (Default is never).
 default: "1000000"

precondition:
 SELECT * FROM info() WHERE OS =~ "windows"

sources:
 - query: |
 LET Root = pathspec(parse="C:", path_type="ntfs")

 -- Progress logging for newer clients
 LET fileList = SELECT * FROM if(condition=version(function="log") &amp;gt; 1,
 then={
 SELECT Root + OSPath AS OSPath
 FROM parse_mft(accessor="ntfs",filename=Root+"$MFT")
 WHERE InUse
 AND log(message="Processing entry %v", args=EntryNumber, dedup=5)
 AND FileName =~ nameRegex
 AND NOT OSPath =~ "WinSXS"
 AND log(message="Scanning file %v", args=OSPath, dedup=5)

 }, else={
 SELECT Root + OSPath AS OSPath
 FROM parse_mft(accessor="ntfs",filename=Root+"$MFT")
 WHERE InUse
 AND FileName =~ nameRegex
 AND NOT OSPath =~ "WinSXS"
 })

 -- These files are typically short - only report a single hit.
 LET search = SELECT Rule, String.Offset AS HitOffset,
 str(str=String.Data) AS HitContext,
 FileName,
 File.Size AS Size,
 File.ModTime AS ModTime
 FROM yara(
 rules=yaraRule, key="A",
 files= OSPath)
 LIMIT 1

 SELECT *, if(condition=AlsoUpload, then=upload(file=FileName)) AS Upload
 FROM foreach(row=fileList, query=search)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sigma.EventLogs</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sigma.eventlogs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sigma.eventlogs/</guid><description>&lt;p>Parse Windows event logs and matches then against Sigma Rules.&lt;/p>
&lt;p>NOTE: This is a very simple artifact for demonstration only. For
more extensive Sigma rules use the &lt;code>Server.Import.CuratedSigma&lt;/code>
artifact to import a curated set of Sigma rules from
&lt;a href="https://sigma.velocidex.com/" target="_blank" >https://sigma.velocidex.com/&lt;/a>
&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sigma.EventLogs
description: |
 Parse Windows event logs and matches then against Sigma Rules.

 NOTE: This is a very simple artifact for demonstration only. For
 more extensive Sigma rules use the `Server.Import.CuratedSigma`
 artifact to import a curated set of Sigma rules from
 https://sigma.velocidex.com/

parameters:
- name: EventLogDirectory
 default: C:/Windows/System32/WinEvt/Logs/
- name: InlineSigmaRules
 description: A single string of sigma rules separated by --- lines
- name: SigmaRuleFile
 type: upload
 description: A file containing sigma rules separated by --- lines
- name: Debug
 type: bool
 description: Enable full debug trace

export: |
 LET StandardSigmaLogSource &amp;lt;= sigma_log_sources(
 `process_creation/windows` = {
 SELECT *
 FROM parse_evtx(
 filename= EventLogDirectory + "/Microsoft-Windows-Sysmon%4Operational.evtx")
 },
 `*/windows/sysmon` = {
 SELECT *
 FROM parse_evtx(
 filename= EventLogDirectory + "/Microsoft-Windows-Sysmon%4Operational.evtx")
 })

 LET StandardSigmaFieldMapping &amp;lt;= dict(
 AccessList="x=&amp;gt;x.EventData.AccessList",
 AccessMask="x=&amp;gt;x.EventData.AccessMask",
 Accesses="x=&amp;gt;x.EventData.Accesses",
 AccountDomain="x=&amp;gt;x.EventData.AccountDomain",
 AccountName="x=&amp;gt;x.EventData.AccountName",
 Account_Name="x=&amp;gt;x.EventData.Account_Name",
 Action="x=&amp;gt;x.EventData.Action",
 AllowedToDelegateTo="x=&amp;gt;x.EventData.AllowedToDelegateTo",
 ApplicationPath="x=&amp;gt;x.EventData.ApplicationPath",
 AttributeLDAPDisplayName="x=&amp;gt;x.EventData.AttributeLDAPDisplayName",
 AttributeValue="x=&amp;gt;x.EventData.AttributeValue",
 AuditPolicyChanges="x=&amp;gt;x.EventData.AuditPolicyChanges",
 AuditSourceName="x=&amp;gt;x.EventData.AuditSourceName",
 AuthenticationPackageName="x=&amp;gt;x.EventData.AuthenticationPackageName",
 CallTrace="x=&amp;gt;x.EventData.CallTrace",
 CallerProcessName="x=&amp;gt;x.EventData.CallerProcessName",
 Caller_Process_Name="x=&amp;gt;x.EventData.Caller_Process_Name",
 CallingProcessName="x=&amp;gt;x.EventData.CallingProcessName",
 CategoryName="x=&amp;gt;x.EventData.`Category Name`",
 CertThumbprint="x=&amp;gt;x.EventData.CertThumbprint",
 Channel="x=&amp;gt;x.System.Channel",
 ClassName="x=&amp;gt;x.EventData.ClassName",
 ClientAddress="x=&amp;gt;x.EventData.ClientAddress",
 Client_Address="x=&amp;gt;x.EventData.Client_Address",
 ClientName="x=&amp;gt;x.EventData.ClientName",
 CommandLine="x=&amp;gt;x.EventData.CommandLine",
 Company="x=&amp;gt;x.EventData.Company",
 Computer="x=&amp;gt;x.System.Computer",
 ComputerName="x=&amp;gt;x.System.Computer",
 ContextInfo="x=&amp;gt;x.EventData.ContextInfo",
 CurrentDirectory="x=&amp;gt;x.EventData.CurrentDirectory",
 Description="x=&amp;gt;x.EventData.Description",
 DestAddress="x=&amp;gt;x.EventData.DestAddress",
 DestPort="x=&amp;gt;x.EventData.DestPort",
 Destination="x=&amp;gt;x.EventData.Destination",
 DestinationAddress="x=&amp;gt;x.EventData.DestinationAddress",
 DestinationHostname="x=&amp;gt;x.EventData.DestinationHostname",
 DestinationIp="x=&amp;gt;x.EventData.DestinationIp",
 DestinationIsIpv6="x=&amp;gt;x.EventData.DestinationIsIpv6",
 DestinationPort="x=&amp;gt;x.EventData.DestinationPort",
 Details="x=&amp;gt;x.EventData.Details",
 DetectionSource="x=&amp;gt;x.EventData.DetectionSource",
 DetectionUser="x=&amp;gt;x.EventData.`Detection User`",
 Device="x=&amp;gt;x.EventData.Device",
 DeviceClassName="x=&amp;gt;x.EventData.DeviceClassName",
 DeviceDescription="x=&amp;gt;x.EventData.DeviceDescription",
 DeviceInstanceID="x=&amp;gt;x.UserData.InstallDeviceID.DeviceInstanceID",
 DeviceName="x=&amp;gt;x.EventData.DeviceName",
 DomainName="x=&amp;gt;x.EventData.SubjectDomainName",
 DriverDescription="x=&amp;gt;x.UserData.InstallDeviceID.DriverDescription",
 DriverProvider="x=&amp;gt;x.UserData.InstallDeviceID.DriverProvider",
 InstallStatus="x=&amp;gt;x.UserData.InstallDeviceID.InstallStatus",
 EngineVersion="x=&amp;gt;x.EventData.EngineVersion",
 ErrorCode="x=&amp;gt;x.EventData.ErrorCode",
 EventID="x=&amp;gt;x.System.EventID.Value",
 EventType="x=&amp;gt;x.EventData.EventType",
 ExecutionProcessID="x=&amp;gt;x.System.Execution_attributes.ProcessID",
 FailureCode="x=&amp;gt;x.EventData.FailureCode",
 FilePath="x=&amp;gt;x.EventData.FilePath",
 FileVersion="x=&amp;gt;x.EventData.FileVersion",
 Filename="x=&amp;gt;x.EventData.Filename",
 GrantedAccess="x=&amp;gt;x.EventData.GrantedAccess",
 GroupName="x=&amp;gt;x.EventData.GroupName",
 GroupSid="x=&amp;gt;x.EventData.GroupSid",
 Hashes="x=&amp;gt;x.EventData.Hashes",
 HiveName="x=&amp;gt;x.EventData.HiveName",
 HostApplication="x=&amp;gt;x.EventData.HostApplication",
 HostName="x=&amp;gt;x.EventData.HostName",
 HostVersion="x=&amp;gt;x.EventData.HostVersion",
 Image="x=&amp;gt;x.EventData.Image",
 image="x=&amp;gt;x.EventData.Image",
 ImageLoaded="x=&amp;gt;x.EventData.ImageLoaded",
 ImagePath="x=&amp;gt;x.EventData.ImagePath",
 Imphash="x=&amp;gt;x.EventData.Hashes",
 Initiated="x=&amp;gt;x.EventData.Initiated",
 InstanceID="x=&amp;gt;x.UserData.UMDFHostDeviceArrivalBegin.InstanceId",
 IntegrityLevel="x=&amp;gt;x.EventData.IntegrityLevel",
 IpAddress="x=&amp;gt;x.EventData.IpAddress",
 IpPort="x=&amp;gt;x.EventData.IpPort",
 JobTitle="x=&amp;gt;x.EventData.name",
 KeyLength="x=&amp;gt;x.EventData.KeyLength",
 Keywords="x=&amp;gt;x.System.Keywords",
 LDAPDisplayName="x=&amp;gt;x.EventData.LDAPDisplayName",
 LayerRTID="x=&amp;gt;x.EventData.LayerRTID",
 Level="x=&amp;gt;x.System.Level",
 LogFileClearedChannel="x=&amp;gt;x.UserData.LogFileCleared.Channel",
 LogFileClearedSubjectUserName="x=&amp;gt;x.UserData.LogFileCleared.SubjectUserName",
 LogonId="x=&amp;gt;x.EventData.LogonId",
 LogonID="x=&amp;gt;x.EventData.LogonID",
 LogonProcessName="x=&amp;gt;x.EventData.LogonProcessName",
 LogonType="x=&amp;gt;x.EventData.LogonType",
 Logon_Account="x=&amp;gt;x.EventData.Logon_Account",
 MachineName="x=&amp;gt;x.EventData.MachineName",
 MemberName="x=&amp;gt;x.EventData.MemberName",
 MemberSid="x=&amp;gt;x.EventData.MemberSid",
 Message="x=&amp;gt;x.EventData",
 ModifyingApplication="x=&amp;gt;x.EventData.ModifyingApplication",
 NewName="x=&amp;gt;x.EventData.NewName",
 NewTemplateContent="x=&amp;gt; Event.EventData.NewTemplateContent",
 NewUacValue="x=&amp;gt;x.EventData.NewUacValue",
 NewValue="x=&amp;gt;x.EventData.NewValue",
 New_Value="x=&amp;gt;x.EventData.`New Value`",
 NewProcessName="x=&amp;gt;x.EventData.NewProcessName",
 NewProcessId="x=&amp;gt;x.EventData.NewProcessId",
 ObjectClass="x=&amp;gt;x.EventData.ObjectClass",
 ObjectName="x=&amp;gt;x.EventData.ObjectName",
 ObjectServer="x=&amp;gt;x.EventData.ObjectServer",
 ObjectType="x=&amp;gt;x.EventData.ObjectType",
 ObjectValueName="x=&amp;gt;x.EventData.ObjectValueName",
 OldUacValue="x=&amp;gt;x.EventData.OldUacValue",
 Origin="x=&amp;gt;x.EventData.Origin",
 OriginalFileName="x=&amp;gt;x.EventData.OriginalFileName",
 OriginalFilename="x=&amp;gt;x.EventData.OriginalFileName",
 param1="x=&amp;gt;x.EventData.param1",
 param2="x=&amp;gt;x.EventData.param2",
 param3="x=&amp;gt;x.EventData.param3",
 param4="x=&amp;gt;x.EventData.param4",
 param5="x=&amp;gt;x.EventData.param5",
 ParentCommandLine="x=&amp;gt;x.EventData.ParentCommandLine",
 ParentImage="x=&amp;gt;x.EventData.ParentImage",
 ParentIntegrityLevel="x=&amp;gt;x.EventData.ParentIntegrityLevel",
 ParentProcessName="x=&amp;gt;x.EventData.ParentProcessName",
 ParentUser="x=&amp;gt;x.EventData.ParentUser",
 PasswordLastSet="x=&amp;gt;x.EventData.PasswordLastSet",
 Path="x=&amp;gt;x.EventData.Path",
 Payload="x=&amp;gt;x.EventData.Payload",
 PipeName="x=&amp;gt;x.EventData.PipeName",
 PossibleCause="x=&amp;gt;x.UserData.PossibleCause",
 PreAuthType="x=&amp;gt;x.EventData.PreAuthType",
 PrivilegeList="x=&amp;gt;x.EventData.PrivilegeList",
 ProcessCommandLine="x=&amp;gt;x.EventData.ProcessCommandLine",
 ProcessGuid="x=&amp;gt;x.EventData.ProcessGuid",
 ProcessId="x=&amp;gt;x.EventData.ProcessId",
 ProcessName="x=&amp;gt;x.EventData.ProcessName",
 Product="x=&amp;gt;x.EventData.Product",
 Properties="x=&amp;gt;x.EventData.Properties",
 Provider="x=&amp;gt;x.UserData.Provider",
 ProviderName="x=&amp;gt;x.System.Provider_attributes.Name",
 Provider_Name="x=&amp;gt;x.System.Provider_attributes.Name",
 QNAME="x=&amp;gt;x.EventData.QNAME",
 query="x=&amp;gt;x.EventData.Query",
 Query="x=&amp;gt;x.UserData.Query",
 QueryName="x=&amp;gt;x.EventData.QueryName",
 QueryResults="x=&amp;gt;x.EventData.QueryResults",
 QueryStatus="x=&amp;gt;x.EventData.QueryStatus",
 RelativeTargetName="x=&amp;gt;x.EventData.RelativeTargetName",
 RuleName="x=&amp;gt;x.EventData.RuleName",
 SAMAccountName="x=&amp;gt;x.EventData.SamAccountName",
 ScriptBlockText="x=&amp;gt;x.EventData.ScriptBlockText",
 SearchFilter="x=&amp;gt;x.System.SearchFilter",
 SecurityUserID="x=&amp;gt;x.System.Security_attributes.UserID",
 ServerName="x=&amp;gt;x.System.ServerName",
 Service="x=&amp;gt;x.EventData.Service",
 ServiceFileName="x=&amp;gt;x.EventData.ServiceFileName",
 ServiceName="x=&amp;gt;x.EventData.ServiceName",
 ServicePrincipalNames="x=&amp;gt;x.EventData.ServicePrincipalNames",
 ServiceStartType="x=&amp;gt;x.EventData.ServiceStartType",
 ServiceType="x=&amp;gt;x.EventData.ServiceType",
 SeverityID="x=&amp;gt;x.EventData.`Severity ID`",
 SeverityName="x=&amp;gt;x.EventData.`Severity Name`",
 ShareLocalPath="x=&amp;gt;x.EventData.ShareLocalPath",
 ShareName="x=&amp;gt;x.EventData.ShareName",
 SidHistory="x=&amp;gt;x.EventData.SidHistory",
 Signature="x=&amp;gt;x.EventData.Signature",
 SignatureStatus="x=&amp;gt;x.EventData.SignatureStatus",
 Signed="x=&amp;gt;x.EventData.Signed",
 Source="x=&amp;gt;x.System.Provider_Name",
 SourceAddress="x=&amp;gt;x.EventData.SourceAddress",
 SourceImage="x=&amp;gt;x.EventData.SourceImage",
 SourceNetworkAddress="x=&amp;gt;x.EventData.SourceNetworkAddress",
 SourcePort="x=&amp;gt;x.EventData.SourcePort",
 Source_Name="x=&amp;gt;x.EventData.`Source Name`",
 Source_Network_Address="x=&amp;gt;x.EventData.Source_Network_Address",
 Source_WorkStation="x=&amp;gt;x.EventData.Source_WorkStation",
 StartAddress="x=&amp;gt;x.EventData.StartAddress",
 StartFunction="x=&amp;gt;x.EventData.StartFunction",
 StartModule="x=&amp;gt;x.EventData.StartModule",
 StartType="x=&amp;gt;x.EventData.StartType",
 State="x=&amp;gt;x.EventData.State",
 Status="x=&amp;gt;x.EventData.Status",
 SubStatus="x=&amp;gt;x.EventData.SubStatus",
 SubjectDomainName="x=&amp;gt;x.EventData.SubjectDomainName",
 SubjectLogonId="x=&amp;gt;x.EventData.SubjectLogonId",
 SubjectUserName="x=&amp;gt;x.EventData.SubjectUserName",
 SubjectUserSid="x=&amp;gt;x.EventData.SubjectUserSid",
 TargetDomainName="x=&amp;gt;x.EventData.TargetDomainName",
 TargetFilename="x=&amp;gt;x.EventData.TargetFilename",
 TargetInfo="x=&amp;gt;x.EventData.TargetInfo",
 TargetImage="x=&amp;gt;x.EventData.TargetImage",
 TargetLogonId="x=&amp;gt;x.EventData.TargetLogonId",
 TargetObject="x=&amp;gt;x.EventData.TargetObject",
 TargetProcessAddress="x=&amp;gt;x.EventData.TargetProcessAddress",
 TargetServerName="x=&amp;gt;x.EventData.TargetServerName",
 TargetSid="x=&amp;gt;x.EventData.TargetSid",
 TargetUserName="x=&amp;gt;x.EventData.TargetUserName",
 TaskDate="x=&amp;gt;x.EventData.TaskContent",
 TaskName="x=&amp;gt;x.EventData.TaskName",
 TemplateContent="x=&amp;gt;x.EventData.TemplateContent",
 ThreatName="x=&amp;gt;x.EventData.`Threat Name`",
 TicketEncryptionType="x=&amp;gt;x.EventData.TicketEncryptionType",
 TicketOptions="x=&amp;gt;x.EventData.TicketOptions",
 Url="x=&amp;gt;x.EventData.url",
 User="x=&amp;gt;x.EventData.User",
 UserName="x=&amp;gt;x.EventData.UserName",
 Value="x=&amp;gt;x.EventData.Value",
 Version="x=&amp;gt;x.System.Version",
 WindowsDefenderProcessName="x=&amp;gt;x.EventData.`Process Name`",
 Workstation="x=&amp;gt;x.EventData.Workstation",
 WorkstationName="x=&amp;gt;x.EventData.WorkstationName",
 param1="x=&amp;gt;x.EventData.param1",
 param2="x=&amp;gt;x.EventData.param2",
 service="x=&amp;gt;x.EventData.Service",
 sha1="x=&amp;gt;x.EventData.Hashes_sha1",
 UserDataProviderName="x=&amp;gt;x.UserData.Operation_StartedOperational.ProviderName",
 UserDataCode="x=&amp;gt;x.UserData.Operation_StartedOperational.Code",
 UserDataHostProcess="x=&amp;gt;x.UserData.Operation_StartedOperational.HostProcess",
 UserDataProviderPath="x=&amp;gt;x.UserData.Operation_StartedOperational.ProviderPath",
 UserDataProcessID="x=&amp;gt;x.UserData.Operation_StartedOperational.ProcessID",
 UserDataNamespace="x=&amp;gt;x.UserData.Operation_ESStoConsumerBinding.Namespace",
 UserDataNamespaceName="x=&amp;gt;x.UserData.Operation_TemporaryEssStarted.NamespaceName",
 UserDataQuery="x=&amp;gt;x.UserData.Operation_TemporaryEssStarted.Query",
 UserDataUser="x=&amp;gt;x.UserData.Operation_TemporaryEssStarted.User",
 UserDataProcessid="x=&amp;gt;x.UserData.Operation_TemporaryEssStarted.Processid",
 UserDataConsumer="x=&amp;gt;x.UserData.Operation_ESStoConsumerBinding.CONSUMER",
 UserDataESS="x=&amp;gt;x.UserData.Operation_ESStoConsumerBinding.ESS",
 UserDataPossibleCause="x=&amp;gt;x.UserData.Operation_ESStoConsumerBinding.PossibleCause",
 UserDataParam1="x=&amp;gt;x.UserData.EventXML.Param1",
 UserDataParam2="x=&amp;gt;x.UserData.EventXML.Param2",
 UserDataParam3="x=&amp;gt;x.UserData.EventXML.Param3",
 UserDataUser="x=&amp;gt;x.UserData.EventXML.User",
 UserDataSessionID="x=&amp;gt;x.UserData.EventXML.SessionID",
 UserDataAddress="x=&amp;gt;x.UserData.EventXML.Address",
 SysmonVersion="x=&amp;gt;x.EventData.SysmonVersion",
 OperationEssStartedNamespaceName="x=&amp;gt;x.UserData.Operation_EssStarted.NamespaceName",
 OperationEssStartedQuery="x=&amp;gt;x.UserData.Operation_EssStarted.Query",
 OperationEssStartedUser="x=&amp;gt;x.UserData.Operation_EssStarted.User",
 OperationEssStartedProcessid="x=&amp;gt;x.UserData.Operation_EssStarted.Processid",
 OperationEssStartedProvider="x=&amp;gt;x.UserData.Operation_EssStarted.Provider",
 OperationEssStartedPossibleCause="x=&amp;gt;x.UserData.Operation_EssStarted.PossibleCause",
 DvrFmwkInstanceId="x=&amp;gt;x.UserData.UMDFHostDeviceRequest.InstanceId",
 DvrFmwk2003InstanceId="x=&amp;gt;x.UserData.UMDFHostDeviceArrivalBegin.InstanceId"
 )

sources:
- query: |
 LET Rules = InlineSigmaRules ||
 if(condition=SigmaRuleFile, then=SigmaRuleFile)

 SELECT * FROM sigma(
 rules=split(string= Rules, sep_string="\n---\n"),
 log_sources= StandardSigmaLogSource, debug=Debug,
 field_mapping= StandardSigmaFieldMapping)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.AllUsers</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.allusers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.allusers/</guid><description>&lt;p>List User accounts. We combine two data sources - the output from
the &lt;code>NetUserEnum&lt;/code> API (termed &lt;code>local&lt;/code> users) and the list of SIDs in
the registry (termed &lt;code>remote&lt;/code> users).&lt;/p>
&lt;p>In this artifact, &amp;lsquo;remote&amp;rsquo; means that user profile was cached in the
registry, but the user does not appear in the output of the
&lt;code>NetUserEnum&lt;/code> API - this normally happens for users remotely logging
into the system using domain credentials.&lt;/p>
&lt;p>On Domain Controllers the &lt;code>NetUserEnum&lt;/code> API will return the contents
of the entire ActiveDirectory as a list of &amp;rsquo;local&amp;rsquo; users, however
this does not mean that the users have logged into the DC
locally. In this artifact we limit the number of users to 1000. If
you need to obtain the full list from the AD, customize this
artifact.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.AllUsers
description: |
 List User accounts. We combine two data sources - the output from
 the `NetUserEnum` API (termed `local` users) and the list of SIDs in
 the registry (termed `remote` users).

 In this artifact, 'remote' means that user profile was cached in the
 registry, but the user does not appear in the output of the
 `NetUserEnum` API - this normally happens for users remotely logging
 into the system using domain credentials.

 On Domain Controllers the `NetUserEnum` API will return the contents
 of the entire ActiveDirectory as a list of 'local' users, however
 this does not mean that the users have logged into the DC
 locally. In this artifact we limit the number of users to 1000. If
 you need to obtain the full list from the AD, customize this
 artifact.

parameters:
 - name: remoteRegKey
 default: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\ProfileList\*

export: |
 -- Cache function for lookupSID
 LET LookupSIDCache(SID) = cache(name="SID", key=SID,
 func=lookupSID(sid=SID) ||

 -- resolve usernames via registry if lookupSID is not available
 -- or yields no results

 pathspec(parse=stat(accessor="registry",
 filename="HKEY_LOCAL_MACHINE/Software/Microsoft/Windows NT/CurrentVersion/ProfileList/" +
 SID + "/ProfileImagePath").Data.value).Basename || "")

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 LET GetTimestamp(High, Low) = if(condition=High,
 then=timestamp(winfiletime=High * 4294967296 + Low))

 -- lookupSID() may not be available on deaddisk analysis
 LET roaming_users &amp;lt;=
 SELECT
 split(string=Key.OSPath.Basename, sep="-")[-1] as Uid,
 "" AS Gid,
 LookupSIDCache(SID=Key.OSPath.Basename || "") AS Name,
 Key.OSPath as Description,
 ProfileImagePath as Directory,
 Key.OSPath.Basename as UUID,
 Key.Mtime as Mtime,
 {
 SELECT Mtime
 FROM stat(filename=expand(path=ProfileImagePath))
 } AS HomedirMtime,
 dict(ProfileLoadTime=GetTimestamp(
 High=LocalProfileLoadTimeHigh, Low=LocalProfileLoadTimeLow),
 ProfileUnloadTime=GetTimestamp(
 High=LocalProfileUnloadTimeHigh, Low=LocalProfileUnloadTimeLow),
 ProfileImagePath=ProfileImagePath,
 ProfileKey=Key.OSPath
 ) AS Data
 FROM read_reg_key(globs=remoteRegKey, accessor="registry")


 LET roaming_users_lookup &amp;lt;= memoize(query=roaming_users, key="UUID")

 -- On a DC the NetUserEnum API will return the entire domain!
 LET local_users &amp;lt;= select User_id as Uid,
 Primary_group_id as Gid, Name,
 Comment as Description,
 get(item=roaming_users_lookup, field=User_sid) AS RoamingData,
 User_sid as UUID
 FROM users()
 LIMIT 1000

 LET local_users_lookup &amp;lt;= memoize(query={
 SELECT UUID FROM local_users
 }, key="UUID")

 -- Populate the mtime from the user's home directory.
 LET local_users_with_mtime = SELECT Uid, Gid, Name, Description,
 RoamingData.Directory AS Directory,
 UUID,
 RoamingData.Mtime As Mtime,
 RoamingData.HomedirMtime AS HomedirMtime,
 RoamingData.Data || dict() AS Data
 FROM local_users

 SELECT * from chain(
 q1=local_users_with_mtime,
 q2={
 SELECT * FROM roaming_users
 -- Only show records who were not shown before
 WHERE NOT get(item=local_users_lookup, field=UUID)
 })
 --ORDER BY Gid DESC
 notebook:
 - type: VQL
 template: |
 /*
 # Users Hunt

 Enumerating all the users on all endpoints can reveal machines
 which had an unexpected login activity. For example, if a user
 from an unrelated department is logging into an endpoint by
 virtue of domain credentials, this could mean their account is
 compromised and the attackers are laterally moving through the
 network.
 */
 LET s = scope()
 SELECT Name, UUID, s.Fqdn AS Fqdn, HomedirMtime as LastMod, Data FROM source()
 WHERE NOT UUID =~ "(-5..$|S-1-5-18|S-1-5-19|S-1-5-20)"

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.AppcompatShims</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.appcompatshims/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.appcompatshims/</guid><description>&lt;p>Application Compatibility shims are a way to persist malware. This
table presents the AppCompat Shim information from the registry in a
nice format.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.AppcompatShims
description: |
 Application Compatibility shims are a way to persist malware. This
 table presents the AppCompat Shim information from the registry in a
 nice format.

reference:
 - http://files.brucon.org/2015/Tomczak_and_Ballenthin_Shims_for_the_Win.pdf

parameters:
 - name: shimKeys
 default: &amp;gt;-
 HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\AppCompatFlags\InstalledSDB\*
 - name: customKeys
 default: &amp;gt;-
 HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\AppCompatFlags\Custom\*\*

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 LET installed_sdb &amp;lt;=
 SELECT Key, Key.Name as SdbGUID, DatabasePath,
 DatabaseType, DatabaseDescription,
 -- Convert windows file time to unix epoch.
 (DatabaseInstallTimeStamp / 10000000) - 11644473600 AS DatabaseInstallTimeStamp
 FROM read_reg_key(
 globs=split(string=shimKeys, sep=",[\\s]*"),
 accessor="registry")

 LET result = SELECT * from foreach(
 row={
 SELECT regex_replace(
 source=OSPath,
 replace="$1",
 re="^.+\\\\([^\\\\]+)\\\\[^\\\\]+$") as Executable,
 regex_replace(
 source=Name,
 replace="$1",
 re="(\\{[^}]+\\}).*$") as SdbGUIDRef,
 Name as ExeName
 FROM glob(
 globs=split(string=customKeys, sep=",[\\s]*"),
 accessor="registry")
 },
 query={
 SELECT Executable, DatabasePath, DatabaseType,
 DatabaseDescription, DatabaseInstallTimeStamp, SdbGUID
 FROM installed_sdb
 WHERE SdbGUID = SdbGUIDRef
 })

 SELECT * from result

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.CertificateAuthorities</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.certificateauthorities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.certificateauthorities/</guid><description>&lt;p>Certificate Authorities installed in Keychains/ca-bundles.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.CertificateAuthorities
description: Certificate Authorities installed in Keychains/ca-bundles.
sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 SELECT Store, IsCA, Subject,
 encode(string=SubjectKeyId, type='hex') AS SubjectKeyId,
 encode(string=AuthorityKeyId, type='hex') AS AuthorityKeyId,
 Issuer, KeyUsageString,
 IsSelfSigned, SHA1, SignatureAlgorithm, PublicKeyAlgorithm, KeyStrength,
 NotBefore, NotAfter, HexSerialNumber
 FROM certificates()

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.DiskInfo</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.diskinfo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.diskinfo/</guid><description>&lt;p>Retrieve basic information about the physical disks of a system.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.DiskInfo
description: Retrieve basic information about the physical disks of a system.
sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 SELECT Partitions,
 Index as DiskIndex,
 InterfaceType as Type,
 PNPDeviceID,
 DeviceID,
 Size,
 Manufacturer,
 Model,
 Name,
 SerialNumber,
 Description
 FROM wmi(
 query="SELECT * from Win32_DiskDrive",
 namespace="ROOT\\CIMV2")

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.Drivers</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.drivers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.drivers/</guid><description>&lt;p>Details for in-use Windows device drivers. This does not display
installed but unused drivers.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.Drivers
description: |
 Details for in-use Windows device drivers. This does not display
 installed but unused drivers.

precondition:
 SELECT OS From info() where OS = 'windows'

parameters:
 - name: AlsoCheckAuthenticode
 type: bool
 description: If selected we also check the authenticode information.
 default: "Y"

 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
 - name: SignedDrivers
 query: |
 SELECT *
 FROM wmi(
 query="select * from Win32_PnPSignedDriver",
 namespace="ROOT\\CIMV2")

 - name: RunningDrivers
 query: |
 SELECT *, if(
 condition=AlsoCheckAuthenticode,
 then=authenticode(filename=PathName)) AS Authenticode,
 hash(path=PathName) AS Hashes
 FROM wmi(
 query="select * from Win32_SystemDriver",
 namespace="ROOT\\CIMV2")
 notebook:
 - type: vql_suggestion
 name: Unique issuers
 template: |
 /*
 # Unique Issuers of drivers

 These are the unique signers of drivers on a system
 (excluding microsoft drivers).

 */
 SELECT count() AS Count,
 enumerate(items=Name) AS Names,
 Authenticode.IssuerName AS Issuer, Hashes
 FROM source(artifact="Windows.Sys.Drivers/RunningDrivers")
 WHERE NOT Issuer =~ "Microsoft"
 GROUP BY Issuer

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.FirewallRules</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.firewallrules/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.firewallrules/</guid><description>&lt;p>List Windows firewall rules.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.FirewallRules
description: List Windows firewall rules.
reference:
 - https://social.technet.microsoft.com/Forums/azure/en-US/aaed9c6a-fb8b-4d43-8b69-9f4e0f619a8c/how-to-check-the-windows-firewall-settings-from-netsh-command?forum=winserverGP

parameters:
 - name: regKey
 default: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\SharedAccess\Parameters\FirewallPolicy\**\FirewallRules\*

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 LET rules = SELECT Name as Value,
 parse_string_with_regex(string=Data,
 regex=["Action=(?P&amp;lt;Action&amp;gt;[^|]+)",
 "Active=(?P&amp;lt;Active&amp;gt;[^|]+)",
 "Dir=(?P&amp;lt;Dir&amp;gt;[^|]+)",
 "Protocol=(?P&amp;lt;Protocol&amp;gt;[^|]+)",
 "LPort=(?P&amp;lt;LPort&amp;gt;[^|]+)",
 "Name=(?P&amp;lt;Name&amp;gt;[^|]+)",
 "Desc=(?P&amp;lt;Desc&amp;gt;[^|]+)",
 "App=(?P&amp;lt;App&amp;gt;[^|]+)"]) as Record,
 Data,
 OSPath
 FROM glob(globs=regKey, accessor="registry")

 SELECT Value,
 Record.Name as Name,
 get(item=Record, field="Desc") as Description,
 Record.App as App,
 if(condition=Record.Active =~ "TRUE", then="Yes", else="No") as Active,
 Record.Action as Action,
 Record.Dir as Dir,
 if(condition=Record.Protocol = "6",
 then="TCP",
 else=if(condition=Record.Protocol = "17",
 then="UDP",
 else=Record.Protocol)) as Protocol,
 if(condition=Record.LPort = NULL,
 then="Any",
 else=Record.LPort) as LPort,
 Record.Name as Name
 FROM rules

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.Interfaces</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.interfaces/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.interfaces/</guid><description>&lt;p>Report information about the systems interfaces. This artifact
simply parses the output from &lt;code>ipconfig /all&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.Interfaces
description: |
 Report information about the systems interfaces. This artifact
 simply parses the output from `ipconfig /all`.

implied_permissions:
 - EXECVE

sources:
 - precondition:
 SELECT OS from info() where OS = "windows"
 query: |
 // Run ipconfig to get all information about interfaces.
 LET ipconfig = SELECT * FROM execve(argv=['ipconfig', '/all'])

 // This produces a single row per interface.
 LET interfaces = SELECT Name, Data FROM parse_records_with_regex(
 file=ipconfig.Stdout,
 accessor='data', // This makes the data appear as a file.
 regex='(?s)Ethernet adapter (?P&amp;lt;Name&amp;gt;[^:]+?):\r\n\r\n(?P&amp;lt;Data&amp;gt;.+?)\r\n(\r\n|$)')

 // Now extract interesting things from each interface definition.
 SELECT Name, parse_string_with_regex(
 string=Data,
 regex=[
 "Description[^:]+: (?P&amp;lt;Description&amp;gt;.+)\r\n",
 "Physical Address[^:]+: (?P&amp;lt;MAC&amp;gt;.+)\r\n",
 "IPv4 Address[^:]+: (?P&amp;lt;IP&amp;gt;[0-9.]+)",
 "Default Gateway[^:]+: (?P&amp;lt;Gateway&amp;gt;.+)\r\n",
 "DNS Servers[^:]+: (?P&amp;lt;DNS&amp;gt;.+)\r\n [^ ]",
 "DHCP Server[^:]+: (?P&amp;lt;DHCP&amp;gt;.+)\r\n"
 ]
 ) As Details FROM interfaces

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.PhysicalMemoryRanges</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.physicalmemoryranges/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.physicalmemoryranges/</guid><description>&lt;p>List Windows physical memory ranges.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.PhysicalMemoryRanges
description: List Windows physical memory ranges.
reference:
 - https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/content/wdm/ns-wdm-_cm_resource_list

parameters:
 - name: physicalMemoryKey
 default: HKEY_LOCAL_MACHINE\HARDWARE\RESOURCEMAP\System Resources\Physical Memory\.Translated

export: |
 LET Profile = '''
 [
 ["CM_RESOURCE_LIST", 0, [
 ["Count", 0, "uint32"],
 ["List", 4, "CM_FULL_RESOURCE_DESCRIPTOR"]
 ]],
 ["CM_FULL_RESOURCE_DESCRIPTOR", 0, [
 ["PartialResourceList", 8, "CM_PARTIAL_RESOURCE_LIST"]
 ]],

 ["CM_PARTIAL_RESOURCE_LIST", 0, [
 ["Version", 0, "uint16"],
 ["Revision", 2, "uint16"],
 ["Count", 4, "uint32"],
 ["PartialDescriptors", 8, "Array", {
 "type": "CM_PARTIAL_RESOURCE_DESCRIPTOR",
 "count": "x=&amp;gt;x.Count"
 }]
 ]],

 ["CM_PARTIAL_RESOURCE_DESCRIPTOR", 20, [
 ["Type", 0, "char"],
 ["ShareDisposition", 1, "char"],
 ["Flags",2, "uint16"],
 ["Start",4, "int64"],
 ["Length",12, "uint32"]
 ]]
 ]
 '''

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 query: |
 SELECT * FROM foreach(
 row={SELECT Data from stat(filename=physicalMemoryKey, accessor="registry")},
 query={
 SELECT * FROM foreach(
 row=parse_binary(
 filename=Data.value,
 accessor="data",
 profile=Profile,
 struct="CM_RESOURCE_LIST").List.PartialResourceList.PartialDescriptors,
 query={
 SELECT Type,
 format(format="%#0x", args=Start) AS Start,
 format(format="%#0x", args=Length) AS Length
 FROM scope()
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.Programs</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.programs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.programs/</guid><description>&lt;p>Represents products as they are installed by Windows Installer. A product generally
correlates to one installation package on Windows. Some fields may be blank as Windows
installation details are left to the discretion of the product author.&lt;/p>
&lt;p>Limitations: This key parses the live registry hives - if a user is not logged in then their data will not be resident in HKU and therefore you should parse the hives on disk (including within VSS/Regback).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.Programs
description: |
 Represents products as they are installed by Windows Installer. A product generally
 correlates to one installation package on Windows. Some fields may be blank as Windows
 installation details are left to the discretion of the product author.

 Limitations: This key parses the live registry hives - if a user is not logged in then their data will not be resident in HKU and therefore you should parse the hives on disk (including within VSS/Regback).

reference:
 - https://github.com/facebook/osquery/blob/master/specs/windows/programs.table

parameters:
 - name: programKeys
 default: &amp;gt;-
 HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Uninstall\*,
 HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Uninstall\*,
 HKEY_USERS\*\Software\Microsoft\Windows\CurrentVersion\Uninstall\*

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'
 queries:
 - |
 SELECT Key.Name as KeyName,
 Key.Mtime AS KeyLastWriteTimestamp,
 DisplayName,
 DisplayVersion,
 InstallLocation,
 InstallSource,
 Language,
 Publisher,
 UninstallString,
 InstallDate,
 Key.OSPath as KeyPath
 FROM read_reg_key(globs=split(string=programKeys, sep=',[\\s]*'),
 accessor="registry")

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.StartupItems</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.startupitems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.startupitems/</guid><description>&lt;p>Applications that will be started up from the various run key
locations.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.StartupItems
description: |
 Applications that will be started up from the various run key
 locations.

reference:
 - https://docs.microsoft.com/en-us/windows/desktop/setupapi/run-and-runonce-registry-keys

parameters:
 - name: AlsoUpload
 type: bool
 description: If set we also upload the files in the startup folders

 - name: runKeyGlobs
 type: csv
 default: |
 KeyGlobs
 HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run*\*
 HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run*\*
 HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\Explorer\Run*\*
 HKEY_USERS\*\SOFTWARE\Microsoft\Windows\CurrentVersion\Run*\*
 HKEY_USERS\*\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run*\*
 HKEY_USERS\*\SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\Explorer\Run*\*

 - name: startupApprovedGlobs
 type: csv
 default: |
 KeyGlobs
 HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\**
 HKEY_USERS\*\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\**

 - name: startupFolderDirectories
 type: csv
 default: |
 FileGlobs
 C:/ProgramData/Microsoft/Windows/Start Menu/Programs/Startup/**
 C:/Users/*/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Startup/**

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET approved &amp;lt;=
 SELECT Name as ApprovedName,
 encode(string=Data, type="hex") as Enabled
 FROM glob(globs=startupApprovedGlobs.KeyGlobs,
 accessor="registry")
 WHERE Enabled =~ "^0[0-9]0+$"

 LET registry_runners = SELECT Name,
 OSPath, Data.value as Details,
 if(
 condition={
 SELECT Enabled from approved
 WHERE Name = ApprovedName
 },
 then="enabled", else="disabled") as Enabled,
 "" AS Upload
 FROM glob(
 globs=runKeyGlobs.KeyGlobs,
 accessor="registry")

 LET enrich_file(OSPath) = SELECT * FROM switch(
 ini={
 SELECT regex_replace(re="[^0-9a-z_]", replace=".",
 source=read_file(filename=OSPath, length=1024)) AS Details
 FROM scope()
 WHERE OSPath.Basename =~ ".(bat|ini|ps1)$"
 }, lnk={
 SELECT { 
 SELECT SourceFile, ShellLinkHeader, LinkInfo, LinkTarget, StringData, ExtraData 
 FROM Artifact.Windows.Forensics.Lnk(TargetGlob=OSPath)
 } as Details
 FROM scope()
 WHERE OSPath.Basename =~ ".lnk$"
 }, default={
 SELECT hash(path=OSPath) AS Details
 FROM scope()
 })

 LET file_runners =
 SELECT Name, OSPath,
 enrich_file(OSPath=OSPath)[0].Details AS Details,
 "enable" as Enabled,
 if(condition=AlsoUpload, then=upload(file=OSPath)) AS Upload
 FROM glob(globs=startupFolderDirectories.FileGlobs)

 SELECT *
 FROM chain(
 first=registry_runners,
 second=file_runners)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sys.Users</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sys.users/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sys.users/</guid><description>&lt;p>List User accounts by inspecting registry keys. This method is a
reliable indicator for users who have physically logged into the
system and thereby created local profiles.&lt;/p>
&lt;p>This will not include domain users or the output from &lt;code>NetUserEnum&lt;/code>&lt;/p>
&lt;ul>
&lt;li>you should collect the &lt;code>Windows.Sys.AllUsers&lt;/code> artifact to get all
possible users on the system.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sys.Users
description: |
 List User accounts by inspecting registry keys. This method is a
 reliable indicator for users who have physically logged into the
 system and thereby created local profiles.

 This will not include domain users or the output from `NetUserEnum`
 - you should collect the `Windows.Sys.AllUsers` artifact to get all
 possible users on the system.

parameters:
 - name: remoteRegKey
 default: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\ProfileList\*

imports:
 - Windows.Sys.AllUsers

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET GetTimestamp(High, Low) = if(condition=High,
 then=timestamp(winfiletime=High * 4294967296 + Low))
 LET S = scope()

 -- lookupSID() may not be available on deaddisk analysis
 SELECT split(string=Key.OSPath.Basename, sep="-")[-1] as Uid,
 "" AS Gid,
 LookupSIDCache(SID=Key.OSPath.Basename || "") AS Name,
 Key.OSPath as Description,
 ProfileImagePath as Directory,
 Key.OSPath.Basename as UUID,
 Key.Mtime as Mtime,
 {
 SELECT Mtime
 FROM stat(filename=expand(path=ProfileImagePath))
 } AS HomedirMtime,
 dict(ProfileLoadTime=GetTimestamp(
 High=S.LocalProfileLoadTimeHigh, Low=S.LocalProfileLoadTimeLow),
 ProfileUnloadTime=GetTimestamp(
 High=S.LocalProfileUnloadTimeHigh, Low=S.LocalProfileUnloadTimeLow)
 ) AS Data
 FROM read_reg_key(globs=remoteRegKey, accessor="registry")

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sysinternals.Autoruns</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sysinternals.autoruns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sysinternals.autoruns/</guid><description>&lt;p>Uses Sysinternals autoruns to scan the host.&lt;/p>
&lt;p>Note this requires syncing the Sysinternals binary from the host.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sysinternals.Autoruns
description: |
 Uses Sysinternals autoruns to scan the host.

 Note this requires syncing the Sysinternals binary from the host.

tools:
 - name: Autorun_386
 url: https://live.sysinternals.com/tools/autorunsc.exe
 serve_locally: true

 - name: Autorun_amd64
 url: https://live.sysinternals.com/tools/autorunsc64.exe
 serve_locally: true

precondition: SELECT OS From info() where OS = 'windows'

implied_permissions:
 - EXECVE

parameters:
 - name: All
 type: bool
 default: Y
 - name: Boot execute
 type: bool
 - name: Codecs
 type: bool
 - name: Appinit DLLs
 type: bool
 - name: Explorer addons
 type: bool
 - name: Sidebar gadgets (Vista and higher)
 type: bool
 - name: Image hijacks
 type: bool
 - name: Internet Explorer addons
 type: bool
 - name: Known DLLs
 type: bool
 - name: Logon startups (this is the default)
 type: bool
 - name: WMI entries
 type: bool
 - name: Winsock protocol and network providers
 type: bool
 - name: Office addins
 type: bool
 - name: Printer monitor DLLs
 type: bool
 - name: LSA security providers
 type: bool
 - name: Autostart services and non-disabled drivers
 type: bool
 - name: Scheduled tasks
 type: bool
 - name: Winlogon entries
 type: bool
 - name: Verify digital signatures
 type: bool
 default: Y
 - name: ToolInfo
 type: hidden
 description: Override Tool information.

sources:
 - query: |
 LET Flags = '''Option,Name
 *,All
 b,Boot execute
 c,Codecs
 d,Appinit DLLs
 e,Explorer addons
 g,Sidebar gadgets (Vista and higher)
 h,Image hijacks
 i,Internet Explorer addons
 k,Known DLLs
 l,Logon startups (this is the default)
 m,WMI entries
 n,Winsock protocol and network providers
 o,Office addins
 p,Printer monitor DLLs
 r,LSA security providers
 s,Autostart services and non-disabled drivers
 t,Scheduled tasks
 w,Winlogon entries
 '''

 LET Options = '''Option,Name
 -s,Verify digital signatures
 '''

 -- The flags actually selected
 LET flags = SELECT Option FROM parse_csv(accessor="data", filename=Flags)
 WHERE get(field=Name)

 -- The options actually selected
 LET options = SELECT Option FROM parse_csv(accessor="data", filename=Options)
 WHERE get(field=Name)

 LET os_info &amp;lt;= SELECT Architecture FROM info()

 // Get the path to the binary.
 LET bin &amp;lt;= SELECT * FROM Artifact.Generic.Utils.FetchBinary(
 ToolName= "Autorun_" + os_info[0].Architecture,
 ToolInfo=ToolInfo)

 // Call the binary and return all its output in a single row.
 LET output = SELECT * FROM execve(argv=[bin[0].OSPath,
 '-nobanner', '-accepteula', '-t', '-a',
 join(array=flags.Option, sep=""),
 join(array=options.Option, sep=" "),
 '-c', -- CSV output
 '-h', -- Also calculate hashes
 '*' -- All user profiles.
 ], length=10000000)

 // Parse the CSV output and return it as rows. We can filter this further.
 SELECT * FROM if(condition=bin,
 then={
 SELECT * FROM foreach(
 row=output,
 query={
 SELECT * FROM parse_csv(filename=utf16(string=Stdout),
 accessor="data")
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sysinternals.SysmonInstall</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sysinternals.sysmoninstall/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sysinternals.sysmoninstall/</guid><description>&lt;p>Sysmon is a kernel level system monitor written by Sysinternals. While we are
not able to distribute Sysmon ourselves, Velociraptor can help you manage its
deployment and installation.&lt;/p>
&lt;p>NOTE: By default we install the Sysmon config from SwiftOnSecurity - we
recommend that you review the config file and, if necessary, override it in
the GUI with one that better suits your needs.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sysinternals.SysmonInstall
description: |
 Sysmon is a kernel level system monitor written by Sysinternals. While we are
 not able to distribute Sysmon ourselves, Velociraptor can help you manage its
 deployment and installation.

 NOTE: By default we install the Sysmon config from SwiftOnSecurity - we
 recommend that you review the config file and, if necessary, override it in
 the GUI with one that better suits your needs.

tools:
 - name: SysmonBinary
 url: https://live.sysinternals.com/tools/sysmon64.exe
 serve_locally: true

 - name: SysmonConfig
 url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
 serve_locally: true

precondition: SELECT OS From info() where OS = 'windows'

required_permissions:
- EXECVE

parameters:
 - name: SysmonFileLocation
 description: If set, we check this location first for sysmon installed.
 default: C:/Windows/sysmon64.exe

sources:
- query: |
 LET bin &amp;lt;= SELECT * FROM switch(
 a={
 SELECT * FROM glob(globs=SysmonFileLocation)
 }, b={
 SELECT * FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="SysmonBinary")
 })

 LET existing_hash = SELECT lowcase(
 string=parse_string_with_regex(
 string=Stdout, regex="hash:.+SHA256=([^\\n\\r]+)").g1) AS Hash
 FROM execve(argv=[bin[0].OSPath, "-c"])

 LET sysmon_config = SELECT * FROM Artifact.Generic.Utils.FetchBinary(
 ToolName="SysmonConfig", IsExecutable=FALSE)

 LET ensure_service_running =
 SELECT * FROM execve(argv=["sc.exe", "start", "sysmon64"])

 LET doit = SELECT * FROM chain(
 a={
 // First force an uninstall to clear the config
 SELECT * FROM execve(argv= [ bin[0].OSPath, "-accepteula", "-u"], length=10000000)
 }, b={
 SELECT * FROM execve(argv= [ bin[0].OSPath,
 "-accepteula", "-i", sysmon_config[0].OSPath ], length=10000000)
 }, c=ensure_service_running)

 // Only install sysmon if the existing config hash is not the same
 // as the specified hash.
 SELECT * FROM if(
 condition=if(
 condition=bin AND sysmon_config,
 else=log(message="Failed to fetch sysmon tools!"),
 then=if(
 condition=existing_hash[0].Hash != Tool_SysmonConfig_HASH,
 then=log(message="Sysmon config hash has changed (%v vs %v) - reinstalling",
 args=[existing_hash[0].Hash, Tool_SysmonConfig_HASH]),
 else=log(message="Existing sysmon config hash has not changed (%v) - skipping reinstall",
 args=Tool_SysmonConfig_HASH) AND FALSE
 )
 ),
 then={ SELECT * FROM doit },
 else={ SELECT * FROM ensure_service_running })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Sysinternals.SysmonLogForward</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.sysinternals.sysmonlogforward/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.sysinternals.sysmonlogforward/</guid><description>&lt;p>A client-side event forwarder to forward Sysmon events to the server.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Sysinternals.SysmonLogForward
description: |
 A client-side event forwarder to forward Sysmon events to the server.

type: CLIENT_EVENT

precondition: SELECT OS From info() where OS = 'windows'

tools:
 - name: SysmonBinary
 url: https://live.sysinternals.com/tools/sysmon64.exe
 serve_locally: true

 - name: SysmonConfig
 url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
 serve_locally: true

parameters:
 - name: SysmonFileLocation
 description: If set, we check this location first for sysmon installed.
 default: C:/Windows/sysmon64.exe

sources:
- query: |
 // First ensure that sysmon is actually installed.
 LET _ &amp;lt;= SELECT * FROM Artifact.Windows.Sysinternals.SysmonInstall(
 SysmonFileLocation=SysmonFileLocation)

 // Just parse and forward events. Use ETW rather than watch_evtx()
 // because it is a little bit faster.
 SELECT System.ID AS ID,
 System.TimeStamp AS Timestamp,
 get(member='EventData') AS EventData
 FROM watch_etw(
 description='Microsoft-Windows-Sysmon/Operational',
 guid='{5770385f-c22a-43e0-bf4c-06f5698ffbd9}')

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Amcache</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.amcache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.amcache/</guid><description>&lt;p>Get information from the system&amp;rsquo;s amcache.&lt;/p>
&lt;p>The Amcache.hve file is a registry file that stores the information
of executed applications. Amcache.hve records the recent processes
that were run and lists the path of the files that’s executed which
can then be used to find the executed program.&lt;/p>
&lt;p>This artifact works on Windows 10 1607 version.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Amcache
description: |
 Get information from the system's amcache.

 The Amcache.hve file is a registry file that stores the information
 of executed applications. Amcache.hve records the recent processes
 that were run and lists the path of the files that’s executed which
 can then be used to find the executed program.

 This artifact works on Windows 10 1607 version.

reference:
 - https://www.andreafortuna.org/cybersecurity/amcache-and-shimcache-in-forensic-analysis/
 - https://www.ssi.gouv.fr/uploads/2019/01/anssi-coriin_2019-analysis_amcache.pdf

parameters:
 - name: amCacheGlob
 default: "%SYSTEMROOT%/appcompat/Programs/Amcache.hve"
 - name: amCacheRegPath
 default: /Root/InventoryApplicationFile/*
 - name: NTFS_CACHE_SIZE
 type: int
 default: 1000

precondition: |
 SELECT OS From info() where OS = 'windows'

sources:
 - name: InventoryApplicationFile
 query: |
 LET X = scope()
 SELECT FileId,
 Key.OSPath.Path as Key,
 Key.OSPath.DelegatePath AS Hive,
 Key.Mtime as LastModified,
 X.LowerCaseLongPath as Binary,
 X.Name AS Name,
 X.Size AS Size,
 X.ProductName AS ProductName,
 X.Publisher AS Publisher,
 X.Version AS Version,
 X.BinFileVersion AS BinFileVersion
 FROM foreach(
 row={
 SELECT OSPath from glob(globs=expand(path=amCacheGlob))
 WHERE log(message="Processing %v", args=OSPath)
 }, query={
 SELECT * from read_reg_key(
 globs=amCacheRegPath,
 root=pathspec(DelegatePath=OSPath),
 accessor='raw_reg'
 )
 })

 - name: File
 query: |
 SELECT * FROM foreach(
 row={
 SELECT OSPath from glob(globs=expand(path=amCacheGlob))
 }, query={
 SELECT get(item=scope(), member="100") As ProductId,
 get(item=scope(), member="101") As SHA1,
 get(item=scope(), member="15") As OSPath,
 Key.Mtime as LastModifiedKey
 FROM read_reg_key(
 root=pathspec(DelegatePath=OSPath),
 globs='/Root/File/*/*',
 accessor='raw_reg'
 )
 })

reports:
 - type: CLIENT
 template: |
 {{define "recent_executions"}}
 LET recent_executions &amp;lt;= SELECT LastModified, Name, count(items=Name) As Count,
 int(int=_LastModified/3600) AS Hour
 FROM source(source="InventoryApplicationFile")
 GROUP BY Hour
 LIMIT 500
 {{ end }}

 {{ define "timeline" }}
 SELECT LastModified,
 format(format="%s (%d)", args=[Name, Count]) As TotalCount
 FROM recent_executions
 {{ end }}

 The AMCache file
 ================

 {{ .Description }}

 ## Execution clusters

 The AMCache artifact only shows us the time of first execution
 of a binary. We get an idea when it was installed. Typically
 execution artifacts are clustered in time - if an attacker
 copies a bunch of new tools they will all start running at about
 the same time.

 The below timeline shows a summary of execution clusters. The
 binaries are grouped in an hour interval. The label is the first
 binary name and the total number of binaries within that hour.

 &amp;gt; For clarity we hide the names of all other binaries, and just
 show the total count.

 {{ Query "recent_executions" "timeline" | Timeline }}


 Here is the same data in tabular form.

 {{ Query "timeline" | Table }}

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.AuditPolicy</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.auditpolicy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.auditpolicy/</guid><description>&lt;p>Uses auditpol to retrieve the logging settings defined in the Windows Audit
Policy.&lt;/p>
&lt;p>Use this artifact to determine which Windows event logs are audited and
identify audit configuration discrepancies across the environment.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.AuditPolicy

description: |
 Uses auditpol to retrieve the logging settings defined in the Windows Audit
 Policy.

 Use this artifact to determine which Windows event logs are audited and
 identify audit configuration discrepancies across the environment.

type: CLIENT

author: Zach Stanford - @svch0st

implied_permissions:
 - EXECVE

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET output = SELECT * FROM execve(
 argv=["auditpol.exe","/get","/category:*","/r"])

 SELECT * FROM foreach(
 row=output,
 query={
 SELECT * FROM parse_csv(filename=Stdout,accessor="data")
 }
 )

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.CatFiles</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.catfiles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.catfiles/</guid><description>&lt;p>Windows stores many hashes in .cat files. These catalog files
contain a set of trusted hashes for drivers and other binaries,
even if the PE files do not themselves contain Authenticode
signatures.&lt;/p>
&lt;p>This artifact extracts all the trusted hashes from a system by
parsing all the cat files.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.CatFiles
description: |
 Windows stores many hashes in .cat files. These catalog files
 contain a set of trusted hashes for drivers and other binaries,
 even if the PE files do not themselves contain Authenticode
 signatures.

 This artifact extracts all the trusted hashes from a system by
 parsing all the cat files.

parameters:
 - name: CatGlobs
 default: C:\Windows\System32\CatRoot\*\*.cat
 - name: SignerExcludeRegex
 description: Exclude hashes from this Signer
 default: Microsoft
 type: regex

 - name: SignerFilterRegex
 description: Only show hashes from this signer.
 default: .
 type: regex

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET parsed_cats = SELECT Name, parse_pkcs7(data=read_file(filename=OSPath)) AS PKCS7
 FROM glob(globs=CatGlobs)

 -- Extract the CertificateTrustList and Subject who signed the cat file.
 LET extracted = SELECT Name, PKCS7.Signer.Subject AS Signer,
 PKCS7.CertificateTrustList.Hash AS CTL
 FROM parsed_cats
 WHERE Signer =~ SignerFilterRegex AND NOT Signer =~ SignerExcludeRegex

 -- Expand all the hashes in the same cat file to flatten the results
 SELECT * FROM foreach(row=extracted, query={
 SELECT * FROM foreach(row=CTL, query={
 SELECT Name, Signer, _value AS Hash FROM scope()
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.CmdShell</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.cmdshell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.cmdshell/</guid><description>&lt;p>This artifact allows running arbitrary commands through the system
shell cmd.exe.&lt;/p>
&lt;p>Since Velociraptor typically runs as system, the commands will also
run as System.&lt;/p>
&lt;p>This is a very powerful artifact since it allows for arbitrary
command execution on the endpoints. Therefore this artifact requires
elevated permissions (specifically the &lt;code>EXECVE&lt;/code>
permission). Typically it is only available with the &lt;code>administrator&lt;/code>
role.&lt;/p>
&lt;p>Note there are some limitations with passing commands to the cmd.exe
shell, such as when specifying quoted paths or command-line
arguments with special characters. Using Windows.System.PowerShell
artifact is likely a better option in these cases.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.CmdShell
description: |
 This artifact allows running arbitrary commands through the system
 shell cmd.exe.

 Since Velociraptor typically runs as system, the commands will also
 run as System.

 This is a very powerful artifact since it allows for arbitrary
 command execution on the endpoints. Therefore this artifact requires
 elevated permissions (specifically the `EXECVE`
 permission). Typically it is only available with the `administrator`
 role.

 Note there are some limitations with passing commands to the cmd.exe
 shell, such as when specifying quoted paths or command-line
 arguments with special characters. Using Windows.System.PowerShell
 artifact is likely a better option in these cases.

required_permissions:
 - EXECVE

precondition:
 SELECT OS From info() where OS = 'windows'

parameters:
 - name: Command
 default: "dir C:\\"

sources:
 - query: |
 LET SizeLimit &amp;lt;= 4096
 SELECT if(condition=len(list=Stdout) &amp;lt; SizeLimit,
 then=Stdout) AS Stdout,
 if(condition=len(list=Stdout) &amp;gt;= SizeLimit,
 then=upload(accessor="data",
 file=Stdout, name="Stdout")) AS StdoutUpload

 FROM execve(argv=["cmd.exe", "/c", Command], length=10000000)

column_types:
- name: StdoutUpload
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.CriticalServices</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.criticalservices/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.criticalservices/</guid><description>&lt;p>This artifact returns information about any services which are
considered critical.&lt;/p>
&lt;p>The default list contains virus scanners. If the software is not
installed at all, it will not be shown.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.CriticalServices
description: |
 This artifact returns information about any services which are
 considered critical.

 The default list contains virus scanners. If the software is not
 installed at all, it will not be shown.

reference:
 - "ATT&amp;amp;CK: T1089"
 - https://github.com/teoseller/osquery-attck/blob/master/windows_critical_service_status.conf

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: lookupTable
 type: csv
 default: |
 ServiceName
 WinDefend
 MpsSvc
 SepMasterService
 SAVAdminService
 SavService
 wscsvc
 wuauserv

sources:
 - query: |
 SELECT Name, DisplayName, Created, State, {
 SELECT * FROM lookupTable WHERE Name =~ ServiceName
 } AS Critical
 FROM Artifact.Windows.System.Services()
 WHERE Critical AND State != "Running"

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.DLLs</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.dlls/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.dlls/</guid><description>&lt;p>Enumerate the DLLs loaded by a running process. It includes hash value
and certificate information.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.DLLs
description: |
 Enumerate the DLLs loaded by a running process. It includes hash value
 and certificate information.

parameters:
 - name: ProcessRegex
 description: A regex applied to process names.
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: ExePathRegex
 default: .
 type: regex
 - name: CommandLineRegex
 default: .
 type: regex
 - name: DllRegex
 description: A regex applied to the full DLL path (e.g. whitelist all system DLLs)
 default: .
 type: regex
 - name: Calculate_Hash
 default: N
 type: bool
 - name: CertificateInfo
 default: N
 type: bool
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
 - query: |

 -- first find processes in scope
 LET processes = SELECT Pid, Name,Exe,CommandLine
 FROM pslist()
 WHERE Name =~ ProcessRegex
 AND Pid =~ PidRegex
 AND Exe =~ ExePathRegex
 AND CommandLine =~ CommandLineRegex

 -- find modules
 LET results = SELECT * FROM foreach(
 row=processes,
 query={
 SELECT Pid, Name,Exe as _Exe,CommandLine as _CommandLine ,
 format(format='%x-%x', args=[ModuleBaseAddress,
 ModuleBaseAddress+ModuleBaseSize]) AS Range,
 ModuleName, ExePath as ModulePath
 FROM modules(pid=Pid)
 WHERE ModulePath =~ DllRegex
 })

 -- add additional enrichment usecases
 LET cert_hash = SELECT *,
 hash(path=expand(path=ModulePath)) AS Hash,
 authenticode(filename=ModulePath) AS Certinfo
 FROM results
 LET cert_nohash = SELECT *, authenticode(filename=ModulePath) AS Certinfo
 FROM results
 LET nocert_hash = SELECT *, hash(path=expand(path=ModulePath)) AS Hash
 FROM results

 -- output rows
 SELECT * FROM if(condition= Calculate_Hash AND CertificateInfo,
 then= cert_hash,
 else= if(condition= Calculate_Hash,
 then= nocert_hash,
 else= if(condition= CertificateInfo,
 then= cert_nohash,
 else= results )))

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.DNSCache</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.dnscache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.dnscache/</guid><description>&lt;p>Collects DNS cache entries using the WMI class &lt;code>MSFT_DNSClientCache&lt;/code>.&lt;/p>
&lt;p>Windows maintains DNS lookups for a short time in the DNS cache.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.DNSCache
description: |
 Collects DNS cache entries using the WMI class `MSFT_DNSClientCache`.

 Windows maintains DNS lookups for a short time in the DNS cache.

parameters:
 - name: kMapOfRecordType
 description: |
 Mapping of decimal DNS record types to human-readable types
 type: hidden
 default: |
 {
 "0": "Reserved",
 "1": "A",
 "2": "NS",
 "3": "MD",
 "4": "MF",
 "5": "CNAME",
 "6": "SOA",
 "7": "MB",
 "8": "MG",
 "9": "MR",
 "10": "NULL",
 "11": "WKS",
 "12": "PTR",
 "13": "HINFO",
 "14": "MINFO",
 "15": "MX",
 "16": "TXT",
 "17": "RP",
 "18": "AFSDB",
 "19": "X25",
 "20": "ISDN",
 "21": "RT",
 "22": "NSAP",
 "23": "NSAP-PTR",
 "24": "SIG",
 "25": "KEY",
 "26": "PX",
 "27": "GPOS",
 "28": "AAAA",
 "29": "LOC",
 "30": "NXT",
 "31": "EID",
 "32": "NIMLOC",
 "33": "SRV",
 "34": "ATMA",
 "35": "NAPTR",
 "36": "KX",
 "37": "CERT",
 "38": "A6",
 "39": "DNAME",
 "40": "SINK",
 "41": "OPT",
 "42": "APL",
 "43": "DS",
 "44": "SSHFP",
 "45": "IPSECKEY",
 "46": "RRSIG",
 "47": "NSEC",
 "48": "DNSKEY",
 "49": "DHCID",
 "50": "NSEC3",
 "51": "NSEC3PARAM",
 "52": "TLSA",
 "53": "SMIMEA",
 "54": "Unassigned",
 "55": "HIP",
 "56": "NINFO",
 "57": "RKEY",
 "58": "TALINK",
 "59": "CDS",
 "60": "CDNSKEY",
 "61": "OPENPGPKEY",
 "62": "CSYNC",
 "63": "ZONEMD",
 "64": "SVCB",
 "65": "HTTPS",
 "99": "SPF",
 "100": "UINFO",
 "101": "UID",
 "102": "GID",
 "103": "UNSPEC",
 "104": "NID",
 "105": "L32",
 "106": "L64",
 "107": "LP",
 "108": "EUI48",
 "109": "EUI64",
 "249": "TKEY",
 "250": "TSIG",
 "251": "IXFR",
 "252": "AXFR",
 "253": "MAILB",
 "254": "MAILA",
 "255": "*",
 "256": "URI",
 "257": "CAA",
 "258": "AVC",
 "259": "DOA",
 "260": "AMTRELAY",
 "32768": "TA",
 "32769": "DLV",
 "65535": "Reserved"
 }

 - name: kMapOfStatus
 description: |
 Mapping of decimal status to human-readable status
 type: hidden
 default: |
 {
 "0": "Success",
 "9003": "NotExist",
 "9701": "NoRecords"
 }

 - name: kMapOfSection
 description: |
 Mapping of decimal section to human-readable section
 type: hidden
 default: |
 {
 "1": "Answer",
 "2": "Authority",
 "3": "Additional"
 }

sources:
 - precondition: |
 SELECT OS from info() where OS = "windows"
 query: |
 LET wmiQuery &amp;lt;= '''
 SELECT Data, Entry, Status, TimeToLive, Type, Section
 FROM MSFT_DNSClientCache
 '''
 LET wmiNamespace &amp;lt;= "root/StandardCimv2"
 LET MapOfRecordType &amp;lt;= parse_json(data=kMapOfRecordType)
 LET MapOfStatus &amp;lt;= parse_json(data=kMapOfStatus)
 LET MapOfSection &amp;lt;= parse_json(data=kMapOfSection)

 LET dns_cache_entries = SELECT
 Entry AS Name,
 Data AS Record,
 get(item=MapOfRecordType,
 member=str(str=Type), default=Type) AS RecordType,
 Type AS _RecordType,
 atoi(string=TimeToLive) AS TTL,
 get(item=MapOfStatus,
 member=str(str=Status), default=Status) AS QueryStatus,
 Status AS _QueryStatus,
 get(item=MapOfSection,
 member=str(str=Section), default=Section) AS SectionType,
 Section AS _SectionType
 FROM wmi(query=wmiQuery, namespace=wmiNamespace)

 SELECT * FROM dns_cache_entries

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.DomainRole</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.domainrole/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.domainrole/</guid><description>&lt;p>This artifact will extract Domain Role per machine.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.DomainRole
author: 'Matt Green - @mgreen27'
description: |
 This artifact will extract Domain Role per machine.

type: CLIENT

parameters:
 - name: HostNameRegex
 description: Regex filter by DNSHostName
 default: .
 - name: DomainRegex
 description: Regex filter by Domain
 default: .
 - name: RoleRegex
 description: Regex filter by Role
 default: .
 
sources:
 - precondition:
 SELECT OS From info() where OS =~ 'windows'

 query: |
 SELECT 
 Domain, 
 DNSHostName, 
 if(condition= DomainRole=0,
 then='Standalone Workstation',
 else=if(condition= DomainRole=1,
 then='Member Workstation',
 else=if(condition= DomainRole=2,
 then='Standalone Server',
 else=if(condition= DomainRole=3,
 then='Member Server',
 else=if(condition= DomainRole=4,
 then='Backup Domain Controller',
 else=if(condition= DomainRole=5,
 then= 'Primary Domain Controller',
 else= 'Unknown' )))))
 ) AS DomainRole
 FROM wmi(query='SELECT * FROM Win32_ComputerSystem',namespace='ROOT/cimv2')
 WHERE 
 DNSHostName =~ HostNameRegex
 AND Domain =~ DomainRegex
 AND DomainRole =~ RoleRegex
&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Handles</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.handles/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.handles/</guid><description>&lt;p>Enumerate the handles from selected processes.&lt;/p>
&lt;p>Uncheck all the handle types below to fetch all handle types.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Handles
description: |
 Enumerate the handles from selected processes.

 Uncheck all the handle types below to fetch all handle types.

parameters:
 - name: processRegex
 description: A regex applied to process names.
 default: .
 type: regex

 - name: Files
 description: Search for File Handles
 type: bool
 default: Y

 - name: Key
 description: Search for Key Handles
 type: bool

 - name: IncludeAccessMasks
 type: bool

sources:
 - query: |
 LET tokens &amp;lt;= SELECT * FROM chain(
 a={SELECT "File" AS Type FROM scope() WHERE Files = 'Y'},
 a2={SELECT "Section" AS Type FROM scope() WHERE Files = 'Y'},
 b={SELECT "Key" AS Type FROM scope() WHERE Key = 'Y'}
 )

 LET processes = SELECT Pid AS ProcPid, Name AS ProcName, Exe
 FROM pslist()
 WHERE ProcName =~ processRegex AND ProcPid &amp;gt; 0

 SELECT * FROM foreach(
 row=processes,
 query={
 SELECT ProcPid, ProcName, Exe, Type, Name, Handle,
 if(condition=IncludeAccessMasks,
 then=AccessMaskPerms) AS AccessMaskPerms
 FROM handles(pid=ProcPid, types=tokens.Type)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.HostsFile</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.hostsfile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.hostsfile/</guid><description>&lt;p>Parses the Windows Hostsfile.&lt;/p>
&lt;p>Regex searching for Hostname and resolution is enabled over output.
NOTE: For Hostname search is on the hostfile line and regex ^ or $
is not recommended.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.HostsFile
author: Matt Green - @mgreen27
description: |
 Parses the Windows Hostsfile.

 Regex searching for Hostname and resolution is enabled over output.
 NOTE: For Hostname search is on the hostfile line and regex ^ or $
 is not recommended.

type: CLIENT

parameters:
 - name: HostsFile
 default: C:\Windows\System32\drivers\etc\hosts
 - name: HostnameRegex
 description: "Hostname target Regex in Hostsfile"
 default: .
 type: regex

 - name: ResolutionRegex
 description: "Resolution target Regex in Hostsfile"
 default: .
 type: regex

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 -- Parse hosts file
 Let lines = SELECT split(string=Data,sep='\\r?\\n|\\r') as List
 FROM read_file(filenames=HostsFile)

 -- extract into fields
 LET results = SELECT * FROM foreach(row=lines,
 query={
 SELECT parse_string_with_regex(
 string=_value,
 regex=[
 "^\\s*(?P&amp;lt;Resolution&amp;gt;[^\\s]+)\\s+" +
 "(?P&amp;lt;Hostname&amp;gt;[^\\#]+)\\s*" +
 "#*\\s*(?P&amp;lt;Comment&amp;gt;.*)$"
 ]) as Record
 FROM foreach(row=List)
 WHERE _value
 AND NOT _value =~ '^\\s*#'
 AND _value =~ HostnameRegex
 AND _value =~ ResolutionRegex
 })

 -- clean up hostname output
 LET hostlist(string)=
 if(condition= len(list=split(string=regex_replace(source=string,
 re='\\s+$', replace=''), sep='\\s+')) = 1,
 then= regex_replace(source=string,re='\\s+$', replace=''),
 else= split(string=regex_replace(source=string,re='\\s+$',
 replace=''), sep='\\s+'))

 -- output rows
 SELECT
 Record.Resolution AS Resolution,
 hostlist(string=Record.Hostname) AS Hostname,
 Record.Comment AS Comment
 FROM results

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.LocalAdmins</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.localadmins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.localadmins/</guid><description>&lt;p>Gets a list of local admin accounts.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.LocalAdmins
description: |
 Gets a list of local admin accounts.

reference:
- https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.localaccounts/get-localgroupmember?view=powershell-5.1

type: CLIENT

required_permissions:
 - EXECVE

parameters:
 - name: PowerShellExe
 default: "C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe"

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET script &amp;lt;= 'Get-LocalGroupMember -SID S-1-5-32-544 | select -ExpandProperty SID -Property Name, PrincipalSource | select Name, Value, PrincipalSource | ConvertTo-Json'

 LET out = SELECT parse_json_array(data=Stdout) AS Output
 FROM execve(argv=[PowerShellExe,
 "-ExecutionPolicy", "Unrestricted", "-encodedCommand",
 base64encode(string=utf16_encode(
 string=script))
 ], length=1000000)
 SELECT * FROM foreach(row=out.Output[0],
 query={
 SELECT Name, Value AS SID, if(condition=PrincipalSource=1,
 then="Local", else=if(condition=PrincipalSource=2,
 then="Domain", else=PrincipalSource)) AS PrincipalSource
 FROM scope()
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.PowerShell</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.powershell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.powershell/</guid><description>&lt;p>This artifact allows running arbitrary commands through the system
PowerShell.&lt;/p>
&lt;p>Since Velociraptor typically runs as system, the commands will also
run as System.&lt;/p>
&lt;p>This is a very powerful artifact since it allows for arbitrary
command execution on the endpoints. Therefore this artifact requires
elevated permissions (specifically the &lt;code>EXECVE&lt;/code>
permission). Typically it is only available with the &lt;code>administrator&lt;/code>
role.&lt;/p>
&lt;p>Note that in addition to running PowerShell cmdlets and scripts, the
Windows.System.PowerShell artifact can also be used to launch
Windows command-line executables with their parameters. This can be
difficult to achieve with the Windows.System.CmdShell artifact due
to complications with spaces in paths and other special character
issues. This PowerShell artifact is able to avoid most of these
problems by encoding the command in Base64.&lt;/p>
&lt;p>As an example, the following command initiates a Windows Defender AV
quick-scan from the default location, which includes a path with
spaces in it:&lt;/p>
&lt;pre>&lt;code> &amp;amp; 'C:\Program Files\Windows Defender\MpCmdRun.exe' -Scan -ScanType 1
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.PowerShell
description: |
 This artifact allows running arbitrary commands through the system
 PowerShell.

 Since Velociraptor typically runs as system, the commands will also
 run as System.

 This is a very powerful artifact since it allows for arbitrary
 command execution on the endpoints. Therefore this artifact requires
 elevated permissions (specifically the `EXECVE`
 permission). Typically it is only available with the `administrator`
 role.

 Note that in addition to running PowerShell cmdlets and scripts, the
 Windows.System.PowerShell artifact can also be used to launch
 Windows command-line executables with their parameters. This can be
 difficult to achieve with the Windows.System.CmdShell artifact due
 to complications with spaces in paths and other special character
 issues. This PowerShell artifact is able to avoid most of these
 problems by encoding the command in Base64.

 As an example, the following command initiates a Windows Defender AV
 quick-scan from the default location, which includes a path with
 spaces in it:

 ```
 &amp;amp; 'C:\Program Files\Windows Defender\MpCmdRun.exe' -Scan -ScanType 1
 ```

required_permissions:
 - EXECVE

precondition:
 SELECT OS From info() where OS = 'windows'

parameters:
 - name: Command
 default: "dir C:/"
 - name: PowerShellExe
 default: "C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe"

sources:
 - query: |
 LET SizeLimit &amp;lt;= 4096
 SELECT if(condition=len(list=Stdout) &amp;lt; SizeLimit,
 then=Stdout) AS Stdout,
 if(condition=len(list=Stdout) &amp;gt;= SizeLimit,
 then=upload(accessor="data",
 file=Stdout,
 name="Stdout" + str(str=count()))) AS StdoutUpload,
 if(condition=len(list=Stderr) &amp;lt; SizeLimit,
 then=Stderr) AS Stderr,
 if(condition=len(list=Stderr) &amp;gt;= SizeLimit,
 then=upload(accessor="data",
 file=Stderr,
 name="Stderr" + str(str=count()))) AS StderrUpload
 FROM execve(argv=[PowerShellExe,
 "-ExecutionPolicy", "Unrestricted", "-encodedCommand",
 base64encode(string=utf16_encode(string=Command))
 ], length=10000000)

column_types:
- name: StdoutUpload
 type: preview_upload
- name: StderrUpload
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Powershell.ModuleAnalysisCache</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.powershell.moduleanalysiscache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.powershell.moduleanalysiscache/</guid><description>&lt;p>ModuleAnalysisCache stores metadata about loaded PowerShell modules.&lt;/p>
&lt;p>Recent updates include filters by regex to enable targeted hunting
use cases.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Powershell.ModuleAnalysisCache
description: |
 ModuleAnalysisCache stores metadata about loaded PowerShell modules.

 Recent updates include filters by regex to enable targeted hunting
 use cases.

reference:
 - https://github.com/PowerShell/PowerShell/blob/281b437a65360ae869d40f3766a1f2bbba786e5e/src/System.Management.Automation/engine/Modules/AnalysisCache.cs#L649

parameters:
 - name: GlobLookup
 default: C:\{Users\*,Windows\System32\config\systemprofile}\AppData\Local\Microsoft\Windows\PowerShell\ModuleAnalysisCache
 - name: ModulePathRegex
 description: Regex of installed ModulePath to target.
 default: .
 type: regex
 - name: ModulePathIgnoreRegex
 description: Regex of installed ModulePath to ignore.
 type: regex
 - name: FunctionNameRegex
 description: Regex of FunctionName to include.
 default: .
 type: regex

sources:
 - query: |
 LET Profile = '
 [
 ["Header", 0, [
 ["Signature", 0, "String", {"length": 13}],
 ["CountOfEntries", 14, "uint32"],
 ["Entries", 18, "Array",
 {"type": "Entry", "count": "x =&amp;gt; x.CountOfEntries"}]
 ]],

 ["Entry", "x=&amp;gt;x.Func.SizeOf + x.ModuleLength + 20", [
 ["Offset", 0, "Value", {"value": "x =&amp;gt; x.StartOf"}],
 ["TimestampTicks", 0, "uint64"],
 ["ModuleLength", 8, "uint32"],
 ["ModuleName", 12, "String", {"length": "x =&amp;gt; x.ModuleLength"}],
 ["CommandCount", "x =&amp;gt; x.ModuleLength + 12", "uint32"],
 ["Func", "x =&amp;gt; x.ModuleLength + 16", "Array",
 {"type": "FunctionInfo", "count": "x =&amp;gt; x.CommandCount"}],
 ["CountOfTypes", "x =&amp;gt; x.Func.EndOf", "uint32"]
 ]],

 ["FunctionInfo", "x =&amp;gt; x.NameLen + 8", [
 ["NameLen", 0, "uint32"],
 ["Name", 4, "String", {"length": "x =&amp;gt; x.NameLen"}],
 ["Count", "x =&amp;gt; x.NameLen + 4", "uint32"]
 ]]
 ]
 '
 LET parsed = SELECT OSPath,
 parse_binary(filename=OSPath, profile=Profile, struct="Header") AS Header
 FROM glob(globs=GlobLookup)

 SELECT * FROM foreach(row=parsed,
 query={
 SELECT * FROM foreach(row=Header.Entries,
 query={
 SELECT OSPath, ModuleName,
 timestamp(epoch=TimestampTicks/10000000 - 62136892800) AS Timestamp,
 Func.Name AS Functions
 FROM scope()
 WHERE ModuleName =~ ModulePathRegex
 AND NOT if(condition= ModulePathIgnoreRegex,
 then= ModuleName =~ ModulePathIgnoreRegex,
 else= False )
 AND filter(list=Functions,regex=FunctionNameRegex)
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Powershell.PSReadline</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.powershell.psreadline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.powershell.psreadline/</guid><description>&lt;p>This Artifact will search and extract lines from PSReadline history file.&lt;/p>
&lt;p>PowerShell is commonly used by attackers across all stages of the attack
lifecycle. The PSReadline module is responsible for command history and from
PowerShell 5 on Windows 10, the default configuration saves a copy of the console
history to disk.&lt;/p>
&lt;p>There are several parameters available for search leveraging regex.&lt;/p>
&lt;ul>
&lt;li>SearchStrings enables regex search over a PSReadline line.&lt;/li>
&lt;li>StringWhiteList enables a regex whitelist for results.&lt;/li>
&lt;li>UserRegex enables a regex search on Username&lt;/li>
&lt;li>UploadFiles enables upload ConsoleHost_history.txt in scope&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Powershell.PSReadline
description: |
 This Artifact will search and extract lines from PSReadline history file.

 PowerShell is commonly used by attackers across all stages of the attack
 lifecycle. The PSReadline module is responsible for command history and from
 PowerShell 5 on Windows 10, the default configuration saves a copy of the console
 history to disk.

 There are several parameters available for search leveraging regex.
 - SearchStrings enables regex search over a PSReadline line.
 - StringWhiteList enables a regex whitelist for results.
 - UserRegex enables a regex search on Username
 - UploadFiles enables upload ConsoleHost_history.txt in scope


author: Matt Green - @mgreen27

reference:
 - https://attack.mitre.org/techniques/T1059/001/
 - https://0xdf.gitlab.io/2018/11/08/powershell-history-file.html

type: CLIENT

parameters:
 - name: ConsoleHostHistory
 default: \AppData\Roaming\Microsoft\Windows\PowerShell\PSReadLine\ConsoleHost_history.txt
 - name: SearchStrings
 default: .
 type: regex
 - name: StringWhiteList
 default:
 type: regex
 - name: UserRegex
 default: .
 type: regex
 - name: UploadFiles
 description: "Upload ConsoleHost_history.txt files in scope"
 type: bool

precondition:
 SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 -- First extract target ConsoleHost_history path for each user
 LET targets = SELECT Name as Username,
 { SELECT Mtime, Atime, Ctime, Btime, Size, OSPath
 FROM stat(filename=expand(path=Directory) + ConsoleHostHistory)
 } AS Stat
 FROM Artifact.Windows.Sys.Users()
 WHERE Directory and Username =~ UserRegex AND Stat.OSPath

 -- Extract targets PSReadline entries
 SELECT * FROM foreach(
 row=targets,
 query={
 SELECT Stat, count() AS LineNum,
 Line,
 Username,
 Stat.OSPath AS OSPath
 FROM parse_lines(filename=Stat.OSPath)
 WHERE LineNum
 AND Line =~ SearchStrings
 AND NOT if(condition=StringWhiteList,
 then=Line =~ StringWhiteList,
 else=FALSE)
 })

 - name: Upload
 query: |
 -- if configured upload ConsoleHost_history.txt in results
 SELECT * FROM if(condition=UploadFiles,
 then={
 SELECT
 Username,
 upload(file=Stat.OSPath) as ConsoleHost_history
 FROM targets
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Pslist</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.pslist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.pslist/</guid><description>&lt;p>List processes and their running binaries.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Pslist
description: |
 List processes and their running binaries.

parameters:
 - name: ProcessRegex
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: ExePathRegex
 default: .
 type: regex
 - name: CommandLineRegex
 default: .
 type: regex
 - name: UsernameRegex
 default: .
 type: regex
 - name: UntrustedAuthenticode
 description: Show only Executables that are not trusted by Authenticode.
 type: bool
 - name: UseTracker
 type: bool
 description: If set we use the process tracker.
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
 - precondition: SELECT OS From info() where OS = 'windows'

 query: |
 LET ProcList = SELECT * FROM if(condition=UseTracker,
 then={
 SELECT Pid, Ppid, NULL AS TokenIsElevated,
 Username, Name, CommandLine, Exe, NULL AS Memory
 FROM process_tracker_pslist()
 }, else={
 SELECT * FROM pslist()
 })

 SELECT Pid, Ppid, TokenIsElevated, Name, CommandLine, Exe,
 token(pid=int(int=Pid)) as TokenInfo,
 hash(path=Exe) as Hash,
 authenticode(filename=Exe) AS Authenticode,
 Username, Memory.WorkingSetSize AS WorkingSetSize
 FROM ProcList
 WHERE Name =~ ProcessRegex
 AND Pid =~ PidRegex
 AND Exe =~ ExePathRegex
 AND CommandLine =~ CommandLineRegex
 AND Username =~ UsernameRegex
 AND NOT if(condition= UntrustedAuthenticode,
 then= Authenticode.Trusted = 'trusted' OR NOT Exe,
 else= False )

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.RootCAStore</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.rootcastore/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.rootcastore/</guid><description>&lt;p>Enumerate the root certificates in the Windows Root store.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.RootCAStore
description: |
 Enumerate the root certificates in the Windows Root store.

reference:
 - "ATT&amp;amp;CK: T1553"
 - https://attack.mitre.org/techniques/T1553/004/

parameters:
 - name: CertificateRootStoreGlobs
 type: csv
 default: |
 Accessor,Glob
 reg,HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\SystemCertificates\ROOT\Certificates\**\Blob
 reg,HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Microsoft\SystemCertificates\ROOT\Certificates\**\Blob
 reg,HKEY_USERS\*\Software\Microsoft\SystemCertificates\Root\Certificates\**\Blob
 reg,HKEY_USERS\*\Software\Policies\Microsoft\SystemCertificates\Root\Certificates\**\Blob

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET profile = '''[
 ["Record", "x=&amp;gt;x.Length + 12", [
 ["Type", 0, "uint32"],
 ["Length", 8, "uint32"],
 ["Data", 12, "String", {
 length: "x=&amp;gt;x.Length",
 term: "",
 }],
 ["UnicodeString", 12, "String", {
 encoding: "utf16",
 }]
 ]],
 ["Records", 0, [
 ["Items", 0, "Array", {
 type: "Record",
 count: 20,
 }]
 ]]
 ]'''

 // Parse the types from the certificate record itself, as well as the X509 cert structure.
 LET GetCert(CertData) = SELECT parse_x509(data=Data)[0] AS Cert
 FROM foreach(row=parse_binary(filename=CertData,
 accessor="data", profile=profile, struct="Records").Items)
 WHERE Type = 32

 // Format the fingerprint as a hex string
 LET GetFinger(CertData) = SELECT format(format="%x", args=Data) AS FingerPrint
 FROM foreach(row=parse_binary(filename=CertData,
 accessor="data", profile=profile, struct="Records").Items)
 WHERE Type = 3

 LET GetName(CertData) = SELECT UnicodeString AS Name
 FROM foreach(row=parse_binary(filename=CertData,
 accessor="data", profile=profile, struct="Records").Items)
 WHERE Type = 11

 // Glob for certificates in all the locations we know about.
 SELECT * FROM foreach(row=CertificateRootStoreGlobs,
 query={
 SELECT OSPath AS _RegistryValue, ModTime,
 GetName(CertData=Data.value)[0].Name AS Name,
 GetFinger(CertData=Data.value)[0].FingerPrint AS FingerPrint,
 GetCert(CertData=Data.value)[0].Cert AS Certificate
 FROM glob(globs=Glob, accessor=Accessor)
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Services</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.services/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.services/</guid><description>&lt;p>List Service details.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Services
description: |
 List Service details.

parameters:
 - name: servicesKeyGlob
 default: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\
 - name: Calculate_hashes
 default: N
 type: bool
 - name: CertificateInfo
 default: N
 type: bool
 - name: NameRegex
 default: .
 type: regex
 - name: DisplayNameRegex
 default: .
 type: regex
 - name: PathNameRegex
 default: .
 type: regex
 - name: ServiceDllRegex
 default: .
 type: regex
 - name: FailureCommandRegex
 default: .
 type: regex
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

export: |
 LET Profile = '''
 [
 ["ServiceFailureActions", 0, [
 ["ResetPeriod", 0, "uint32"],
 ["__ActionsCount", 12, "uint32"],
 ["__lpsaActionsHeader", 16, "uint32"],
 ["FailureAction", "x=&amp;gt;x.__lpsaActionsHeader", "Array", {
 "type": "ServiceAction",
 "count": "x=&amp;gt;x.__ActionsCount"
 }]
 ]],
 ["ServiceAction", 8, [
 ["Type", 0, "Enumeration", {
 "type": "uint32",
 "map": {
 "SC_ACTION_NONE": 0,
 "SC_ACTION_RESTART": 1,
 "SC_ACTION_REBOOT": 2,
 "SC_ACTION_RUN_COMMAND": 3,
 }}],
 ["__DelayMsec", 4, "uint32"],
 ["Delay", 4,"Value",{ "value": "x=&amp;gt;x.__DelayMsec/1000" }],
 ]],
 ]
 '''

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET service &amp;lt;= SELECT State, Name, DisplayName, Status,
 ProcessId as Pid, ExitCode, StartMode,
 PathName, ServiceType, StartName as UserAccount,
 {
 SELECT Mtime as Created
 FROM stat(filename=servicesKeyGlob + Name, accessor='registry')
 } AS Created,
 {
 SELECT expand(path=ServiceDll) AS ServiceDll
 FROM read_reg_key(globs=servicesKeyGlob + Name + "\\Parameters")
 LIMIT 1
 } AS ServiceDll,
 {
 SELECT FailureCommand FROM read_reg_key(globs=servicesKeyGlob + Name)
 LIMIT 1
 } AS FailureCommand,
 {
 SELECT if(condition=FailureActions,
 then=parse_binary(accessor='data',
 filename= FailureActions || " ",
 profile=Profile,
 struct='ServiceFailureActions')) as FailureActions
 FROM read_reg_key(globs=servicesKeyGlob + Name)
 } AS FailureActions,
 expand(path=parse_string_with_regex(regex=
 ['^"(?P&amp;lt;AbsoluteExePath&amp;gt;[^"]+)','(?P&amp;lt;AbsoluteExePath&amp;gt;^[^ "]+)'],
 string=PathName).AbsoluteExePath) as AbsoluteExePath
 FROM wmi(query="SELECT * From Win32_service", namespace="root/CIMV2")
 WHERE Name =~ NameRegex
 AND DisplayName =~ DisplayNameRegex
 AND PathName =~ PathNameRegex
 AND if(condition=ServiceDll, then=ServiceDll =~ ServiceDllRegex, else=TRUE)
 AND if(condition=FailureCommand, then=FailureCommand =~ FailureCommandRegex, else=TRUE)

 SELECT *,
 if(condition=Calculate_hashes,
 then=hash(path=AbsoluteExePath, accessor="auto")) AS HashServiceExe,
 if(condition=CertificateInfo,
 then=authenticode(filename=AbsoluteExePath || " ")) AS CertinfoServiceExe,
 if(condition=Calculate_hashes,
 then=hash(path=ServiceDll || " ",accessor="auto")) AS HashServiceDll,
 if(condition=CertificateInfo,
 then=authenticode(filename=ServiceDll || " ")) AS CertinfoServiceDll
 FROM service

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Shares</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.shares/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.shares/</guid><description>&lt;p>This artifact will extract network shares per machine.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Shares
author: 'Matt Green - @mgreen27'
description: |
 This artifact will extract network shares per machine.

type: CLIENT

parameters:
 - name: NameRegex
 description: Regex filter for share name. e.g Admin\$ for Admin$
 default: .
 type: regex
 - name: PathRegex
 description: Regex filter for local path. e.g C:\\Windows$ for Admin$
 default: .
 type: regex

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 SELECT Name, Path, Caption, Status,MaximumAllowed,AllowMaximum,InstallDate
 FROM wmi(query='SELECT * FROM Win32_Share',namespace='root/cimv2')
 WHERE Name =~ NameRegex AND Path =~ PathRegex
&lt;/code>&lt;/pre></description></item><item><title>Windows.System.Signers</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.signers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.signers/</guid><description>&lt;p>This artifact searches for all signed files and stacks them by signer.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.Signers
description: |
 This artifact searches for all signed files and stacks them by signer.

parameters:
 - name: ExecutableGlobs
 default: C:/Windows/**/*.{dll,exe}
 - name: ShowAllSigners
 description: When checked we show all signed files instead of stacking them.
 type: bool
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET results = SELECT OSPath, count() AS Count,
 parse_pe(file=OSPath).Authenticode.Signer.Subject AS Signer
 FROM glob(globs=ExecutableGlobs)
 WHERE Signer

 SELECT * FROM if(condition=ShowAllSigners,
 then={
 SELECT OSPath, Signer FROM results
 }, else={
 SELECT Count, Signer FROM results
 GROUP BY Signer
 ORDER BY Count DESC
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.SVCHost</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.svchost/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.svchost/</guid><description>&lt;p>Typically a windows system will have many svchost.exe
processes. Sometimes attackers name their processes svchost.exe to
try to hide. Typically svchost.exe is spawned by services.exe.&lt;/p>
&lt;p>This artifact lists all the processes named svchost.exe and their
parents if the parent is not also named services.exe.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.SVCHost
description: |
 Typically a windows system will have many svchost.exe
 processes. Sometimes attackers name their processes svchost.exe to
 try to hide. Typically svchost.exe is spawned by services.exe.

 This artifact lists all the processes named svchost.exe and their
 parents if the parent is not also named services.exe.

sources:
 - precondition: |
 SELECT OS From info() where OS = 'windows'

 query: |
 // Cache the pslist output in memory.
 LET processes &amp;lt;= SELECT Pid, Ppid, Name, Exe FROM pslist()

 // Get the pids of all procecesses named services.exe
 LET services &amp;lt;= SELECT Pid FROM processes where Name =~ "services.exe"

 // The interesting processes are those which are not spawned by services.exe
 LET suspicious = SELECT Pid As SVCHostPid,
 Ppid As SVCHostPpid,
 Exe as SVCHostExe,
 CommandLine as SVCHostCommandLine
 FROM processes
 WHERE Name =~ "svchost" AND NOT Ppid in services.Pid

 // Now for each such process we display its actual parent.
 SELECT * from foreach(
 row=suspicious,
 query={
 SELECT SVCHostPid, SVCHostPpid, SVCHostExe,
 SVCHostCommandLine, Name as ParentName,
 Exe As ParentExe
 FROM processes
 WHERE Pid=SVCHostPpid
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.TaskScheduler</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.taskscheduler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.taskscheduler/</guid><description>&lt;p>The Windows task scheduler is a common mechanism that malware uses
for persistence. It can be used to run arbitrary programs at a later
time. Commonly malware installs a scheduled task to run itself
periodically to achieve persistence.&lt;/p>
&lt;p>This artifact enumerates all the task jobs (which are XML
files). The artifact uploads the original XML files and then
analyses them to provide an overview of the commands executed and
the user under which they will be run.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.TaskScheduler
description: |
 The Windows task scheduler is a common mechanism that malware uses
 for persistence. It can be used to run arbitrary programs at a later
 time. Commonly malware installs a scheduled task to run itself
 periodically to achieve persistence.

 This artifact enumerates all the task jobs (which are XML
 files). The artifact uploads the original XML files and then
 analyses them to provide an overview of the commands executed and
 the user under which they will be run.

parameters:
 - name: TasksPath
 default: C:/Windows/System32/Tasks/**
 - name: AlsoUpload
 type: bool
 description: |
 If set we also upload the task XML files.
 - name: UploadCommands
 type: bool
 description: |
 If set we attempt to upload the commands that are
 mentioned in the scheduled tasks
 - name: Username
 type: regex
 default: .*

sources:
 - name: Analysis
 query: |
 LET Uploads = SELECT Name, OSPath, if(
 condition=AlsoUpload='Y',
 then=upload(file=OSPath)) AS Upload, Mtime
 FROM glob(globs=TasksPath)
 WHERE NOT IsDir

 // Job files contain invalid XML which confuses the parser - we
 // use regex to remove the invalid tags.
 LET parse_task = select OSPath, Mtime, parse_xml(
 accessor='data',
 file=regex_replace(
 source=utf16(string=Data),
 re='&amp;lt;[?].+?&amp;gt;',
 replace='')) AS XML
 FROM read_file(filenames=OSPath)

 LET Results = SELECT XML.Task.RegistrationInfo.URI AS TaskName,
 Mtime,
 expand(path=XML.Task.Actions.Exec.Command) AS Command,
 XML.Task.Actions.Exec.Arguments AS Arguments,
 XML.Task.Principals.Principal.UserId AS UserId,
 XML.Task.Principals.Principal.RunLevel AS RunLevel,
 XML.Task.Principals.Principal.LogonType AS LogonType,
 XML.Task.Triggers.SessionStateChangeTrigger.StateChange AS StateChange,
 XML.Task.Actions.ComHandler.ClassId AS ComHandler,
 timestamp(epoch=XML.Task.RegistrationInfo.Date) AS RegistrationTime,
 timestamp(epoch=XML.Task.Triggers.CalendarTrigger.StartBoundary) AS StartBoundary,
 XML as _XML
 FROM foreach(row=Uploads, query=parse_task)

 SELECT *,
 authenticode(filename=Command) AS Authenticode,
 if(condition=UploadCommands and ExpandedCommand,
 then=upload(file=Command)) AS Upload
 FROM Results
 WHERE UserId =~ Username
 
column_types:
- name: Upload
 type: upload_preview
- name: Authenticode
 type: collapsed

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.UntrustedBinaries</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.untrustedbinaries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.untrustedbinaries/</guid><description>&lt;p>Windows runs several services and binaries as part of the
operating system. Sometimes malware pretends to run as those well
known names to hide itself in plain sight. For example, a
malware service might call itself svchost.exe so it shows up in the
process listing as a benign service.&lt;/p>
&lt;p>This artifact checks that the common systems binaries are
signed. If a malware replaces these files or names itself in this
way their signature might not be correct.&lt;/p>
&lt;p>Note that unfortunately Microsoft does not sign all their common
binaries so many will not be signed (e.g. conhost.exe).&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.UntrustedBinaries
description: |
 Windows runs several services and binaries as part of the
 operating system. Sometimes malware pretends to run as those well
 known names to hide itself in plain sight. For example, a
 malware service might call itself svchost.exe so it shows up in the
 process listing as a benign service.

 This artifact checks that the common systems binaries are
 signed. If a malware replaces these files or names itself in this
 way their signature might not be correct.

 Note that unfortunately Microsoft does not sign all their common
 binaries so many will not be signed (e.g. conhost.exe).

parameters:
 - name: processNamesRegex
 description: A regex to select running processes which we consider should be trusted.
 default: "lsass|svchost|conhost|taskmgr|winlogon|wmiprv|dwm|csrss|velociraptor"
 type: regex
 - name: DISABLE_DANGEROUS_API_CALLS
 type: bool
 description: |
 Enable this to disable potentially flakey APIs which may cause
 crashes.

sources:
 - precondition: |
 SELECT OS From info() where OS = 'windows'
 query: |
 LET binaries = SELECT lowcase(string=Exe) As Binary
 FROM pslist()
 WHERE Exe =~ processNamesRegex
 GROUP BY Binary

 LET auth = SELECT authenticode(filename=Binary) As Authenticode
 FROM binaries

 SELECT Authenticode.Filename As Filename,
 Authenticode.IssuerName as Issuer,
 Authenticode.SubjectName as Subject,
 Authenticode.Trusted as Trusted from auth

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.VAD</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.vad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.vad/</guid><description>&lt;p>This artifact enables enumeration of process memory sections via the Virtual
Address Descriptor (VAD). The VAD is used by the Windows memory manager to
describe allocated process memory ranges.&lt;/p>
&lt;p>Available filters include process, mapping path, memory permissions
or by content with yara.&lt;/p>
&lt;p>Use the UploadSection switch to upload any sections.&lt;/p>
&lt;p>A notebook suggestion is available for Strings analysis on uploaded sections.&lt;/p>
&lt;p>NOTE:&lt;/p>
&lt;ul>
&lt;li>ProtectionChoice is a choice to filter on section protection. Default is
all sections and ProtectionRegex can override selection.&lt;/li>
&lt;li>To filter on unmapped sections the MappingNameRegex: ^$ can be used.&lt;/li>
&lt;li>When uploading sections during analysis, its recommended to run once for
scoping, then a second time once confirmed for upload.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.VAD
author: "Matt Green - @mgreen27"
description: |
 This artifact enables enumeration of process memory sections via the Virtual
 Address Descriptor (VAD). The VAD is used by the Windows memory manager to
 describe allocated process memory ranges.

 Available filters include process, mapping path, memory permissions
 or by content with yara.

 Use the UploadSection switch to upload any sections.

 A notebook suggestion is available for Strings analysis on uploaded sections.

 NOTE:

 - ProtectionChoice is a choice to filter on section protection. Default is
 all sections and ProtectionRegex can override selection.
 - To filter on unmapped sections the MappingNameRegex: ^$ can be used.
 - When uploading sections during analysis, its recommended to run once for
 scoping, then a second time once confirmed for upload.

parameters:
 - name: ProcessRegex
 description: A regex applied to process names.
 default: .
 type: regex
 - name: PidRegex
 default: .
 type: regex
 - name: ProtectionChoice
 type: choices
 description: Select memory permission you would like to return. Default All.
 default: Any
 choices:
 - Any
 - Execute, read and write
 - Any executable
 - name: ProtectionRegex
 type: regex
 description: Allows a manual regex selection of section Protection permissions. If configured take preference over Protection choice.
 - name: MappingNameRegex
 type: regex
 - name: UploadSection
 description: Upload suspicious section.
 type: bool
 - name: SuspiciousContent
 description: A yara rule of suspicious section content
 type: yara
 - name: ContextBytes
 description: Include this amount of bytes around yara hit as context.
 default: 0
 type: int

export: |
 // These functions help to resolve the Kernel Device Filenames
 // into a regular filename with drive letter.
 LET DriveReplaceLookup &amp;lt;= SELECT
 split(sep_string="\\", string=Name)[-1] AS Drive,
 upcase(string=SymlinkTarget) AS Target,
 len(list=SymlinkTarget) AS Len
 FROM winobj()
 WHERE Name =~ "^\\\\GLOBAL\\?\\?\\\\.:"

 LET _DriveReplace(Path) = SELECT Drive + Path[Len:] AS ResolvedPath
 FROM DriveReplaceLookup
 WHERE upcase(string=Path[:Len]) = Target

 LET DriveReplace(Path) = _DriveReplace(Path=Path)[0].ResolvedPath || Path

sources:
 - query: |
 -- firstly find processes in scope
 LET processes = SELECT int(int=Pid) AS Pid,
 Name, Exe, CommandLine, StartTime
 FROM process_tracker_pslist()
 WHERE Name =~ ProcessRegex
 AND format(format="%d", args=Pid) =~ PidRegex
 AND log(message="Scanning pid %v : %v", args=[Pid, Name])

 -- next find sections in scope
 LET sections = SELECT * FROM foreach(
 row=processes,
 query={
 SELECT StartTime as ProcessCreateTime,Pid, Name,
 DriveReplace(Path=MappingName) AS MappingName,
 format(format='%x-%x', args=[Address, Address+Size]) AS AddressRange,
 Address as _Address,
 State,Type,ProtectionMsg,Protection,
 Size as SectionSize,
 pathspec(
 DelegateAccessor="process",
 DelegatePath=Pid,
 Path=Address) AS _PathSpec
 FROM vad(pid=Pid)
 WHERE if(condition=MappingNameRegex,
 then= MappingName=~MappingNameRegex,
 else= True)
 AND if(condition = ProtectionRegex,
 then= Protection=~ProtectionRegex,
 else= if(condition= ProtectionChoice='Any',
 then= TRUE,
 else= if(condition= ProtectionChoice='Execute, read and write',
 then= Protection= 'xrw',
 else= if(condition= ProtectionChoice='Any executable',
 then= Protection=~'x'))))
 })

 -- if suspicious yara added, search for it
 LET yara_sections = SELECT *
 FROM foreach(row={
 SELECT * FROM sections
 WHERE NOT State =~ "RESERVE"
 }, query={
 SELECT
 ProcessCreateTime, Pid, Name,MappingName,
 AddressRange,State,Type,ProtectionMsg,
 Protection,SectionSize,
 dict(Rule=Rule,
 Meta=Meta,
 Tags=Tags,
 Offset=String.Offset,
 Name=String.Name) as YaraHit,
 upload( accessor='scope',
 file='String.Data',
 name=format(format="%v-%v_%v.bin-%v-%v",
 args=[
 Name, Pid, AddressRange,
 if(condition= String.Offset - ContextBytes &amp;lt; 0,
 then= 0,
 else= String.Offset - ContextBytes),
 if(condition= String.Offset + ContextBytes &amp;gt; SectionSize,
 then= SectionSize,
 else= String.Offset + ContextBytes ) ])
 ) as HitContext,
 _PathSpec, _Address
 FROM yara( blocksize=if(condition= SectionSize &amp;lt; 10000000,
 then= SectionSize,
 else= 10000000 ),
 accessor='offset',
 files=_PathSpec,
 rules=SuspiciousContent,
 end=SectionSize, key='X',
 number=1,
 context=ContextBytes
 )
 })

 -- finalise results
 LET results = SELECT *,
 process_tracker_callchain(id=Pid).Data as ProcessChain
 FROM if(condition= SuspiciousContent,
 then= yara_sections,
 else= sections)

 -- upload sections if selected
 LET upload_results = SELECT *,
 upload(accessor='sparse',
 file=pathspec(
 DelegateAccessor="process",
 DelegatePath=Pid,
 Path=[dict(Offset=_Address, Length=SectionSize),]),
 name=pathspec(
 Path=format(
 format='%v-%v_%v.bin',
 args= [ Name, Pid, AddressRange ]))) as SectionDump
 FROM results

 -- output rows
 SELECT * FROM if(condition= UploadSection,
 then= upload_results,
 else= results)

 notebook:
 - type: vql_suggestion
 name: Strings analysis
 template: |

 /*
 # Strings analysis
 */

 LET MinStringSize = 8
 LET FindPrintable = '''
 rule find_strings {
 strings:
 $wide = /(^|[^ -~\s]\x00)([ -~\s]\x00){%#%,}(\x00|[^ -~\s]|$)/
 $ascii = /(^|[^ -~\s])([ -~\s]{%#%,})([^ -~\s]|$)/
 condition:
 any of them
 }'''
 LET YaraRule = regex_replace(source=FindPrintable,re='''\%\#\%''',replace=str(str=MinStringSize))


 LET sections = SELECT vfs_path, client_path,file_size, uploaded_size
 FROM uploads(client_id=ClientId, flow_id=FlowId)
 WHERE vfs_path =~ '\.bin$'

 LET find_result(name) = SELECT *
 FROM source(artifact="Windows.System.VAD")
 WHERE SectionDump.StoredName = name
 LIMIT 1


 LET row_results = SELECT *, find_result(name=client_path)[0] as Result
 FROM sections
 WHERE Result

 SELECT * FROM foreach(row=row_results,
 query={
 SELECT
 regex_replace(source=String.Data,re='[^ -~]',replace='') as String,
 strip(prefix='$',string=String.Name) as Type,
 String.Offset as Offset,
 Result.MappingName as MappingName,
 Result.AddressRange as AddressRange,
 Result.Name as ProcesName,
 Result.Pid as Pid,
 Result.Protection as Protection
 --,vfs_path
 FROM yara(
 accessor='fs',
 files=vfs_path,
 rules=YaraRule,
 key='X',
 number=9999999999999999 )
 })
 WHERE NOT String =~ '''^\s*$'''

column_types:
 - name: HitContext
 type: preview_upload

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.VBScript</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.vbscript/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.vbscript/</guid><description>&lt;p>This artifact allows running VBScript through cscript.exe.&lt;/p>
&lt;p>This is a very powerful artifact since it allows for arbitrary command execution
on the endpoints as SYSTEM. Therefore this artifact requires elevated permissions
(specifically the EXECVE permission). Typically it is only available with the
administrator role.&lt;/p>
&lt;p>Note: Output is formatted to 1 row per line of Stdout. Ensure appropriately
formatted scripts. Pasting scripts direct from word or webpages may lead to
formatting issues when unicode characters are substituted. Copy script into
a notepad, save as ASCII then try again.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.VBScript
author: Matt Green - @mgreen27
description: |
 This artifact allows running VBScript through cscript.exe.

 This is a very powerful artifact since it allows for arbitrary command execution
 on the endpoints as SYSTEM. Therefore this artifact requires elevated permissions
 (specifically the EXECVE permission). Typically it is only available with the
 administrator role.

 Note: Output is formatted to 1 row per line of Stdout. Ensure appropriately
 formatted scripts. Pasting scripts direct from word or webpages may lead to
 formatting issues when unicode characters are substituted. Copy script into
 a notepad, save as ASCII then try again.

required_permissions:
 - EXECVE

implied_permissions:
 - FILESYSTEM_WRITE

precondition:
 SELECT OS From info() where OS = 'windows'

parameters:
 - name: Script
 default: Wscript.Echo "Hello world!"

sources:
 - query: |
 LET temp_script &amp;lt;= tempfile(extension='.vbs', data=str(str=Script))

 SELECT Stdout
 FROM execve(argv=['cscript.exe','//NoLogo','/E:vbs',temp_script], sep='\n')

&lt;/code>&lt;/pre></description></item><item><title>Windows.System.WMIQuery</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.system.wmiquery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.system.wmiquery/</guid><description>&lt;p>This artifact enables querying Windows Management Instrumentation (WMI).&lt;/p>
&lt;p>Windows Management Instrumentation (WMI) is the Microsoft implementation of
Web-Based Enterprise Management (WBEM), which is an industry initiative to
develop a standard technology for accessing management information in an
enterprise environment. WMI uses the Common Information Model (CIM) industry
standard to represent systems, applications, networks, devices, and other
managed components. CIM is developed and maintained by the Distributed
Management Task Force (DMTF).&lt;/p>
&lt;p>Please see the second reference link for an example of built-in system classes.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.System.WMIQuery
author: Matt Green - @mgreen27
description: |
 This artifact enables querying Windows Management Instrumentation (WMI).

 Windows Management Instrumentation (WMI) is the Microsoft implementation of
 Web-Based Enterprise Management (WBEM), which is an industry initiative to
 develop a standard technology for accessing management information in an
 enterprise environment. WMI uses the Common Information Model (CIM) industry
 standard to represent systems, applications, networks, devices, and other
 managed components. CIM is developed and maintained by the Distributed
 Management Task Force (DMTF).

 Please see the second reference link for an example of built-in system classes.

reference:
 - https://docs.microsoft.com/en-us/windows/win32/wmisdk/wmi-start-page
 - https://docs.microsoft.com/en-us/windows/win32/cimwin32prov/operating-system-classes

required_permissions:
 - EXECVE

parameters:
 - name: WMIQuery
 description: "Add target WMI query: e.g SELECT * FROM &amp;lt;CLASSNAME&amp;gt;"
 default: "SELECT * FROM Win32_Process"

 - name: Namespace
 description: "Add target Namespace: e.g root/cimv2"
 default: root/cimv2

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 SELECT * FROM wmi(namespace=Namespace,query=WMIQuery)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Timeline.MFT</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.timeline.mft/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.timeline.mft/</guid><description>&lt;p>Enables querying the MFT with advanced filters such as time, path or other
NTFS attributes.&lt;/p>
&lt;p>Output is to Timeline field format to enable simple review across Timeline
queries. The TimeOutput parameter enables configuring which NTFS attribute
timestamps are in focus as event_time. for example:
STANDARD_INFORMATION (4), FILE_NAME (4) or ALL (8)&lt;/p>
&lt;p>This artifact also has the same anomaly logic as AnalyzeMFT added to
each row to aid analysis.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Timeline.MFT
description: |
 Enables querying the MFT with advanced filters such as time, path or other
 NTFS attributes.

 Output is to Timeline field format to enable simple review across Timeline
 queries. The TimeOutput parameter enables configuring which NTFS attribute
 timestamps are in focus as event_time. for example:
 STANDARD_INFORMATION (4), FILE_NAME (4) or ALL (8)

 This artifact also has the same anomaly logic as AnalyzeMFT added to
 each row to aid analysis.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: MFTFilename
 default: "C:/$MFT"
 - name: Accessor
 default: ntfs
 - name: PathRegex
 description: "regex search over OSPath."
 type: regex
 - name: NameRegex
 default: .
 type: regex
 description: "regex search over File Name"
 - name: Inode
 type: int64
 description: "search for inode"
 - name: DateAfter
 type: timestamp
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: DateBefore
 type: timestamp
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 - name: SizeMax
 type: int64
 description: "Entries in the MFT over this size in bytes."
 - name: SizeMin
 type: int64
 description: "Entries in the MFT under this size in bytes."
 - name: EntryType
 description: |
 Type of entry. File, Directory or Both.
 type: choices
 default: Both
 choices:
 - File
 - Directory
 - Both
 - name: AllocatedType
 description: |
 Type of entry. Allocated, Unallocated or Both.
 type: choices
 default: Both
 choices:
 - Allocated
 - Unallocated
 - Both
 - name: TimeOutput
 description: |
 Timestamps to output as event_time. SI, FN or both.
 NOTE: both will output 8 rows per MFT entry.
 type: choices
 default: STANDARD_INFORMATION
 choices:
 - STANDARD_INFORMATION
 - FILE_NAME
 - ALL

sources:
 - query: |
 LET hostname &amp;lt;= SELECT Fqdn FROM info()
 LET DateAfterTime &amp;lt;= if(condition=DateAfter,
 then=DateAfter, else=timestamp(epoch="1600-01-01"))
 LET DateBeforeTime &amp;lt;= if(condition=DateBefore,
 then=DateBefore, else=timestamp(epoch="2200-01-01"))
 LET records = SELECT *,
 Created0x10 &amp;lt; Created0x30 as FNCreatedShift,
 Created0x10.Unix * 1000000000 = Created0x10.UnixNano as USecZero,
 Created0x10 &amp;gt; LastModified0x10 as PossibleCopy,
 ( LastAccess0x10 &amp;gt; LastModified0x10 AND LastAccess0x10 &amp;gt; Created0x10 ) as VolumeCopy
 FROM parse_mft(filename=MFTFilename, accessor=Accessor)
 WHERE
 FileName =~ NameRegex AND
 OSPath =~ PathRegex AND
 if(condition=Inode, then= EntryNumber=atoi(string=Inode)
 OR ParentEntryNumber=atoi(string=Inode),
 else=TRUE) AND
 if(condition=SizeMax, then=FileSize &amp;lt; SizeMax,
 else=TRUE) AND
 if(condition=SizeMin, then=FileSize &amp;gt; SizeMin,
 else=TRUE) AND
 if(condition= EntryType="Both", then=TRUE,
 else= if(condition= EntryType="File",
 then= IsDir=False,
 else= if(condition= EntryType="Directory",
 then= IsDir=True))) AND
 if(condition= AllocatedType="Both", then=TRUE,
 else= if(condition= AllocatedType="Allocated",
 then= InUse=True,
 else= if(condition= AllocatedType="Unallocated",
 then= InUse=False))) AND
 (((Created0x10 &amp;gt; DateAfterTime) AND (Created0x10 &amp;lt; DateBeforeTime)) OR
 ((Created0x30 &amp;gt; DateAfterTime) AND (Created0x30 &amp;lt; DateBeforeTime)) OR
 ((LastModified0x10 &amp;gt; DateAfterTime) AND (LastModified0x10 &amp;lt; DateBeforeTime)) OR
 ((LastModified0x30 &amp;gt; DateAfterTime) AND (LastModified0x30 &amp;lt; DateBeforeTime)) OR
 ((LastRecordChange0x10 &amp;gt; DateAfterTime) AND (LastRecordChange0x10 &amp;lt; DateBeforeTime)) OR
 ((LastRecordChange0x30 &amp;gt; DateAfterTime) AND (LastRecordChange0x30 &amp;lt; DateBeforeTime)) OR
 ((LastAccess0x10 &amp;gt; DateAfterTime) AND (LastAccess0x10 &amp;lt; DateBeforeTime)) OR
 ((LastAccess0x30 &amp;gt; DateAfterTime) AND (LastAccess0x30 &amp;lt; DateBeforeTime)))

 LET common_fields = SELECT EntryNumber, ParentEntryNumber,
 OSPath, FileName, FileSize, IsDir,InUse,
 Created0x10, Created0x30,
 LastModified0x10, LastModified0x30,
 LastRecordChange0x10, LastRecordChange0x30,
 LastAccess0x10, LastAccess0x30,
 FNCreatedShift, USecZero, PossibleCopy, VolumeCopy
 FROM scope()

 LET standard_information_rows = SELECT * FROM chain(
 si_modified = {
 SELECT *,
 LastModified0x10 as event_time,
 format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) LastModified time",
 args=EntryNumber) as message
 FROM common_fields
 },
 si_access = {
 SELECT *,
 LastAccess0x10 as event_time,
 format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) LastAccess time",
 args=EntryNumber) as message
 FROM common_fields
 },
 si_created = {
 SELECT *,
 LastRecordChange0x10 as event_time,
 format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) LastRecordChange time",
 args=EntryNumber) as message
 FROM common_fields
 },
 si_born = {
 SELECT *,
 Created0x10 as event_time,
 format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) Created time",
 args=EntryNumber) as message
 FROM common_fields
 })
 LET file_name_rows = SELECT * FROM chain(
 fn_modified = {
 SELECT *,
 LastModified0x30 as event_time,
 format(format="MFTEntry:%v $FILE_NAME (0x30) LastModified time",
 args=EntryNumber) as message
 FROM common_fields
 },
 fn_access = {
 SELECT *,
 LastAccess0x30 as event_time,
 format(format="MFTEntry:%v $FILE_NAME (0x30) LastAccess time",
 args=EntryNumber) as message
 FROM common_fields
 },
 fn_created = {
 SELECT *,
 LastRecordChange0x30 as event_time,
 format(format="MFTEntry:%v $FILE_NAME (0x30) LastRecordChange time",
 args=EntryNumber) as message
 FROM common_fields
 },
 fn_born = {
 SELECT *,
 Created0x30 as event_time,
 format(format="MFTEntry:%v $FILE_NAME (0x30) Created time",
 args=EntryNumber) as message
 FROM common_fields
 })

 SELECT
 event_time,
 hostname.Fqdn[0] as hostname,
 "MFT" as parser,
 MFTFilename as source,
 message,
 OSPath as path,
 { SELECT EntryNumber,ParentEntryNumber,FileSize,
 IsDir, InUse
 FROM scope() } as optional_1,

 { SELECT FNCreatedShift, USecZero, PossibleCopy,
 VolumeCopy
 FROM scope() } as optional_2,

 { SELECT LastModified0x10,LastAccess0x10,
 LastRecordChange0x10,Created0x10
 FROM scope() } as optional_3,

 { SELECT LastModified0x30,LastAccess0x30,
 LastRecordChange0x30,Created0x30
 FROM scope() } as optional_4

 FROM foreach(
 row=records,
 query={
 SELECT * FROM chain(
 standard_information={
 SELECT * FROM if(
 condition=TimeOutput="STANDARD_INFORMATION" OR TimeOutput="ALL",
 then=standard_information_rows)
 },
 file_name={
 SELECT * FROM if(
 condition=TimeOutput="FILE_NAME" OR TimeOutput="ALL",
 then=file_name_rows)
 })
 })

&lt;/code>&lt;/pre></description></item><item><title>Windows.Timeline.Prefetch</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.timeline.prefetch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.timeline.prefetch/</guid><description>&lt;p>Windows keeps a cache of prefetch files. When an executable is run,
the system records properties about the executable to make it faster
to run next time. By parsing this information we are able to
determine when binaries are run in the past. On Windows10 we can see
the last 8 execution times and creation time (9 potential executions).&lt;/p>
&lt;p>This artifact is a timelined output version of the standard Prefetch
artifact. There are several parameters available.&lt;/p>
&lt;ul>
&lt;li>dateAfter enables search for prefetch evidence after this date.&lt;/li>
&lt;li>dateBefore enables search for prefetch evidence before this date.&lt;/li>
&lt;li>binaryRegex enables to filter on binary name, e.g evil.exe.&lt;/li>
&lt;li>hashRegex enables to filter on prefetch hash.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Timeline.Prefetch
author: Matt Green - @mgreen27
description: |
 Windows keeps a cache of prefetch files. When an executable is run,
 the system records properties about the executable to make it faster
 to run next time. By parsing this information we are able to
 determine when binaries are run in the past. On Windows10 we can see
 the last 8 execution times and creation time (9 potential executions).

 This artifact is a timelined output version of the standard Prefetch
 artifact. There are several parameters available.
 - dateAfter enables search for prefetch evidence after this date.
 - dateBefore enables search for prefetch evidence before this date.
 - binaryRegex enables to filter on binary name, e.g evil.exe.
 - hashRegex enables to filter on prefetch hash.

reference:
 - https://www.forensicswiki.org/wiki/Prefetch

parameters:
 - name: prefetchGlobs
 default: C:\Windows\Prefetch\*.pf
 - name: dateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
 type: timestamp
 - name: dateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
 type: timestamp
 - name: binaryRegex
 description: "Regex of executable name."
 type: regex
 - name: hashRegex
 description: "Regex of prefetch hash."
 type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
 - query: |
 LET hostname &amp;lt;= SELECT Fqdn FROM info()

 SELECT LastRunTimes as event_time,
 hostname.Fqdn[0] as hostname,
 "Prefetch" as parser,
 message,
 OSPath as source,
 Executable as file_name,
 CreationTime as prefetch_ctime,
 ModificationTime as prefetch_mtime,
 FileSize as prefetch_size,
 Hash as prefetch_hash,
 Version as prefetch_version,
 PrefetchFileName as prefetch_file,
 RunCount as prefetch_count
 FROM foreach(
 row={
 SELECT *
 FROM Artifact.Windows.Forensics.Prefetch(
 prefetchGlobs=prefetchGlobs,
 dateAfter=dateAfter,
 dateBefore=dateBefore,
 binaryRegex=binaryRegex,
 hashRegex=hashRegex)
 },
 query={
 SELECT *
 FROM chain(a1={
 SELECT *
 FROM flatten(query={
 SELECT Executable,
 FileSize,
 Hash,
 Version,
 LastRunTimes,
 "Evidence of Execution: " + Executable + format(
 format=" Prefetch run count %v", args=RunCount) as message,
 RunCount,
 OSPath,
 PrefetchFileName,
 CreationTime,
 ModificationTime,
 Binary
 FROM scope()
 })
 }, b1={
 -- One more row for creation time
 SELECT Executable,
 FileSize,
 Hash,
 Version,
 CreationTime AS LastRunTimes,
 "Evidence of Execution (Btime): " + Executable + format(
 format=" Prefetch run count %v", args=RunCount) as message,
 RunCount,
 OSPath,
 PrefetchFileName,
 CreationTime,
 ModificationTime,
 Binary
 FROM scope()
 })
 -- This group by applies on only a single prefetch file to
 -- remove duplication with CreationTime
 GROUP BY LastRunTimes
 })
 ORDER BY event_time

&lt;/code>&lt;/pre></description></item><item><title>Windows.Timeline.Registry.RunMRU</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.timeline.registry.runmru/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.timeline.registry.runmru/</guid><description>&lt;h1 id="output-all-available-runmru-registry-keys-in-timeline-format">Output all available RunMRU registry keys in timeline format.&lt;/h1>
&lt;p>RunMRU is when a user enters a command into the START &amp;gt; Run prompt.
Entries will be logged in the user hive under: Software\Microsoft\Windows\CurrentVersion\Explorer\RunMRU&lt;/p>
&lt;p>The artifact numbers all entries with the most recent at
reg_mtime starting at 0. Second recent 1, Third recent 2 etc.&lt;/p>
&lt;p>Default output enables a line per MRU entry. The boolean parameter
&lt;code>groupResults&lt;/code> enables Grouped results with ordering.&lt;/p>
&lt;p>Note: This artifact will collect RunMRU from &lt;code>ntuser.dat&lt;/code> files and
may exclude very recent entries in transaction (HKCU). Future
versions of this content might address this gap.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Timeline.Registry.RunMRU
description: |
 # Output all available RunMRU registry keys in timeline format.

 RunMRU is when a user enters a command into the START &amp;gt; Run prompt.
 Entries will be logged in the user hive under: Software\Microsoft\Windows\CurrentVersion\Explorer\RunMRU

 The artifact numbers all entries with the most recent at
 reg_mtime starting at 0. Second recent 1, Third recent 2 etc.

 Default output enables a line per MRU entry. The boolean parameter
 `groupResults` enables Grouped results with ordering.

 Note: This artifact will collect RunMRU from `ntuser.dat` files and
 may exclude very recent entries in transaction (HKCU). Future
 versions of this content might address this gap.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
 type: hidden
 default: Software\Microsoft\Windows\CurrentVersion\Explorer\RunMRU\MRUList
 - name: dateAfter
 description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: dateBefore
 description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
 type: timestamp
 - name: targetUser
 description: "target user regex"
 type: regex
 - name: regexValue
 description: "regex search over RunMRU values."
 type: regex
 - name: groupResults
 description: "groups MRU entries to one message line"
 type: bool

sources:
 - query: |
 LET hostname_lu &amp;lt;= SELECT Fqdn FROM info()
 LET HKEY_USERS &amp;lt;= pathspec(parse="HKEY_USERS", path_type="registry")

 // First we need to extract populated RunMRU
 LET MRUList &amp;lt;= SELECT OSPath,
 Data.value as RunMruOrder,
 len(list=Data.value) as RunMruLength,
 Username,
 UUID
 FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)

 // Now extract RunMRU entries and order
 LET results &amp;lt;= SELECT * FROM foreach(
 row=MRUList,
 query={
 SELECT
 OSPath.DelegatePath as source,
 Username,
 Mtime as reg_mtime,
 OSPath.Basename as reg_name,
 HKEY_USERS + UUID + OSPath.Dirname.Path as reg_key,

 -- Value data is similar to 'cmd.exe\1' so we just need the bit before the \
 regex_replace(source=Data.value, re="\\\\1$", replace="") as reg_value,
 Data.type as reg_type,
 RunMruLength - 1 - len(list=regex_replace(
 source=RunMruOrder,
 re="^.*" + OSPath.Basename,
 replace="")) as mru_order,
 RunMruOrder
 FROM glob(globs='*', root=OSPath.Dirname, accessor="raw_reg")
 WHERE not reg_name = "MRUList" AND
 if(condition=targetUser, then=Username =~ targetUser,
 else=TRUE) AND
 if(condition=dateAfter, then=reg_mtime &amp;gt; timestamp(string=dateAfter),
 else=TRUE) AND
 if(condition=dateBefore, then=reg_mtime &amp;lt; timestamp(string=dateBefore),
 else=TRUE)
 AND log(message=UUID)
 ORDER BY mru_order
 })

 // join mru values and order for presentation
 LET usercommands &amp;lt;= SELECT Username as user, mru_order,
 format(format="MRU%v: %v", args=[mru_order,reg_value]) as mru_grouped
 FROM results

 // Prepare join use case
 LET joinOut = SELECT
 reg_mtime as event_time,
 hostname_lu[0].Fqdn as hostname,
 "RunMRU" as parser,
 "RunMRU evidence user: " + Username + ", " +
 join(array=mru_grouped, sep=" | ") + "'" as message,
 source,
 Username as user
 FROM foreach(row=usercommands,
 query={
 SELECT *, Username,
 {
 SELECT mru_grouped
 FROM usercommands
 WHERE user = Username
 ORDER BY mru_grouped
 } as mru_grouped
 FROM results
 ORDER BY mru_grouped
 })
 GROUP BY source

 // Prepare split use case
 LET splitOut = SELECT
 reg_mtime as event_time,
 hostname_lu.Fqdn[0] as hostname,
 "RunMRU" as parser,
 "RunMRU evidence user: " + Username +
 format(format=", order: %v, command: %v", args=[mru_order,reg_value])
 + "'" as message,
 source,
 Username as user,
 reg_key,
 reg_mtime,
 reg_name,
 reg_value,
 reg_type
 FROM results

 // Print out chosen usecase
 SELECT *
 FROM if(condition=groupResults,
 then={ SELECT * FROM joinOut},
 else={ SELECT * FROM splitOut})
 WHERE if(condition=regexValue, then=message =~ regexValue, else=TRUE)

&lt;/code>&lt;/pre></description></item><item><title>Windows.Triage.SDS</title><link>https://docs.velociraptor.app/artifact_references/pages/windows.triage.sds/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.velociraptor.app/artifact_references/pages/windows.triage.sds/</guid><description>&lt;p>Collects the $Secure:$SDS stream from the NTFS volume. The $Secure
stream is both a directory (it has I30 stream) and a file (it has a
$DATA stream) and therefore confuses the Windows.KapeFiles.Target
artifact which relies on globbing. Use this artifact to collect the
$SDS stream.&lt;/p>
&lt;pre>&lt;code class="language-yaml">
name: Windows.Triage.SDS
description: |
 Collects the $Secure:$SDS stream from the NTFS volume. The $Secure
 stream is both a directory (it has I30 stream) and a file (it has a
 $DATA stream) and therefore confuses the Windows.KapeFiles.Target
 artifact which relies on globbing. Use this artifact to collect the
 $SDS stream.

parameters:
 - name: Drive
 description: The Drive letter to analyze
 default: "C:"

sources:
 - precondition:
 SELECT OS From info() where OS = 'windows'

 query: |
 LET Device &amp;lt;= pathspec(parse=Drive)

 SELECT *, upload(accessor="mft",
 file=Device + Inode,
 name=pathspec(Path=Name)) AS Upload
 FROM foreach(row=parse_ntfs(device=Device, mft=9).Attributes, column="_value")
 WHERE Name =~ "\\$S" AND TypeId IN (128, 160)

&lt;/code>&lt;/pre></description></item></channel></rss>